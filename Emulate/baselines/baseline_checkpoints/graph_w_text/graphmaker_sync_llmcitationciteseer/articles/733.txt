Autonomous vehicles require efficient motion planning to navigate complex environments. This paper presents a novel hierarchical reinforcement learning approach, 'HiRLMP', which decomposes the motion planning problem into a hierarchy of tasks and sub-tasks. HiRLMP utilizes a high-level planner to generate a coarse trajectory and a low-level planner to refine the trajectory using a reinforcement learning policy. Our experiments demonstrate that HiRLMP outperforms state-of-the-art methods in terms of safety, efficiency, and adaptability to dynamic environments.