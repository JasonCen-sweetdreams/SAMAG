Virtual reality (VR) has revolutionized human-computer interaction, but understanding user intent remains a significant challenge. This paper presents EyeGazeAnalytics, a novel machine learning framework that leverages eye movement data to infer user goals in VR environments. Our approach combines convolutional neural networks (CNNs) with graph-based models to analyze eye gaze patterns and identify relevant objects of interest. We evaluate EyeGazeAnalytics on a large-scale dataset of VR user interactions and demonstrate significant improvements in intent recognition accuracy compared to state-of-the-art methods.