Autonomous vehicles require real-time decision-making to navigate complex scenarios. This paper presents a novel hierarchical reinforcement learning (HRL) framework for efficient control of autonomous vehicles. Our approach leverages a high-level planning module to generate abstract actions, which are then translated into low-level control outputs using a deep deterministic policy gradient algorithm. We introduce a hierarchical exploration strategy that adaptively allocates exploration resources between the planning and control modules, resulting in improved learning efficiency and robustness. Experimental results on a simulated autonomous driving platform demonstrate the effectiveness of our approach in achieving real-time control while outperforming flat RL baselines.