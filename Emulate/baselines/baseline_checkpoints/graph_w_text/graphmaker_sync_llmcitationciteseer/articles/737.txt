Autonomous vehicles require efficient decision-making strategies to navigate complex scenarios. This paper proposes a hierarchical reinforcement learning (HRL) framework, 'Automa', which integrates task decomposition and option learning to improve decision-making in autonomous vehicles. Automa decomposes the driving task into a hierarchy of sub-tasks, each with its own option policy. We demonstrate that Automa achieves superior performance and adaptability compared to flat reinforcement learning methods in various simulated driving scenarios, including lane merging and pedestrian interaction.