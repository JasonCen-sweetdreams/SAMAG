This paper addresses the challenging problem of coordinating multi-agent systems in urban traffic control. We propose a hierarchical reinforcement learning framework that integrates both macro- and micro-level control strategies. The upper level optimizes traffic signal control policies using a graph attention network, while the lower level adapts agent behavior to local traffic conditions using deep Q-networks. Our approach is validated through simulations on a real-world traffic network, demonstrating significant reductions in travel time and congestion compared to traditional traffic signal control methods.