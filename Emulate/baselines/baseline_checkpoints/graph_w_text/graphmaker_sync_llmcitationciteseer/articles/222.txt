Autonomous vehicles rely on reinforcement learning (RL) to adapt to complex driving scenarios. However, RL agents can be vulnerable to adversarial attacks, which can compromise safety and reliability. This paper introduces a novel framework, 'AdvRL', which integrates adversarial training into the RL process for autonomous vehicle control. We formulate the attack as a minimax game between the RL agent and an adversary, and demonstrate that AdvRL improves the robustness of the agent to targeted attacks. Experimental results on a simulated driving environment show that AdvRL outperforms traditional RL methods in adversarial scenarios, while maintaining comparable performance in nominal conditions.