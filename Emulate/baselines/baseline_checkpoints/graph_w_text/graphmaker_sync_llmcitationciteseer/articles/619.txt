Anomaly detection in time series data is a crucial task in various domains, including finance, healthcare, and IoT. While deep learning models have achieved state-of-the-art performance, they often lack interpretability, hindering their adoption in high-stakes applications. This paper proposes a novel hierarchical attention network (HAN) architecture that not only detects anomalies accurately but also provides explanations for its predictions. Our approach leverages attention mechanisms to identify relevant time series segments and features, enabling model interpretability. Experimental results on three real-world datasets demonstrate the effectiveness of HAN in detecting anomalies and providing actionable insights.