Voice assistants have become ubiquitous in smart homes, but their accessibility for people with disabilities remains limited. This paper presents a co-design approach to develop inclusive voice assistants, focusing on multimodal input strategies. We conducted a series of workshops with individuals with disabilities, identifying pain points and opportunities for improvement. Our findings inform the design of an adaptable voice assistant that incorporates gestures, eye-tracking, and lip-reading input modalities. A usability study with 20 participants demonstrates significant improvements in task completion rates and user satisfaction. Our work contributes to the development of more accessible and inclusive voice assistants, enhancing the quality of life for people with disabilities.