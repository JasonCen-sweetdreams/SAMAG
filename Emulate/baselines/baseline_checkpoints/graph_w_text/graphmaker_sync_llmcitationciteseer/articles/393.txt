Conversational search systems rely on efficient passage retrieval to provide accurate answers to user queries. This paper presents a novel neural ranking model, 'ConvRank', which leverages pre-trained language models and incorporates conversational context to improve passage ranking. We propose a multi-task learning framework that jointly optimizes passage relevance, semantic similarity, and conversation coherence. Experimental results on the TREC Conversational Assistance Track dataset demonstrate that ConvRank outperforms state-of-the-art models in terms of mean average precision and response quality.