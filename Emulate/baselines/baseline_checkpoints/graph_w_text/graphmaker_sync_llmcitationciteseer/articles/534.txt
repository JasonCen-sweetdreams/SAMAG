In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper proposes a novel framework for coordinated task allocation using deep reinforcement learning (DRL). Our approach, called 'CATS', learns to allocate tasks to agents based on their capabilities, preferences, and task dependencies. We employ a decentralized DRL architecture, where each agent learns to make decisions based on local observations and communication with neighboring agents. Experimental results on a variety of task allocation scenarios demonstrate that CATS outperforms traditional optimization-based methods in terms of solution quality, scalability, and adaptability to dynamic environments.