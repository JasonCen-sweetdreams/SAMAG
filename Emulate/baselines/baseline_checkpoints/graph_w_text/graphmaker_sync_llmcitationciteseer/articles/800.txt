Contrastive learning has emerged as a powerful approach for self-supervised representation learning. However, existing methods often struggle with noisy or ambiguous data, leading to suboptimal feature learning. This paper proposes a novel adaptive margin-based contrastive loss function, 'AdaMargin', which dynamically adjusts the margin based on the similarity distribution of positive and negative samples. We demonstrate that AdaMargin improves the robustness of feature learning to noisy data and outperforms state-of-the-art methods on benchmark image classification datasets, including CIFAR-10 and ImageNet.