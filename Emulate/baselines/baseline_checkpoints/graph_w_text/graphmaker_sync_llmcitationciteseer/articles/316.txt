In multi-agent systems, task allocation is a critical problem that requires efficient and adaptive decision-making. This paper presents a decentralized task allocation framework that leverages hierarchical reinforcement learning (HRL) to optimize task assignments in dynamic environments. Our approach, called HRL-TA, uses a two-level hierarchy of agents, where higher-level agents coordinate task assignments and lower-level agents execute tasks. We evaluate HRL-TA in a simulated package delivery scenario and demonstrate significant improvements in task completion rates and agent utility compared to traditional decentralized allocation methods.