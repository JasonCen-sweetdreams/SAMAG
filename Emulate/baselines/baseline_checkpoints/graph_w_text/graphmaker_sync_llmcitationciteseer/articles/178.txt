In multi-agent systems, cooperative behavior is crucial for achieving complex goals. However, current approaches often rely on hand-crafted rules or simplistic communication models. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework, which enables agents to learn cooperative strategies from raw sensor data. HGAT leverages graph attention mechanisms to model relationships between agents and their environment, while a hierarchical architecture facilitates the learning of abstract, high-level policies. Experimental results in a simulated search-and-rescue scenario demonstrate that HGAT agents outperform state-of-the-art baselines in terms of cooperation efficiency and adaptability to changing environments.