Multi-agent planning has become increasingly important in real-world applications, but the lack of interpretability in current models hinders their adoption. This paper proposes a novel hierarchical attention network (HAN) framework that integrates planning and explanation in a unified architecture. Our approach leverages attention mechanisms to model complex interactions between agents and objects, while generating interpretable explanations for the plans generated. We evaluate our approach on a series of benchmark scenarios, demonstrating improved planning performance and enhanced explainability compared to state-of-the-art methods.