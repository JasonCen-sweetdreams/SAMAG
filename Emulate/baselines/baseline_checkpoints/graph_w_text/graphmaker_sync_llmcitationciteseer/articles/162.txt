Explainable recommendation systems are crucial for building trust and transparency in AI-driven decision-making. This paper proposes a novel Hierarchical Attention-based Graph Neural Network (HAGNN) model that learns to generate interpretable recommendations by capturing complex relationships between users, items, and their attributes. Our approach leverages graph attention mechanisms to selectively focus on relevant features and relationships, generating explanations that are both accurate and informative. We evaluate HAGNN on multiple benchmark datasets, demonstrating significant improvements in recommendation accuracy and explanation quality compared to state-of-the-art methods.