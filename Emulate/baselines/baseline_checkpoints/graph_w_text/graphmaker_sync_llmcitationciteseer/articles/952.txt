Entity disambiguation is a crucial step in knowledge graph construction, but it becomes increasingly challenging as the graph size grows. This paper proposes a novel approach that leverages graph neural networks (GNNs) to learn representations of entities and their context, enabling accurate disambiguation at scale. We introduce a hierarchical attention mechanism that captures both local and global dependencies in the graph, and demonstrate its effectiveness on several real-world knowledge graphs. Our experiments show that our approach outperforms state-of-the-art methods in terms of both accuracy and computational efficiency, making it a viable solution for large-scale knowledge graph construction.