Autonomous traffic signal control can significantly reduce traffic congestion and emissions. This paper proposes a novel multi-agent reinforcement learning (MARL) framework, 'TrafficSync', which coordinates traffic signals to optimize traffic flow. We introduce a decentralized, graph-based learning approach that enables agents to learn from local observations and communicate with neighboring agents to achieve global coordination. Experimental results on a large-scale traffic simulator demonstrate that TrafficSync outperforms traditional decentralized control methods, reducing average travel time by 23.5% and emissions by 17.2%.