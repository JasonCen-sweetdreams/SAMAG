In multi-agent systems, efficient resource allocation is crucial for achieving global objectives. This paper presents a novel framework that leverages deep reinforcement learning to coordinate agents in complex, dynamic environments. We introduce a hierarchical, graph-structured architecture that learns to allocate resources and schedule tasks among agents, while minimizing conflicts and maximizing overall system performance. Experimental results on a simulated smart grid scenario demonstrate the effectiveness of our approach in reducing energy costs and improving grid stability compared to traditional optimization methods.