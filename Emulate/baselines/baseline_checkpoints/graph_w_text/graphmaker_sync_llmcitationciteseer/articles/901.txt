This paper presents a decentralized task allocation framework for autonomous vehicles using multi-agent reinforcement learning. We propose a novel algorithm, 'MARL-TA', that enables vehicles to learn and adapt to dynamic environments and tasks in real-time. MARL-TA uses a decentralized partially observable Markov decision process (DEC-POMDP) to model the task allocation problem, and employs a deep Q-network to learn the optimal policy. Experimental results on a simulated urban traffic scenario demonstrate that MARL-TA achieves significant improvements in task completion rates and reduces overall travel time compared to traditional centralized allocation methods.