In multi-agent systems, distributed decision-making is a crucial task that requires efficient communication and coordination among agents. This paper proposes a novel approach using hierarchical graph neural networks (HGNNs) to learn distributed decision-making policies. Our method utilizes a hierarchical graph structure to model agent interactions and incorporates attention mechanisms to focus on relevant agents and their relationships. Experimental results on a series of benchmark problems demonstrate that our approach outperforms existing methods in terms of decision-making accuracy and adaptability to changing environments.