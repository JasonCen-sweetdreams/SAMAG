Cooperative multi-agent systems have numerous applications in robotics, smart cities, and autonomous vehicles. Effective task allocation is crucial for achieving efficient collaboration. This paper proposes a decentralized task allocation framework using deep reinforcement learning, enabling agents to adapt to changing environments and learn from experience. We introduce a novel attention-based neural network architecture that incorporates communication constraints and partial observability, outperforming traditional heuristic-based approaches in simulated experiments.