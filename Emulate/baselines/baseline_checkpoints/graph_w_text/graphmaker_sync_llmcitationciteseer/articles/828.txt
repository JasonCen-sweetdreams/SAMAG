Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can compromise their reliability in safety-critical applications. This paper proposes a novel Bayesian neural architecture search (BNAS) approach to improve the adversarial robustness of DNNs. Our method leverages a probabilistic surrogate model to efficiently explore the architecture space and identify robust designs. We evaluate our approach on several benchmark datasets and demonstrate significant improvements in adversarial robustness compared to state-of-the-art methods. Furthermore, our analysis reveals that the discovered architectures exhibit unique structural properties that contribute to their robustness.