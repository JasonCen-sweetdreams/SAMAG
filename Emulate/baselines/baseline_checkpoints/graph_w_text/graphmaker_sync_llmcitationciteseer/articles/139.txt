Multimodal time series forecasting is a crucial task in various applications, including healthcare, finance, and climate modeling. However, existing deep learning methods suffer from scalability issues and struggle to handle the complexity of multimodal data. This paper presents a novel architecture, 'Multimodal Transformer Ensemble' (MTE), which leverages the strengths of transformer models and ensemble learning to achieve state-of-the-art performance on large-scale multimodal datasets. We propose a hierarchical attention mechanism that adaptively weights the importance of different modalities and a parallel ensemble strategy that reduces computational overhead. Experiments on a large-scale healthcare dataset demonstrate the scalability and effectiveness of MTE in multimodal time series forecasting.