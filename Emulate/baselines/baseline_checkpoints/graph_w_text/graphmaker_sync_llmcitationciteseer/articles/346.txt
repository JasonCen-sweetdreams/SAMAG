This paper presents a novel framework for designing intelligent virtual assistants (IVAs) that cater to the diverse needs of individuals with disabilities in smart home environments. Our approach integrates machine learning-based intent recognition with situated cognition theory to create personalized and adaptive interfaces. We evaluate our IVA prototype through a user study with 30 participants, demonstrating significant improvements in task completion rates and user satisfaction for individuals with visual and motor impairments. Our findings have implications for the development of inclusive and accessible smart home systems.