This paper presents a novel hierarchical attention-based multi-agent reinforcement learning framework for autonomous vehicle control. We propose a decentralized approach where each vehicle learns to communicate with its neighbors and negotiate control decisions based on its local observations. Our method utilizes attention mechanisms to selectively focus on relevant neighbors and filter out noisy information. Experimental results on a simulated autonomous driving environment demonstrate improved navigation efficiency, safety, and scalability compared to existing centralized and decentralized control methods.