Virtual reality (VR) systems require accurate and efficient interaction mechanisms to provide an immersive user experience. This paper proposes a novel gaze-based interaction framework that leverages deep learning-based eye tracking to detect user intentions. Our approach uses a convolutional neural network (CNN) to classify gaze patterns and infer user interactions, achieving an average accuracy of 95.2% on a benchmark dataset. We also present a comprehensive evaluation of our system in a VR gaming scenario, demonstrating significant improvements in interaction latency and user satisfaction compared to traditional controller-based interfaces.