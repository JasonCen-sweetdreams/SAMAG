Multi-agent systems exhibit complex behavior, making policy learning challenging. This paper presents a novel graph-based approach, 'GraphMA', which enables coordinated exploration among agents. By modeling agent interactions as a graph, we develop a policy learning framework that incorporates graph convolutional networks and attention mechanisms. GraphMA adaptively adjusts exploration strategies based on the graph structure, leading to improved coordination and overall system performance. Experimental results on a suite of multi-agent benchmark tasks demonstrate the effectiveness of GraphMA in achieving better coordination and scalability compared to state-of-the-art methods.