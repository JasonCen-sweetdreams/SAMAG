Explainable AI (XAI) has become a crucial aspect of sentiment analysis, as it enables transparency into AI-driven decision-making processes. This paper proposes a novel Hierarchical Attention Network (HAN) architecture, which incorporates both word-level and sentence-level attention mechanisms to capture nuanced sentiment expressions. Our approach leverages a hierarchical fusion of local and global contextual information to provide interpretable sentiment scores. Experimental results on benchmark datasets demonstrate that our HAN model outperforms state-of-the-art XAI methods in terms of sentiment accuracy and explanation quality.