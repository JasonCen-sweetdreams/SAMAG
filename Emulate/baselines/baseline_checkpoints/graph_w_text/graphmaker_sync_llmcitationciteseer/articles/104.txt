Multimodal neural networks have achieved state-of-the-art performance in various applications, but their vulnerability to adversarial attacks remains a significant concern. This paper proposes a novel approach to detect adversarial attacks in multimodal neural networks using graph-based contrastive learning. We construct a graph representation of the input data and learn a contrastive loss function that captures the relationships between different modalities. Our approach can detect adversarial attacks with high accuracy and outperforms existing methods on several benchmark datasets. We also provide theoretical insights into the robustness of our approach against various types of attacks.