Coordinating heterogeneous multi-agent systems (MAS) is a challenging problem, especially when agents have different capabilities, goals, and communication constraints. This paper proposes a novel framework that leverages reinforcement learning (RL) and graph attention to coordinate MAS. Our approach, called Graph-RL-MAS, represents the agent interactions as a graph and uses attention mechanisms to focus on the most critical agents and their relationships. We evaluate Graph-RL-MAS on a variety of MAS scenarios, including robotic search and rescue, and demonstrate improved coordination and task completion rates compared to state-of-the-art methods.