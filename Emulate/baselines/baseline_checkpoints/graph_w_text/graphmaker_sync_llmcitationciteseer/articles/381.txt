Robot navigation in dynamic environments remains a challenging problem due to the complexity of sensorimotor interactions and the need for real-time decision-making. This paper proposes a hierarchical reinforcement learning framework, 'HRL-Nav', which decomposes the navigation task into a series of sub-goals and learns to adapt to changing environmental conditions. We introduce a novel attention-based mechanism that selectively focuses on relevant sensory inputs, reducing the dimensionality of the state space and improving navigation efficiency. Experimental results on a simulated robotic platform demonstrate that HRL-Nav outperforms existing flat RL methods in terms of task completion time and success rate.