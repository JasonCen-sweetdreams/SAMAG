Query expansion is a crucial component in ad-hoc retrieval systems, aiming to bridge the vocabulary gap between users' queries and relevant documents. This paper proposes a novel context-aware embedding-based approach, dubbed CAQE, which leverages semantic relationships between query terms and their co-occurring context words. Our method adapts a transformer-based architecture to learn dense vector representations that capture nuanced query-term dependencies. Experimental results on the TREC Robust04 dataset demonstrate that CAQE significantly outperforms state-of-the-art query expansion techniques, achieving a 15% improvement in mean average precision.