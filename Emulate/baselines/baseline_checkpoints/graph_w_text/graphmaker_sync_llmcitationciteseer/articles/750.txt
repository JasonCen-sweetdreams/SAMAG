Question answering over knowledge graphs (KGs) has become increasingly important in natural language processing. However, existing embedding methods struggle to capture the complex structural relationships in large KGs. This paper proposes a novel hyperbolic geometry-based embedding approach, HyperQA, which leverages the ability of hyperbolic spaces to model hierarchical structures. We demonstrate that HyperQA outperforms state-of-the-art methods in both link prediction and question answering tasks on several benchmark datasets. Furthermore, our approach is more computationally efficient and scalable to large KGs.