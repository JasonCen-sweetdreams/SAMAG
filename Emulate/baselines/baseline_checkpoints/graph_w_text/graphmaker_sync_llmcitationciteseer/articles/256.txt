Deep reinforcement learning (DRL) models have shown promising results in various applications, but they are vulnerable to adversarial attacks. Existing detection methods focus on supervised learning-based approaches, which require labeled data and are computationally expensive. This paper proposes an unsupervised graph-based approach, 'GADRL', to detect adversarial attacks in DRL models. We leverage graph convolutional networks (GCNs) to learn a representation of the state-action graph and identify anomalies indicative of adversarial attacks. Experimental results on a range of DRL environments demonstrate the effectiveness of GADRL in detecting various types of attacks with high accuracy and low false positives.