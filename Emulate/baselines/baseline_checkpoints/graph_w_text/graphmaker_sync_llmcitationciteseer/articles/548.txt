Public displays are becoming increasingly prevalent in urban spaces, but interacting with them remains a challenge. This paper presents a novel gaze-based interface for public displays using deep neural networks. We propose a convolutional neural network (CNN) that detects and tracks users' gazes in real-time, enabling intuitive and hands-free interaction. Our approach leverages a combination of computer vision and machine learning techniques to overcome the limitations of traditional gaze-tracking systems. Experimental results demonstrate the feasibility and effectiveness of our method, achieving an average accuracy of 92.5% in gaze-based selection tasks.