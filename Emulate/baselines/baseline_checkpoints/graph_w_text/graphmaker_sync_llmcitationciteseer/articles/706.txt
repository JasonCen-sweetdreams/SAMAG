Explainable recommendation systems (ERS) have gained significant attention in recent years. However, most existing ERS methods focus on modeling user-item interactions and neglect the rich structural information present in the data. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) model that integrates graph attention and hierarchical representation learning to capture complex relationships between users, items, and their attributes. Our approach provides personalized explanations for recommendations, improving transparency and trust in AI-driven systems. Experimental results on several real-world datasets demonstrate the efficacy of HGAT in terms of recommendation accuracy and explanation quality.