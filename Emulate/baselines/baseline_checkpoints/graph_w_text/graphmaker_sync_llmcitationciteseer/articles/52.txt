The increasing adoption of autonomous vehicles (AVs) on public roads necessitates the development of efficient coordination strategies to ensure safe and efficient traffic flow. This paper proposes a novel multi-agent reinforcement learning framework that leverages graph attention mechanisms to model complex interactions between AVs and their environment. Our approach enables AVs to learn coordinated behaviors, such as lane changing and merging, in a decentralized manner. Experimental results using a realistic traffic simulator demonstrate that our method outperforms traditional rule-based approaches and achieves significant improvements in traffic throughput and safety.