In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a decentralized task allocation framework, 'AgentTA', that leverages deep reinforcement learning to adapt to dynamic environments. Each agent learns to optimize its task selection based on local observations and limited communication with neighboring agents. Our approach incorporates a graph neural network to model agent interactions and a novel reward function that balances task completion with resource utilization. Experimental results on a simulated search-and-rescue scenario demonstrate that AgentTA outperforms traditional centralized allocation methods in terms of task completion time and resource efficiency.