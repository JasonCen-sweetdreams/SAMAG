This paper presents an empirical study on designing gestural interfaces for older adults with cognitive impairments. We conducted a series of user studies to identify the challenges and opportunities of using gesture-based interfaces with this population. Our findings suggest that gesture recognition accuracy can be improved by incorporating machine learning-based models that adapt to individual motor abilities and cognitive deficits. We propose a novel framework, ' GestureEase', which integrates personalized gesture recognition, error correction, and feedback mechanisms to enhance the user experience. Our results show that GestureEase significantly improves task completion rates and user satisfaction compared to traditional interface designs.