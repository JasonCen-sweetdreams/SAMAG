This paper presents a novel approach to coordinating multi-agent systems using hierarchical task networks (HTNs) and deep reinforcement learning (DRL). We introduce a hierarchical framework that decomposes complex tasks into smaller sub-tasks, enabling agents to reason about their actions at multiple levels of abstraction. Our DRL algorithm, 'HTN-Q', learns to select optimal sub-tasks and allocate resources efficiently, while adapting to dynamic environments. Experimental results on a simulated search-and-rescue scenario demonstrate the effectiveness of our approach in improving task completion rates and reducing communication overhead.