Explainable recommender systems have gained significant attention in recent years, but most existing approaches focus on either model-based or model-agnostic explanations. This paper proposes a novel hierarchical multi-task learning framework, 'ExplainHTL', which integrates both types of explanations. Our approach leverages a hierarchical attention mechanism to capture complex user-item relationships and a multi-task objective to jointly optimize rating prediction and explanation generation. We conduct extensive experiments on three real-world datasets and demonstrate that ExplainHTL outperforms state-of-the-art models in terms of recommendation accuracy and explanation quality.