Multi-agent systems often require efficient task allocation to achieve complex goals. This paper presents a novel approach to distributed task allocation using reinforcement learning. Our method, 'MA-RL', enables agents to learn from their interactions with the environment and other agents, adapting to changing task requirements and agent capabilities. We evaluate MA-RL in a simulated disaster response scenario, demonstrating improved task completion rates and reduced communication overhead compared to traditional centralized allocation methods.