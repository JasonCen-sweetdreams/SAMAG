Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks, which can compromise their reliability and security. This paper proposes a novel approach to detect adversarial attacks in DNNs using Bayesian neural networks (BNNs). Our method, 'BayesDetect', leverages the uncertainty estimation capabilities of BNNs to identify input samples that are likely to be adversarial. We evaluate BayesDetect on several benchmark datasets and demonstrate its effectiveness in detecting a wide range of attacks, including FGSM, PGD, and CW attacks. Our results show that BayesDetect outperforms existing detection methods, achieving an average detection accuracy of 95.2% across all datasets.