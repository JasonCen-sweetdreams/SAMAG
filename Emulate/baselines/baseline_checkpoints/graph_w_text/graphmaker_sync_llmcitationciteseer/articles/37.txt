Clinical decision support systems (CDSSs) can significantly improve healthcare outcomes, but their opacity hinders trust and adoption. This paper presents a novel Hierarchical Attention Network (HAN) architecture that enables explainable AI-powered CDSSs. Our approach integrates domain-specific knowledge graphs with attention mechanisms to generate transparent and interpretable recommendations. We evaluate HAN on a large-scale electronic health records dataset, demonstrating improved predictive performance and enhanced explainability compared to state-of-the-art CDSS models.