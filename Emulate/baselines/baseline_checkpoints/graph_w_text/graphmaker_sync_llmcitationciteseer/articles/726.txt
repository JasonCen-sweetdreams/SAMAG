This paper presents a novel gesture recognition system designed for elderly individuals, leveraging transfer learning and depth sensors to improve accuracy and accessibility. Our approach fine-tunes a pre-trained convolutional neural network (CNN) on a dataset of elderly-specific gestures, and incorporates depth information from a low-cost sensor to enhance robustness to varying lighting and environmental conditions. Experimental results show that our system achieves an average recognition accuracy of 92.5%, outperforming state-of-the-art methods in this domain. We discuss the implications of our work for promoting independent living and healthcare for older adults.