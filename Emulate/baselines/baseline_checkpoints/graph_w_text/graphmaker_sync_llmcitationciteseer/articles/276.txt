Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks, but its vulnerability to adversarial attacks remains a significant concern. This paper proposes a novel approach to improve the robustness of DRL agents by leveraging multi-agent exploration. We introduce a framework, 'ROAM', which encourages agents to explore diverse trajectories and learn from each other's experiences. Our method effectively increases the model's robustness to adversarial perturbations while maintaining its performance in the nominal environment. Experimental results on various Atari games demonstrate the effectiveness of ROAM in enhancing the robustness of DRL agents.