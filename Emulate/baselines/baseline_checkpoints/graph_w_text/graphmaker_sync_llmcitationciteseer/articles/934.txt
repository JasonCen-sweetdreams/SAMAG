Gesture recognition systems have transformed human-computer interaction, but individuals with motor disabilities often face challenges using these systems. This paper presents an adaptive gesture recognition framework, 'AdaptGest', which leverages machine learning and computer vision to accommodate varying motor abilities. AdaptGest integrates a novel gesture representation model with a personalized adaptation mechanism, enabling the system to learn from user interactions and adjust its recognition thresholds accordingly. Our user study with 20 participants with motor disabilities demonstrates significant improvements in recognition accuracy and user experience compared to existing gesture recognition systems.