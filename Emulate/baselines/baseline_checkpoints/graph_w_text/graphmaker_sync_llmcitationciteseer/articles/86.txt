Autonomous vehicles rely heavily on reinforcement learning (RL) to navigate complex scenarios. However, the lack of interpretability in RL models hinders their widespread adoption. This paper proposes a novel framework, 'ExpRL', which incorporates explainability techniques into RL for autonomous vehicle control. We introduce a model-agnostic explanation method that generates visual explanations of the RL agent's decision-making process. Our experiments on a real-world autonomous driving dataset demonstrate that ExpRL improves the transparency and accountability of RL models, leading to safer and more efficient vehicle control.