Reinforcement learning (RL) agents often struggle to generalize in partially observable environments, where the state is only partially observable. This paper proposes a novel hierarchical attention network (HAT) architecture that incorporates attention mechanisms at multiple scales to selectively focus on relevant observations. We demonstrate that HAT enables the agent to learn more interpretable and robust policies in various RL tasks, including robotic control and navigation. Furthermore, we provide a theoretical analysis of the attention mechanisms, showing that they can be used to extract meaningful explanations for the agent's decisions.