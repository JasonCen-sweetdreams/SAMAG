Voice assistants have become ubiquitous in modern life, but their effectiveness for individuals with speech and language disorders remains limited. This paper presents a comprehensive study on spoken language understanding for individuals with dysarthria, a speech disorder characterized by impaired articulation and intelligibility. We develop a novel acoustic model that leverages transfer learning and attention mechanisms to improve speech recognition accuracy for individuals with dysarthria. Our user study with 30 participants demonstrates significant improvements in voice assistant interaction quality and user satisfaction, thereby enhancing the accessibility of these systems for individuals with dysarthria.