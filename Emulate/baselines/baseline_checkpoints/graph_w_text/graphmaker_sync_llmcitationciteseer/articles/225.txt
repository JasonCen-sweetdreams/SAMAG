In dynamic environments, multi-agent systems face the challenge of task allocation, where agents must adapt to changing task demands and resource constraints. We propose a novel distributed task allocation framework that leverages multi-agent reinforcement learning (MARL) to optimize task assignments. Our approach incorporates a decentralized communication protocol and a novel reward function that encourages agents to explore and exploit task opportunities. Experimental results in a simulated disaster response scenario demonstrate that our framework outperforms traditional centralized and decentralized allocation methods in terms of task completion rates and agent utilization.