In complex, dynamic environments, task allocation among multiple agents is a challenging problem. This paper presents MADARA, a novel multi-agent reinforcement learning framework that learns to allocate tasks adaptively based on environmental uncertainty. MADARA integrates a hierarchical task representation with a probabilistic graphical model to reason about uncertain task dependencies. Experimental results in a simulated disaster response scenario demonstrate that MADARA outperforms traditional, rule-based allocation methods in terms of task completion rate and agent utilization.