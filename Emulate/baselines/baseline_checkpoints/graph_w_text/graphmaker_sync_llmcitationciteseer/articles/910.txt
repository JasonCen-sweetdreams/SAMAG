Deep neural networks have achieved state-of-the-art performance in various machine learning tasks, but their success heavily relies on the careful tuning of hyperparameters. Bayesian optimization with Gaussian processes has emerged as a popular approach for hyperparameter tuning, but it can be computationally expensive. This paper proposes an efficient Bayesian optimization method that leverages a novel acquisition function, 'GP-UCB-EI', which balances exploration and exploitation. We conduct experiments on several benchmark datasets and demonstrate that our approach outperforms existing methods in terms of both computational efficiency and model performance.