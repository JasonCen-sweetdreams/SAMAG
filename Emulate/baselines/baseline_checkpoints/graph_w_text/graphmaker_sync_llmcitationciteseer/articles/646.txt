Conversational interfaces are increasingly prevalent in modern computing, but their effectiveness relies heavily on user engagement. This study investigates the impact of anthropomorphic feedback on user experience and behavior in conversational systems. We designed and conducted a user study with 120 participants, comparing three types of feedback: human-like, machine-like, and no feedback. Our results show that anthropomorphic feedback significantly improves user engagement, perceived system intelligence, and self-reported enjoyment. Furthermore, we identify specific linguistic features that contribute to these effects. The findings have implications for the design of conversational interfaces in various applications, such as chatbots, voice assistants, and online customer support.