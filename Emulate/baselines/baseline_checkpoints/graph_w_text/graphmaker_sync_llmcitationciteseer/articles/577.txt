Autonomous vehicles rely on efficient decision-making to navigate complex scenarios. This paper presents a novel reinforcement learning approach, 'GNRL', which leverages graph neural networks (GNNs) to learn a compact representation of the environment. By incorporating graph-based state abstraction, GNRL reduces the action space and accelerates policy learning. We demonstrate the effectiveness of GNRL on a suite of simulated driving tasks, showcasing improved performance and reduced training time compared to traditional reinforcement learning methods.