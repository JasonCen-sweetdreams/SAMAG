Multi-agent systems have shown promise in various applications, but coordinating agents in dynamic environments remains a significant challenge. This paper proposes a novel approach that leverages deep reinforcement learning to improve agent coordination. Our method, called DynaCo, uses a hierarchical architecture that combines a high-level coordination module with low-level action execution modules. We evaluate DynaCo in a simulated urban search and rescue scenario and demonstrate improved coordination and task completion rates compared to existing methods. Our results suggest that DynaCo can be applied to a wide range of dynamic environments, enabling more effective multi-agent systems.