Effective task allocation is crucial in multi-agent systems, where agents with varying capabilities and constraints need to coordinate to achieve complex goals. This paper proposes a novel approach using deep reinforcement learning to autonomously allocate tasks in such systems. Our method, called 'ATA-MAS', employs a decentralized, asynchronous framework that adapts to dynamic environment changes and agent failures. We evaluate ATA-MAS on a range of simulated scenarios, demonstrating improved task completion rates and reduced communication overhead compared to traditional, centralized allocation strategies.