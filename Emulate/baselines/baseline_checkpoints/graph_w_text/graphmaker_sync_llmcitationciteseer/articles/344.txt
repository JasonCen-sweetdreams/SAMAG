This paper proposes a decentralized multi-agent reinforcement learning (MARL) framework for dynamic task allocation in smart grids. We consider a scenario where multiple agents, each representing a microgrid, must allocate tasks (e.g., energy storage, generation, and consumption) to optimize overall grid efficiency. Our approach leverages a novel graph-based representation of the grid topology and a hierarchical deep reinforcement learning architecture to learn optimal task allocation policies. Experimental results on a simulated smart grid environment demonstrate improved efficiency, scalability, and adaptability compared to traditional centralized optimization methods.