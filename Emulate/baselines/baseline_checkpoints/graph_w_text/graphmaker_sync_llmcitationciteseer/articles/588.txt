In this paper, we propose a novel approach for distributed task allocation in multi-agent systems using graph neural networks (GNNs). Our approach, called TAGNN, leverages the structural properties of the agent communication graph to learn a distributed task allocation policy. TAGNN consists of two components: a GNN-based task encoder that learns to represent tasks as graph embeddings, and a decentralized allocation algorithm that uses these embeddings to allocate tasks to agents. We evaluate TAGNN on a variety of synthetic and real-world scenarios, demonstrating its effectiveness in achieving efficient and fair task allocation. Our results show that TAGNN outperforms existing methods in terms of task completion time, agent utilization, and adaptability to changing system conditions.