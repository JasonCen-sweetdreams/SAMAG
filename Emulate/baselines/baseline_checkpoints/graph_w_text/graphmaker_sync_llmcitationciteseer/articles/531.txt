Skeleton-based action recognition has gained significant attention in recent years due to its potential applications in human-computer interaction and healthcare. However, existing methods often struggle to model the complex spatial and temporal relationships between joints. This paper proposes a novel hierarchical attention-based graph neural network (HAGNN) that leverages both node-level and graph-level attention mechanisms to capture nuanced patterns in skeleton data. Our approach achieves state-of-the-art performance on the NTU RGB-D and Kinetics datasets, outperforming existing methods by a significant margin. We also provide an in-depth analysis of the attention weights, revealing insights into the importance of different joints and their interactions.