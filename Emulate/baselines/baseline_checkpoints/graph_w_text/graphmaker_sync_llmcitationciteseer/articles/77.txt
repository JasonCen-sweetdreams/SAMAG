The proliferation of big data has led to the widespread adoption of distributed relational databases. However, optimizing query performance in these systems remains a significant challenge. This paper presents a novel query optimization framework, 'DistributedQueryOptimizer', that leverages machine learning and graph-based techniques to improve query efficiency. Our approach involves learning a query performance model from historical query executions and using it to guide the optimization process. Experimental results on a real-world dataset demonstrate that our framework outperforms existing query optimizers in terms of query latency and resource utilization.