 Passage retrieval is a crucial step in many information retrieval applications, including question answering and text summarization. This paper proposes a novel hierarchical attention-based neural ranking model, HANR, which leverages both local and global contextual information to improve passage retrieval accuracy. HANR employs a multi-layered attention mechanism to capture hierarchical relationships between query terms, passage sentences, and passage-level representations. Experimental results on several benchmark datasets demonstrate that HANR outperforms state-of-the-art neural ranking models, achieving significant improvements in terms of mean average precision and normalized discounted cumulative gain.