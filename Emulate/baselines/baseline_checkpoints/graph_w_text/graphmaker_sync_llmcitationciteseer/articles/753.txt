Virtual reality (VR) has transformed human-computer interaction, but existing interfaces often neglect the role of embodiment in cognition. This paper explores the concept of embodied cognition in VR, where users' gestures and body language influence their mental representations. We design and evaluate a multimodal interaction system, 'EMERGE', which leverages machine learning-based gesture recognition, gaze tracking, and physiological signals to create a more immersive and intuitive user experience. Our user study demonstrates that EMERGE enhances cognitive processing, reduces mental workload, and increases user engagement in VR environments.