Multi-agent cooperation is a challenging problem in AI research, particularly when agents have different goals and capabilities. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) architecture that enables explainable cooperation among multiple agents. HGAT learns to represent agents as nodes in a hierarchical graph, where attention mechanisms are applied to model complex relationships between agents. We demonstrate the effectiveness of HGAT in a variety of cooperative scenarios, including robot soccer and disaster response. Our results show that HGAT outperforms state-of-the-art methods in terms of task performance and provides interpretable insights into agent decision-making.