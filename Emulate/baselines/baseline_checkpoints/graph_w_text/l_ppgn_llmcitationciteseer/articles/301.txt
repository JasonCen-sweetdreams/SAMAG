Explainable document retrieval is crucial for building trust in search engines. This paper proposes a novel learning-to-rank framework, 'HierAtt', which incorporates hierarchical attention mechanisms to model document relevance. Our approach leverages both local and global context to identify relevant passages and sentences within documents, enabling more interpretable ranking decisions. Experimental results on the TREC-8 dataset demonstrate that HierAtt outperforms state-of-the-art neural ranking models while providing insightful attention weights for explainability.