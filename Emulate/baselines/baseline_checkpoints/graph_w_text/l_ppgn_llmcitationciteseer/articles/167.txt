Distributed graph databases have become increasingly popular in recent years, but query optimization remains a significant challenge due to the complexity of graph structures and the need to balance query performance with resource utilization. This paper proposes a novel approach to query optimization using reinforcement learning, where an agent learns to select optimal execution plans based on a reward function that incorporates both query latency and resource utilization. We evaluate our approach on a real-world graph database and demonstrate significant improvements in query performance and resource efficiency compared to traditional optimization techniques.