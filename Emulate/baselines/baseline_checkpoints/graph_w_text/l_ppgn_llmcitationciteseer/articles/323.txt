As augmented reality (AR) technology becomes increasingly prevalent, effective interaction methods are crucial for a seamless user experience. This paper explores the potential of gaze-based interaction with virtual objects in AR environments. We propose a novel approach that leverages machine learning-based gaze tracking and object recognition to enable users to select and manipulate virtual objects using only their gaze. Our user study demonstrates improved interaction accuracy and reduced cognitive load compared to traditional controller-based methods. We also discuss the implications of our approach for accessibility and future AR applications.