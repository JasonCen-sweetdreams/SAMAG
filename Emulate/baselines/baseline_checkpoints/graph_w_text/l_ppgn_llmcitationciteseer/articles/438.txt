While multi-agent reinforcement learning (MARL) has achieved success in various domains, the lack of interpretability hinders its applicability in real-world scenarios. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable MARL. Our HAN model learns to focus on relevant agents and their interactions, facilitating the identification of key decision-making factors. We evaluate our approach on a suite of MARL benchmarks and demonstrate improved performance and interpretability compared to state-of-the-art methods.