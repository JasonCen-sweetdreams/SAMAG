Few-shot image classification remains a challenging problem in machine learning, where models must adapt to new classes with limited training data. This paper introduces a hierarchical meta-learning framework, 'HierML', which leverages a nested learning structure to learn more effective task embeddings. Our approach consists of two stages: a task-agnostic meta-learner that adapts to new tasks, and a task-specific learner that fine-tunes the model using hierarchical attention. We demonstrate the effectiveness of HierML on several benchmark datasets, achieving state-of-the-art performance on few-shot image classification tasks.