This paper presents EyeTrackingLens, a novel gaze-based interface designed to enhance the virtual reality (VR) experience. Our system leverages machine learning-based eye tracking to infer user intentions and enable seamless interactions with virtual objects. We develop a probabilistic gaze estimation model that integrates eye movement data with scene context, achieving a significant reduction in error rates compared to existing approaches. A user study demonstrates that EyeTrackingLens improves task efficiency and user satisfaction in VR applications, while also reducing eye fatigue and discomfort.