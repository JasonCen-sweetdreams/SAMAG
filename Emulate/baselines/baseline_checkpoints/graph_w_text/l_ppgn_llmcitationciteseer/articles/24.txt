Knowledge graph embedding (KGE) is a crucial task in AI, but existing methods often struggle with large-scale graphs and complex relationships. This paper introduces HierGAT, a novel hierarchical graph attention network for efficient KGE. HierGAT leverages a hierarchical representation of the graph, combining local and global attention mechanisms to capture both entity and relation semantics. Our experiments on benchmark datasets demonstrate that HierGAT outperforms state-of-the-art KGE methods in terms of link prediction and graph reconstruction, while requiring significantly fewer parameters and computational resources.