Few-shot learning on molecular structures is crucial for rapidly discovering new materials and drugs. However, existing graph neural networks (GNNs) struggle to generalize to unseen molecular structures with limited labeled data. This paper proposes a Hierarchical Graph Attention Network (HiGAT) that leverages attention mechanisms at multiple scales to capture complex structural patterns. HiGAT learns to focus on relevant substructures and adapt to new molecular structures with as few as 5 labeled examples. Experimental results on benchmark molecular datasets demonstrate that HiGAT outperforms state-of-the-art GNNs and achieves competitive performance with traditional machine learning methods.