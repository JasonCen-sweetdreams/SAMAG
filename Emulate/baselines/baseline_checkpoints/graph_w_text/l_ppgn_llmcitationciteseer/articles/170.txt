Few-shot intent detection in conversational AI is a challenging problem due to the limited availability of labeled data. We propose a novel meta-learning approach, 'IntentMeta', which leverages model-agnostic meta-learning to adapt to new intent types with only a few examples. Our method uses a task-aware attention mechanism to selectively focus on relevant context and intent information. Experimental results on popular conversational AI benchmarks demonstrate that IntentMeta outperforms state-of-the-art few-shot learning methods, achieving an average accuracy improvement of 12.5% on unseen intent types.