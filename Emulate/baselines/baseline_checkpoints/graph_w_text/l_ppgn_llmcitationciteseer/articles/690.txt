Traditional document ranking models rely on static representations of documents, neglecting the nuanced context of user queries. We propose a novel neural ranking model, 'ContextRank', which leverages query-dependent document encoding and contextualized embeddings. By incorporating query-aware attention mechanisms and semantic role labeling, ContextRank captures the intricate relationships between query terms, document entities, and their contextual roles. Experimental results on the TREC-2004 dataset demonstrate significant improvements in ranking accuracy and relevance over state-of-the-art neural ranking models.