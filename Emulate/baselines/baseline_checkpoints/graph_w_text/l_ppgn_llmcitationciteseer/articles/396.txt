Conversational search systems aim to mimic human-like interactions, but often struggle with complex, multi-turn queries. This paper proposes a novel approach to deep query reformulation, which leverages hierarchical graph attention mechanisms to capture contextual relationships between entities and intents. Our model, 'ConverseQA', learns to recursively refine queries by identifying key concepts, resolving coreference, and generating follow-up questions. Experimental results on the TREC Conversational Assistance Track dataset demonstrate significant improvements in retrieval accuracy and conversational coherence compared to state-of-the-art baselines.