Question answering (QA) models have achieved remarkable performance in recent years, but their lack of transparency hinders trust and understanding. We propose a novel hierarchical graph attention network (HGAT) for explainable QA, which leverages graph-based attention mechanisms to capture complex relationships between entities, concepts, and context. Our approach enables interpretable and fine-grained explanations for QA predictions, improving model trustworthiness and facilitating knowledge graph construction. Experimental results on benchmark datasets demonstrate the effectiveness of HGAT in achieving state-of-the-art performance while providing human-understandable explanations.