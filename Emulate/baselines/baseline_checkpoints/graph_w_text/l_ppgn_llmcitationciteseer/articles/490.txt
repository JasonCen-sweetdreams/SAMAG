In multi-agent systems, efficient exploration is crucial for collective decision-making. This paper presents a novel decentralized approach, 'Dec-GNN-Explore', which leverages graph neural networks (GNNs) to facilitate coordinated exploration among agents. Each agent maintains a local GNN that learns to represent its surroundings and shares information with neighboring agents. We introduce a decentralized entropy-based objective that encourages agents to explore diverse regions while minimizing communication overhead. Experimental results on a range of multi-agent environments demonstrate the superior exploration efficiency and robustness of Dec-GNN-Explore compared to traditional, centralized methods.