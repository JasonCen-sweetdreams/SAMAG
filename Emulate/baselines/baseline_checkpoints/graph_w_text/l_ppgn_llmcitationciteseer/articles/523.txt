This paper proposes a novel multi-agent reinforcement learning framework for cooperative route planning in autonomous vehicle systems. Our approach, called 'CoopRoute', leverages the strengths of both centralized and decentralized planning by assigning a hierarchical structure to the agents. Each agent learns to optimize its own route while adapting to the actions of other agents, resulting in improved overall system efficiency and reduced travel times. We evaluate CoopRoute on a simulated urban traffic network and demonstrate its ability to outperform traditional planning methods in complex scenarios.