Voice assistants have become ubiquitous in modern life, but their interactions are often influenced by cognitive biases that can perpetuate social inequalities. This study examines the impact of confirmation bias, anchoring bias, and availability heuristic on user interactions with voice assistants. We conducted a mixed-methods study involving 120 participants and found that these biases can lead to biased responses, reinforce stereotypes, and affect user trust. We propose a set of design guidelines for inclusive voice assistants, emphasizing the need for explicit bias mitigation strategies and more transparent AI decision-making processes.