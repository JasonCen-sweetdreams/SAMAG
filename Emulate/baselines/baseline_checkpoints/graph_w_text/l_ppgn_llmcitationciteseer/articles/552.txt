Coordinating task-oriented multi-agent systems is a challenging problem in artificial intelligence. This paper proposes a novel approach that leverages deep graph reinforcement learning to learn effective coordination policies. We represent the multi-agent system as a graph, where agents are nodes and edges capture their interactions. By learning a policy that optimizes a global reward function, our approach can coordinate agents to achieve complex tasks in a decentralized manner. Experimental results on a variety of task-oriented domains demonstrate the effectiveness of our approach in improving coordination efficiency and task performance.