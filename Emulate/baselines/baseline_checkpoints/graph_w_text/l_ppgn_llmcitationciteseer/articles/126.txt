Decentralized task allocation is a fundamental problem in multi-agent systems, where agents must cooperate to accomplish complex tasks. This paper proposes a novel approach based on graph-based reinforcement learning, where agents learn to allocate tasks by interacting with a graph-structured environment. We introduce a decentralized policy gradient algorithm that allows agents to learn from local observations and communicate with their neighbors to achieve global optimality. Experimental results on a variety of task allocation scenarios demonstrate the effectiveness and scalability of our approach compared to traditional centralized methods.