Open-domain question answering (ODQA) relies on efficient passage retrieval to identify relevant documents. Existing methods employ dense passage embeddings, which can be computationally expensive and require large-scale indexing. This paper proposes Hierarchical Document Representation (HDR), a novel approach that represents documents as a hierarchy of coarse-to-fine embeddings. Our method leverages a hierarchical attention mechanism to selectively focus on relevant sections and sentences, reducing the computational cost of passage retrieval. Experimental results on the Natural Questions and TriviaQA datasets demonstrate that HDR achieves state-of-the-art performance while reducing the indexing time by 3.5x and the retrieval time by 2x.