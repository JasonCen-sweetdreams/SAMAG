Virtual Reality (VR) has the potential to revolutionize accessibility for individuals with motor impairments. However, current gesture recognition systems often fail to accommodate diverse abilities and user preferences. This paper presents 'AdaptiGesture', a novel framework that leverages machine learning and user-centered design to create personalized, adaptive gesture recognition models for VR. Our approach incorporates multimodal sensor data and user feedback to iteratively refine gesture recognition, ensuring high accuracy and user satisfaction. A user study with 20 participants demonstrated significant improvements in gesture recognition accuracy and overall VR experience compared to existing systems.