Cloud computing resources are often underutilized, leading to significant energy waste and operational costs. This paper proposes a novel deep reinforcement learning (DRL) approach to optimize resource allocation in cloud data centers. We design a hierarchical DRL framework that integrates a high-level resource manager with low-level controller agents, enabling adaptive resource provisioning and workload scheduling. Experimental results on a real-world cloud infrastructure show that our approach achieves up to 30% energy savings and 25% reduction in response times compared to state-of-the-art heuristics.