Knowledge graph embedding (KGE) has become a crucial component in various AI applications. However, existing KGE methods struggle to capture complex relationships between entities in multi-relational knowledge graphs. This paper proposes a novel hierarchical graph attention network (HGAN) model that leverages the hierarchical structure of knowledge graphs to learn more informative entity representations. HGAN consists of a stacked attention mechanism that adaptively focuses on relevant neighboring entities and relationships at each hierarchical level. Experimental results on several benchmark datasets demonstrate that HGAN outperforms state-of-the-art KGE methods in link prediction and triple classification tasks.