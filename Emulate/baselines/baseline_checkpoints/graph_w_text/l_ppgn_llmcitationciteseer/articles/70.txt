This paper presents a novel multi-agent reinforcement learning (MARL) framework for real-time traffic control. Our approach, dubbed 'TrafficMA', leverages a decentralized, communication-efficient protocol to coordinate actions among multiple agents, each responsible for controlling a specific traffic signal. By incorporating a graph attention mechanism to model complex traffic dynamics, TrafficMA achieves significant improvements in traffic flow and reduces congestion compared to traditional, rule-based control systems. We evaluate our approach using a large-scale, real-world traffic simulation platform and demonstrate its scalability and adaptability to diverse traffic scenarios.