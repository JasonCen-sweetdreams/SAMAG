Neural search systems have gained popularity in recent years, but their performance is often bottlenecked by the computational cost of dense document embeddings. This paper proposes a novel ranking model, 'SparseRank', which leverages sparse document embeddings to reduce the dimensionality of the search space. We introduce a hierarchical attention mechanism that adaptively selects relevant document features, resulting in improved retrieval efficiency without sacrificing ranking accuracy. Experimental results on several benchmark datasets demonstrate the effectiveness of SparseRank in reducing computational overhead while achieving state-of-the-art retrieval performance.