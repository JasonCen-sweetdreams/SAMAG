Neural retrieval models have achieved state-of-the-art performance in various information retrieval tasks. However, they often suffer from limited contextual understanding, leading to suboptimal ranking results. This paper proposes a novel query-driven document expansion approach, 'QDE', which leverages the query context to selectively expand relevant documents. We introduce a two-stage framework that first identifies query-dependent keywords and then incorporates these keywords into the document representation via a learned attention mechanism. Experimental results on several benchmarks demonstrate that QDE consistently improves the ranking performance of neural retrieval models, especially for long-tail queries.