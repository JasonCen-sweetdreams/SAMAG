Open-domain question answering (ODQA) systems rely on effective document retrieval and passage ranking to answer user queries. This paper proposes a novel query-driven document expansion approach, 'QDDE', which iteratively refines the document set based on the query context and passage relevance. We introduce a neural ranking model that incorporates query-specific entity embeddings and semantic role labeling to better capture the question intent. Experimental results on the SQuAD dataset demonstrate that QDDE achieves significant improvements in top-1 passage accuracy and answer recall compared to state-of-the-art ODQA systems.