Time-series forecasting models often lack interpretability, making it challenging to understand their predictions. This paper introduces Hierarchical Attention Networks (HANs) for explainable time-series forecasting. HANs employ a hierarchical structure to learn attention weights at multiple scales, enabling the model to focus on relevant features and time-steps. We propose a novel attention-based feature importance metric, which provides insights into the model's decision-making process. Experimental results on several benchmark datasets demonstrate that HANs achieve state-of-the-art forecasting performance while providing meaningful explanations for their predictions.