In multi-agent systems, effective dialogue management is crucial for task-oriented communication. This paper proposes a novel framework, 'RL-Dialogue', that leverages reinforcement learning to optimize dialogue policies for multiple agents. Our approach utilizes a hierarchical reinforcement learning architecture, comprising a high-level task manager and low-level dialogue generators, to adaptively generate responses that balance task progress with dialogue coherence. Experimental results show that RL-Dialogue outperforms traditional rule-based and supervised learning approaches in terms of task completion rate and dialogue fluency.