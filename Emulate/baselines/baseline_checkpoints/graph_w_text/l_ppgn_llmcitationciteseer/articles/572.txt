Virtual reality (VR) systems rely on accurate gesture recognition to provide immersive experiences. This paper presents a novel hierarchical task modeling approach for adaptive gesture recognition, exploiting the inherent structure of VR tasks. Our method, 'HTMR', represents tasks as a hierarchical composition of sub-tasks, enabling the model to focus on relevant gesture patterns. We evaluate HTMR on a large-scale VR gesture dataset, demonstrating improved recognition accuracy and adaptability to new tasks compared to state-of-the-art methods.