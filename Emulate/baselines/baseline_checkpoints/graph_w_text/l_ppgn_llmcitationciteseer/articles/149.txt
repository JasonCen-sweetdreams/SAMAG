Few-shot relation extraction (FSRE) is a challenging task, especially when dealing with long-tail relations and limited labeled data. We propose a novel Hierarchical Graph Attention Network (HGAT) that leverages graph structures to model entity interactions and attention mechanisms to focus on crucial context. HGAT consists of a hierarchical graph encoder and a relation-aware attention module, enabling the model to capture complex relational patterns from limited examples. Experimental results on the FewRel dataset demonstrate that HGAT outperforms state-of-the-art FSRE models, achieving an average F1-score improvement of 4.2% on 1-shot and 2-shot settings.