Coordinating multiple agents in complex environments is a challenging problem in multi-agent systems. This paper proposes a hierarchical reinforcement learning framework, 'HierMA', which learns to coordinate agents at both local and global levels. The framework consists of a high-level coordinator that sets goals for individual agents, which then learn to achieve these goals using deep reinforcement learning. We evaluate HierMA in a simulated robotic soccer domain and demonstrate improved coordination and task accomplishment compared to decentralized and centralized approaches. Our results have implications for real-world applications such as search and rescue, and autonomous vehicles.