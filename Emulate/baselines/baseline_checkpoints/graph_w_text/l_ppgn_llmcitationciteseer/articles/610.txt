Virtual reality (VR) has revolutionized human-computer interaction, but existing interfaces often neglect the user's attention and intentions. This paper introduces a novel eye-gaze driven adaptive interface, 'EGAIA', which leverages pupillometry and machine learning to infer user interests and adapt the VR environment accordingly. EGAIA incorporates a probabilistic model of user attention, which is updated in real-time using eye-tracking data. We conducted a user study with 30 participants and found that EGAIA significantly improves user engagement, reduces cognitive load, and enhances overall VR experience.