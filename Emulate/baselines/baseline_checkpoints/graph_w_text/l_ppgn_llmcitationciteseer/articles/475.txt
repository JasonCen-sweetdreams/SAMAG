Cooperative task allocation in multi-agent systems is a challenging problem, especially when agents have diverse capabilities and tasks require collaborative efforts. This paper introduces a novel deep reinforcement learning framework, 'CATALYST', that enables agents to learn coordinated exploration strategies for efficient task allocation. Our approach combines graph neural networks with multi-agent Q-learning to facilitate information sharing and joint decision-making. Experimental results on a realistic disaster response scenario demonstrate that CATALYST outperforms traditional approaches in terms of task completion rate and overall system efficiency.