Deep reinforcement learning (DRL) has achieved remarkable success in various robotics tasks, but its lack of interpretability hinders its adoption in real-world applications. This paper presents a novel explainability framework, 'RL-Explain', which leverages attention mechanisms and saliency maps to provide insights into DRL decision-making processes. We demonstrate RL-Explain's effectiveness in a robotic grasping task, showcasing improved transparency and trustworthiness of the DRL policy. Our results indicate that RL-Explain can facilitate the development of more reliable and efficient DRL-based robotic systems.