State-of-the-art neural ranking models often rely on complex and computationally expensive architectures to capture nuanced query-document relationships. This paper proposes a novel query graph embedding approach, 'QGE', which leverages graph neural networks to efficiently model query semantics and re-rank documents. QGE learns a compact, dense representation of the query graph, enabling fast and accurate similarity computations with candidate documents. Our experiments on the TREC DL 2019 dataset demonstrate significant improvements in ranking performance, with a 15% increase in NDCG@10 compared to strong baseline models, while reducing computational costs by up to 40%.