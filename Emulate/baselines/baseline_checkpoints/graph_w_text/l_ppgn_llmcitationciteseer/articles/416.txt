In decentralized multi-agent systems, task allocation is a complex problem due to the lack of centralized control and communication constraints. This paper proposes a novel reinforcement learning approach, 'DRL-TA', which enables agents to learn task allocation strategies through experience. We model the task allocation problem as a Markov decision process and develop a decentralized Q-learning algorithm that enables agents to adapt to changing task requirements and agent availability. Experimental results on a simulated search-and-rescue scenario demonstrate that DRL-TA outperforms traditional heuristic-based methods in terms of task completion time and resource utilization.