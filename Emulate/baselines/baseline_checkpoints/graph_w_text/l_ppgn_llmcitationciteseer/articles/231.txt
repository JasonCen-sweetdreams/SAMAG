Conversational AI systems are increasingly vulnerable to sophisticated adversarial attacks that can manipulate user interactions. This paper proposes a novel graph-based anomaly detection framework, 'ConverseGuard', to detect such attacks in real-time. ConverseGuard models user-AI interactions as a graph and leverages graph neural networks to identify anomalous patterns indicative of adversarial behavior. We evaluate ConverseGuard on a large-scale conversational dataset and demonstrate its effectiveness in detecting targeted attacks, including those that evade traditional detection methods.