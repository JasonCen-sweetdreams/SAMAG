Individuals with motor impairments often face significant barriers when interacting with gestural interfaces. This paper presents a novel framework for designing accessible gestural interfaces that accommodate a wide range of motor abilities. We conducted a user study with 20 participants with varying levels of motor impairment, and identified key design principles for reducing error rates and improving user experience. Our proposed interface, 'AccessibleGest', incorporates machine learning-based gesture recognition and real-time feedback mechanisms to facilitate more accurate and efficient interactions. Results show that AccessibleGest outperforms existing interfaces in terms of user satisfaction and task completion rates.