We present a novel multi-agent reinforcement learning framework, 'GraphMA', which leverages graph attention networks to improve coordination and communication among agents in complex environments. By learning to focus on relevant graph structures, GraphMA reduces the curse of dimensionality and achieves faster convergence compared to existing methods. We evaluate our approach on a range of cooperative and competitive tasks, demonstrating improved performance and scalability in simulations of robotic swarm control and traffic management.