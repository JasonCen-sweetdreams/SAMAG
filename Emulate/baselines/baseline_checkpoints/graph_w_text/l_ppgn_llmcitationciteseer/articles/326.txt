Autonomous drone navigation in uncertain environments is a challenging problem, requiring efficient exploration and adaptation to changing conditions. This paper proposes a hierarchical reinforcement learning framework, 'HRL-Drone', which integrates a high-level decision-making module with a low-level control policy. The high-level module uses a probabilistic graph model to reason about the environment and select goals, while the low-level policy employs a deep reinforcement learning algorithm to execute the selected goals. Experimental results in simulated and real-world scenarios demonstrate that HRL-Drone outperforms state-of-the-art methods in terms of navigation efficiency and robustness to uncertainty.