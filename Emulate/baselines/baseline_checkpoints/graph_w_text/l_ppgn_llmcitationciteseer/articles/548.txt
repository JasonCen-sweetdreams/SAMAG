Explainability is crucial in time series forecasting, as it enables model interpretability and trustworthiness. This paper introduces Hierarchical Attention Networks (HANs), a novel architecture that integrates attention mechanisms at multiple scales to capture complex patterns in time series data. HANs leverage hierarchical representations to identify relevant features and contextual relationships, producing more accurate and interpretable forecasts. We evaluate HANs on several benchmark datasets, demonstrating improved performance and explainability compared to state-of-the-art models. Our approach has significant implications for real-world applications, such as demand forecasting and anomaly detection.