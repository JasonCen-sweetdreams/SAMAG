Deep neural networks are vulnerable to adversarial attacks, which can be mitigated by adversarial training. However, existing methods often overlook the uncertainty associated with the learned models. This paper proposes a novel uncertainty-aware regularization technique, 'UncerReg', which incorporates Bayesian neural networks into the adversarial training framework. UncerReg encourages the model to learn more robust features by penalizing the uncertainty of the predictions on adversarial examples. Experimental results on ImageNet and CIFAR-10 datasets demonstrate that UncerReg significantly improves the robustness of image classification models against various types of attacks while maintaining competitive clean accuracy.