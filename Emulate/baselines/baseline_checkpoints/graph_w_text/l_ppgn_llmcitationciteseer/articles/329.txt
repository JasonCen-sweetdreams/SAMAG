Autonomous vehicles require efficient lane-changing strategies to ensure safe and smooth traffic flow. This paper presents a novel deep hierarchical reinforcement learning (DHRL) framework for lane-changing decision-making. Our approach integrates a high-level policy network with a low-level motion planning network, enabling the vehicle to adapt to dynamic environments and unexpected events. We evaluate the DHRL framework on a realistic simulation platform and demonstrate improved performance compared to traditional rule-based and reinforcement learning approaches.