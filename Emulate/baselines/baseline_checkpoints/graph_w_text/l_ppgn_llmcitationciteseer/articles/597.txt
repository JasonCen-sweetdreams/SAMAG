Cloud computing platforms face the challenge of optimizing resource allocation to meet dynamic workload demands. This paper proposes a novel deep hierarchical reinforcement learning (DHRL) framework that learns to allocate resources efficiently by modeling the complex interactions between virtual machines, containers, and physical hosts. Our approach integrates a high-level resource manager with a low-level scheduling agent, enabling the system to adapt to changing workloads and minimize costs. Experimental results demonstrate that DHRL achieves significant improvements in resource utilization and response times compared to existing heuristic-based approaches.