Time series forecasting is crucial in various domains, including finance, healthcare, and climate science. While AI-driven models have achieved state-of-the-art performance, they often lack interpretability, hindering trust and adoption. This paper introduces HATSF, a novel hierarchical attention network that provides explainable time series forecasting. HATSF incorporates a hierarchical attention mechanism to selectively focus on relevant features and time steps, generating interpretable attention weights. We evaluate HATSF on multiple real-world datasets, demonstrating improved forecasting accuracy and robustness compared to state-of-the-art models. Furthermore, our model provides transparent insights into the forecasting process, enabling users to understand and trust the predictions.