This paper proposes a decentralized approach to coordinating multiple autonomous agents in complex, dynamic environments. We employ reinforcement learning to train individual agents to adapt to changing circumstances and learn effective coordination strategies. Our method, dubbed '-AgentRL', leverages graph neural networks to model agent interactions and optimize collective behavior. Experimental results on a simulated traffic scenario demonstrate improved coordination and reduced congestion compared to traditional centralized control methods.