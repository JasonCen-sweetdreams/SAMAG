Individuals with motor disabilities face significant barriers when interacting with gestural interfaces. This paper presents 'AccessibleGest', a novel framework that leverages machine learning and computer vision to enable accessible gestural interactions. We propose a real-time gesture recognition system that adapts to the unique abilities of individuals with motor disabilities, allowing for accurate and efficient gesture detection. Our user study involving 20 participants with motor disabilities demonstrates that AccessibleGest outperforms state-of-the-art gesture recognition systems, achieving an average recognition accuracy of 92.5%. We also present a set of design guidelines for developing accessible gestural interfaces.