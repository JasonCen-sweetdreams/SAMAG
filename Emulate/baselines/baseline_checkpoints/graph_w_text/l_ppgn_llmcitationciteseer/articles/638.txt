This paper investigates the role of embodied cognition in virtual reality (VR) environments, focusing on the relationship between gesture-based interaction and cognitive load. We designed an experiment where participants performed a series of tasks in a VR simulation, using either gesture-based or controller-based input methods. Our results show that gesture-based interaction reduces cognitive load and improves task performance, particularly in tasks requiring spatial reasoning and problem-solving. We discuss the implications of these findings for the design of VR systems and interfaces that leverage embodied cognition principles.