The proliferation of multi-model databases has led to an increased complexity in query optimization. Traditional cost-based optimizers struggle to navigate the vast space of possible query plans, resulting in suboptimal performance. This paper proposes a novel approach, 'QueryRLE', which leverages reinforcement learning to efficiently explore the query optimization space. By formulating the optimization problem as a Markov decision process, QueryRLE learns to adapt to changing database workloads and query patterns, outperforming state-of-the-art optimizers in experiments on real-world datasets.