Query reformulation is a crucial task in search engines to improve the retrieval of relevant documents. Traditional methods rely on manual rules or supervised learning, which may not generalize well to diverse query patterns. This paper proposes a reinforcement learning approach, 'RL-Reform', that learns to reformulate queries by interacting with a simulated search engine environment. We design a novel reward function that balances the trade-off between query similarity and relevance improvement. Experimental results on a large-scale query log dataset demonstrate that RL-Reform outperforms state-of-the-art methods in terms of search engine efficiency and user satisfaction.