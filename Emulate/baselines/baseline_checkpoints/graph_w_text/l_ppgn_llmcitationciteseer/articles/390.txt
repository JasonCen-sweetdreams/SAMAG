Gesture recognition systems have the potential to improve the lives of people with disabilities, but existing systems often fail to account for individual differences in motor abilities. This paper presents a novel approach to adaptive gesture recognition, which leverages machine learning and computer vision techniques to learn personalized gesture models for users with disabilities. Our system, ' GestureAdapt', incorporates a user-centered design approach, involving participatory design and co-creation with users to ensure that the system is accessible, usable, and meets their needs. We evaluate GestureAdapt with a user study involving 20 participants with mobility and dexterity impairments, demonstrating significant improvements in gesture recognition accuracy and user satisfaction.