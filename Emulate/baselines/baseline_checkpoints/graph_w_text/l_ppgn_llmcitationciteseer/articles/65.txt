Knowledge graph embeddings have achieved state-of-the-art performance in various AI applications, but their lack of interpretability hinders their adoption in high-stakes domains. We propose a novel hierarchical attention network (HAN) that learns to explicitly model entity relationships and attributes in knowledge graphs. Our approach leverages attention mechanisms to selectively focus on relevant entities, attributes, and relationships, enabling the generation of transparent and explainable embeddings. Experimental results on benchmark datasets demonstrate the effectiveness of HAN in improving both performance and interpretability over existing knowledge graph embedding methods.