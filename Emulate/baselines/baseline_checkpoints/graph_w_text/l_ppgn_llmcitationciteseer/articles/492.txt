In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel distributed task allocation framework that leverages reinforcement learning to adapt to dynamic environments. Our approach, called 'RL-TA', utilizes a decentralized Q-learning algorithm to enable agents to learn optimal task assignments based on local observations and rewards. We evaluate RL-TA in a simulated disaster response scenario, demonstrating improved task completion rates and reduced communication overhead compared to traditional, centralized allocation methods.