Multimodal information retrieval (MIR) aims to retrieve relevant information from diverse media types, such as images, text, and audio. However, the complexity of MIR queries often hinders the retrieval performance. This paper proposes a context-aware query expansion (CAQE) approach that leverages multimodal features and contextual information to refine MIR queries. CAQE incorporates a novel attention mechanism to weigh the importance of different modalities and contextual cues, such as user location and search history. Experimental results on a large-scale MIR dataset demonstrate that CAQE significantly improves the retrieval accuracy and diversity compared to state-of-the-art query expansion methods.