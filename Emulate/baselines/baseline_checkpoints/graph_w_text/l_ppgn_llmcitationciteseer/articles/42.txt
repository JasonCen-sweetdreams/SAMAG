Coordinating the actions of multiple agents in complex environments is a challenging problem in multi-agent systems. This paper proposes a hierarchical reinforcement learning framework, 'HierMA', which enables agents to learn both individual and collaborative strategies. We introduce a novel hierarchical architecture that consists of a high-level coordination module and low-level action modules, allowing agents to adapt to changing environments and optimize global rewards. Experimental results on a traffic management scenario demonstrate that HierMA outperforms traditional decentralized and centralized approaches, achieving improved traffic flow and reduced congestion.