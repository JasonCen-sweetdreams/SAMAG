Cooperative multi-agent reinforcement learning (MARL) is a challenging problem in AI research, particularly in complex graph-structured environments. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages graph attention mechanisms to facilitate cooperative decision-making among agents. HGAT incorporates a hierarchical graph representation, enabling agents to selectively focus on relevant neighboring agents and learn coordinated policies. Experimental results on a range of MARL benchmarks demonstrate that HGAT outperforms state-of-the-art methods, achieving improved cooperation and scalability in large-scale graph environments.