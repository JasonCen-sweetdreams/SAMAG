Voice assistants have become ubiquitous in modern life, but their language understanding capabilities often reflect the cultural and linguistic biases of their designers. This paper presents a comprehensive study on the effects of cultural and linguistic biases in dialogue systems, focusing on the nuances of language usage across different demographics. We propose a novel framework for culturally sensitive dialogue design, incorporating participatory design methods and machine learning-based bias detection. Our evaluation on a diverse set of users shows that our approach significantly improves the conversational experience, reducing errors and increasing user satisfaction.