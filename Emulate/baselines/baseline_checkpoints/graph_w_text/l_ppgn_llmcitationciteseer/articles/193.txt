Knowledge graph embedding (KGE) has emerged as a powerful technique for incorporating semantic information into recommendation systems. However, existing methods often suffer from high computational complexity and limited context-awareness. This paper proposes a novel KGE approach, 'HierAtt-KGE', which leverages hierarchical attention mechanisms to selectively focus on relevant entities and relationships. Our experiments on three real-world datasets demonstrate that HierAtt-KGE outperforms state-of-the-art KGE methods in terms of recommendation accuracy, while reducing computational overhead by up to 40%. We also provide insights into the interpretability of learned attention weights, shedding light on the importance of specific knowledge graph structures.