Virtual reality (VR) has the potential to revolutionize accessibility, but existing gesture recognition systems often fail to accommodate users with diverse abilities. This paper presents a novel adaptive framework, ' GestureFit', which dynamically adjusts gesture recognition models based on individual user behavior and preferences. Our approach leverages a combination of machine learning and HCI principles to improve recognition accuracy and reduce fatigue for users with disabilities. A user study with 30 participants demonstrates significant improvements in usability and user satisfaction compared to traditional gesture recognition systems.