Gesture-based interfaces have become increasingly popular in modern computing, but their accessibility for users with motor disabilities remains a significant concern. This paper presents a novel framework for designing inclusive gesture-based interfaces that accommodate users with varying levels of motor abilities. We propose a machine learning-based approach to gesture recognition that incorporates personalized models and adaptive thresholding to improve accuracy and user satisfaction. A user study with 20 participants with motor disabilities demonstrates the effectiveness of our approach in reducing error rates and enhancing user experience.