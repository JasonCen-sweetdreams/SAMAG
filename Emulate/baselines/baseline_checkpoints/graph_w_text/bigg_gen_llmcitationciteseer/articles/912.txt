Conversational agents require effective dialogue management to engage users in productive conversations. This paper proposes a task-oriented dialogue management framework that leverages hierarchical reinforcement learning (HRL) to optimize conversation flow. Our approach decomposes the dialogue management problem into two levels: a high-level task manager that selects the next dialogue act, and a low-level response generator that produces the corresponding utterance. We evaluate our framework on a suite of benchmark datasets and demonstrate significant improvements in task success rate and user satisfaction compared to state-of-the-art methods.