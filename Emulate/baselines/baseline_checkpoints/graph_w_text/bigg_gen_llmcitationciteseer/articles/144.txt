Explainability is crucial for real-world adoption of reinforcement learning (RL) systems. Existing approaches focus on providing post-hoc explanations, which can be misleading or incomplete. This paper proposes a novel hierarchical attention framework, 'HierAttnRL', which incorporates explainability into the RL decision-making process. By learning attention weights over state and action features, our framework provides transparent and interpretable policies. Experimental results on Atari and MuJoCo benchmarks demonstrate that HierAttnRL achieves comparable performance to state-of-the-art RL methods while providing insightful explanations for its decisions.