Reinforcement learning (RL) has achieved remarkable success in complex decision-making tasks, but its lack of transparency hinders trust and adoption. This paper proposes a novel hierarchical attention network (HAN) architecture that learns to generate interpretable explanations for RL policies. By incorporating attention mechanisms at multiple levels, HAN identifies relevant state features and highlights critical decision-making steps. Experimental results on Atari games and robotic control tasks demonstrate that HAN improves policy transparency while maintaining competitive performance with state-of-the-art RL algorithms.