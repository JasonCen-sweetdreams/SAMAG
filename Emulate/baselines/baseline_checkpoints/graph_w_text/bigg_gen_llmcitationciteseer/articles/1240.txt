Coordinating multi-agent systems is a challenging problem in distributed artificial intelligence. This paper proposes a novel framework that combines reinforcement learning with graph attention mechanisms to learn effective coordination strategies. We model the agent interactions as a graph and use attention weights to focus on the most critical agents and their relationships. Our approach is evaluated on a series of complex coordination tasks, demonstrating improved performance and scalability compared to state-of-the-art methods. We also provide theoretical guarantees on the convergence of our algorithm and its robustness to agent failures.