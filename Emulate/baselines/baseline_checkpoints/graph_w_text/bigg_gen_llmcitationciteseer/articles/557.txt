Multi-label classification is a common problem in various applications, but it often suffers from label imbalance and high dimensionality. This paper proposes a novel hierarchical attention network (HAN) that efficiently tackles these challenges. Our HAN model consists of two attention mechanisms: a label-aware attention module that selectively focuses on relevant labels, and a feature-aware attention module that adaptively weights input features. Experimental results on several benchmark datasets demonstrate that our approach outperforms state-of-the-art methods in terms of both accuracy and computational efficiency.