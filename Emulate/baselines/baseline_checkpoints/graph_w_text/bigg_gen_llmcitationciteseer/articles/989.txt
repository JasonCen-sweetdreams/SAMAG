This paper presents a decentralized task allocation framework for autonomous agents using multi-agent reinforcement learning. Our approach, called 'Dec-TARL', enables agents to learn efficient task allocation strategies in complex, dynamic environments. We introduce a novel graph-based representation of agent-task relationships and a decentralized Q-learning algorithm that leverages local observations and communication with neighboring agents. Experimental results in a simulated warehouse scenario demonstrate that Dec-TARL outperforms traditional centralized allocation methods in terms of task completion time and agent utility.