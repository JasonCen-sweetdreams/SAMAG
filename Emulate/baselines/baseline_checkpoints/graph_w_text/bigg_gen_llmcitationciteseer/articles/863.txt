Entity disambiguation is a fundamental task in natural language processing, but it remains challenging for long-tail entities, which dominate real-world datasets. This paper proposes a hierarchical attention network (HAN) that leverages both local and global context to disambiguate entities efficiently. Our HAN model consists of a novel entity-aware attention mechanism that adaptively weighs the importance of contextual words and a hierarchical aggregation strategy that captures both entity-specific and topic-level information. Experimental results on several benchmark datasets demonstrate that our approach achieves state-of-the-art performance with significant improvements in accuracy and speed over existing methods.