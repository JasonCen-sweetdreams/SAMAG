As autonomous vehicles become increasingly prevalent, their ability to cooperate and make joint decisions is crucial for safe and efficient operation. This paper presents a novel multi-agent reinforcement learning framework, 'MAVERIC', which enables interpretable decision-making in cooperative autonomous vehicle systems. MAVERIC incorporates a attention-based neural network architecture that learns to identify relevant contextual information and communicate effectively between agents. Experimental results on a simulated highway scenario demonstrate that MAVERIC achieves improved cooperative behavior and reduced collision rates compared to existing decentralized RL approaches.