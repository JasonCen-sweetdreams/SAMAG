Autonomous vehicles operating in dynamic environments require efficient and adaptive control strategies to ensure safety and efficiency. This paper proposes a hierarchical reinforcement learning framework that integrates a high-level task planner with a low-level motion controller. Our approach leverages a deep neural network to learn a hierarchical policy that adaptively adjusts to changing environmental conditions, such as pedestrian movement or road closures. We demonstrate the effectiveness of our approach through simulations and experiments on a real-world autonomous vehicle platform, showcasing improved performance and robustness compared to traditional reinforcement learning methods.