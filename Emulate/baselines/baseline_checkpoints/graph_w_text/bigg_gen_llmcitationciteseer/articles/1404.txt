Neural search has recently gained popularity due to its ability to capture semantic relationships between queries and documents. However, it often struggles with vocabulary mismatch and lacks robustness to out-of-vocabulary terms. This paper proposes Contrastive Query Expansion (CQE), a novel method that leverages contrastive learning to generate semantically coherent and diverse query expansions. CQE learns to identify relevant terms by contrasting positive and negative samples, and then uses these terms to expand the original query. Our experiments on several benchmark datasets demonstrate that CQE improves the retrieval performance of neural search models by up to 15%, while reducing the computational overhead by 30% compared to traditional query expansion methods.