Virtual reality (VR) systems often require users to dedicate one hand for navigation, limiting their freedom of movement and immersion. We present EyeGaze+, a novel gaze-based interface that enables hands-free navigation in VR. Our approach leverages machine learning-driven eye-tracking and object detection to infer user intent, allowing users to navigate through virtual environments using only their gaze. We evaluate EyeGaze+ in a user study, demonstrating improved navigation efficiency and reduced user fatigue compared to traditional controller-based methods.