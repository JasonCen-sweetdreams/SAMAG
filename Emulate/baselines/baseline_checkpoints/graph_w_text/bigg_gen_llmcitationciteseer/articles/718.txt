Coordinating autonomous vehicles in complex urban environments requires efficient communication and decision-making among agents. This paper proposes a novel hierarchical attention-based multi-agent reinforcement learning framework, 'HierAttn-MARL', which enables agents to selectively focus on relevant information from neighboring vehicles and the environment. We demonstrate improved coordination and reduced collisions in simulated urban scenarios, outperforming existing decentralized and centralized approaches. HierAttn-MARL's adaptability to changing traffic patterns and its ability to handle partial observability make it a promising solution for real-world autonomous vehicle deployment.