Augmented reality (AR) systems have become increasingly popular, but their user interfaces often rely on indirect input methods, such as controllers or voice commands. This paper explores the potential of gaze-based interfaces for AR, where users interact with virtual objects using their gaze. We designed and evaluated a gaze-based AR system, examining both user experience and performance metrics. Our results show that gaze-based interaction can improve user engagement and reduce task completion time, especially for complex AR tasks. We also identify key challenges and limitations, including accuracy and calibration issues, and discuss implications for future AR interface design.