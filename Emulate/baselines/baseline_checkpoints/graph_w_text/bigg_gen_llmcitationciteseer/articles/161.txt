Explainable recommendation systems (ERS) have gained significant attention in recent years due to the growing need for transparency in AI-driven decision-making. This paper proposes a novel hybrid attentional graph neural network (HAGNN) framework that integrates graph convolutional networks (GCNs) with attention-based transformers for ERS. HAGNN leverages the strengths of both models to capture complex item relationships and user preferences, while providing interpretable explanations for its recommendations. Our extensive experiments on several benchmark datasets demonstrate the superiority of HAGNN over state-of-the-art methods in terms of both recommendation accuracy and explanation quality.