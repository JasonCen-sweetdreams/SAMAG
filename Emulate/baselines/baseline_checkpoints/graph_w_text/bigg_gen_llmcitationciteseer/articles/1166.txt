Emotion recognition from speech and text is a crucial AI application, but existing models often suffer from high computational complexity and lack of interpretability. This paper proposes a novel hierarchical multi-task learning framework, 'EMoTask', which jointly learns emotion recognition and related tasks such as sentiment analysis and speaker diarization. By sharing knowledge across tasks and leveraging task hierarchies, EMoTask achieves significant improvements in emotion recognition accuracy and efficiency while providing insights into the decision-making process through task-specific attention weights. Experimental results on benchmark datasets demonstrate the effectiveness of EMoTask in various emotional intelligence applications.