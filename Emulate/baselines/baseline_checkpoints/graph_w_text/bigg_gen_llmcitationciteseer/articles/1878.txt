Individuals with motor disabilities face significant challenges when interacting with digital systems. This paper presents a novel approach to designing adaptive gesture-based interfaces that can accommodate varying levels of motor ability. We propose a machine learning-based framework that uses real-time gesture recognition and adaptation to provide personalized interaction modalities. Our user study with 20 participants with motor disabilities demonstrates significant improvements in interaction accuracy and user satisfaction compared to traditional gesture-based interfaces. Our findings have implications for the design of inclusive and accessible HCI systems.