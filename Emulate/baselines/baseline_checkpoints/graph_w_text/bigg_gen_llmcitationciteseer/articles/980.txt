We present a novel approach to decentralized task allocation in multi-agent systems, where agents learn to allocate tasks autonomously using reinforcement learning. Our method, called 'Dec-TARL', leverages a decentralized actor-critic framework to learn optimal task allocation policies. We evaluate Dec-TARL in a simulated urban search and rescue scenario, demonstrating improved task completion rates and reduced communication overhead compared to traditional centralized methods. Our results show that Dec-TARL can effectively scale to large teams of agents, making it a promising solution for real-world multi-agent systems.