As augmented reality (AR) technology becomes increasingly prevalent, there is a growing need for effective human-computer interaction (HCI) methods. This paper introduces 'GazeVA', a novel gaze-based interaction framework for virtual assistants in AR environments. GazeVA leverages machine learning-based gaze estimation and natural language processing to enable users to interact with virtual agents using only their gaze and voice commands. We evaluate GazeVA in a user study and demonstrate significant improvements in interaction efficiency and user satisfaction compared to traditional controller-based input methods.