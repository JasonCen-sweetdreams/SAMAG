Anomaly detection in time-series data is crucial for various applications, including predictive maintenance, healthcare, and finance. This paper proposes a novel hierarchical graph convolutional network (HGCN) architecture for explainable AI-driven anomaly detection. Our approach leverages the strengths of graph neural networks and hierarchical representations to capture complex patterns in time-series data. We introduce a novel explainability module that provides feature importance scores, enabling the identification of contributing factors to detected anomalies. Experimental results on real-world datasets demonstrate the effectiveness of our approach in detecting anomalies and improving explainability compared to state-of-the-art methods.