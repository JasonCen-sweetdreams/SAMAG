 Gesture recognition systems have transformative potential for individuals with motor impairments, but existing solutions often neglect accessibility considerations. This paper presents 'EasyMotion', a novel framework that incorporates participatory design and machine learning to recognize gestures from users with varying abilities. We conducted co-design workshops with individuals with motor impairments to inform the development of a gesture vocabulary and an adaptive recognition algorithm. Experimental results show that EasyMotion achieves high recognition accuracy (95.6%) and outperforms state-of-the-art systems in user satisfaction and usability metrics.