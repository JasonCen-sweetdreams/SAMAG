Autonomous urban traffic management poses a complex problem of coordinating multiple agents to optimize traffic flow. This paper proposes a decentralized, reinforcement learning-based framework, 'CATS', that enables autonomous vehicles to learn cooperative policies for traffic signal control. We introduce a novel, attention-based mechanism that allows agents to share knowledge and adjust to changing traffic conditions. Experimental results on a simulated urban traffic network demonstrate that CATS reduces congestion by 23% compared to traditional, rule-based traffic signal control systems.