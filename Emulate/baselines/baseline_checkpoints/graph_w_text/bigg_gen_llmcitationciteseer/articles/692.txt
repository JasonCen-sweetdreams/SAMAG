Distributed column-store databases have become increasingly popular for storing and querying large datasets. However, query optimization remains a significant challenge due to the complex interplay between data distribution, storage, and query execution plans. This paper proposes a novel approach to query optimization using reinforcement learning, where an agent learns to select optimal query plans based on a reward function that balances query latency and resource utilization. We evaluate our approach on a real-world dataset and demonstrate significant improvements in query performance compared to traditional optimization techniques.