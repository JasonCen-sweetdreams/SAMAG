Individuals with motor impairments often face significant barriers when interacting with digital systems. This paper presents a novel approach to designing adaptive gestural interfaces that can accommodate a wide range of motor abilities. Our system, 'GestAid', uses a machine learning-based framework to analyze the user's gestures and adapt the interface in real-time to their capabilities. We evaluate GestAid with a user study involving 20 participants with varying levels of motor impairment, demonstrating improved interaction accuracy and user satisfaction compared to traditional interface designs.