Virtual reality (VR) systems often rely on manual controllers for interaction, which can be cumbersome and limit the sense of immersion. In this paper, we propose a gaze-based interaction system for VR that leverages deep learning-based eye movement prediction. Our approach uses a convolutional neural network (CNN) to predict the user's gaze direction from eye movement data, and then maps the predicted gaze to a corresponding action in the virtual environment. We evaluate our system in a user study and show that it achieves high accuracy and low latency, enabling users to interact with virtual objects in a natural and intuitive way.