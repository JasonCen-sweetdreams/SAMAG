In multi-agent systems, task allocation is a crucial problem that requires efficient and adaptive decision-making. This paper presents a novel decentralized task allocation framework that leverages deep graph reinforcement learning. Our approach, dubbed 'GraphMA', represents the agent-task graph as a dynamic relational structure and learns a policy that maximizes task completion while minimizing communication overhead. We demonstrate GraphMA's effectiveness in simulated environments and real-world robotics scenarios, showcasing improved task allocation efficiency and adaptability to changing environmental conditions.