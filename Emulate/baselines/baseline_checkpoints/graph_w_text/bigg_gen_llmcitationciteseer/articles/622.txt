Multi-agent systems (MAS) are increasingly used in real-world applications, but their decision-making processes often lack transparency. This paper proposes a novel Hierarchical Attention Network (HAN) architecture for explainable decision-making in MAS. HAN leverages attention mechanisms to capture complex dependencies between agents and their environment, enabling the generation of interpretable explanations for joint actions. Experimental results on a simulated traffic management scenario demonstrate that HAN outperforms state-of-the-art MAS methods while providing meaningful insights into agent decision-making processes.