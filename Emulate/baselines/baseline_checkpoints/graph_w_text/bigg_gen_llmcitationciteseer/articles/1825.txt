In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a novel approach that leverages graph convolutional networks (GCNs) to learn cooperative task allocation strategies. We model the agent-task interactions as a graph and propose a GCN-based architecture that incorporates agent features, task requirements, and environmental constraints. Experimental results on a simulated search-and-rescue scenario demonstrate that our approach outperforms traditional methods, achieving higher task completion rates and reduced communication overhead. We also analyze the learned GCN embeddings to provide insights into the emergent coordination patterns among agents.