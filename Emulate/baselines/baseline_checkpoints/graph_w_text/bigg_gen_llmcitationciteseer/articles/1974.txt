This paper presents a novel approach to distributed constraint optimization problems (DCOPs) using multi-agent reinforcement learning (MARL). We propose a framework that enables agents to learn cooperative policies to solve DCOPs in a decentralized manner. Our approach combines graph neural networks with deep Q-networks to learn effective communication and decision-making strategies. Experimental results on a set of benchmark DCOP instances demonstrate the effectiveness of our approach in terms of solution quality and computational efficiency, outperforming existing state-of-the-art methods.