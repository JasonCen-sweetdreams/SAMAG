Virtual reality (VR) has become increasingly popular, but current interfaces often neglect the user's gaze as a valuable input modality. We propose a novel gaze-informed adaptive interface (GIAI) that leverages eye-tracking data to dynamically adjust the VR environment, enhancing user experience and reducing cognitive load. Our approach integrates a machine learning-based gaze classification model with a real-time VR rendering engine, enabling personalized interface adaptations. A user study with 30 participants demonstrates significant improvements in task completion time, error rate, and user satisfaction using GIAI compared to traditional VR interfaces.