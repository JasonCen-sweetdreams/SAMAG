Virtual reality (VR) has the potential to revolutionize accessibility, but existing VR systems often exclude users with visual impairments. This paper presents a novel framework, 'AccessibleVR', which incorporates tactile, auditory, and olfactory feedback to provide an immersive experience for visually impaired users. Our approach leverages machine learning-based object recognition and 3D audio spatialization to convey spatial information. We conducted a user study with 20 visually impaired participants, demonstrating significant improvements in navigation and object interaction using AccessibleVR compared to traditional screen-reader-based interfaces.