Deep neural networks are vulnerable to backdoor attacks, where maliciously crafted inputs can manipulate the model's predictions. Adversarial training is a promising defense strategy, but existing methods are computationally expensive and often require large datasets. This paper proposes a novel efficient adversarial training framework, 'EfficientBackdoor', which leverages a surrogate model-based approach to generate adversarial examples. We introduce a gradient-based optimization technique that reduces the computational overhead while maintaining the robustness of the trained model. Experimental results on multiple benchmark datasets demonstrate that EfficientBackdoor achieves state-of-the-art robustness against backdoor attacks with significantly reduced training time.