Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables understanding of complex decision-making processes. This paper presents Hierarchical Graph Attention Networks (HGAT), a novel architecture that integrates graph attention mechanisms with hierarchical reinforcement learning. HGAT learns to represent agents' interactions as hierarchical graphs, allowing it to focus on relevant agents and their relationships. We demonstrate HGAT's ability to provide interpretable explanations for MARL policies in complex scenarios, while achieving superior performance compared to state-of-the-art methods. Experimental results on the SMAC benchmark show that HGAT improves the transparency and accountability of MARL systems.