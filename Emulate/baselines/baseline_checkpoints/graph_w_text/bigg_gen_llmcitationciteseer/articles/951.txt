Neural information retrieval (IR) models have demonstrated superior performance in ad-hoc retrieval tasks. However, they often struggle with lexical gaps between queries and documents. This paper proposes a novel query expansion approach, 'NeuQE', which leverages the semantic representation capabilities of neural models to generate context-aware expansion terms. We introduce a reinforcement learning-based framework that optimizes the query expansion process by maximizing the expected retrieval performance. Experimental results on several benchmark datasets show that NeuQE significantly outperforms traditional query expansion methods and improves the overall retrieval effectiveness of neural IR models.