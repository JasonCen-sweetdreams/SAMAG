This paper addresses the problem of cooperative task allocation in multi-agent systems, where agents with different capabilities and resources must work together to accomplish complex tasks. We propose a graph-based reinforcement learning approach, 'Graph-MARL', which learns to allocate tasks by modeling the agents' interactions as a graph. Graph-MARL uses a decentralized policy gradient method to optimize the task allocation policy, taking into account the agents' individual preferences and the global system constraints. Experimental results on a simulated disaster response scenario demonstrate that Graph-MARL outperforms existing methods in terms of task completion rate and overall system efficiency.