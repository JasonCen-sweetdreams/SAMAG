Recent advancements in neural ranking models have significantly improved the performance of information retrieval systems. However, these models often come with high computational costs, limiting their applicability to large-scale systems. This paper proposes a novel hybrid neural ranking model, 'HNRM', which combines the strengths of traditional term-based retrieval methods with the learning capabilities of neural networks. HNRM leverages a hierarchical attention mechanism to selectively integrate term-based features and neural embeddings, enabling efficient and effective document retrieval. Experimental results on the TREC Deep Learning Track dataset demonstrate that HNRM outperforms state-of-the-art neural ranking models while reducing computational overhead by up to 40%.