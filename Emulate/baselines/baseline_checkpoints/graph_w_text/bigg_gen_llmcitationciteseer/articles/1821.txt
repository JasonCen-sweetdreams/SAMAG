Virtual reality (VR) has transformed the way users interact with digital information, but understanding user experience in VR environments remains a challenge. This paper presents a novel approach to analyzing eye movement patterns to infer user experience in VR. We propose a machine learning-based framework, 'EyeUX', which leverages a combination of eye tracking data, head movement, and user feedback to predict user satisfaction. Our results show that EyeUX can accurately identify areas of high visual attention and disengagement, enabling designers to optimize VR interfaces for enhanced user experience. We demonstrate the effectiveness of EyeUX in a case study on a popular VR game.