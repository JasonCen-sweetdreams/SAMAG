Decentralized task allocation is a fundamental problem in multi-agent systems, where agents need to coordinate to accomplish complex tasks. This paper proposes a novel approach using graph neural networks (GNNs) to learn decentralized task allocation policies. Our method, called GraphAgent, represents the agent interaction graph as a dynamic graph signal processing framework, allowing agents to learn from local observations and communicate with their neighbors to allocate tasks efficiently. Experimental results on a variety of synthetic and real-world scenarios demonstrate the effectiveness of GraphAgent in achieving high task allocation efficiency and robustness to agent failures.