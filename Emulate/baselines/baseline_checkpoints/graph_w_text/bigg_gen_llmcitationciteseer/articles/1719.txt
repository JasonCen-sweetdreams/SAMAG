Multi-agent systems often require efficient task allocation strategies to achieve complex goals. This paper proposes a decentralized framework for heterogeneous agents, where each agent learns to allocate tasks using graph-based reinforcement learning. We model the agent communication network as a graph and employ a novel graph convolutional policy to learn task allocation decisions. Our approach is evaluated on a simulated logistics scenario, demonstrating improved task completion rates and reduced communication overhead compared to traditional centralized approaches.