This paper presents a novel multi-agent reinforcement learning framework that leverages graph attention mechanisms to efficiently scale to large numbers of agents. Our approach, dubbed 'GraphMARL', incorporates a hierarchical graph structure to model complex agent interactions and enables adaptive attention weights to focus on relevant agent relationships. We evaluate GraphMARL on a range of cooperative and competitive tasks, demonstrating significant improvements in both learning speed and final policy performance compared to existing methods. Our results have important implications for real-world applications such as autonomous traffic management and smart grid control.