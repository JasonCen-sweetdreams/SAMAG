In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper proposes a decentralized task allocation framework, 'Hierarchical-Agent', which leverages hierarchical reinforcement learning to enable agents to adapt to changing environments. We introduce a novel hierarchical architecture that consists of a high-level task allocator and low-level agent controllers, which are trained using a decentralized, model-free reinforcement learning algorithm. Experimental results on a simulated robotic search-and-rescue scenario demonstrate that Hierarchical-Agent outperforms traditional, centralized allocation methods in terms of task completion time and adaptability to unexpected events.