In multi-agent systems, task allocation is a critical problem that requires efficient and adaptive decision-making. This paper presents a novel approach to coordinated task allocation using graph-based reinforcement learning. We model the agent-task interaction as a graph and employ a decentralized Q-learning algorithm to learn optimal task assignments. Our approach leverages graph convolutional networks to capture structural dependencies between agents and tasks, enabling more effective coordination. Experimental results on a simulated warehouse management scenario demonstrate significant improvements in task completion rates and reduced communication overhead compared to traditional auction-based methods.