The increasing adoption of autonomous vehicles (AVs) has created a pressing need for efficient coordination mechanisms to ensure safe and efficient traffic flow. This paper proposes a novel multi-agent reinforcement learning framework, 'MARL-Coord', to coordinate AVs in dynamic traffic scenarios. We model the problem as a decentralized partially observable Markov decision process and employ a graph neural network-based architecture to learn coordination strategies. Our experiments demonstrate that MARL-Coord outperforms traditional traffic signal control methods in reducing congestion and travel times, while improving safety and stability.