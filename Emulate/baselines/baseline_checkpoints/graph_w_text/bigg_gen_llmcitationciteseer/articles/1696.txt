Coordinating multi-agent systems is a challenging problem that arises in various applications, including autonomous vehicles, smart grids, and robotics. This paper proposes a novel framework for coordinating multi-agent systems using dynamic partially observable Markov decision processes (D-POMDPs). Our approach leverages a hierarchical decomposition of the problem space, allowing agents to reason about their local observations and coordinate with other agents to achieve global objectives. We provide a theoretical analysis of the proposed framework and demonstrate its effectiveness in a simulated traffic management scenario, showing improved coordination and reduced congestion compared to existing methods.