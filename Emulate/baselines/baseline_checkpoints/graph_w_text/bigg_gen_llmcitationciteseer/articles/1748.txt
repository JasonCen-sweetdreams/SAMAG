This paper presents a novel multi-agent reinforcement learning (MARL) framework for real-time traffic control. We propose a scalable architecture that leverages decentralized learning and communication protocols to enable efficient coordination among autonomous agents. Our approach, 'TrafficMAgent', incorporates graph neural networks to model complex traffic patterns and utilizes a hierarchical reinforcement learning strategy to optimize traffic flow. Experimental results on a large-scale traffic simulation demonstrate that TrafficMAgent outperforms state-of-the-art MARL methods in terms of reduce congestion and travel time.