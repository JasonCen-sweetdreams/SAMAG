Graph neural networks (GNNs) have shown promising results in node classification tasks, but their performance degrades when faced with limited labeled data. We propose a novel hierarchical attention-based GNN architecture, HAGNet, which leverages the hierarchical structure of graph data to adaptively focus on relevant nodes and features. Our approach achieves state-of-the-art results on several benchmarks, even when only a few labeled nodes are available. We provide theoretical insights into the effectiveness of hierarchical attention and demonstrate HAGNet's robustness to varying graph structures and node degrees.