Brain-Computer Interfaces (BCIs) have revolutionized assistive technology, but their efficiency is often hindered by inadequate visualization of neural signals. This paper introduces 'NeuroVista', a novel multimodal visualization framework that adaptively adjusts to the user's brain activity, cognitive load, and feedback preferences. Our approach combines electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) signals to provide a more comprehensive understanding of user intent. We evaluate NeuroVista through a user study, demonstrating significant improvements in BCI accuracy, user satisfaction, and cognitive workload reduction.