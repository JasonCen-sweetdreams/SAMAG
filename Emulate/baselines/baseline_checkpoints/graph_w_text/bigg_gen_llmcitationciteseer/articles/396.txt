Urban traffic congestion is a pressing concern, and real-time optimization can significantly mitigate its impact. This paper proposes a decentralized multi-agent system (MAS) framework, 'TrafficOpt', which leverages reinforcement learning (RL) to coordinate autonomous vehicles and traffic signals. We develop a novel, distributed RL algorithm that enables agents to learn from local observations and communicate with neighbors to optimize traffic flow. Experiments on a simulated traffic network demonstrate that TrafficOpt reduces congestion by 23% compared to traditional, centralized approaches, while adapting to dynamic traffic patterns and minimizing communication overhead.