Decentralized task allocation is a fundamental problem in multi-agent systems, where agents need to allocate tasks to maximize overall system efficiency. This paper proposes a novel hierarchical reinforcement learning approach, called HRL-TA, to solve this problem. HRL-TA consists of a high-level task allocation module and a low-level action selection module, which learn to allocate tasks and select actions in a decentralized manner. We evaluate HRL-TA in a simulated logistics scenario, where agents need to allocate tasks to deliver packages to customers. Experimental results show that HRL-TA outperforms traditional decentralized task allocation methods, achieving higher system efficiency and scalability.