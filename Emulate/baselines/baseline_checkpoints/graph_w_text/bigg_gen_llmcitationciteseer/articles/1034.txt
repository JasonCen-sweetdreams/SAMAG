As augmented reality (AR) technology becomes increasingly prevalent, there is a growing need for intuitive and accurate gesture recognition systems. This paper presents an adaptive gesture recognition framework that leverages machine learning and computer vision techniques to recognize and adapt to user gestures in real-time. Our approach incorporates a novel gesture representation model that combines skeletal data with surface electromyography (sEMG) signals, enabling more accurate and personalized recognition. We evaluate our system through a user study, demonstrating significant improvements in recognition accuracy and user satisfaction compared to existing state-of-the-art methods.