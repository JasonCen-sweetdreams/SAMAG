Multi-agent systems require effective cooperation to achieve complex tasks. This paper presents a novel hierarchical attention network (HAN) architecture that enables agents to learn cooperative strategies from raw observation data. HAN integrates intra-agent attention to focus on relevant observations and inter-agent attention to model relationships between agents. We evaluate HAN on a suite of cooperative navigation tasks and demonstrate improved team performance compared to existing multi-agent reinforcement learning methods. Our approach paves the way for more sophisticated AI systems that can seamlessly coordinate with human agents.