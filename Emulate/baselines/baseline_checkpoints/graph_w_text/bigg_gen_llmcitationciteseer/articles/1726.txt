Virtual reality (VR) has the potential to revolutionize accessibility for individuals with disabilities. However, existing VR interfaces often neglect the emotional and cognitive states of users, leading to frustration and disengagement. This paper presents an emotion-aware adaptive interface framework, 'EmpaVR', which leverages real-time affective computing and user modeling to dynamically adjust VR experiences. EmpaVR incorporates machine learning-driven emotional state recognition, personalized feedback mechanisms, and adaptivity algorithms to optimize user engagement and task performance. Our user study with 30 participants showed significant improvements in emotional satisfaction, task completion rates, and self-reported accessibility.