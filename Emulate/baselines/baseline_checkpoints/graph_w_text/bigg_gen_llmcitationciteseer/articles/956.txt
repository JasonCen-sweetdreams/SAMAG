In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel distributed task allocation framework, 'Graph-MARL', which leverages graph reinforcement learning to optimize task assignments for heterogeneous agents. By modeling agent interactions as a graph, we can capture complex dependencies and constraints, and learn effective allocation policies that adapt to changing environmental conditions. Our experiments on a variety of benchmark scenarios demonstrate that Graph-MARL outperforms state-of-the-art decentralized task allocation methods in terms of task completion time and system efficiency.