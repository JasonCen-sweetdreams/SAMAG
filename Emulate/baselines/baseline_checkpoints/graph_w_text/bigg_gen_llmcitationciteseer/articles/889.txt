Virtual reality (VR) interfaces rely on accurate user intention recognition to provide seamless interactions. This paper presents EyeGazeTracker, a machine learning-based approach that leverages eye-tracking data to predict user intentions in VR environments. We propose a novel gaze-based feature extraction method that captures subtle changes in user attention and combines it with a hierarchical classification framework to recognize user intentions. Our evaluation on a large-scale VR dataset demonstrates that EyeGazeTracker outperforms state-of-the-art methods in predicting user intentions, achieving an average accuracy of 92.5%. The proposed approach has significant implications for enhancing user experience in VR applications.