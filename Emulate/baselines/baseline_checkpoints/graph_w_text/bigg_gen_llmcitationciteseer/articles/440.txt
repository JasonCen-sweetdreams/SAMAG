Few-shot learning has gained significant attention in recent years, but existing methods often struggle with scalability and graph-structured data. We propose a novel Hierarchical Graph Attention Network (HGAT) framework that leverages a hierarchical attention mechanism to efficiently process graph data. HGAT adaptively focuses on relevant sub-graphs and meta-learns a robust feature extractor, enabling effective few-shot learning on large-scale graph datasets. Our experiments on multiple benchmark datasets demonstrate HGAT's state-of-the-art performance and improved scalability compared to existing few-shot learning methods.