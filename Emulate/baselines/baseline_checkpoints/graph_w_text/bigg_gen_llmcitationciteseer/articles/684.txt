Object detection remains a fundamental problem in computer vision, but the quest for efficient models that balance accuracy and speed has led to a proliferation of architectural designs. This paper proposes a novel meta-learning approach to neural architecture search (NAS) for object detection, dubbed 'MetaOD'. By learning to adapt to diverse object detection tasks, MetaOD discovers efficient architectures that outperform state-of-the-art detectors on COCO and PASCAL VOC benchmarks. We demonstrate that our method reduces the search space by 3 orders of magnitude while achieving 2x faster inference times without compromising accuracy.