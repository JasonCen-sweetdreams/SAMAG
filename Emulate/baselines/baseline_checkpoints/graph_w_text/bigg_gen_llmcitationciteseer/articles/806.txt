Optimizing query execution plans in distributed database systems is a complex problem due to the exponential growth of possible plans. Traditional approaches rely on rule-based systems or static cost models, which may not adapt well to changing workloads. This paper explores the application of reinforcement learning to query optimization, where the database system learns to select optimal plans based on feedback from past executions. We propose a novel framework, 'RL-Optimizer', which integrates a deep Q-network with a distributed database system. Experimental results on the TPC-DS benchmark demonstrate that RL-Optimizer outperforms state-of-the-art optimizers in reducing query latency and improving system throughput.