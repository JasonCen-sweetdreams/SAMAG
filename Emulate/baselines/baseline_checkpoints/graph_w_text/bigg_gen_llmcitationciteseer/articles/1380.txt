Urban traffic management is a complex problem that requires coordinating agents with different goals, constraints, and capabilities. This paper proposes a novel approach that leverages deep reinforcement learning to coordinate heterogeneous agents, including traffic signals, autonomous vehicles, and human-driven cars. We introduce a multi-agent framework that integrates graph attention networks and deep Q-networks to learn effective policies for minimizing congestion, reducing travel times, and improving safety. Experimental results using real-world traffic data from San Francisco demonstrate that our approach outperforms state-of-the-art methods and achieves significant improvements in traffic efficiency.