Dialogue state tracking (DST) is a crucial component of task-oriented dialogue systems, but it remains a challenging problem in multi-domain settings. This paper introduces Hierarchical Attention Networks (HANs) to model the hierarchical structure of dialogue states and capture dependencies between domains. Our approach leverages a novel attention mechanism that selectively focuses on relevant dialogue context and domain-specific knowledge graphs. Experimental results on the MultiWOZ dataset demonstrate that HANs outperform state-of-the-art DST models in terms of joint goal accuracy and scalability, while reducing model parameters by 30%