Recommendation systems have become ubiquitous in modern online services, but their black-box nature raises concerns about transparency and accountability. We propose a novel Hierarchical Attention Network (HAN) architecture that incorporates explainability mechanisms to provide insights into recommendation decisions. Our approach leverages user and item embeddings to learn attention weights that reflect the relative importance of different features. Extensive experiments on real-world datasets demonstrate that HAN outperforms state-of-the-art recommendation models while providing interpretable explanations for its predictions.