High-dimensional data clustering is a challenging problem in machine learning, particularly when dealing with large datasets. Traditional hierarchical clustering methods suffer from the curse of dimensionality, leading to poor clustering quality and high computational costs. This paper proposes a novel approach, 'Deep Hierarchical Clustering' (DHC), which leverages the representational power of deep neural networks to learn hierarchical cluster structures. We introduce a new loss function that encourages cluster separability and a self-supervised training strategy that eliminates the need for labeled data. Experimental results on several benchmark datasets demonstrate that DHC outperforms state-of-the-art clustering methods in terms of clustering accuracy and computational efficiency.