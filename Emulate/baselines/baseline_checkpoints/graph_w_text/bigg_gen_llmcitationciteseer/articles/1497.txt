As augmented reality (AR) technology becomes increasingly prevalent, there is a growing need for more natural and intuitive interaction methods. This paper proposes a machine learning-based approach for gaze-based interaction with AR displays. We present a novel deep learning model that leverages user gaze patterns to predict their intended interactions with virtual objects. Our approach achieves high accuracy and low latency, enabling seamless interaction with AR environments. We evaluate our method on a dataset of user interactions and demonstrate its effectiveness in various AR applications.