Multi-agent reinforcement learning (MARL) has gained significant attention in recent years, but existing approaches often struggle to scale to complex scenarios. We propose a novel hierarchical graph attention network (HGAT) framework that leverages graph neural networks and attention mechanisms to model complex interactions between agents. Our approach learns to selectively focus on relevant agents and their relationships, enabling more efficient and effective learning in MARL environments. We evaluate HGAT on several benchmarks, demonstrating improved performance and scalability compared to state-of-the-art methods.