Query expansion is a crucial step in information retrieval (IR) systems, as it directly impacts the quality of search results. However, traditional query expansion methods often rely on static, hand-crafted rules or simple statistical models. This paper proposes a novel context-aware query expansion approach, CAQE, which leverages reinforcement learning to dynamically adapt to the search context. CAQE learns to select the most effective expansion terms by interacting with the IR system and receiving rewards based on retrieval performance. Experimental results on several benchmark datasets demonstrate that CAQE outperforms state-of-the-art query expansion methods, achieving significant improvements in precision, recall, and mean average precision.