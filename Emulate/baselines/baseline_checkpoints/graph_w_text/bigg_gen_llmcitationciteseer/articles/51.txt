Cooperative task allocation is a challenging problem in multi-agent systems, where agents must collaborate to achieve a common goal. This paper proposes a novel multi-agent reinforcement learning framework that incorporates graph attention mechanisms to model inter-agent dependencies. We introduce a decentralized policy that leverages attention weights to focus on relevant agents and tasks, resulting in improved task allocation efficiency and adaptability. Experimental results on a simulated robotic team demonstrate the effectiveness of our approach in various scenarios, including dynamic task arrivals and agent failures.