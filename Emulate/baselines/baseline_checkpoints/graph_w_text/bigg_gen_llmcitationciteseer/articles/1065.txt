Deep reinforcement learning (DRL) algorithms are vulnerable to adversarial attacks that can compromise their performance and stability. This paper proposes a novel graph-based anomaly detection framework, 'DRL-Guard', to identify and mitigate such attacks in real-time. By modeling the agent's interaction with the environment as a graph, we leverage graph convolutional networks to detect anomalies in the state-action trajectory. Our experiments on popular DRL benchmarks demonstrate that DRL-Guard can detect a wide range of adversarial attacks with high accuracy, while incurring minimal overhead on the agent's policy.