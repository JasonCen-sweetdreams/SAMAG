Multi-agent reinforcement learning (MARL) has seen significant progress in recent years, but the lack of interpretability hinders its adoption in real-world applications. This paper introduces HAN-MARL, a novel hierarchical attention network that learns to explain the decision-making process of each agent in a multi-agent system. Our approach leverages attention mechanisms to identify relevant features and agents, and generates natural language explanations for the learned policies. Experimental results on a series of benchmarks demonstrate that HAN-MARL outperforms state-of-the-art MARL algorithms in terms of both performance and explainability.