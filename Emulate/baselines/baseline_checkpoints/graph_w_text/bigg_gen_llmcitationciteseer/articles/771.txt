Coordinating multiple agents in complex, dynamic environments is a fundamental challenge in artificial intelligence. We propose a novel framework for decentralized decision-making, which leverages partially observable Markov decision processes (POMDPs) to model individual agents' interactions. Our approach, dubbed 'Dec-POMDP-MA', enables agents to reason about incomplete information and coordinate their actions without centralized control. We demonstrate the effectiveness of Dec-POMDP-MA in a simulated disaster response scenario, where multiple agents must navigate uncertain environments to achieve a common goal.