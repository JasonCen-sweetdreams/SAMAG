Voice assistants have become ubiquitous, but their limitations can lead to frustration and exclusion for users with disabilities. This paper investigates multimodal error recovery strategies for voice assistants, focusing on individuals with visual impairments. We designed and evaluated a novel interface that combines speech, touch, and vibration cues to facilitate error correction. Our user study with 20 participants demonstrates significant improvements in task completion rates and user satisfaction compared to traditional speech-only interfaces. The findings inform the development of more inclusive and accessible voice assistants.