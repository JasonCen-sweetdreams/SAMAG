This paper presents a novel hierarchical multi-agent reinforcement learning framework for autonomous traffic management. Our approach, dubbed 'HMRAT', consists of a two-level hierarchy: a high-level controller that allocates traffic signals to individual intersections and a low-level controller that optimizes traffic flow at each intersection. We employ a decentralized actor-critic algorithm to learn cooperative policies among agents, leveraging graph attention mechanisms to model complex traffic dynamics. Experimental results on a simulated urban traffic network demonstrate that HMRAT significantly reduces congestion and travel times compared to traditional traffic signal control methods.