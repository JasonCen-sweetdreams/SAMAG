Ad-hoc retrieval systems struggle to effectively capture user intent from short, ambiguous queries. We propose a neural query expansion framework that incorporates pseudo-relevance feedback to improve retrieval performance. Our approach leverages a transformer-based architecture to learn contextualized representations of query terms and pseudo-relevant documents. Experimental results on several benchmark datasets demonstrate significant improvements in retrieval effectiveness, particularly for verbose queries. We also show that our approach can be effectively combined with traditional retrieval models to achieve state-of-the-art performance.