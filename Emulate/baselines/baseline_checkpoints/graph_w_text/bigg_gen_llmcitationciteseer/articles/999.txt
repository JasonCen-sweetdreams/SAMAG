This paper presents a novel approach to recognizing users' intentions from their gaze patterns, enabling the development of adaptive user interfaces that can dynamically adjust to users' goals. We propose a deep learning-based model that combines convolutional and recurrent neural networks to analyze eye-tracking data and infer user intentions. Our approach is evaluated on a dataset of 30 participants performing various tasks on a desktop computer, achieving an accuracy of 87.5% in intention recognition. The results demonstrate the potential of gaze-based intention recognition for enhancing user experience and improving interface adaptability.