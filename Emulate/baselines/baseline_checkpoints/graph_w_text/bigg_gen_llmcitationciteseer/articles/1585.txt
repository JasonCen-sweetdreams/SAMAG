This paper presents a novel approach to designing personalized gesture recognition systems for individuals with motor impairments. We propose a machine learning framework that leverages a combination of computer vision and sensor data to recognize gestures, and incorporates a user-centered design approach to accommodate individual differences in motor abilities. Our system, called 'GestureFit', uses a hierarchical clustering algorithm to group users based on their gesture patterns, and adapts the recognition model to each user's unique characteristics. We evaluate GestureFit with a user study involving 20 participants with motor impairments, and demonstrate significant improvements in gesture recognition accuracy compared to existing systems.