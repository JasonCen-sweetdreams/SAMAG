In virtual reality (VR) systems, users rely heavily on visual and auditory cues to navigate virtual environments. However, neglecting the haptic channel can lead to a sense of disconnection and reduced immersion. This paper presents a novel vibro-tactile feedback framework that leverages haptic cueing to enhance user experience in VR. Our approach utilizes machine learning-based pattern recognition to identify subtle hand and finger movements, generating synchronized vibrotactile feedback to amplify proprioceptive awareness. In a user study with 30 participants, we demonstrate significant improvements in task completion time, accuracy, and overall user satisfaction compared to traditional visual-only interfaces.