Query expansion is a crucial step in ad-hoc retrieval, but existing methods often rely on heuristics or manual tuning. We propose a novel query expansion approach, QERL, which leverages reinforcement learning to adaptively select expansion terms. Our method incorporates a reward function that balances retrieval precision and recall, and utilizes a deep Q-network to learn the optimal expansion policy. Experimental results on the TREC Robust04 dataset demonstrate that QERL outperforms state-of-the-art methods in terms of mean average precision and NDCG@20, with significant improvements in cold-start scenarios.