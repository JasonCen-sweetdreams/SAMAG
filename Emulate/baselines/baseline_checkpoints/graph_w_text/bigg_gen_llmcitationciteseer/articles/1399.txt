Ad-hoc search systems rely on query expansion techniques to improve retrieval effectiveness. This paper explores the application of neural retrieval models to query expansion, proposing a novel approach that leverages the semantic capabilities of transformer-based architectures. Our method, dubbed 'NeuroXPand', uses a fine-tuned BERT model to generate context-aware expansion terms, which are then combined with traditional retrieval models to produce a robust ranking. Experimental results on the TREC-8 ad-hoc track demonstrate significant improvements in mean average precision and NDCG, especially for difficult queries.