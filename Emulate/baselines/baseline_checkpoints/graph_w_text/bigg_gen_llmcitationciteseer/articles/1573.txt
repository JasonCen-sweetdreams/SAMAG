In multi-agent systems, coordinated exploration is crucial for efficient decision-making. However, the complexity of agent interactions and the large state space make it challenging to design effective exploration strategies. This paper introduces a novel approach, Graph Attention-based Coordinated Exploration (GACE), which leverages graph attention networks to model agent interactions and learn a coordinated exploration policy. We demonstrate the effectiveness of GACE in a variety of multi-agent environments, including robotic swarms and smart traffic management, and show improved performance compared to state-of-the-art methods.