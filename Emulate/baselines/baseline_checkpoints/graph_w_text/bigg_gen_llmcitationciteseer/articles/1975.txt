We propose a novel decentralized task allocation framework for autonomous agents, leveraging multi-armed bandit (MAB) algorithms to optimize task assignments in dynamic environments. Our approach, 'AgentMAB', allows agents to learn from their interactions with the environment and adapt to changes in task availability and agent capabilities. We introduce a novel reward function that balances exploration and exploitation, and demonstrate through simulations that AgentMAB outperforms traditional assignment algorithms in terms of overall system efficiency and fairness.