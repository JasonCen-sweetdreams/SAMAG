Explainable recommender systems have garnered increasing attention in recent years, as users seek transparency into the reasoning behind suggested items. This paper proposes a novel hierarchical graph attention network (HGAT) architecture, which captures both local and global relationships between users, items, and their attributes. By incorporating attention mechanisms at multiple scales, our model generates interpretable explanations for recommendation results, improving user trust and satisfaction. Experimental results on benchmark datasets demonstrate the effectiveness of HGAT in terms of recommendation accuracy, diversity, and explanation quality.