Query expansion (QE) is a crucial component in ad-hoc retrieval systems, aiming to enhance the retrieval effectiveness by adding relevant terms to the original query. However, existing QE methods often rely on heuristics or manual tuning, leading to suboptimal performance. This paper proposes a novel deep reinforcement learning (DRL) framework, 'QE-DRL', which formulates QE as a sequential decision-making problem. By interacting with the retrieval environment, QE-DRL learns to select optimal expansion terms that maximize the expected retrieval reward. Experimental results on several benchmark datasets demonstrate that QE-DRL outperforms state-of-the-art QE methods, achieving significant improvements in retrieval effectiveness.