Graph embedding has emerged as a crucial technique for graph-structured data analysis. However, existing methods struggle to scale to large multi-relational graphs, which are common in real-world applications. This paper presents Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages hierarchical attention mechanisms to learn distributed representations of nodes in multi-relational graphs. HGAT adaptively selects relevant relational contexts and incorporates them into a hierarchical representation, enabling efficient and effective embedding of large graphs. Experimental results on benchmark datasets demonstrate the superiority of HGAT over state-of-the-art methods in terms of both scalability and performance.