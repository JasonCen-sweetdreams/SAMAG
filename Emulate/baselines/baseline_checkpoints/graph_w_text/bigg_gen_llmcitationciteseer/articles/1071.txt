Cooperative learning in multi-agent systems is challenging due to partial observability and high-dimensional state spaces. This paper proposes a novel hierarchical attention network (HAN) architecture that enables agents to selectively focus on relevant information from their local observations and communicate effectively with teammates. Our HAN-based approach outperforms existing methods in various cooperative tasks, achieving improved convergence speeds and higher reward rates. We also provide theoretical analysis on the attention mechanism, demonstrating its role in reducing the complexity of the joint policy space.