Ad-hoc retrieval systems often struggle to accurately capture user intent, particularly when relevance feedback is limited. This paper proposes a neural query expansion approach, 'NQE-ARF', which leverages a transformer-based architecture to generate context-aware query expansions. Our method incorporates a novel attention mechanism that selectively weights relevance feedback to adaptively refine query representations. Experimental results on the TREC-8 ad-hoc retrieval benchmark demonstrate that NQE-ARF outperforms state-of-the-art query expansion techniques, achieving significant improvements in retrieval effectiveness and robustness.