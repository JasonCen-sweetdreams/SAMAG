Accurate and efficient object detection is a critical component of autonomous vehicle systems. This paper presents a novel real-time object detection framework, 'YOLO-Evolve', which leverages the You Only Look Once (YOLO) architecture and incorporates several optimizations for improved speed and accuracy. We propose a hierarchical feature fusion approach that combines multi-scale feature maps, a spatial attention module, and a confidence-based non-maximum suppression technique. Experiments on the KITTI and Cityscapes datasets demonstrate that YOLO-Evolve achieves state-of-the-art performance while maintaining a processing time of under 30 ms per frame.