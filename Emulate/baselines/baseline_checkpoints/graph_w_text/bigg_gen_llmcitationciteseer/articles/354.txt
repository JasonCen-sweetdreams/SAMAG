Multi-label classification is a fundamental problem in machine learning, where each instance can be associated with multiple labels. However, real-world datasets often contain noisy labels, which can significantly degrade the performance of classification models. This paper proposes a novel hierarchical attention network (HAN) to tackle this problem. Our HAN model consists of two stages: a label attention module that adaptively weights the importance of each label, and a instance attention module that selectively focuses on relevant instances. Experimental results on several benchmark datasets demonstrate that our approach outperforms state-of-the-art methods in terms of both accuracy and efficiency, even in the presence of high levels of label noise.