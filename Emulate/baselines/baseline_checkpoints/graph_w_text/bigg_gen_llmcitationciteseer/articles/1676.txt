Ad-hoc search systems often struggle to retrieve relevant documents due to the limited query context. This paper presents a neural query expansion approach, NQE, which leverages transformer-based language models to generate context-aware query expansions. NQE incorporates a novel attention mechanism that selectively weights query terms based on their semantic importance and contextual relevance. Our experiments on the TREC-8 ad-hoc retrieval benchmark show that NQE significantly outperforms state-of-the-art query expansion techniques, achieving a 15% improvement in mean average precision.