Individuals with motor impairments often face barriers when interacting with computers, limiting their ability to fully engage with digital technologies. This paper presents a novel approach to designing adaptive gestural interfaces that can accommodate diverse motor abilities. We propose a machine learning-based framework that leverages user behavior data to dynamically adjust gesture recognition models, enabling more accurate and efficient input. Our user study with 20 participants with motor impairments demonstrates significant improvements in interaction speed and accuracy compared to traditional gestural interfaces. The findings have implications for promoting inclusivity in human-computer interaction design.