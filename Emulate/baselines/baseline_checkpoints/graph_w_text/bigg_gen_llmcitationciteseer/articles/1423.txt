Multi-agent pathfinding is a complex problem in AI, with applications in robotics, video games, and autonomous systems. This paper introduces a novel deep reinforcement learning approach, 'MAP-RL', which leverages graph neural networks to efficiently find near-optimal paths for multiple agents in dynamic environments. We propose a hierarchical planning strategy that decomposes the problem into sub-tasks, enabling faster computation and improved scalability. Experimental results on several benchmarks demonstrate that MAP-RL outperforms state-of-the-art algorithms in terms of solution quality and computational efficiency.