Graph-structured data is ubiquitous in many domains, but existing graph neural networks often overlook the hierarchical structure inherent in these graphs. We propose a novel hierarchical attention-based graph neural network (HAGNN) that learns to selectively focus on relevant subgraphs and nodes at each level of the hierarchy. Our approach leverages a recursive attention mechanism to capture long-range dependencies and structural relationships, leading to improved feature learning and better performance on downstream tasks. Experimental results on several benchmark datasets demonstrate the effectiveness of HAGNN in graph classification, node classification, and graph regression tasks.