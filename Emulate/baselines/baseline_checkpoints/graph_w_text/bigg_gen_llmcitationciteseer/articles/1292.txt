Deep reinforcement learning (DRL) has achieved impressive results in various domains, but the lack of transparency in decision-making hinders trust and adoption. This paper proposes a novel meta-learning approach, 'EXPLAIN', which enables efficient model-agnostic explainability for DRL policies. By leveraging gradients of the policy's expected return, EXPLAIN learns to generate importance scores for state features, facilitating interpretability without requiring access to the underlying model architecture. We demonstrate the effectiveness of EXPLAIN on several Atari games and a real-world robotic control task, showcasing its ability to provide meaningful explanations for DRL policies.