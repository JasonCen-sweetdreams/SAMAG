Deep neural networks have been shown to be vulnerable to adversarial attacks, which can significantly compromise their performance. This paper proposes a novel Bayesian neural pruning approach, 'BayesPrune', to robustify deep neural networks against such attacks. BayesPrune iteratively prunes the network based on Bayesian uncertainty estimates, removing redundant or vulnerable neurons. We demonstrate that BayesPrune achieves state-of-the-art robustness against various attack types, including PGD and CW attacks, while maintaining accuracy on clean data. Our approach can be integrated with existing defense mechanisms, providing a scalable solution for real-world applications.