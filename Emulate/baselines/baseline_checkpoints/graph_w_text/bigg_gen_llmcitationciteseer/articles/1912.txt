This paper proposes a novel approach to dynamic task allocation in multi-agent systems using reinforcement learning. We introduce a decentralized framework, 'CoopRL', where autonomous agents learn to cooperate and allocate tasks in real-time based on their individual capabilities and environmental changes. Our approach uses a combination of Q-learning and graph-based coalition formation to optimize task allocation and reduce communication overhead. Experimental results demonstrate that CoopRL outperforms traditional centralized approaches in terms of task completion rate and system adaptability.