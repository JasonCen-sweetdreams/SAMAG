Multimodal retrieval has gained significant attention in recent years, but it remains a challenging task due to the complexity of representing and matching diverse multimedia data types. This paper proposes a novel query expansion approach that leverages the strengths of deep neural networks to improve the effectiveness of multimodal retrieval. Our method, called 'DeepQE', uses a multi-task learning framework to jointly learn query representations, document representations, and a similarity metric. Experimental results on a large-scale multimodal dataset show that DeepQE significantly outperforms state-of-the-art query expansion techniques, achieving an average improvement of 15% in terms of mean average precision.