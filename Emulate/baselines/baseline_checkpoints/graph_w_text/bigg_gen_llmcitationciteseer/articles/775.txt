Autonomous vehicles require efficient task allocation strategies to navigate complex scenarios. This paper presents a novel multi-agent reinforcement learning approach, 'MATRL', that enables distributed task allocation among autonomous vehicles. MATRL combines decentralized partially observable Markov decision processes with graph neural networks to learn task allocation policies. We evaluate MATRL in a simulated urban environment, demonstrating improved task completion rates and reduced communication overhead compared to traditional centralized approaches. The proposed framework has potential applications in autonomous delivery, surveillance, and search-and-rescue missions.