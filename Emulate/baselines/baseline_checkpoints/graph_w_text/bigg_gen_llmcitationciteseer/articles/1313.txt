Knowledge graph embeddings have become a crucial component in various AI applications. However, existing methods often suffer from high computational complexity and limited scalability. This paper proposes a novel attention-based graph convolutional network (AGCN) architecture for efficient knowledge graph embeddings. Our approach leverages attention mechanisms to selectively focus on relevant neighbors and filter out noisy information, reducing the computational overhead. Experimental results on several benchmark datasets demonstrate that AGCN achieves state-of-the-art performance while requiring significantly fewer parameters and computations compared to existing methods.