Optimizing query execution plans in distributed graph databases is a challenging problem due to the complex interplay between graph structure, data distribution, and query patterns. This paper proposes a novel reinforcement learning-based approach, 'GraphOpt', which leverages a hierarchical graph representation to learn efficient query plans. Our approach leverages a combination of graph convolutional networks and Q-learning to adapt to changing query workloads and optimize query execution times. Experimental results on real-world graph datasets demonstrate that GraphOpt outperforms state-of-the-art query optimizers by up to 3x in terms of query latency and 2x in terms of resource utilization.