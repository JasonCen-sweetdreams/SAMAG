Conversational interfaces for voice assistants have become increasingly prevalent, but their accessibility for users with disabilities remains a significant concern. This paper presents an emotion-aware dialogue management approach to improve the interaction experience for users with emotional or cognitive impairments. Our proposed framework, 'EmpaDia', incorporates affective computing and machine learning techniques to recognize and respond to user emotions, adapting the conversation flow to accommodate individual needs. Experimental results with 50 participants demonstrate that EmpaDia enhances user satisfaction, reduces frustration, and promotes more effective task completion compared to traditional dialogue management systems.