Passage retrieval is a crucial component of many information retrieval systems. While query expansion has been shown to improve retrieval effectiveness, existing methods often rely on hand-crafted features and heuristics. This paper proposes a novel neural query expansion approach, dubbed 'NeuroQE', which leverages pre-trained language models to generate context-aware query expansions. We demonstrate that NeuroQE outperforms traditional query expansion methods on several benchmark datasets, achieving significant improvements in passage retrieval accuracy. Furthermore, we analyze the robustness of NeuroQE to query ambiguity and variability, showcasing its potential for real-world information retrieval applications.