Coordinating multiple agents to achieve a common goal is a fundamental problem in artificial intelligence. While recent advances in deep reinforcement learning have shown promise, these methods often lack interpretability and transparency. This paper proposes a novel hierarchical attention network (HAN) architecture that facilitates explainable multi-agent cooperation. By incorporating attention mechanisms at both the local and global levels, HAN enables agents to selectively focus on relevant information and communicate effectively with each other. We evaluate HAN on a range of cooperative tasks, demonstrating improved performance and interpretability compared to existing state-of-the-art methods.