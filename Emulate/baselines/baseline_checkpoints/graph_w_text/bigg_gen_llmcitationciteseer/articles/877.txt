This paper presents a novel multi-agent reinforcement learning approach for autonomous traffic signal control. We model traffic signals as agents that learn to cooperate and adapt to dynamic traffic conditions to minimize congestion and reduce travel times. Our method, called MARL-TSC, extends the traditional Q-learning algorithm to incorporate graph neural networks for modeling complex traffic networks. Experimental results on a real-world traffic dataset demonstrate that MARL-TSC outperforms traditional traffic signal control methods, reducing average travel times by up to 23% and decreasing congestion by 17%