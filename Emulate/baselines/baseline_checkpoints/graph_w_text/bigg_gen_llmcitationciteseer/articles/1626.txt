Multi-agent task allocation is a fundamental problem in distributed artificial intelligence. This paper proposes a novel hierarchical reinforcement learning framework, 'HiMAL', which enables efficient task allocation in large-scale multi-agent systems. HiMAL utilizes a two-level hierarchy, where high-level agents learn to allocate tasks to low-level agents based on their capabilities and availability. We demonstrate the scalability and effectiveness of HiMAL through extensive simulations on a variety of task allocation scenarios, showcasing significant improvements over traditionalflat allocation methods.