In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a decentralized approach using reinforcement learning, where agents learn to allocate tasks based on local observations and communication with neighbors. Our method, called 'DRL-TA', uses a novel combination of deep Q-networks and graph neural networks to learn task allocation policies. Experimental results on a simulated robotic search and rescue scenario demonstrate that DRL-TA outperforms traditional decentralized approaches, achieving higher task completion rates and adaptability to dynamic environments.