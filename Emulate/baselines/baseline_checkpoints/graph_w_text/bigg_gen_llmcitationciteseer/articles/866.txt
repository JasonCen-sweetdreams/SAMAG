Task scheduling in multi-agent systems is a challenging problem, particularly when agents have diverse capabilities and tasks have varying priorities. This paper proposes a hierarchical reinforcement learning (HRL) framework that leverages both macro- and micro-level decision-making to optimize task scheduling. Our approach, 'HierSched', decomposes the scheduling problem into a hierarchical structure, where high-level policies select tasks and low-level policies allocate agents. We demonstrate the effectiveness of HierSched in a simulated logistics domain, showing significant improvements in task completion rates and agent utilization compared to state-of-the-art baselines.