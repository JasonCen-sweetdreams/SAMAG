In multi-agent systems, effective task allocation is crucial for achieving global objectives. This paper proposes a novel framework, 'RL-TA', that leverages reinforcement learning to adaptively allocate tasks to agents based on their dynamic capabilities and environmental changes. We introduce a decentralized, model-free approach that enables agents to learn from their interactions and adjust task assignments in real-time. Experimental results demonstrate that RL-TA outperforms traditional, planning-based methods in terms of task completion time and resource utilization, even in the presence of agent failures and communication disruptions.