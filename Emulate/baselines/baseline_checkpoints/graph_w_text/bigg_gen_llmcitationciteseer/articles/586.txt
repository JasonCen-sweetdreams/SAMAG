Deep learning models are vulnerable to adversarial attacks, which can compromise their performance in critical applications. Existing defense methods focus on known attack types, but unknown attacks can still cause significant damage. This paper proposes a novel adversarial training framework, 'ATAK', which leverages a generative model to simulate unknown attacks and augment the training dataset. We demonstrate that ATAK improves the robustness of deep neural networks against a wide range of unknown attacks, including those generated by state-of-the-art attack algorithms. Our experiments on multiple benchmark datasets show that ATAK achieves state-of-the-art performance in terms of robustness and accuracy.