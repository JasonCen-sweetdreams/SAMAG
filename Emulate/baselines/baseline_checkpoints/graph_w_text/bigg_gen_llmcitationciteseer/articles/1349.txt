Virtual reality (VR) technology has the potential to revolutionize various aspects of our lives, but accessibility remains a significant barrier for individuals with motor impairments. This paper presents 'GazeInt', a novel gaze-based intent recognition system for accessible VR interaction. We leverage a combination of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to classify user intentions from gaze patterns, achieving an accuracy of 92.5% on a dataset of 20 participants. Our system enables users to interact with virtual objects using only their gaze, reducing the need for manual input and enhancing overall VR experience.