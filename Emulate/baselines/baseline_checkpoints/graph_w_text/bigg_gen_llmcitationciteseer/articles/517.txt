This paper proposes a novel multi-agent reinforcement learning framework for distributed resource allocation in smart grids. We model the problem as a decentralized Markov decision process, where each agent represents a distributed energy resource. Our approach leverages deep Q-networks and a decentralized actor-critic architecture to learn cooperative policies that optimize energy allocation and reduce peak demand. Experimental results on a simulated grid show that our approach outperforms traditional optimization methods and improves the overall efficiency of the smart grid.