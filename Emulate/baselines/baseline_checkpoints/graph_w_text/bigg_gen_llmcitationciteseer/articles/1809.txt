Virtual reality (VR) systems have the potential to revolutionize accessibility for individuals with motor impairments. This paper presents a novel gaze-based gesture recognition approach that enables users to interact with VR environments using only their eye movements. Our method leverages a convolutional neural network (CNN) to classify gaze patterns into distinct gestures, achieving an accuracy of 92.5% on a dataset of 20 users. We demonstrate the effectiveness of our approach in a VR-based game, where users with motor impairments can play using only their gaze. Our results show that gaze-based gesture recognition can significantly enhance the accessibility of VR systems.