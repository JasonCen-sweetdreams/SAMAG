Explainable recommendation systems have gained significant attention in recent years, but most existing methods rely on simplistic user-item interaction models. This paper proposes a novel knowledge graph embedding approach, 'KGExplain', which incorporates semantic relationships between entities to provide more accurate and interpretable recommendations. KGExplain leverages a graph attention mechanism to capture complex dependencies between users, items, and attributes, and integrates a multi-task learning framework to jointly optimize recommendation and explanation objectives. Experimental results on several benchmark datasets demonstrate the effectiveness of KGExplain in improving recommendation accuracy and generating coherent explanations.