Decentralized task allocation is a fundamental problem in multi-agent systems, where agents must allocate tasks to maximize global utility without centralized coordination. This paper proposes a novel approach using graph convolutional networks (GCNs) to learn decentralized task allocation policies. We model the agent-agent and agent-task interactions as a graph and use GCNs to learn a robust and adaptive policy that can handle complex task dependencies and agent capabilities. Experimental results on a simulated robotics scenario demonstrate that our approach outperforms traditional decentralized allocation methods and achieves near-optimal performance.