This paper explores the relationship between embodied cognition and gestural interaction in virtual reality (VR) environments. We conducted a user study to investigate how different gestural interfaces affect cognitive load and task performance in a virtual puzzle-solving task. Our results show that participants who used gestures that mimicked real-world actions (e.g., grasping and manipulating objects) demonstrated lower cognitive load and improved task performance compared to those using abstract gestures. We discuss the implications of these findings for the design of intuitive and effective VR interfaces, highlighting the importance of embodied cognition in shaping user experience.