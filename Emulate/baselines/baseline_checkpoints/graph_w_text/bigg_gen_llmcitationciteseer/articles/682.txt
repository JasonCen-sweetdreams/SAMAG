Hierarchical task networks (HTNs) are a popular formalism for representing complex tasks in AI planning. However, learning HTNs from experience remains a challenging problem. This paper proposes a novel online learning framework that integrates deep reinforcement learning with HTN planning. Our approach, called HTN-DRL, uses a hierarchical actor-critic architecture to learn both the HTN structure and the underlying primitive actions. We demonstrate the effectiveness of HTN-DRL on a set of challenging robotic manipulation tasks, showing improved learning efficiency and generalization capabilities compared to existing methods.