This paper proposes a novel approach to distributed multi-agent planning under uncertainty, leveraging deep reinforcement learning (DRL) to optimize agent policies. We introduce a hierarchical framework, 'MA-DRL', that integrates graph neural networks for agent communication and a decentralized actor-critic architecture for policy learning. Our approach enables real-time adaptation to uncertain environments and improves overall team performance in complex scenarios. Experimental results on a robotic search-and-rescue domain demonstrate the effectiveness of MA-DRL in achieving coordinated behavior among agents.