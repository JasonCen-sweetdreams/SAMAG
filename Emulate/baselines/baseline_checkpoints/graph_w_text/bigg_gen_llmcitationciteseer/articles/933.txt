Voice-controlled interfaces in augmented reality (AR) are prone to errors, negatively impacting user experience. This paper presents a novel approach to error detection using gaze tracking, which leverages the user's visual attention to identify potential errors. Our method, 'GazeCorrect', utilizes a machine learning model to analyze the user's gaze patterns and detect anomalies that may indicate incorrect voice commands. We conducted a user study with 30 participants, demonstrating a significant reduction in error rates (28.5%) and improvement in user satisfaction (35%) when using GazeCorrect. Our results have implications for the design of more robust and user-friendly voice-controlled interfaces in AR applications.