Cooperative multi-agent reinforcement learning (MARL) is a challenging problem due to the exponential growth in action spaces and the need for effective communication among agents. This paper proposes a novel hierarchical graph attention network (HGAT) to tackle these challenges. HGAT leverages graph attention mechanisms to learn cooperative relationships between agents and hierarchical representations to reduce the action space complexity. We evaluate HGAT on several MARL benchmarks, demonstrating significant improvements in task completion rates and sample efficiency compared to state-of-the-art methods.