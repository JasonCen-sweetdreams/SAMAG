Dialogue state tracking (DST) is a crucial component of task-oriented dialogue systems. While recent advances in graph neural networks have improved DST performance, they often lack interpretability. This paper presents a novel Hierarchical Graph Attention Network (HiGAT) architecture that incorporates graph attention mechanisms at multiple scales to capture complex contextual relationships between dialogue turns. We propose a novel explainability module that generates attention-based visualizations of the model's reasoning process, enabling developers to identify errors and improve model performance. Experimental results on the MultiWOZ benchmark demonstrate that HiGAT achieves state-of-the-art performance while providing insightful explanations for its predictions.