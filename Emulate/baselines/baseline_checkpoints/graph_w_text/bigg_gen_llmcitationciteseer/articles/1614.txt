Information retrieval (IR) systems often rely on dense document representations to facilitate efficient query processing. This paper introduces a novel query-adaptive document embedding technique, 'QADE', which leverages contextualized language models to adaptively encode documents based on the query semantics. Our approach exploits the attention mechanism to focus on query-relevant document regions, resulting in more accurate and efficient retrieval. Experimental results on the TREC-8 dataset demonstrate significant improvements in retrieval effectiveness and speed compared to state-of-the-art dense retrieval methods.