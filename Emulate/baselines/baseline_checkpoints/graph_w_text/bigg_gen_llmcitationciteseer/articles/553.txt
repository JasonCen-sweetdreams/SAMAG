Hierarchical reinforcement learning (HRL) has shown great promise in autonomous robotics, but its application is often hindered by high computational costs and sample inefficiency. This paper introduces a novel HRL framework, 'HiRLayer', which leverages a hierarchical abstraction of the state-space to reduce the complexity of the exploration-exploitation trade-off. We propose a multi-level attention mechanism that selectively focuses on relevant sub-goals, allowing the agent to learn more efficiently and effectively. Experimental results on a robotic grasping task demonstrate that HiRLayer outperforms state-of-the-art HRL methods in terms of both sample efficiency and task performance.