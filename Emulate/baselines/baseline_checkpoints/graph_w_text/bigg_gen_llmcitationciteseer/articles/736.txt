Neural information retrieval (NIR) models have demonstrated significant improvements over traditional retrieval methods. However, they often rely on manually crafted query expansion (QE) techniques, which can be suboptimal. This paper proposes a novel approach to QE using deep reinforcement learning (DRL). We formulate QE as a Markov decision process, where the agent learns to select expansion terms that maximize the expected retrieval performance. Our experiments on the MSMARCO passage ranking dataset show that the proposed DRL-based QE method outperforms state-of-the-art QE techniques, achieving a 12.5% improvement in mean reciprocal rank.