Virtual reality (VR) games often struggle to balance difficulty levels, leading to player frustration or boredom. This paper presents 'GazeFit', a novel VR game adaptation system that leverages eye-tracking data to dynamically adjust game difficulty in real-time. We develop a machine learning model that infers player expertise and affective states from eye movement patterns, such as fixation duration and pupil dilation. Our user study with 30 participants demonstrates that GazeFit improves player engagement, reduces frustration, and enhances overall gaming experience.