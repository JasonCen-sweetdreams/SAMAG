Autonomous vehicles (AVs) must make rapid, high-stakes decisions in complex environments. While reinforcement learning (RL) has shown promise in AV control, the opacity of RL policies hinders trust and understanding. This paper presents XRL, a novel framework for explainable RL in AV decision-making. XRL integrates model-based RL with attention mechanisms and visual saliency maps to provide interpretable explanations of policy decisions. We evaluate XRL on a suite of realistic AV scenarios, demonstrating improved transparency and robustness without sacrificing control performance.