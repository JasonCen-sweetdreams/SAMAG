Graph neural networks have shown great promise in node classification tasks, but often struggle with noisy or adversarially perturbed graph structures. This paper introduces a novel hierarchical graph attention mechanism, 'HGAN', which recursively applies attentional aggregation at multiple scales to capture both local and global graph patterns. We demonstrate the robustness of HGAN to various types of graph corruptions and perturbations, achieving state-of-the-art performance on several benchmark datasets. Additionally, we provide theoretical guarantees on the stability of HGAN to graph perturbations, making it a reliable choice for real-world applications.