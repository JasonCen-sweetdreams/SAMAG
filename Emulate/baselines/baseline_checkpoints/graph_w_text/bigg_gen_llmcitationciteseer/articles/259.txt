Traditional information retrieval (IR) models rely on bag-of-words representations, which fail to capture nuanced semantic relationships between documents. This paper proposes a novel neural IR approach that leverages knowledge graph embeddings to learn dense, contextualized document representations. Our method, 'KG-IR', integrates entity disambiguation and relation inference to encode documents as graph-based semantic vectors. Experimental results on the TREC-8 dataset demonstrate that KG-IR outperforms state-of-the-art neural IR models in terms of retrieval accuracy and efficiency, particularly for complex queries.