Multi-hop reasoning is a crucial capability for question answering and knowledge graph completion tasks. However, existing models often rely on opaque neural networks, making it challenging to understand their decision-making process. We propose a novel Hierarchical Graph Attention Network (HGAT) that integrates graph attention and hierarchical reasoning to facilitate explainable multi-hop reasoning. HGAT learns to iteratively refine its attention weights, enabling the model to focus on relevant nodes and edges while ignoring irrelevant information. Experimental results on benchmark datasets demonstrate that HGAT achieves state-of-the-art performance while providing interpretable explanations for its predictions.