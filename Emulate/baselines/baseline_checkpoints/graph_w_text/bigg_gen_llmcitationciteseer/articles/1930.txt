Zero-shot learning (ZSL) enables models to recognize unseen classes, but existing approaches often suffer from high computational overhead and poor performance. This paper presents a novel hierarchical attention network (HAN) for efficient ZSL in computer vision. Our HAN model leverages a dual-attention mechanism that selectively focuses on relevant semantic attributes and visual features, allowing for efficient knowledge transfer from seen to unseen classes. Experimental results on benchmark datasets demonstrate that our approach achieves state-of-the-art performance while reducing computational cost by up to 3x compared to existing ZSL methods.