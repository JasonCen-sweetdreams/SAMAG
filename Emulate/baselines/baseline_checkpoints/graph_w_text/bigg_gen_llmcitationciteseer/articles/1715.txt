Deep reinforcement learning (RL) has achieved remarkable success in various domains, but its lack of transparency hinders its adoption in high-stakes applications. This paper proposes a novel graph-based attention mechanism, dubbed GRAFT, to enhance the explainability of RL agents. By modeling the agent's observation space as a graph, GRAFT selectively focuses on relevant state features and their relationships, thereby providing insights into the decision-making process. We evaluate GRAFT on a suite of Atari games and demonstrate improved performance and interpretability compared to existing RL methods.