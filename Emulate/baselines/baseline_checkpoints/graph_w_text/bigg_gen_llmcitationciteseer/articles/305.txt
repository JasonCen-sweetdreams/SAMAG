Knowledge graph embedding (KGE) has become a crucial task in various applications, including question answering, recommendation systems, and natural language processing. However, existing KGE methods often suffer from scalability issues and neglect the hierarchical structure of relations. This paper proposes a novel KGE approach, HERA, which leverages hierarchical relation attention to model complex relationships between entities. By incorporating a hierarchical attention mechanism, HERA can capture both local and global dependencies among relations, leading to improved performance on link prediction and entity classification tasks. Experimental results on several benchmark datasets demonstrate the effectiveness and efficiency of HERA compared to state-of-the-art KGE methods.