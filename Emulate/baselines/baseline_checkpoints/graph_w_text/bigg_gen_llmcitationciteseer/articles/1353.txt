Traditional information retrieval (IR) methods rely on manual feature engineering and bag-of-words representations, which often fail to capture nuanced semantic relationships between documents. This paper proposes a novel hierarchical neural embedding framework, 'HiNER', which learns to represent documents as dense vectors in a hierarchical manner. We employ a stacked attention mechanism to capture both local and global context, enabling more accurate document retrieval. Experimental results on several benchmark datasets demonstrate that HiNER outperforms state-of-the-art IR methods, including those based on BERT and Transformers, in terms of retrieval precision and efficiency.