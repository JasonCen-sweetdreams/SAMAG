Neural retrieval models have achieved state-of-the-art performance in ad-hoc retrieval tasks, but their effectiveness is heavily reliant on the quality of the query representation. This paper proposes a novel query expansion technique that leverages contrastive learning to generate semantically coherent and diverse expansion terms. Our approach, dubbed 'ConEx', marginalized the impact of irrelevant terms by learning a query-agnostic discriminator that separates relevant from non-relevant terms. Experimental results on the TREC-CAR dataset demonstrate that ConEx consistently outperforms existing query expansion methods, leading to significant improvements in retrieval effectiveness.