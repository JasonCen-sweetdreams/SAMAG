Multi-agent systems often require efficient task allocation to achieve cooperative goals. This paper presents a novel approach to distributed task allocation using reinforcement learning. We propose an algorithm, 'MARL-TA', that enables agents to learn from their experiences and adapt to changing task requirements. MARL-TA employs a decentralized, asynchronous framework, allowing agents to communicate and negotiate task assignments in real-time. Experimental results on a simulated search-and-rescue scenario demonstrate improved task completion rates and reduced communication overhead compared to traditional, centralized allocation methods.