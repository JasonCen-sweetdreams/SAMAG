This paper presents a decentralized task allocation framework for multi-agent systems, where agents learn to allocate tasks efficiently through distributed reinforcement learning. We propose a novel algorithm, 'DTRL', which leverages local observations and communication with neighboring agents to learn optimal task assignments. DTRL is shown to converge to near-optimal solutions in various scenarios, outperforming traditional centralized approaches. Experimental results demonstrate the effectiveness of DTRL in a realistic disaster response scenario, highlighting its potential for real-world applications.