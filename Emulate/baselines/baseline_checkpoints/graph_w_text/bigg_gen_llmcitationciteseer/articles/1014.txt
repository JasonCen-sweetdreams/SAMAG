Explainability and interpretability are crucial in graph-based node classification tasks, particularly in high-stakes applications like social network analysis and bioinformatics. We propose a novel Hierarchical Graph Attention Network (HGAN) architecture that leverages self-attention mechanisms to learn node representations at multiple scales. HGAN incorporates a hierarchical clustering module to identify informative graph structures, facilitating explainable node classification. Experimental results on benchmark datasets demonstrate that HGAN outperforms state-of-the-art methods in terms of accuracy and feature importance interpretability.