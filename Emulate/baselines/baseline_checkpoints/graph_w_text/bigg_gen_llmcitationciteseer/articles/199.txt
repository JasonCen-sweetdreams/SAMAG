Conversational search systems aim to provide accurate and relevant passages in response to user queries. However, the limited context and ambiguity in natural language queries pose significant challenges to passage retrieval. This paper proposes a neural query expansion framework, 'NQE-CS', that leverages pre-trained language models to expand queries with semantically relevant keywords. Our approach involves fine-tuning a BERT-based model on a large conversational search dataset and incorporating a novel keyword selection mechanism based on attention weights. Experimental results on the TREC Conversational Assistance Track dataset demonstrate that NQE-CS significantly outperforms existing state-of-the-art methods in terms of passage retrieval accuracy and relevance.