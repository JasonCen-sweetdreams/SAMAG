Virtual reality (VR) has revolutionized various domains, but users' diverse visual attention patterns and preferences remain a significant challenge. This paper presents 'GazeFit', a novel gaze-based adaptive user modeling framework that dynamically tailors VR experiences to individual users. By leveraging machine learning-based gaze analysis and real-time user feedback, GazeFit optimizes VR content presentation, navigation, and interaction to enhance user engagement and comfort. Our user study demonstrates significant improvements in VR experience quality and reduced user fatigue compared to traditional, one-size-fits-all approaches.