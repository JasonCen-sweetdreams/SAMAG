Virtual reality (VR) has the potential to revolutionize various aspects of our lives, but existing interaction methods can be inaccessible to individuals with disabilities. This paper presents a novel gaze-based interface, 'GazeVR', which enables users to interact with VR environments using only their gaze. We develop a machine learning model that accurately predicts user intentions from eye movement data, and integrate it with a VR platform to provide an immersive and inclusive experience. Our user study with participants with and without disabilities demonstrates the effectiveness of GazeVR in facilitating accessible VR interactions.