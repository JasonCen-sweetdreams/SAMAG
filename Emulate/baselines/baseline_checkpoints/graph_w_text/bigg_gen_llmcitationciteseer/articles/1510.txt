This paper presents a novel approach to dynamic task allocation for heterogeneous multi-agent teams, where agents have varying capabilities and tasks have different requirements. We formulate the problem as a decentralized Markov decision process and propose a reinforcement learning-based solution that enables agents to learn effective task allocation strategies. Our approach, called HeteroTaskRL, uses a graph neural network to represent agent-task relationships and a deep Q-network to learn the optimal allocation policy. Experimental results on a simulated disaster response scenario demonstrate that HeteroTaskRL outperforms state-of-the-art methods in terms of task completion efficiency and adaptability to changing team compositions.