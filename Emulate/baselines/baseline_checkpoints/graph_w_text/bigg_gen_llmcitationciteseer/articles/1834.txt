Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but the lack of interpretability hinders its widespread adoption. This paper proposes a novel hierarchical attention network (HAN) architecture that provides explanations for DRL policies. Our approach integrates attention mechanisms at multiple levels to identify relevant state features, abstract representations, and action influences. We demonstrate the effectiveness of HAN on several Atari games and a real-world robotics task, showcasing improved transparency and controllability of the learned policies.