Virtual reality (VR) has the potential to revolutionize accessible computing, but existing interfaces often neglect the needs of users with disabilities. This paper presents 'GazeAid', a novel gaze-informed adaptive interface that leverages eye-tracking data to facilitate intuitive interaction in VR environments. Our approach dynamically adjusts the interface layout, font size, and color scheme based on the user's gaze patterns, reducing cognitive load and improving overall usability. A user study with 20 participants, including individuals with visual impairments, demonstrates significant improvements in task completion time and user satisfaction.