Task planning for robots in complex environments requires efficient decision-making and adaptability. This paper introduces HRL-TPE, a hierarchical reinforcement learning framework that integrates task planning and execution. We propose a novel hierarchical policy representation, which decomposes tasks into sub-tasks and learns to select the most promising ones based on the current state. Our approach leverages a graph-based representation of the task space and incorporates domain knowledge to prune the search space. Experimental results on a robotic arm platform demonstrate that HRL-TPE outperforms flat reinforcement learning methods in terms of task completion time and success rate.