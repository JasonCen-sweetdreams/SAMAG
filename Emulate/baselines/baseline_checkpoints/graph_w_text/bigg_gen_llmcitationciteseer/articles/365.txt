In multi-agent systems, cooperation and communication are crucial for achieving common goals. However, most existing approaches rely on complex, black-box models that hinder interpretability and trust. This paper proposes a novel Hierarchical Attention Graph Neural Network (HAGNN) architecture that enables explainable multi-agent cooperation. HAGNN integrates graph attention mechanisms with hierarchical representations to model agent interactions, intentions, and goals. Our experiments on a variety of cooperative tasks demonstrate that HAGNN outperforms state-of-the-art methods in both performance and interpretability, providing actionable insights into agent decision-making processes.