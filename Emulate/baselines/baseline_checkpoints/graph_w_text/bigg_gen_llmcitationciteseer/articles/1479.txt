In multi-agent reinforcement learning, task complexity often hinders the learning process. We propose a novel hierarchical task decomposition framework, 'HTD-MA', which leverages a divide-and-conquer approach to simplify complex tasks. HTD-MA recursively decomposes tasks into sub-tasks, and each agent learns to solve these sub-tasks using a deep reinforcement learning policy. We demonstrate the effectiveness of HTD-MA in a variety of multi-agent scenarios, including robotic soccer and autonomous driving. Experimental results show that HTD-MA outperforms existing methods in terms of task completion rate and learning efficiency.