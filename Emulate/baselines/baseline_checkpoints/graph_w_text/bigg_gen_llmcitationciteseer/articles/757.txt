With the increasing complexity of urban systems, there is a growing need for coordination among heterogeneous agents in smart cities. Existing approaches often rely on simplistic reward functions that fail to capture the nuances of real-world scenarios. This paper proposes a novel framework for coordinating agents with multi-objective reward functions, which incorporates both quantitative and qualitative metrics. We leverage a hybrid approach that combines reinforcement learning with constraint programming to optimize agent behavior while satisfying conflicting objectives. Experimental results on a real-world transportation dataset demonstrate the effectiveness of our approach in improving overall system efficiency and reducing congestion.