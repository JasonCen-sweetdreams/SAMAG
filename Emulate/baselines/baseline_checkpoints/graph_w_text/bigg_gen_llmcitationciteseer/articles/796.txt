State-of-the-art neural ranking models often rely on computationally expensive, multi-stage pipelines to achieve optimal retrieval performance. This paper proposes a novel, adaptive re-ranking approach that leverages query-document embeddings to efficiently identify relevant documents. Our method, 'AdaRerank', learns to dynamically adjust the ranking threshold based on the query's semantic context, reducing the number of documents that require expensive neural scoring. Experimental results on the TREC Deep Learning Track demonstrate that AdaRerank achieves comparable retrieval accuracy to state-of-the-art methods while reducing computational overhead by up to 40%.