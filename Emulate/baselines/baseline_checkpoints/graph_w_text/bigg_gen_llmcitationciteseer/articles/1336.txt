Open-domain question answering (ODQA) systems often struggle with complex, nuanced queries that require deeper semantic understanding. We propose a novel approach that leverages deep semantic role labeling (SRL) to enhance query reformulation in ODQA. Our method, SRL-QR, uses a BERT-based SRL model to identify and disambiguate predicate-argument structures in queries, which are then used to generate more effective reformulations. Experimental results on the Natural Questions dataset demonstrate that SRL-QR significantly improves answer retrieval accuracy and outperforms state-of-the-art query reformulation methods.