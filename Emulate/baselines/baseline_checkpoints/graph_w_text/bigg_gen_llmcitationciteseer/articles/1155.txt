Augmented reality (AR) has the potential to revolutionize human-computer interaction, but existing input methods often hinder user experience. This paper explores gaze-based interaction as a promising alternative. We designed and evaluated a gaze-driven interface for AR applications, leveraging machine learning-based gaze estimation and precision timing. Our user study reveals significant improvements in task completion time and user satisfaction compared to traditional input methods. Furthermore, we identify key factors influencing user performance and provide design recommendations for gaze-based AR interfaces.