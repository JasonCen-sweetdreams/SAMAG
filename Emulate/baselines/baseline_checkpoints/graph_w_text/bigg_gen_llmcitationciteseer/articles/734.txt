Task allocation in distributed systems is a challenging problem, particularly in scenarios with complex dependencies and constraints. This paper proposes a novel multi-agent reinforcement learning framework that leverages graph neural networks to learn optimal task allocation policies. We introduce a new graph-based state representation that captures task dependencies and agent capabilities, and demonstrate that our approach outperforms traditional heuristic-based methods in simulated environments. Experimental results on a real-world logistics dataset show that our framework can improve task allocation efficiency by up to 25% compared to baseline methods.