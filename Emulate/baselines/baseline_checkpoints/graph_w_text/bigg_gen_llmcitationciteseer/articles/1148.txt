Autonomous robot navigation in complex environments remains a challenging task. This paper presents a novel hierarchical reinforcement learning (HRL) framework, 'HierNav', which leverages a multi-level abstraction of the environment to improve navigation efficiency. HierNav decomposes the navigation task into a hierarchy of sub-tasks, each solved using a separate reinforcement learning agent. We introduce a new attention-based mechanism to adaptively select the most relevant sub-task based on the current environment state, reducing the exploration-exploitation trade-off. Experimental results on a simulated robotics platform demonstrate that HierNav outperforms existing flat RL methods in terms of navigation success rate and computational efficiency.