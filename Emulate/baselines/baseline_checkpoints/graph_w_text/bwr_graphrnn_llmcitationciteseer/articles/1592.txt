Large-scale multi-agent systems often require efficient task allocation to achieve global objectives. This paper proposes a novel hierarchical reinforcement learning framework, 'HRL-TA', which leverages hierarchical task decomposition and distributed reinforcement learning to allocate tasks in a decentralized manner. We demonstrate that HRL-TA outperforms traditional centralized approaches in terms of task completion time and system scalability, while also exhibiting improved robustness to agent failures. Experimental results on a simulation platform with 1000+ agents validate the effectiveness of our approach in real-world scenarios.