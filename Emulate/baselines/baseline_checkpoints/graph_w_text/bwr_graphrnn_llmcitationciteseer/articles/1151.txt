This paper proposes a decentralized multi-agent reinforcement learning framework for coordinating autonomous vehicles in complex scenarios. Our approach, called 'MAV-CAD', utilizes a graph neural network to model the interactions between vehicles and a decentralized actor-critic algorithm to learn cooperative policies. We demonstrate the effectiveness of MAV-CAD in reducing congestion and improving safety in simulations of real-world traffic scenarios. The results show that MAV-CAD outperforms traditional rule-based approaches and centralized optimization methods in terms of both efficiency and adaptability.