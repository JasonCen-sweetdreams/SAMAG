In complex robotic task planning, explainability is crucial for human-robot collaboration and trust. We propose a novel Hierarchical Attention Network (HAN) architecture that integrates symbolic planning with deep learning. HAN learns to attend to relevant task constraints and object affordances, generating interpretable plans. We evaluate our approach on a benchmark robotic task planning dataset, demonstrating improved plan quality and explainability compared to state-of-the-art methods. Moreover, we provide a visual analytics tool to facilitate human understanding of the planning process.