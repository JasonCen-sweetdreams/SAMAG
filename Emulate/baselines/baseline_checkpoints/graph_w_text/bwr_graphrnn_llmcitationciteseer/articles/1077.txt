Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its vulnerability to adversarial attacks poses a significant threat. This paper presents a novel approach to detect adversarial attacks in DRL environments using graph-based anomaly detection. We model the agent's interactions with the environment as a graph and leverage graph convolutional networks to identify anomalous patterns indicative of attacks. Our approach is evaluated on several DRL benchmarks and demonstrates superior detection performance compared to existing methods. The proposed technique has far-reaching implications for improving the robustness of DRL systems in safety-critical applications.