Neural ranking models have shown promising results in information retrieval tasks, but their computational complexity and memory requirements hinder their adoption in large-scale search systems. This paper proposes a novel indexing framework, 'NeuIndex', that facilitates efficient query processing and reduces memory footprint for neural ranking models. We introduce a dimensionality reduction technique that preserves the ranking semantics of the neural model, enabling fast and accurate retrieval of top-k documents. Experimental results on several benchmark datasets demonstrate that NeuIndex achieves significant speedups and memory savings while maintaining retrieval effectiveness.