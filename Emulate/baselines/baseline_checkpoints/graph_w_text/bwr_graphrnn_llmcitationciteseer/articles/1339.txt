Virtual reality (VR) systems require intuitive and natural interaction methods. This paper presents a novel gaze-based interaction framework for VR, leveraging deep learning-based eye-tracking to accurately estimate user intent. Our approach utilizes a convolutional neural network (CNN) to analyze eye movement patterns and classify gaze targets in real-time. We evaluate our system using a VR-based puzzle game and demonstrate significant improvements in interaction accuracy and user experience compared to traditional controller-based methods.