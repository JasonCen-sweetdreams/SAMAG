Deep neural networks have achieved state-of-the-art performance in image classification tasks, but their lack of transparency hinders trust and understanding. This paper proposes a novel hierarchical attention mechanism that enables explainable image classification. Our approach combines attention modules at multiple scales to selectively focus on relevant regions and features, generating attention maps that provide insights into the decision-making process. We evaluate our method on several benchmark datasets and demonstrate improved accuracy and interpretability compared to existing attention-based models.