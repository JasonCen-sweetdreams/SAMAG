Coordinating multiple agents in complex environments is a challenging problem in artificial intelligence. This paper proposes a novel graph-based reinforcement learning framework, 'GraphCoord', which enables agents to learn cooperative policies in decentralized settings. We model the agent interactions as a graph and use graph neural networks to learn a shared policy that optimizes the global reward. Experimental results in simulated robotic soccer and autonomous driving scenarios demonstrate that GraphCoord outperforms existing decentralized reinforcement learning methods in terms of coordination efficiency and overall performance.