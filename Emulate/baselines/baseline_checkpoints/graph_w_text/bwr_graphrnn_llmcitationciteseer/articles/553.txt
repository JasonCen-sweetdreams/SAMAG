Cooperative multi-agent reinforcement learning (MARL) has garnered significant attention in recent years, but existing methods often suffer from scalability issues and limited interpretability. This paper proposes a novel hierarchical graph attention network (HGAT) framework for MARL, which leverages graph neural networks to model agent interactions and attention mechanisms to focus on critical relationships. We evaluate HGAT on several cooperative MARL benchmarks, demonstrating improved performance, stability, and interpretability compared to state-of-the-art methods.