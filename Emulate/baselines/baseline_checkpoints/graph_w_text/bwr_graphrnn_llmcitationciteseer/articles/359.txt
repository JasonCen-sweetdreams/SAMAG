Virtual reality (VR) interfaces often rely on manual navigation methods, which can be slow and fatiguing. This paper introduces EyeGazePath, a novel navigation model that leverages users' gaze patterns to infer their navigational intent. Our approach combines a convolutional neural network (CNN) with a Markov chain model to predict the user's desired navigation path. We evaluate EyeGazePath in a VR environment and demonstrate significant reductions in navigation time and effort compared to traditional methods. Our findings suggest that gaze-driven navigation can enhance the overall VR user experience.