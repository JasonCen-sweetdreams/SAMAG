This paper presents a decentralized multi-agent reinforcement learning approach for autonomous traffic control. We propose a novel framework, 'MARL-ATC', which enables multiple autonomous vehicles to learn and adapt to dynamic traffic scenarios in real-time. By leveraging decentralized learning and communication protocols, MARL-ATC improves traffic flow and reduces congestion in complex urban environments. Experimental results using a realistic traffic simulator demonstrate that MARL-ATC outperforms traditional centralized control methods and achieves significant reductions in travel time and fuel consumption.