Knowledge graph embedding (KGE) is a crucial task in artificial intelligence, aiming to represent entities and relationships in a low-dimensional vector space. This paper proposes a novel KGE approach, dubbed GraphAttentionKE, which leverages graph attention networks to model complex relationships between entities. By adaptively assigning attention weights to different neighbors, our model captures nuanced semantic patterns and improves entity representation. Experiments on benchmark datasets demonstrate that GraphAttentionKE outperforms state-of-the-art KGE methods, achieving significant gains in link prediction and entity classification tasks.