Virtual reality (VR) has revolutionized the way we interact with digital information, but user engagement remains a significant challenge. This paper presents a novel gaze-informed adaptive interface, 'GazeAdapt', which dynamically adjusts the VR environment based on the user's gaze patterns. Our approach leverages machine learning to identify user interest and adapt the interface in real-time, thereby enhancing user engagement and reducing cognitive load. We evaluate GazeAdapt in a user study and demonstrate significant improvements in user experience and task performance compared to traditional static interfaces.