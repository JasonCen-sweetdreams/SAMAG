Deep neural networks are prone to making overconfident predictions on out-of-distribution (OOD) inputs, which can lead to catastrophic failures in safety-critical applications. This paper proposes a novel meta-learning approach to detect OOD inputs efficiently. Our method, called Meta-OOD, learns to adapt to new OOD scenarios by leveraging a few labeled examples from the target distribution. We demonstrate the effectiveness of Meta-OOD on multiple benchmark datasets, achieving state-of-the-art performance in detecting OOD inputs while requiring significantly less computational resources than existing methods.