Few-shot relation extraction is a challenging task that requires models to generalize well to unseen relations with limited training data. We propose a novel hierarchical graph attention network (HGAT) that leverages the graph structure of entity-relation graphs to learn more effective representations. Our approach employs a hierarchical attention mechanism that selectively focuses on relevant entities and relations at different levels of abstraction. Experiments on two benchmark datasets show that HGAT significantly outperforms state-of-the-art methods in few-shot relation extraction, achieving an average F1-score improvement of 12.5%.