Distributed databases have become increasingly popular for handling large-scale data storage and processing. However, query optimization remains a significant challenge due to the inherent complexity of distributed systems. This paper proposes a novel approach to cardinality estimation using machine learning techniques, which can significantly improve query optimization. We develop a neural network-based model that learns the relationship between query features and cardinality estimates, and integrate it with a cost-based optimizer. Experimental results on a real-world distributed database show that our approach outperforms traditional methods by up to 30% in terms of query execution time.