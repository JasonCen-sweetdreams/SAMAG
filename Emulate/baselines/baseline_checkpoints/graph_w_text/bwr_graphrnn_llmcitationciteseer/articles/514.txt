Urban traffic congestion is a pervasive problem that affects many cities worldwide. This paper explores the use of autonomous agents, coordinated through reinforcement learning, to optimize traffic signal control in real-time. We propose a decentralized framework, 'Traffic Harmony', where agents learn to adjust signal timings based on local traffic conditions and communication with neighboring agents. Our approach incorporates domain knowledge from traffic engineering and leverages multi-agent reinforcement learning to adapt to changing traffic patterns. Experimental results using real-world traffic data demonstrate significant reductions in congestion and travel times compared to traditional fixed-time signal control strategies.