Explainability is crucial for real-world deployment of autonomous systems. This paper presents Hierarchical Explainable Reinforcement Learning (HERL), a novel framework that integrates hierarchical reinforcement learning with model-based explanations. HERL utilizes a hierarchical policy to decompose complex tasks into simpler sub-tasks, while an explainable model is learned to provide insights into the decision-making process. Experimental results on a simulated autonomous driving environment demonstrate that HERL achieves improved task performance and explainability compared to state-of-the-art reinforcement learning methods.