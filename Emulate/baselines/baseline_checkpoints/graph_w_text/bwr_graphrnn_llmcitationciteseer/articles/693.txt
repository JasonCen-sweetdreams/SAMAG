This paper presents a novel approach to coordinating task-oriented autonomous agents in complex environments. We propose a hierarchical reinforcement learning framework that enables agents to learn both high-level task decomposition and low-level action execution policies. Our method, called HRL-TA, leverages a two-level hierarchy of agents, where higher-level agents focus on task allocation and lower-level agents execute tasks using reinforcement learning. Experimental results in a simulated warehouse scenario demonstrate that HRL-TA outperforms traditional flat reinforcement learning and manual task assignment methods in terms of task completion efficiency and adaptability to changing environments.