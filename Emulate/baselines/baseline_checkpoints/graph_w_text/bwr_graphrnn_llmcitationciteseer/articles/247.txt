Autonomous traffic signal control has the potential to significantly reduce congestion and emissions in urban areas. This paper proposes a novel multi-agent reinforcement learning (MARL) framework for coordinating traffic signals in real-time. Our approach leverages a decentralized, communication-efficient architecture where each agent learns to optimize its own signal timing based on local observations and sparse rewards. We demonstrate the scalability of our method through large-scale simulations, showing improved traffic flow and reduced waiting times compared to traditional, fixed-timing strategies.