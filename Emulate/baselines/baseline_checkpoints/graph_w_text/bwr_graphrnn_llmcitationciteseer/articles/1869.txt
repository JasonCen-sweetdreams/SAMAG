Explainable recommendation systems are crucial for building trustworthy AI-driven decision-making tools. This paper proposes a novel hierarchical attention-based graph neural network (HAGNN) architecture that incorporates node-level and graph-level attention mechanisms to model complex user-item interactions. We demonstrate the effectiveness of HAGNN in capturing both local and global dependencies in user behavior, resulting in improved recommendation accuracy and interpretability. Our experiments on real-world datasets show that HAGNN outperforms state-of-the-art baselines while providing transparent explanations for recommended items.