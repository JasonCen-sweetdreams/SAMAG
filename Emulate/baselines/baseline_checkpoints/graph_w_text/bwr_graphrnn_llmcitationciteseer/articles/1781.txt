Multi-agent pathfinding is a challenging problem in artificial intelligence, particularly in dynamic environments with complex constraints. This paper presents a novel approach that leverages deep reinforcement learning to efficiently compute near-optimal paths for multiple agents. Our method, called MAP-RL, uses a decentralized actor-critic framework to learn cooperative policies that minimize collisions and reduce overall travel time. We demonstrate the effectiveness of MAP-RL in various scenarios, including warehouse robotics and autonomous vehicle routing, and show significant improvements over traditional graph-based methods.