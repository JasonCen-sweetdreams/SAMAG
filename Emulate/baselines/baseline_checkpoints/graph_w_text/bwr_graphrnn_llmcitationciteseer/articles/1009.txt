In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a decentralized task allocation framework, 'DRL-TA', that leverages deep reinforcement learning to optimize task assignments in dynamic environments. We propose a novel, graph-structured neural network that learns to represent agent capabilities, task requirements, and environment constraints, enabling agents to adaptively allocate tasks based on real-time observations. Experimental results on a simulated search-and-rescue scenario demonstrate that DRL-TA outperforms state-of-the-art, centralized allocation methods in terms of task completion time and success rate.