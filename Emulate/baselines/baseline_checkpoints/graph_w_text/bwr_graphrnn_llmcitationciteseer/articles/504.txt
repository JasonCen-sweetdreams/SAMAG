In multi-agent dialogue systems, understanding the decision-making process of agents is crucial for transparency and trust. This paper presents a novel hierarchical attention network (HAN) framework for explainable multi-agent dialogue management. Our approach leverages attention mechanisms to selectively focus on relevant context and agent interactions, generating interpretable dialogue responses. We evaluate our HAN model on a real-world dialogue dataset and demonstrate improved response accuracy and explainability compared to state-of-the-art baseline models. Furthermore, our framework provides insights into agent decision-making, facilitating more effective human-agent collaboration.