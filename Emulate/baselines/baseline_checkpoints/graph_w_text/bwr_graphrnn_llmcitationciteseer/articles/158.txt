Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its lack of interpretability hinders its adoption in safety-critical domains. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that incorporates attention mechanisms at both the feature and decision levels. Our approach enables the identification of relevant state features and action sequences contributing to the agent's decision-making process. Experimental results on a set of Atari games demonstrate that HAN-based DRL agents not only achieve competitive performance but also provide insightful explanations for their actions.