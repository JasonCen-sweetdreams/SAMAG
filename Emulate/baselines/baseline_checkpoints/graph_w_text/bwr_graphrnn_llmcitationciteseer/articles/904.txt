Individuals with motor impairments often rely on gaze-based typing systems, which can be prone to errors. This paper presents a novel deep learning approach, 'GazeCorrect', to correct typing errors in real-time using gaze data. We propose a multi-task learning framework that jointly predicts the intended character and the error type. Our model leverages a combination of convolutional and recurrent neural networks to capture the spatial and temporal patterns in gaze data. Experiments on a large-scale gaze dataset demonstrate that GazeCorrect outperforms state-of-the-art correction methods, reducing error rates by up to 30% and improving overall typing efficiency.