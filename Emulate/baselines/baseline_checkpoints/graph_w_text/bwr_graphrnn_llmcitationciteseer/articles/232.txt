Urban traffic control is a complex problem that requires coordinating the actions of multiple agents. This paper proposes a decentralized multi-agent reinforcement learning framework that leverages graph attention to learn effective communication strategies among agents. Our approach, dubbed 'GraphMAC', represents the traffic network as a graph and uses attention mechanisms to focus on the most relevant neighboring agents. We demonstrate the efficacy of GraphMAC in a realistic simulation environment, showcasing improved traffic flow and reduced congestion compared to traditional decentralized methods.