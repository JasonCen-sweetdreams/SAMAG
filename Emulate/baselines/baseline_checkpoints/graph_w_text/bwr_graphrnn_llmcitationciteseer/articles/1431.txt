Multimodal emotion recognition is a challenging task due to the complexity of human emotions and the presence of multiple modalities. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework that leverages the strengths of graph neural networks and attention mechanisms to model the relationships between modalities. Our approach incorporates a hierarchical graph structure to capture emotions at multiple scales and utilizes attention weights to selectively focus on relevant modalities. Experimental results on the IEMOCAP dataset demonstrate that HGAT outperforms state-of-the-art multimodal fusion methods, achieving an average F1-score of 84.2% across six emotions.