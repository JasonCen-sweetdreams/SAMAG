Virtual reality (VR) has transformed gesture recognition, but the underlying cognitive mechanisms remain poorly understood. This paper explores the role of embodied cognition in VR-based gesture recognition, focusing on the interplay between motor control, proprioception, and visual feedback. We designed an immersive VR experiment to investigate how users' motor experiences influence gesture recognition accuracy and gesture variability. Our results show that embodied cognition significantly improves gesture recognition, particularly for complex gestures, and that users' motor control strategies adapt to the VR environment. These findings have implications for the design of VR-based gesture recognition systems and highlight the importance of considering embodied cognition in HCI research.