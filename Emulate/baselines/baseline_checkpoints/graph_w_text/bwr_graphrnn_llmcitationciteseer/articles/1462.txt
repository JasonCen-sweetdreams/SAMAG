Multi-agent reinforcement learning (MARL) has gained significant attention in recent years, but most existing approaches struggle to scale to complex, dynamic environments. This paper proposes a novel hierarchical graph attention network (HGAN) architecture, which integrates graph neural networks and attention mechanisms to model complex agent interactions. HGAN enables agents to selectively focus on relevant neighboring agents and learn hierarchical representations of the environment. We evaluate HGAN on a range of MARL benchmarks, demonstrating improved performance and scalability compared to state-of-the-art methods.