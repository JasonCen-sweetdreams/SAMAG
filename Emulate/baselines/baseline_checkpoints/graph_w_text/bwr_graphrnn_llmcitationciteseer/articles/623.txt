This paper proposes a decentralized multi-agent reinforcement learning framework for dynamic task allocation in smart cities. We consider a scenario where multiple agents, representing urban service providers, need to allocate tasks to optimize overall city performance. Our approach, called Dec-MARL, utilizes a novel communication mechanism that enables agents to share experiences and learn from each other in a decentralized manner. We evaluate Dec-MARL on a realistic simulation platform and demonstrate its ability to adapt to changing city dynamics, outperforming traditional centralized task allocation methods.