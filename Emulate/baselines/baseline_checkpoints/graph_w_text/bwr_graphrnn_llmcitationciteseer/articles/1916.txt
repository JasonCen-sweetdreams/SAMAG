The increasing adoption of neural retrieval models in ad-hoc search systems has led to a significant performance gap between traditional keyword-based retrieval methods and neural methods. This gap is primarily due to the expensive computations required for neural ranking models. In this paper, we propose a novel query optimization framework, 'NeuroOpt', that leverages the structural properties of neural networks to reduce the computational overhead. NeuroOpt employs a hierarchical pruning strategy to eliminate irrelevant documents and a novel caching mechanism to minimize redundant computations. Our experiments on a large-scale ad-hoc search dataset demonstrate that NeuroOpt achieves an average speedup of 3.2x over state-of-the-art neural retrieval models while maintaining comparable retrieval effectiveness.