Emotional intelligence is crucial in human-human interaction, but its significance has been overlooked in virtual human-computer interaction. This paper proposes a novel gaze-based framework, 'EmoGaze', which enables virtual agents to recognize and respond to users' emotions in real-time. We develop a deep learning model that leverages eye-tracking data to infer users' emotional states and generates empathetic responses. Our user study demonstrates that EmoGaze significantly improves user engagement and satisfaction in virtual interactions, paving the way for more human-like HCI.