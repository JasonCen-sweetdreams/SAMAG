Neural ranking models have shown promising results in ad-hoc retrieval tasks, but their computational cost and memory requirements limit their applicability to large-scale search engines. This paper proposes a novel neural ranking architecture, 'EffiRank', which leverages a hierarchical attention mechanism and a knowledge distillation strategy to reduce the model's complexity while preserving its retrieval effectiveness. Experimental results on the TREC Deep Learning Track dataset demonstrate that EffiRank outperforms state-of-the-art neural ranking models in terms of both efficiency and effectiveness, making it a viable solution for real-world search engines.