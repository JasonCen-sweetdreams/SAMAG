Autonomous vehicles require efficient decision-making strategies to navigate complex scenarios. This paper presents a novel deep hierarchical reinforcement learning (DHRL) framework that integrates high-level goal-directed planning with low-level motion control. Our approach employs a hierarchical policy architecture, where a high-level planning module selects goals, and a low-level control module executes actions to achieve those goals. We demonstrate the effectiveness of DHRL in a simulated urban driving environment, showing improved decision-making performance and reduced computational overhead compared to flat reinforcement learning baselines.