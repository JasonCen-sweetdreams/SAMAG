As virtual reality (VR) technology advances, there is a growing need for more natural and intuitive interaction methods. This paper presents a novel approach for detecting user intentions in VR using gaze-based input. Our method leverages a deep learning-based gaze estimation model and a probabilistic intention recognition framework to infer user goals from their gaze patterns. We evaluate our approach in a series of experiments involving object manipulation and navigation tasks, demonstrating improved interaction performance and user experience compared to traditional controller-based methods.