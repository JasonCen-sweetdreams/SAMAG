Graph Convolutional Networks (GCNs) have been widely used for graph-structured data analysis. However, their robustness against adversarial attacks on node attributes has not been thoroughly investigated. In this paper, we propose a novel attack method, called AttrAttack, which modifies node attributes to mislead GCNs. We also develop a defense mechanism, called RobustGCN, which incorporates an attention-based module to detect and correct attribute perturbations. Experimental results on several benchmark datasets show that AttrAttack significantly degrades GCN performance, while RobustGCN improves robustness against attribute-based attacks.