Dense passage retrieval (DPR) models have achieved state-of-the-art results in open-domain question answering tasks. However, their computational cost and memory requirements increase quadratically with the number of passages in the index. This paper proposes a query-driven indexing approach that selectively indexes passages based on their relevance to the query. Our approach leverages a learned passage representation model to identify relevant passages and constructs a sparse index that reduces memory usage by up to 90% while maintaining retrieval performance. Experimental results on the Natural Questions dataset demonstrate the effectiveness of our approach in reducing computational cost and improving query latency.