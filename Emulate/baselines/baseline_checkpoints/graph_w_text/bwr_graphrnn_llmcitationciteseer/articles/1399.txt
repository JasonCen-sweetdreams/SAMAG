Distributed database systems (DDS) have become increasingly popular for handling large-scale datasets, but optimizing query workloads remains a challenging problem. This paper proposes a novel approach that leverages reinforcement learning (RL) to optimize query scheduling in DDS. Our method, dubbed 'RL-Optimizer', uses a deep Q-network to learn an optimal query scheduling policy based on runtime metrics, such as query latency and resource utilization. We evaluate RL-Optimizer on a realistic benchmark and demonstrate significant improvements in query throughput and latency compared to traditional rule-based scheduling algorithms.