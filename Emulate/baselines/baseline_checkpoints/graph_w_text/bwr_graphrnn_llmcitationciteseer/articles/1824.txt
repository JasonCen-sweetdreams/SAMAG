Embodied conversational agents (ECAs) have the potential to facilitate social interactions for people with disabilities. However, existing ECAs often fail to account for diverse communication styles and abilities. This paper presents the design and evaluation of 'IncluBot', an ECA that leverages multimodal input (speech, gaze, and gesture) to engage users in inclusive conversations. We conducted a user study with 30 participants with varying abilities, demonstrating that IncluBot increased user engagement and perceived social presence compared to traditional text-based interfaces. Our findings inform the development of more inclusive and accessible ECAs that can benefit individuals with disabilities.