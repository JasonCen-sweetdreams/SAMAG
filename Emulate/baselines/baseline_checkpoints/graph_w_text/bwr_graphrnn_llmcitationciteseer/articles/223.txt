Neural search engines have shown promise in improving search results, but often rely on cumbersome query expansion techniques. This paper proposes a novel approach, 'ConQE', which leverages contrastive representation learning to generate informative query expansions. By training a neural network to predict similar queries, we learn a dense representation space that captures semantic relationships between queries and documents. Experimental results on the TREC-CAR dataset demonstrate that ConQE outperforms state-of-the-art query expansion methods, achieving a 12.5% improvement in mean average precision.