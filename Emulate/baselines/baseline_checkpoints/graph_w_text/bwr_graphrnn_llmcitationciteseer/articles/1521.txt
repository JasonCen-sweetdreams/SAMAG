This paper proposes a novel approach to cooperative task allocation for multi-agent systems, leveraging reinforcement learning to optimize task assignments and improve system performance. Our approach, called CATARL, combines a decentralized Markov decision process with a hierarchical reinforcement learning framework to enable agents to learn and adapt to changing task requirements and environmental conditions. Experimental results demonstrate that CATARL outperforms existing methods in terms of task completion rate and overall system efficiency, making it a promising solution for real-world applications such as disaster response and search and rescue operations.