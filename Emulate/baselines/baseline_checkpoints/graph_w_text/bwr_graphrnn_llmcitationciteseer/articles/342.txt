Explainable AI techniques have gained significant attention in recent years, particularly in question answering tasks. This paper proposes a novel hierarchical attention network (HAN) architecture that provides interpretable explanations for the question answering process. Our approach employs a multi-stage attention mechanism that selectively focuses on relevant context and question tokens, facilitating the generation of faithful explanations. Experimental results on the SQuAD dataset demonstrate that our HAN model achieves state-of-the-art performance while providing meaningful explanations for the predicted answers.