Knowledge graph embedding (KGE) is a crucial task in AI, aiming to represent entities and relations in a low-dimensional vector space. However, existing methods often struggle with the problem of negative sampling, which can lead to suboptimal performance. This paper proposes an adaptive negative sampling strategy, dubbed 'AdaNS', that dynamically adjusts the sampling distribution based on the current model's performance. Our approach leverages a reinforcement learning framework to learn the optimal sampling policy, resulting in improved embedding quality and accelerated training. We evaluate AdaNS on several benchmark datasets, demonstrating significant gains in link prediction and entity classification tasks.