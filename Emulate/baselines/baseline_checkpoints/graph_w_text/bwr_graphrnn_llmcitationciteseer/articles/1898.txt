Multimodal sentiment analysis (MSA) aims to predict sentiment from text, images, and videos. However, existing methods often overlook the uncertainty associated with modalities. This paper introduces HANA, a hierarchical attention network that integrates uncertainty estimation into MSA. HANA employs a Bayesian neural network to model the uncertainty of each modality, and then uses attention weights to fuse the uncertain representations. We evaluate HANA on two benchmark datasets and demonstrate improved performance and robustness compared to state-of-the-art methods. Additionally, we provide insights into the uncertainty distributions, highlighting the importance of considering uncertainty in MSA.