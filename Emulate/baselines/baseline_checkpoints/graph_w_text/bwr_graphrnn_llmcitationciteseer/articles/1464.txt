This paper introduces GRIP, a novel gaze-based intention recognition framework for adaptive interface personalization. GRIP utilizes a combination of convolutional neural networks and graph-based attention mechanisms to infer user intentions from eye movement patterns. We evaluate GRIP on a dataset of 50 users interacting with a web-based interface and demonstrate significant improvements in task completion time and user satisfaction compared to traditional rule-based personalization approaches. The proposed framework has implications for enhancing user experience in various applications, including web browsing, gaming, and assistive technologies.