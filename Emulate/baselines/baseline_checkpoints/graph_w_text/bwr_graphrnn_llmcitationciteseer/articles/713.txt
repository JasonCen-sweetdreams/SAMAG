Knowledge graph embedding has become a crucial task in various AI applications. However, existing methods often suffer from scalability issues and neglect the hierarchical structure inherent in many knowledge graphs. This paper proposes a novel approach, HierGAT, which leverages hierarchical graph attention networks to efficiently embed knowledge graphs. By recursively applying attention mechanisms at different granularities, HierGAT captures complex relational patterns and outperforms state-of-the-art methods on benchmark datasets. Experimental results demonstrate the scalability and effectiveness of HierGAT in various knowledge graph-based applications.