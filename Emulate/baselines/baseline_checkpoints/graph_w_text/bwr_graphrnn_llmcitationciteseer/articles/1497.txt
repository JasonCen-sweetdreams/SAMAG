Autonomous vehicles require real-time control systems that can adapt to complex, dynamic environments. This paper presents a hierarchical reinforcement learning framework for autonomous vehicle control, which decomposes the control problem into a set of nested, hierarchically organized tasks. Our approach leverages a deep Q-network to learn high-level, strategic decisions, while a separate, low-level controller optimizes vehicle dynamics in real-time. We demonstrate the effectiveness of our approach in a simulated urban driving scenario, achieving improved safety and efficiency compared to traditional, monolithic control architectures.