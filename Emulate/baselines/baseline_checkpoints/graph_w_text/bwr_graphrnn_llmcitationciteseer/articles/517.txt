This paper proposes a novel approach to decentralized task allocation for autonomous agents using graph-based reinforcement learning. We model the agent environment as a graph, where agents learn to allocate tasks based on their capabilities and the graph structure. Our approach leverages a decentralized reinforcement learning framework that enables agents to learn from their experiences and adapt to changing environmental conditions. Experimental results demonstrate that our approach outperforms traditional centralized task allocation methods in terms of task completion rate and agent utilization.