Virtual reality (VR) has shown promise in social skills training for individuals with autism spectrum disorder (ASD) and other conditions. However, inadequate emotional feedback can hinder the effectiveness of these interventions. This paper presents an exploratory study on designing emotional feedback mechanisms for VR-based social skills training. We propose a novel affective computing framework that incorporates machine learning-based emotion recognition and adaptive feedback generation. Our user study with 20 participants with ASD demonstrates that our approach leads to improved emotional regulation and social skills performance compared to traditional VR training. We discuss the implications of our findings for designing more empathetic and effective VR-based interventions.