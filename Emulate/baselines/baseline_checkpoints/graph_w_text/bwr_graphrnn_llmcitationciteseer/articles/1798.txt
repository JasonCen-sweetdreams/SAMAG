Neural search engines have gained popularity for their ability to capture semantic relationships in queries and documents. However, they often struggle with complex or ambiguous queries, leading to suboptimal retrieval performance. This paper proposes a deep query reformulation approach, 'NeuQR', which leverages a transformer-based architecture to generate a set of semantically diverse query variants. These variants are then used to retrieve a diverse set of candidate documents, which are subsequently re-ranked using a neural scoring model. Experiments on the TREC Deep Learning track demonstrate that NeuQR significantly improves retrieval effectiveness, particularly for difficult queries, while reducing computational overhead.