This paper presents a decentralized task allocation framework for autonomous agents using multi-agent deep reinforcement learning. We propose a novel algorithm, 'MATRL', which enables agents to learn cooperative policies for task allocation in complex, dynamic environments. MATRL utilizes a decentralized actor-critic architecture, where each agent learns to allocate tasks based on local observations and communication with neighboring agents. Our experiments on a simulated search-and-rescue scenario demonstrate that MATRL outperforms traditional, centralized methods in terms of task completion time and team efficiency.