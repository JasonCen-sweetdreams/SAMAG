Virtual reality (VR) has the potential to revolutionize accessibility, but current input methods can be exclusionary for users with disabilities. This paper presents a novel gestural input framework, 'GestVR', which leverages machine learning and computer vision to enable users to interact with VR environments using a range of natural, full-body gestures. We conducted a user study with participants with and without disabilities, demonstrating significant improvements in usability, accessibility, and overall user experience. Our approach opens up new possibilities for inclusive VR interactions, enabling a broader range of users to engage with immersive technologies.