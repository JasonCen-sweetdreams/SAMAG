Node classification is a fundamental task in graph-structured data analysis. However, existing graph neural networks (GNNs) often suffer from scalability issues and poor performance on large graphs. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages hierarchical graph representations and attention mechanisms to improve node classification. HGAT learns to focus on relevant subgraphs and adaptively aggregates features from different layers, resulting in improved performance and efficiency. Experimental results on several benchmark datasets demonstrate the effectiveness of HGAT in comparison to state-of-the-art GNNs.