Few-shot image classification remains a challenging task in machine learning, particularly when limited labeled data is available. This paper presents a novel meta-learning approach, 'ProtoMeta', which leverages self-supervised prototypical networks to learn robust representations from unlabeled data. We introduce a new metric-based loss function that encourages the learning of prototype representations that are closer to the true class means. Experiments on several benchmark datasets demonstrate that ProtoMeta significantly outperforms existing few-shot classification methods, achieving state-of-the-art results on Mini-ImageNet and CIFAR-FS.