Open-domain question answering (ODQA) requires efficient passage retrieval from a large corpus to answer a given question. Existing approaches often rely on keyword-based matching or dense retrievers, which can be computationally expensive. This paper proposes a Hierarchical Document Representation (HDR) model that leverages a novel document encoding scheme to capture both local and global contextual information. Our experiments on the Natural Questions and TriviaQA datasets demonstrate that HDR achieves state-of-the-art passage retrieval accuracy while reducing the computational cost by up to 30% compared to existing dense retrieval methods.