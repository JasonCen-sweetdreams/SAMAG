Object detection in aerial imagery is a challenging task, especially when annotated data is scarce. This paper proposes a novel deep transfer learning approach that leverages pre-trained models and fine-tunes them on a few labeled examples. We introduce a residual feature fusion module that adaptively combines features from different layers, enabling the model to capture rich contextual information. Experimental results on the popular Inria Aerial Image Dataset demonstrate that our approach achieves state-of-the-art performance on few-shot object detection tasks, outperforming existing methods by a significant margin.