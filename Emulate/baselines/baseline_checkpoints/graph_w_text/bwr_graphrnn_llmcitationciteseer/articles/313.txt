State-of-the-art neural ranking models for document retrieval rely on dense, fixed-size representations of documents and queries. However, this approach can be computationally expensive and may not effectively capture the nuances of complex queries. We propose a novel hierarchical attention mechanism that selectively focuses on relevant document segments and query terms, reducing the computational overhead while improving retrieval accuracy. Experiments on benchmark datasets demonstrate that our approach outperforms existing neural ranking models in terms of both efficiency and effectiveness.