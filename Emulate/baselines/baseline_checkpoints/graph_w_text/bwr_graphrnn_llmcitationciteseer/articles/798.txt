Cloud computing systems require efficient resource allocation to meet dynamic workload demands. This paper proposes a novel multi-agent reinforcement learning (MARL) framework, 'CloudAllocator', which allocates resources adaptively based on real-time system state and workload patterns. Our approach uses decentralized, self-organizing agents that learn to cooperate and negotiate resource allocation decisions, resulting in improved system utilization and reduced latency. Experimental results on a large-scale cloud simulation platform demonstrate the effectiveness of CloudAllocator in minimizing resource wastage and enhancing overall system performance.