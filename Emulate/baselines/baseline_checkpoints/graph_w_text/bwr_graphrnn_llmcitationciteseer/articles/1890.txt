Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can significantly degrade their performance. This paper proposes a novel input preprocessing technique, dubbed 'AdverGuard', to robustify DNNs against such attacks. AdverGuard applies a series of transformations to the input data, including pixel-wise masking and feature-space whitening, to suppress the effects of adversarial perturbations. Our experiments on multiple benchmark datasets demonstrate that AdverGuard can improve the robustness of DNNs against various types of attacks, including FGSM and PGD, while maintaining their accuracy on clean data.