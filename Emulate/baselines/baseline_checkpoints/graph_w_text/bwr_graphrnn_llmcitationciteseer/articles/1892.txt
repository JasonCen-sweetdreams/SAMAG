Urban traffic congestion is a growing concern, and traditional traffic signal control systems often struggle to optimize traffic flow in real-time. This paper proposes a hierarchical reinforcement learning (HRL) framework for autonomous traffic signal control, which leverages both high-level traffic pattern recognition and low-level signal timing optimization. Our approach integrates a graph neural network (GNN) with a deep Q-network (DQN) to learn a hierarchical policy that adapts to changing traffic conditions. Experimental results on a large-scale traffic simulator demonstrate that our HRL approach outperforms state-of-the-art methods in reducing congestion, decreasing travel times, and improving overall traffic network efficiency.