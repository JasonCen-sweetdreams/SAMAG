Individuals with dysarthria, a speech disorder affecting articulation and pronunciation, often face challenges when interacting with voice assistants. This paper presents an investigation into adaptive speech recognition techniques to improve the accessibility of voice assistants for users with dysarthria. We propose a novel framework that incorporates personalized acoustic models, spectral features, and uncertainty-based confidence scoring. Our evaluation with a dataset of dysarthric speech shows significant improvements in speech recognition accuracy and user satisfaction, highlighting the potential of our approach to enhance the inclusivity of voice-controlled systems.