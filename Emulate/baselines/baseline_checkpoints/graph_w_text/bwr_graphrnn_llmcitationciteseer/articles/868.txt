Effective task allocation is crucial in multi-agent systems, where agents must coordinate to achieve complex goals. This paper proposes a novel deep reinforcement learning framework for cooperative task allocation, called CTARL. CTARL leverages a decentralized actor-critic architecture, where each agent learns to allocate tasks based on local observations and interactions with its neighbors. We demonstrate the scalability and adaptability of CTARL in various simulated multi-agent scenarios, including search-and-rescue and package delivery tasks. Experimental results show that CTARL outperforms traditional task allocation algorithms, such as auctions and graph-based methods, in terms of task completion rate and overall system efficiency.