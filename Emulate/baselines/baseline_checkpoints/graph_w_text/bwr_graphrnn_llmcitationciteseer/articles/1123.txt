Question answering (QA) over knowledge graphs (KGs) has gained significant attention in recent years. However, existing methods struggle to effectively integrate multi-modal information from KGs, leading to suboptimal performance. This paper proposes a novel hierarchical attention-based model, 'HAT-QA', which learns to jointly embed KG entities, relations, and modalities in a shared vector space. Our approach leverages a hierarchical attention mechanism to selectively focus on relevant KG components and modalities, enabling more accurate QA. Experimental results on the MultiModalQA benchmark demonstrate that HAT-QA outperforms state-of-the-art methods by 12.5% in terms of average F1-score.