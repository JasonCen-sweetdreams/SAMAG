Autonomous vehicles (AVs) are increasingly being deployed in complex urban environments, requiring efficient task allocation to maximize their utility. This paper presents a decentralized multi-agent reinforcement learning (MARL) framework for task allocation among AVs. Our approach leverages graph neural networks to model the spatial relationships between AVs and tasks, and employs a novel communication protocol to facilitate agent-to-agent negotiation. Experimental results on a realistic simulation platform demonstrate significant improvements in task completion rates and reduced latency compared to centralized optimization methods.