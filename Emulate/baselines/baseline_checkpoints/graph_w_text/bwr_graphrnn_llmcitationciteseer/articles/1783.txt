Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can compromise their reliability in safety-critical applications. This paper proposes a novel approach to improving the adversarial robustness of DNNs by integrating Bayesian neural networks with symbolic learning. Our method, 'BayesSL', first learns a probabilistic neural network to model the uncertainty of the input data, and then uses symbolic reasoning to identify and prune vulnerable neurons. We evaluate BayesSL on several benchmark datasets and demonstrate its effectiveness in improving the robustness of DNNs against various types of adversarial attacks.