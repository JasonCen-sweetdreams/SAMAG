Voice assistants have become ubiquitous, but their speech-centric interfaces often exclude users with disabilities. This paper presents a multimodal framework, 'AccessibleVA', which integrates computer vision, gesture recognition, and haptic feedback to create a more inclusive voice assistant. We conducted a user study with 30 participants with varying abilities, demonstrating that AccessibleVA significantly improves task completion rates and user satisfaction compared to traditional voice-only interfaces. Our approach has implications for enhancing accessibility in smart homes, healthcare, and education.