Existing sentiment analysis models often struggle to capture complex relationships between modalities in multi-modal data. This paper presents a novel hierarchical attention network (HAN) architecture that leverages explainable AI techniques to identify influential modalities and features. Our proposed HAN model employs a hierarchical structure to learn attention weights at multiple levels, enabling the model to selectively focus on relevant modalities and features. Experimental results on a large-scale multi-modal dataset demonstrate that our approach outperforms state-of-the-art models in terms of accuracy and interpretability, providing actionable insights into the decision-making process.