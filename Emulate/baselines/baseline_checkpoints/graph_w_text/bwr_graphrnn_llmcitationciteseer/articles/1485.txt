Individuals with motor impairments often face significant barriers when interacting with digital systems. This paper presents a novel approach to designing gestural interfaces that adapt to the unique abilities and needs of each user. Our system, dubbed 'Gesto', employs a machine learning-based framework to recognize and learn from user gestures, dynamically adjusting the interface to accommodate varying levels of motor control. A user study with 20 participants demonstrates that Gesto significantly improves task completion times and reduces user frustration compared to traditional, one-size-fits-all interfaces.