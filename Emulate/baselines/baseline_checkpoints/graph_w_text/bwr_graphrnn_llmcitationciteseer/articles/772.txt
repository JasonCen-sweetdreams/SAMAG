Autonomous vehicles (AVs) require robust decision-making systems to navigate complex scenarios. This paper presents a hierarchical reinforcement learning framework, 'HierRL', which learns to prioritize tasks and adapt to uncertainty in real-time. Our approach integrates a high-level planning module with a low-level control policy, leveraging probabilistic graphical models to reason about uncertainty. We demonstrate HierRL's effectiveness in simulated and real-world AV experiments, showcasing improved safety and efficiency in diverse weather and traffic conditions.