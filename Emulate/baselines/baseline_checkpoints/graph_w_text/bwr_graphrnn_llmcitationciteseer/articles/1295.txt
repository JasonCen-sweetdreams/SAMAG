This paper presents a novel approach to coordinated task allocation in multi-agent systems using reinforcement learning. We propose a decentralized framework, 'CATAR', where each agent learns to select tasks based on its own capabilities, task urgency, and the actions of other agents. Our algorithm incorporates a graph-based encoding of agent-task relationships and a hierarchical reward function that promotes cooperation and efficiency. Experimental results on a simulated disaster response scenario demonstrate that CATAR outperforms traditional auction-based methods in terms of task completion rate and overall system utility.