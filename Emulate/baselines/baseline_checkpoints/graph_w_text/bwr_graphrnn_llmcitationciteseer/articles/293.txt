In multi-agent systems, task allocation is a complex problem, particularly when agents have diverse capabilities and tasks have varying requirements. This paper proposes a hierarchical reinforcement learning framework for distributed task allocation in heterogeneous multi-agent systems. Our approach leverages a high-level task allocator that assigns tasks to agent groups, and a low-level allocator that distributes tasks within each group. We demonstrate the effectiveness of our approach through simulations in a disaster response scenario, where agents with different capabilities work together to rescue people and deliver aid.