This paper proposes a decentralized multi-agent reinforcement learning (MARL) framework for efficient resource allocation in smart grids. We model the problem as a cooperative game, where agents representing different grid nodes learn to optimize their resource allocation strategies to minimize energy losses and maximize overall grid stability. Our approach combines deep Q-networks with a communication protocol that enables agents to share knowledge and adapt to changing grid conditions. Experimental results on a realistic grid simulation platform demonstrate improved resource allocation efficiency and resilience compared to traditional centralized optimization methods.