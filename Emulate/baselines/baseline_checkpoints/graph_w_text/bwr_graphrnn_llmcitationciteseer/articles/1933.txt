Voice assistants have become ubiquitous in smart homes, but their speech recognition capabilities often struggle with accented speech, leading to frustration and exclusion. This paper presents a user-centered design approach to improve the recognition of accented speech in voice assistants. We conducted a series of studies with 30 participants from diverse linguistic backgrounds, analyzing their interactions with popular voice assistants. Our findings highlight the importance of phonetic adaptation, language modeling, and user feedback in enhancing recognition accuracy. We propose a novel framework, 'AccentAware', which integrates these insights and demonstrates a significant improvement in recognition rates for accented speech.