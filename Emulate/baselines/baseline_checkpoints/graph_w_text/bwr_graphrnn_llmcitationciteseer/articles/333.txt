Reinforcement learning agents often struggle to provide interpretable decision-making processes, hindering their adoption in high-stakes applications. This paper presents a novel Hierarchical Attention Network (HAN) architecture that integrates attention mechanisms at multiple levels to generate explainable policies. Our approach learns to focus on relevant state features, action sequences, and temporal dependencies, producing a hierarchical representation of the decision-making process. We evaluate HAN on a suite of Atari games and demonstrate significant improvements in both policy performance and interpretability over existing state-of-the-art methods.