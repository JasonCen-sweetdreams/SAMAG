Ad-hoc retrieval is a fundamental task in information retrieval, where the goal is to retrieve relevant documents for a given query. Query expansion is a popular technique to improve retrieval performance, but it often relies on manual feature engineering and heuristics. This paper proposes a neural query expansion framework, 'NQE', which leverages pre-trained language models to learn dense embeddings of queries and documents. We develop a novel attention-based mechanism to adaptively select expansion terms based on the query context and document relevance. Experiments on several TREC datasets demonstrate that NQE outperforms state-of-the-art query expansion methods, achieving significant improvements in mean average precision and recall.