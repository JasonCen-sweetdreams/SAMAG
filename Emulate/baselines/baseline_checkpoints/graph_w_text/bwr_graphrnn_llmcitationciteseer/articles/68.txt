Reinforcement learning (RL) has achieved impressive success in complex decision-making tasks, but the lack of interpretability hinders its adoption in high-stakes applications. This paper proposes an attention-based state abstraction framework, 'AttnAbs', that provides explainability in RL by identifying relevant state features and their relationships. We introduce a novel attention mechanism that learns to focus on salient state variables and abstract away irrelevant ones, resulting in more transparent and efficient policy learning. Experimental results on a range of Atari games demonstrate that AttnAbs improves policy interpretability without sacrificing performance.