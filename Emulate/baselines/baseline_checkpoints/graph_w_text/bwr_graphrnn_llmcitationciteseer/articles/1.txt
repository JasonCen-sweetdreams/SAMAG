As manufacturing systems increasingly incorporate robots and human workers, real-time collaboration becomes essential. This paper presents a hierarchical reinforcement learning framework, 'HRL-Collab', that enables robots to adapt to dynamic human behaviors and optimize collaborative task execution. Our approach leverages a two-level hierarchy: a high-level policy selects collaboration strategies, while a low-level policy controls robot actions. We evaluate HRL-Collab in a simulated manufacturing environment and demonstrate improved task efficiency and worker satisfaction compared to traditional scripted robot control.