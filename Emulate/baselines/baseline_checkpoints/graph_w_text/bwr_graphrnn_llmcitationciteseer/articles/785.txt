Individuals with motor impairments face significant challenges when interacting with technology. This paper presents a novel approach to personalized gesture recognition, leveraging machine learning and computer vision techniques to improve the accuracy and usability of gesture-based interfaces. We propose a framework that adaptively learns to recognize gestures from a user's unique motor patterns, accommodating variations in ability and movement. Our user study with 20 participants demonstrates a significant improvement in gesture recognition accuracy and user satisfaction, paving the way for more inclusive and accessible human-computer interaction.