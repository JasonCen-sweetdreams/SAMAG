Virtual reality (VR) systems rely on accurate and intuitive user input methods. This paper presents a novel gaze-based interaction approach using deep learning techniques. Our method, named 'GazeNet', leverages a convolutional neural network to predict user intent from eye gaze patterns. We conducted a user study with 30 participants and demonstrated that GazeNet achieves an average accuracy of 92.1% in identifying intended virtual objects. Furthermore, our approach reduces the latency of traditional ray-casting methods by 35%. The proposed system has the potential to enhance the overall VR experience and facilitate more natural human-computer interaction.