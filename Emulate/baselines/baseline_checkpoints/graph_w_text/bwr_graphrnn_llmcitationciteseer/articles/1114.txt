As augmented reality (AR) technology becomes increasingly prevalent, there is a growing need for more intuitive and natural interaction methods. This paper presents a novel gaze-based interaction system for AR environments using deep learning. We propose a convolutional neural network (CNN) architecture that predicts the user's intended target from eye-tracking data. Our approach leverages a large-scale dataset of gaze patterns and achieves state-of-the-art performance in identifying objects of interest. We demonstrate the feasibility of our system in a real-world AR application, showcasing improved user experience and reduced interaction time.