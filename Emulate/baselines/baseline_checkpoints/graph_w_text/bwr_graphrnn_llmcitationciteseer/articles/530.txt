As information systems continue to grow in scale and complexity, efficient retrieval of relevant information from diverse modalities (e.g., text, images, videos) becomes increasingly challenging. This paper proposes a novel deep neural ranking model, 'MMR-NET', which leverages multi-modal fusion and hierarchical attention mechanisms to improve retrieval efficiency and effectiveness. Experimental results on a large-scale dataset demonstrate that MMR-NET outperforms state-of-the-art approaches in terms of precision, recall, and latency, making it a promising solution for real-world information retrieval applications.