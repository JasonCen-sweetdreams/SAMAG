Autonomous urban traffic control demands intelligent decision-making to minimize congestion and reduce travel times. This paper presents a novel hierarchical reinforcement learning (HRL) framework for multi-agent traffic control. Our approach decomposes the complex task into a hierarchical structure, consisting of high-level route planning and low-level traffic signal control. We propose a distributed asynchronous advantage actor-critic algorithm that enables efficient learning and adapts to dynamic traffic patterns. Experimental results on a realistic simulator demonstrate that our HRL framework reduces travel times by 23% and decreases congestion by 17% compared to traditional traffic signal control methods.