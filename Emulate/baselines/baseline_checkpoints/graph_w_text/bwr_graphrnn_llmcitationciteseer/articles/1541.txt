Ad-hoc retrieval models typically rely on exact term matching, neglecting the rich contextual information inherent in queries. This paper introduces a novel neural ranking model, 'CtxQER', which leverages pre-trained language models to generate contextualized query embeddings. We propose a hierarchical attention mechanism that adaptively weighs the importance of query terms based on their semantic roles. Experiments on the TREC-CAR dataset demonstrate that CtxQER significantly outperforms state-of-the-art models, particularly for complex, multi-entity queries. Our analysis reveals that the proposed approach effectively captures nuanced query semantics, leading to improved retrieval effectiveness.