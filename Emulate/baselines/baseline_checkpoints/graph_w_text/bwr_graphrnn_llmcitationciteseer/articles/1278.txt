With the increasing demand for multi-modal search, query expansion techniques have become crucial for improving retrieval efficiency. This paper proposes a novel deep learning-based approach, 'MMQE', which leverages the strengths of both language models and visual feature extractors to expand queries. MMQE uses a multi-task learning framework to jointly learn query semantics and visual representations, enabling effective expansion of queries for text-image searches. Experimental results on a large-scale dataset demonstrate that MMQE outperforms state-of-the-art query expansion methods in terms of retrieval accuracy and efficiency.