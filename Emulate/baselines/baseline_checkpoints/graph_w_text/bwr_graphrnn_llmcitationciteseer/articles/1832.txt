Voice assistants have become ubiquitous in modern life, but individuals with dysarthria, a speech disorder affecting articulation and pronunciation, often struggle to interact with these systems effectively. This paper presents a novel framework for designing accessible voice assistants tailored to the needs of individuals with dysarthria. We propose a multi-modal input method combining speech recognition with gesture-based input, and develop a personalized error correction mechanism that adapts to the user's speech patterns. A user study with 20 participants with dysarthria demonstrates significant improvements in interaction accuracy and user satisfaction compared to commercial voice assistants.