Node classification in large-scale graphs is a fundamental problem in graph-based machine learning. However, existing methods often suffer from high computational complexity and limited scalability. This paper proposes a novel hierarchical graph attention network (HGAT) framework that leverages attention mechanisms to selectively focus on relevant nodes and edges. We introduce a hierarchical aggregation strategy that iteratively applies attention at multiple granularity levels, enabling efficient feature extraction and propagation. Experiments on benchmark datasets demonstrate that HGAT achieves state-of-the-art node classification performance while reducing computational overhead by up to 75% compared to existing methods.