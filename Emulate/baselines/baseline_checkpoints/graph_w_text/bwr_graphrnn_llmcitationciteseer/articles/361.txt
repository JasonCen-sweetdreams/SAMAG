Explainability has become a crucial aspect in modern AI systems, particularly in multi-task learning (MTL) where models are prone to task interference. This paper introduces Hierarchical Attention Networks (HANs) for explainable MTL, which leverage attention mechanisms to selectively focus on relevant task-specific features. HANs consist of a hierarchical structure of task-agnostic and task-specific attention layers, allowing for interpretable feature importance and attention weights. Our experiments on several benchmark MTL datasets demonstrate that HANs outperform existing state-of-the-art MTL models while providing insightful explanations for task relationships and feature interactions.