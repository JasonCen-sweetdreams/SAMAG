Multi-agent reinforcement learning (MARL) has shown promise in solving complex tasks, but the lack of interpretability hinders its adoption in real-world applications. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that leverages attention mechanisms to provide explainable MARL policies. Our approach enables the identification of crucial agents, actions, and states that contribute to the team's decision-making process. We evaluate HAN on a set of cooperative and competitive MARL benchmarks, demonstrating improved performance and interpretability compared to state-of-the-art methods.