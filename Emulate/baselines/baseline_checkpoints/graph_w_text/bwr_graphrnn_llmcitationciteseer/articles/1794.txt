Multi-agent systems often struggle with efficient task allocation due to the complexity of coordinating heterogeneous agents. This paper proposes a novel approach that leverages reinforcement learning to adaptively allocate tasks to agents based on their capabilities and preferences. Our framework, 'HARVEST', uses a decentralized Q-learning algorithm to learn the optimal task assignments, taking into account the dynamic environment and agent interactions. Experimental results on a simulated logistics scenario demonstrate that HARVEST significantly outperforms traditional allocation methods, achieving up to 35% reduction in task completion time and 25% increase in overall system efficiency.