Anomaly detection in industrial time series data is crucial for ensuring process efficiency and preventing costly downtime. This paper proposes a novel deep reinforcement learning (DRL) framework, 'AnomRL', which leverages the strengths of both model-based and data-driven approaches. AnomRL uses a hybrid actor-critic architecture to learn a policy for identifying anomalies in real-time, combining the benefits of accurate modeling and adaptability to changing process conditions. Experimental results on a large-scale industrial dataset demonstrate the effectiveness of AnomRL in detecting anomalies with high precision and recall, outperforming state-of-the-art methods.