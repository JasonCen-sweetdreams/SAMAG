Node classification is a fundamental task in graph-structured data analysis, but existing methods often struggle with scaling to large networks. This paper proposes a novel hierarchical attention-based graph neural network (HAGNN) that leverages both local and global structural features to improve node classification accuracy. We introduce a hierarchical attention mechanism that adaptively weights node representations at different scales, enabling the model to capture complex relationships between nodes. Experimental results on several large-scale benchmark datasets demonstrate that HAGNN outperforms state-of-the-art graph neural network models, achieving a significant improvement in node classification accuracy.