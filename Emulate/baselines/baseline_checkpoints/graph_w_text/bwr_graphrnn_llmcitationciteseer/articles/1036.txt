Query expansion is a crucial technique in information retrieval to improve the retrieval performance. Traditional methods rely on manual feature engineering and fail to capture the semantic relationships between words. This paper proposes a novel neural query expansion approach, 'NeuroQE', which leverages pre-trained language models to learn dense semantic embeddings for query terms. We introduce a multi-task learning framework to jointly optimize the retrieval performance and semantic similarity between words. Experimental results on several benchmark datasets show that NeuroQE outperforms state-of-the-art query expansion methods by 15% in terms of mean average precision.