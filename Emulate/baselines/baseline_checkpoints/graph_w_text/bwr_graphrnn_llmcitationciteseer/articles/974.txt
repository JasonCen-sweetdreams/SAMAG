Gesture recognition systems have become increasingly prevalent in human-computer interaction, but their design often overlooks the needs of users with motor impairments. This paper presents a user-centered approach to designing inclusive gesture recognition systems, focusing on users with cerebral palsy and Parkinson's disease. We conducted a series of participatory design workshops and usability studies to inform the development of a novel gesture recognition framework that incorporates adaptive machine learning algorithms and personalized gesture sets. Our results show significant improvements in recognition accuracy and user satisfaction compared to traditional gesture recognition systems.