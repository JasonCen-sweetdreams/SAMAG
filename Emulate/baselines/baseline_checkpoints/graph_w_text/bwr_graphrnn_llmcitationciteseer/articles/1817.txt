This paper presents the design and evaluation of ' GestureEase', a gesture-based interface tailored to support older adults with dementia. Our approach incorporates a multimodal fusion of computer vision, machine learning, and user-centered design to recognize and adapt to individual differences in gesture patterns. A user study with 20 participants demonstrates significant improvements in task completion time, accuracy, and user satisfaction compared to traditional touchscreen interfaces. Our findings inform the development of more inclusive and accessible interfaces for older adults with dementia, highlighting the potential for HCI to promote healthy aging and social participation.