In multi-agent reinforcement learning, the ability to learn hierarchical task representations is crucial for efficient coordination and planning. This paper presents a novel unsupervised learning approach, called HTR-MA, which discovers hierarchical task representations from raw agent observations. Our method leverages a hierarchical variational autoencoder to learn a disentangled representation of tasks, and a graph-based clustering algorithm to identify meaningful task clusters. Experimental results on a range of multi-agent environments demonstrate that HTR-MA significantly outperforms existing methods in terms of task completion rate and agent coordination.