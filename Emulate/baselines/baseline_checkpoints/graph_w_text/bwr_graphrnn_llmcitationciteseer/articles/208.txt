Query expansion (QE) is a crucial component in ad-hoc retrieval, as it helps to alleviate the vocabulary mismatch problem. However, existing QE methods often rely on handcrafted rules or superficial keyword extraction. This paper proposes a novel deep reinforcement learning (DRL) framework, 'QE-DRL', which learns to expand queries by optimizing a reward function that balances retrieval effectiveness and efficiency. Our approach leverages a neural query encoder and a reinforcement learning agent that interactively refines the query representation. Experimental results on several benchmark datasets demonstrate that QE-DRL outperforms state-of-the-art QE methods in terms of precision, recall, and F1-score.