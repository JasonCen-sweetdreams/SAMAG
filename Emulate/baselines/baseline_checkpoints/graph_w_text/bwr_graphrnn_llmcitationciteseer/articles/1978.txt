Cooperative multi-agent systems require efficient task allocation strategies to achieve common goals. This paper proposes a novel approach using deep reinforcement learning to allocate tasks among agents in a distributed setting. We design a decentralized, asynchronous framework where agents learn to optimize their task assignments based on local observations and communication with neighboring agents. Experimental results on a simulated search-and-rescue scenario demonstrate improved task completion rates and reduced communication overhead compared to traditional auction-based methods.