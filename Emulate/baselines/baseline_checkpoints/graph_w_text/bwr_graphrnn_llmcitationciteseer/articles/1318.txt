As autonomous vehicles (AVs) become increasingly prevalent, ensuring their decision-making processes are transparent and trustworthy is crucial. This paper presents a novel hierarchical reinforcement learning framework, 'XRL', which incorporates explainability techniques to shed light on the decision-making process of AVs. XRL employs a hierarchical policy architecture, where a high-level policy selects among multiple low-level policies, each responsible for a specific driving scenario. We propose a model-agnostic explanation method, 'AV-Explainer', which generates visual and textual explanations for the AV's actions. Experimental results on a simulated driving environment demonstrate that XRL outperforms state-of-the-art reinforcement learning methods in terms of both driving performance and explanation quality.