Autonomous agents require effective dialogue management to achieve task-oriented goals in human-agent interactions. This paper proposes a hierarchical reinforcement learning framework, HierRL, which integrates a high-level task manager with a low-level dialogue generator. The task manager learns to select relevant tasks and subtasks, while the dialogue generator uses a deep reinforcement learning model to generate context-dependent responses. We evaluate HierRL in a simulated environment and show that it outperforms state-of-the-art methods in terms of task success rate and dialogue coherence. Our approach has implications for the development of more sophisticated autonomous agents in real-world applications.