Voice assistants have become ubiquitous in modern life, but their language processing capabilities often perpetuate cultural and linguistic biases. This paper presents a mixed-methods study on the impact of cultural and linguistic biases on voice assistant interactions. We conducted a survey of 500 participants from diverse linguistic and cultural backgrounds, followed by a usability study of three popular voice assistants. Our results show that existing voice assistants struggle to recognize and respond to non-standard dialects and accents, leading to frustration and exclusion. We propose a set of design guidelines for inclusive voice assistants, including culturally-sensitive language models and adaptive error correction mechanisms.