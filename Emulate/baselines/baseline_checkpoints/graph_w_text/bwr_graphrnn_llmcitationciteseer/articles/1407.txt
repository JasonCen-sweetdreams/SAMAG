This paper presents a novel approach to coordinating multi-agent systems for urban traffic management using hierarchical reinforcement learning. We propose a two-level framework, where high-level agents learn to optimize traffic signal control policies and low-level agents adapt to local traffic conditions. Our method leverages graph neural networks to represent complex traffic networks and incorporates real-time traffic data to improve policy learning. Experimental results on a simulated traffic network demonstrate that our approach outperforms traditional traffic signal control methods, reducing congestion and travel times by up to 25%.