Explainable AI has become a crucial aspect of recommender systems, as they need to provide transparent and trustworthy suggestions. This paper proposes a novel hierarchical graph attention network (HGAN) framework that leverages item relationships and user preferences to generate personalized explanations for recommendations. HGAN consists of a hierarchical graph encoder and a multi-hop attention mechanism, which allows the model to capture complex item relationships and identify influential items. Experimental results on four benchmark datasets demonstrate that HGAN outperforms state-of-the-art explainable recommendation models in terms of accuracy, diversity, and explanation quality.