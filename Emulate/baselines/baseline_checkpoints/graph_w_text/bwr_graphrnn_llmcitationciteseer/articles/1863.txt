In multi-agent systems, task allocation is a complex problem that requires efficient decision-making to maximize overall performance. This paper proposes a novel deep reinforcement learning framework, 'MATRL', which leverages graph neural networks to model agent interactions and learn optimal task assignments. We introduce a hierarchical action space decomposition method that reduces the complexity of the task allocation problem, enabling MATRL to scale to large numbers of agents and tasks. Experimental results on a simulated robotic warehouse scenario demonstrate that MATRL outperforms state-of-the-art methods in terms of task completion efficiency and adaptability to changing environmental conditions.