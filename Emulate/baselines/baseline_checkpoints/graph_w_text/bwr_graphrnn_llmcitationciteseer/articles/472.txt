Task allocation in multi-agent systems is crucial for efficient collaboration. This paper presents a novel approach that leverages deep reinforcement learning to optimize task assignment and coordination among agents. We propose a hierarchical framework, CMATA, which learns to allocate tasks based on agent capabilities, task dependencies, and environmental constraints. Our experiments demonstrate that CMATA outperforms traditional methods in scenarios with varying agent availability and task complexity, showcasing its potential for real-world applications such as disaster response and robotic search and rescue.