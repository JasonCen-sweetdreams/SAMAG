Individuals with dysarthria, a speech disorder affecting articulation and intelligibility, often struggle to interact with voice assistants. This paper presents 'DysaVA', a novel framework for designing inclusive voice assistants that accommodate users with dysarthria. We propose a multi-modal input system combining acoustic, linguistic, and visual features to improve speech recognition accuracy. Our user study with 20 participants with dysarthria demonstrates that DysaVA significantly enhances interaction experience, reducing errors by 35% and increasing user satisfaction by 42%. We discuss implications for accessible HCI design and future directions for personalized assistive technologies.