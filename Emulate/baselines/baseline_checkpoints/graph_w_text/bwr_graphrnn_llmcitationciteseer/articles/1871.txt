Coordinated exploration in multi-agent systems is crucial for efficient task allocation and decision-making. This paper proposes a novel approach that leverages hierarchical graph neural networks (HGNNs) to represent agent interactions and environment dynamics. Our method, called CoEx-HGNN, learns to identify informative regions of the state space and allocate agents to explore these areas in a coordinated manner. Experimental results on a variety of multi-agent environments demonstrate that CoEx-HGNN outperforms existing methods in terms of exploration efficiency and task success rate.