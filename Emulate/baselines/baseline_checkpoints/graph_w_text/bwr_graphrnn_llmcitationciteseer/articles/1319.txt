This paper explores the application of deep reinforcement learning to coordinate multi-agent systems in dynamic task allocation scenarios. We propose a novel framework, 'MACTOR', which utilizes a decentralized actor-critic architecture to learn effective task assignment and scheduling policies. Our approach leverages graph neural networks to model agent interactions and incorporate domain knowledge into the learning process. Experimental results on a simulated warehouse management domain demonstrate that MACTOR outperforms traditional optimization methods in terms of task completion efficiency and adaptability to changing environmental conditions.