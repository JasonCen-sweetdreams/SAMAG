Traditional ranking models in information retrieval rely on handcrafted features and shallow neural networks, limiting their ability to capture complex document structures and relationships. We propose a novel hierarchical graph neural network (HGNN) architecture, which models documents as hierarchical graphs of entities, concepts, and keywords. Our approach learns to rank documents by aggregating node and edge features, enabling the capture of semantic relationships and contextual information. Experiments on benchmark datasets demonstrate significant improvements in ranking performance and efficiency compared to state-of-the-art models, making HGNN a promising solution for large-scale information retrieval applications.