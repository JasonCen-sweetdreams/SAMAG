Conventional information retrieval (IR) systems often struggle to balance retrieval effectiveness with query response time. This paper proposes a hybrid retrieval model that combines the strengths of lexical and semantic matching techniques. Our approach leverages pre-trained language models to generate dense semantic embeddings, which are then incorporated into a probabilistic retrieval framework. Experimental results on several benchmark datasets demonstrate significant improvements in retrieval accuracy and efficiency, particularly for complex queries. We also explore the impact of embedding dimensionality and query rewriting strategies on model performance.