This paper addresses the problem of coordinating autonomous agents in complex, dynamic environments. We propose a decentralized partially observable Markov decision process (Dec-POMDP) framework that enables agents to reason about their own and other agents' actions, observations, and goals. Our approach leverages a novel belief-space planning algorithm that efficiently computes, communicates, and updates agents' policies. Experimental results in a robotic search-and-rescue scenario demonstrate the effectiveness of our method in achieving coordinated behavior and improving overall team performance.