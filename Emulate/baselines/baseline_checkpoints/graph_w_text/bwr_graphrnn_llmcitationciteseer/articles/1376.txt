Autonomous agents in complex environments often face challenges in task allocation due to incomplete information and uncertainty. This paper proposes a distributed task allocation framework, 'POMDP-TA', that leverages partially observable Markov decision processes (POMDPs) to reason about agent beliefs and preferences. We develop a scalable algorithm that integrates POMDP planning with distributed constraint optimization to allocate tasks efficiently. Experimental results on a simulated robotic swarm demonstrate that POMDP-TA outperforms existing decentralized approaches in terms of task completion rate and agent satisfaction.