Wearable devices have become ubiquitous, but their potential for affective state recognition remains underexplored. This paper presents EmoGlass, a novel system that leverages computer vision and deep learning to recognize emotional states from facial expressions, head movements, and physiological signals captured by a smart glasses prototype. Our approach integrates a convolutional neural network (CNN) for facial feature extraction, a recurrent neural network (RNN) for temporal modeling, and a multimodal fusion strategy to combine heterogeneous sensor data. Evaluations on a dataset of 100 participants demonstrate EmoGlass's ability to accurately recognize five emotional states (happiness, sadness, anger, fear, and surprise) with a mean F1-score of 0.83.