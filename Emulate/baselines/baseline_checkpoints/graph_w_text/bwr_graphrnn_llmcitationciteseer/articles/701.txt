This paper proposes a decentralized multi-agent reinforcement learning framework for adaptive traffic signal control. We model each traffic signal as an autonomous agent that learns to optimize traffic flow through real-time communication with neighboring agents. Our approach, dubbed 'Traffic Harmony', leverages graph neural networks to capture complex traffic patterns and adapts to changing traffic conditions. Experiments on a realistic traffic simulator demonstrate that Traffic Harmony reduces congestion by 23% and travel times by 17% compared to traditional fixed-time signal control methods.