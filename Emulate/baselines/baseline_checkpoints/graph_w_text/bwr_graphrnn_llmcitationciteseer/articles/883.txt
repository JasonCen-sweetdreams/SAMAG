Coordinating multi-agent systems in environments with incomplete information is a challenging problem. Traditional methods rely on explicit communication or domain-specific knowledge, limiting their applicability. We propose a novel approach that leverages deep reinforcement learning to learn coordination strategies in decentralized partial-observation Markov decision processes. Our method, called 'Dec-PPO', combines decentralized policy optimization with a neural network architecture that incorporates attention mechanisms to handle incomplete information. Experimental results on a range of benchmarks demonstrate that Dec-PPO outperforms state-of-the-art methods in achieving efficient coordination in multi-agent systems.