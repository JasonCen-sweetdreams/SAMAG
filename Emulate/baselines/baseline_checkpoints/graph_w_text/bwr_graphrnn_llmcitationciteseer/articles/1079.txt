Deep reinforcement learning (DRL) agents have achieved remarkable success in complex decision-making tasks, but their opacity hinders trust and interpretability. This paper presents a novel model-agnostic explainability framework, 'RL-Explain', which leverages attention mechanisms and feature importance scores to provide insightful explanations for DRL agent decisions. Our approach is evaluated on several Atari games and a real-world robotics control task, demonstrating significant improvements in explanation fidelity and efficiency compared to existing methods.