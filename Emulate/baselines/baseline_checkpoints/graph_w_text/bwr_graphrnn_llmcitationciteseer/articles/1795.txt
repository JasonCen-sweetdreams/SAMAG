Graph Convolutional Networks (GCNs) have emerged as a powerful tool for graph-structured data analysis. However, designing efficient GCN architectures remains a manual and time-consuming process. This paper proposes a novel neural architecture search (NAS) algorithm, GraphNAS, which leverages reinforcement learning to search for optimal GCN architectures. GraphNAS incorporates a novel graph-aware reward function and a dynamic pruning mechanism to reduce search space. Experimental results on several benchmark datasets demonstrate that GraphNAS discovers GCN architectures with improved computational efficiency and comparable accuracy to state-of-the-art manual designs.