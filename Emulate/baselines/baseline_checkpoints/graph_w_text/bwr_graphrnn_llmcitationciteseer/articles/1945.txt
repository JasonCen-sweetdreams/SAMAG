In multi-agent systems, task allocation is a complex problem, especially in dynamic environments. This paper proposes a novel hierarchical reinforcement learning framework, 'HRL-MA', that enables agents to coordinate and adapt to changing task requirements. Our approach combines a high-level task allocator with low-level agent controllers, allowing agents to learn effective task assignment strategies while responding to unexpected events. Experimental results in a simulated disaster response scenario demonstrate that HRL-MA significantly improves task completion rates and reduces response times compared to traditional decentralized approaches.