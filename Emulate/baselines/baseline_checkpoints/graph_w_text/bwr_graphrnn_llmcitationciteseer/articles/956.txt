In multi-agent systems, task allocation is a critical problem that requires efficient and adaptive decision-making. This paper proposes a decentralized cooperative learning framework, 'CoopLearn', that enables agents to learn from each other and allocate tasks dynamically. We introduce a novel graph neural network-based approach that captures agent relationships and task dependencies, allowing agents to make informed decisions without a centralized controller. Experimental results on a simulated robotic swarm demonstrate that CoopLearn outperforms traditional centralized allocation methods in terms of task completion rate and system adaptability.