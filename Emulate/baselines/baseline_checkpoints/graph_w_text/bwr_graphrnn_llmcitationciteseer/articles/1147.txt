In multi-agent systems, decision making often involves complex interactions and trade-offs between agents. This paper proposes a novel Hierarchical Attention Network (HAN) architecture to model agent interactions and provide explainable decision-making. HAN consists of two levels of attention: intra-agent attention to capture local agent behaviors and inter-agent attention to model global interactions. We evaluate HAN on a real-world autonomous vehicle dataset and demonstrate improved decision-making performance and interpretability compared to existing approaches. Our results have significant implications for Explainable AI (XAI) in multi-agent systems.