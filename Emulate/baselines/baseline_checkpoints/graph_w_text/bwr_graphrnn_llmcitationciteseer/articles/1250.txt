Coordinating autonomous agents in complex multi-agent systems is a challenging problem. This paper proposes a hierarchical reinforcement learning framework, 'HierAgent', which enables agents to learn coordinated policies in a decentralized manner. HierAgent employs a novel hierarchical structure, where high-level agents learn to coordinate low-level agents, facilitating the emergence of complex behaviors. We demonstrate the effectiveness of HierAgent in a series of experiments, showcasing its ability to coordinate agents in tasks such as resource allocation and predator-prey scenarios.