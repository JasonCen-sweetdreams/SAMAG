In multi-agent systems, coordinating agents to achieve efficient resource allocation is a challenging problem. This paper proposes a novel approach that leverages deep reinforcement learning to learn decentralized policies for resource allocation. We introduce a hierarchical framework that consists of a high-level coordinator and low-level agents, where the coordinator learns to allocate resources based on the agents' observations and actions. Experimental results on a simulated resource allocation problem demonstrate that our approach outperforms traditional methods in terms of resource utilization and allocation efficiency.