Traditional document representation methods in information retrieval (IR) often rely on bag-of-words or vector space models, which fail to capture complex relationships between entities and concepts. This paper introduces a novel hypergraph-based document representation, 'HyperDoc', which leverages high-order dependencies between words and entities to improve retrieval efficiency. We demonstrate the effectiveness of HyperDoc on several benchmark datasets, achieving significant improvements in recall and precision compared to state-of-the-art methods. Furthermore, we show that HyperDoc can be seamlessly integrated with existing IR systems, making it a practical solution for real-world applications.