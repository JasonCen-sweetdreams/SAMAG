Multi-agent pathfinding in dynamic environments is a challenging problem that arises in various applications, including autonomous vehicles and robotics. This paper presents a deep reinforcement learning approach, called DMAP, that learns to optimize agent trajectories in real-time. We propose a novel graph attention mechanism that captures the complex interactions between agents and the environment, and develops a hierarchical policy that balances global exploration and local exploitation. Experimental results on a set of simulated scenarios demonstrate that DMAP outperforms state-of-the-art methods in terms of efficiency, safety, and adaptability.