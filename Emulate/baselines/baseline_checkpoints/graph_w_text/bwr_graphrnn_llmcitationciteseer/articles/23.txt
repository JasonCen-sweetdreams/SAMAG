Explainability is crucial in modern recommendation systems to build trust with users. This paper proposes a novel Hierarchical Graph Neural Network (HGNN) architecture that incorporates both item and user graph structures to generate personalized recommendations. Our model learns to identify influential items and users, providing interpretable explanations for the recommended items. We conduct extensive experiments on multiple benchmark datasets, demonstrating the superiority of HGNN over state-of-the-art methods in terms of both recommendation accuracy and explanation quality.