Conversational AI systems rely on accurate intent detection and slot filling to understand user requests. Existing approaches typically treat these tasks separately, leading to suboptimal performance. We propose a novel multi-task learning framework, ' JointIDSF', which jointly learns intent detection and slot filling using a shared encoder and task-specific decoders. Our approach leverages a hierarchical attention mechanism to model complex relationships between intent and slot labels. Experimental results on two benchmark datasets, ATIS and SNIPS, demonstrate that JointIDSF outperforms state-of-the-art models on both tasks, achieving a 5.2% absolute improvement in intent detection accuracy and a 3.5% increase in slot filling F1-score.