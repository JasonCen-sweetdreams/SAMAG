Deep neural networks have been shown to be vulnerable to adversarial attacks, which can be catastrophic in safety-critical applications. This paper proposes a novel hierarchical adversarial training framework, 'HAT', which leverages the idea of curriculum learning to improve the robustness of deep models. HAT iteratively generates adversarial examples at multiple scales, from local to global, and incorporates them into the training process. Experimental results on benchmark datasets demonstrate that HAT-trained models achieve state-of-the-art robustness against various types of attacks, including white-box and black-box attacks, while maintaining competitive performance on clean data.