Neural information retrieval (NIR) models have shown promising results in ad-hoc retrieval tasks. However, they often struggle to capture the nuances of user queries, leading to suboptimal performance. In this paper, we propose a novel query expansion framework that leverages the strengths of both traditional keyword extraction and neural language modeling. Our approach, called 'NeuroXPand', combines the semantic spaces of BERT and Word2Vec to generate high-quality expansion terms, which are then weighted using a neural ranking model. Experimental results on the TREC-CAR dataset demonstrate that NeuroXPand significantly improves the retrieval effectiveness of state-of-the-art NIR models, particularly for short and ambiguous queries.