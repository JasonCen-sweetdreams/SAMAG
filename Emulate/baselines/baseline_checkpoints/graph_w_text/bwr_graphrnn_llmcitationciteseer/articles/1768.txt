As robots increasingly interact with humans in shared workspaces, there is a growing need for efficient human-robot collaboration (HRC) strategies. This paper proposes a hierarchical reinforcement learning (HRL) framework that enables robots to adapt to changing human preferences and tasks in real-time. Our approach combines a high-level policy that selects tasks based on human feedback with a low-level policy that executes the selected task. We demonstrate the effectiveness of our HRL framework in a simulated HRC environment, achieving significant improvements in task completion efficiency and human satisfaction compared to traditional flat reinforcement learning approaches.