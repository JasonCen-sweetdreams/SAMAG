Traditional latent semantic analysis (LSA) techniques for document retrieval suffer from the curse of dimensionality and ignore semantic relationships between words. This paper proposes a novel approach, 'LSA-WE', which integrates word embeddings into the LSA framework to capture nuanced word semantics. We demonstrate that LSA-WE significantly improves document retrieval efficiency and effectiveness, achieving a 25% increase in precision and a 30% reduction in retrieval time compared to traditional LSA methods. Experiments on a large-scale news article dataset validate the efficacy of our approach.