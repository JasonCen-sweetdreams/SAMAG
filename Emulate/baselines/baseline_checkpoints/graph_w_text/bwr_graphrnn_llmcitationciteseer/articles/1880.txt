Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can compromise their reliability in critical applications. This paper proposes a novel approach to enhance the robustness of DNNs against such attacks using Bayesian neural network ensembling (BNNE). We demonstrate that BNNE can improve the model's resistance to attacks by averaging predictions from an ensemble of Bayesian neural networks, each with a different prior distribution. Experimental results on popular image classification datasets show that our approach achieves state-of-the-art robustness to adversarial attacks while maintaining competitive accuracy on clean data.