Distributed databases have become increasingly popular for handling large-scale data storage and processing. However, query optimization in such systems remains a challenging problem. This paper proposes a novel approach to query optimization using reinforcement learning. We model the query optimization problem as a Markov decision process and use deep Q-networks to learn an optimal query execution plan. Our approach takes into account various factors such as data distribution, network latency, and node availability. Experimental results on a real-world distributed database show that our approach outperforms traditional query optimization techniques by up to 30% in terms of query execution time.