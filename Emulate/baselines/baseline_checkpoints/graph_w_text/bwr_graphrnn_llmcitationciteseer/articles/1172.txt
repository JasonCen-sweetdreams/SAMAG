Explainability in recommender systems has gained significant attention in recent years. This paper proposes a novel attention-based framework that incorporates knowledge graph embeddings to provide interpretable recommendations. Our approach, 'Att-KGE', learns to attend to relevant entities in the knowledge graph and generates personalized explanations for each recommendation. Experimental results on real-world datasets demonstrate that Att-KGE outperforms state-of-the-art baselines in terms of recommendation accuracy and explanation quality.