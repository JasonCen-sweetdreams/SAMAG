Query expansion (QE) is a crucial step in ad-hoc retrieval, aiming to bridge the vocabulary gap between users' queries and relevant documents. This paper presents a novel reinforcement learning (RL) approach to QE, which learns to select the most effective expansion terms by interacting with a simulated search environment. Our method, dubbed 'RL-QE', leverages a deep Q-network to estimate the expected retrieval performance of different expansion strategies, and adaptively adjusts the exploration-exploitation trade-off during training. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art QE methods in terms of retrieval effectiveness and efficiency.