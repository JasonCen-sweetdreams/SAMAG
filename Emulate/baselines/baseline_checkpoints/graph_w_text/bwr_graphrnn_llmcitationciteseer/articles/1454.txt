Multimedia knowledge graphs have become increasingly popular for integrating heterogeneous data from various sources. However, existing embedding models require large amounts of labeled data, which is often scarce and expensive to obtain. This paper proposes a novel zero-shot learning approach, 'MultimediaZSL', which leverages the graph structure and multimodal features to learn robust embeddings without any labeled data. We introduce a hierarchical attention mechanism that adaptively weights the importance of different modalities and relations, resulting in improved embedding quality and better performance on downstream tasks. Experiments on several benchmark datasets demonstrate the effectiveness of MultimediaZSL in facilitating knowledge graph completion and entity disambiguation.