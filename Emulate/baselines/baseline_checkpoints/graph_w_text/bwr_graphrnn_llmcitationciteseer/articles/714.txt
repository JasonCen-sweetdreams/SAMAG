This paper presents a novel approach to cooperative path planning for multi-agent systems using deep reinforcement learning. We propose a decentralized framework, 'MAPPER', which enables agents to learn cooperative behaviors and adapt to changing environmental conditions. MAPPER uses a hybrid architecture combining graph neural networks and deep Q-networks to represent agent interactions and optimize path planning. Experimental results on a simulated urban transportation scenario demonstrate that MAPPER outperforms traditional model-based planning methods in terms of task completion time and agent safety.