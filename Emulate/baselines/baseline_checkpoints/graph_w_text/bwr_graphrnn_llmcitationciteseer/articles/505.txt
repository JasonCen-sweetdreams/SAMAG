Cooperative task allocation is a complex problem in multi-agent systems, where agents must coordinate to achieve a common goal. This paper presents a novel multi-agent reinforcement learning framework, 'CoopMARL', which leverages graph neural networks to learn cooperative policies. We introduce a hierarchical reward function that encourages agents to form coalitions and allocate tasks efficiently. Experimental results on a variety of cooperative task allocation scenarios demonstrate that CoopMARL outperforms existing methods in terms of solution quality and computation time.