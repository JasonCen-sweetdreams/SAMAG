Query expansion is a crucial step in ad-hoc information retrieval, where the goal is to reformulate an initial query to retrieve more relevant documents. This paper proposes a novel deep reinforcement learning framework, 'DeepQE', which learns to select optimal expansion terms by maximizing a reward function that balances retrieval effectiveness and query clarity. We leverage a hierarchical encoder-decoder architecture to model the query-document relationship and incorporate a curiosity-driven exploration strategy to adapt to diverse query types. Experimental results on several benchmark datasets demonstrate that DeepQE significantly outperforms state-of-the-art query expansion methods in terms of precision, recall, and mean average precision.