Join operations are a fundamental component of relational databases, but their optimization remains a challenging task, especially in distributed environments. This paper presents a novel approach that leverages machine learning to optimize join operations in distributed relational databases. We propose a framework that uses reinforcement learning to adaptively select the most efficient join order based on the database schema, data distribution, and query workload. Experimental results on a real-world dataset demonstrate that our approach outperforms state-of-the-art join optimization techniques, achieving up to 3x improvement in query execution time.