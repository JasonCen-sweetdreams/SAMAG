Knowledge graph embedding (KGE) has become a crucial technique for AI applications, but existing methods struggle to capture complex relationships between entities. We propose HiGAT, a novel KGE framework that leverages hierarchical graph attention networks to model entity relationships at different granularity levels. HiGAT uses a stacked attention mechanism to aggregate features from neighboring entities, enabling the capture of both local and global structural patterns. Our experiments on benchmark datasets show that HiGAT outperforms state-of-the-art KGE methods in link prediction and entity classification tasks, while reducing computational cost.