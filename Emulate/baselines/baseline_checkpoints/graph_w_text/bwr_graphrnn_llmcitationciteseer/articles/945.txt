Multi-agent systems (MAS) are increasingly used in complex applications, but task allocation remains a challenging problem. This paper presents a decentralized task allocation framework, 'DRL-TA', which leverages deep reinforcement learning to optimize task assignments in heterogeneous MAS. We propose a novel actor-critic architecture that incorporates graph attention mechanisms to capture agent interactions and task dependencies. Experimental results on a simulated logistics scenario demonstrate that DRL-TA outperforms traditional optimization methods in terms of task completion time and resource utilization, while adapting to dynamic agent availability and task priorities.