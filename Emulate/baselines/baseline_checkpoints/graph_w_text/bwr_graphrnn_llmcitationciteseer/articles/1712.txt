Query expansion is a crucial step in ad-hoc retrieval, but existing methods often rely on heuristics or manual feature engineering. This paper proposes a novel deep reinforcement learning framework, 'RL-QE', which learns to generate effective expansion terms by maximizing a reward function that balances retrieval accuracy and efficiency. Our approach leverages a hierarchical attention mechanism to model complex query-document relationships and adaptively selects expansion terms based on their expected impact on retrieval performance. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art query expansion methods, achieving significant improvements in mean average precision and normalized discounted cumulative gain.