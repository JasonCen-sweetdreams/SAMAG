Older adults with cognitive impairments face significant barriers when interacting with modern digital systems. This paper presents a novel multimodal interface framework, 'EasyAccess', that integrates speech, gesture, and gaze-based inputs to facilitate intuitive and accessible interactions. We conducted a user study with 30 older adults with cognitive impairments, demonstrating that EasyAccess significantly improved task completion rates and reduced frustration compared to traditional keyboard-and-mouse interfaces. Our findings highlight the importance of considering cognitive and sensory abilities in HCI design, and provide insights for developing more inclusive and supportive technologies.