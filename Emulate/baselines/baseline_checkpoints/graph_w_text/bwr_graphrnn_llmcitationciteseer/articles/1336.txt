Explainability is crucial in autonomous driving, where reinforcement learning (RL) agents make critical decisions. We propose a novel Hierarchical Attention Network (HAN) architecture that integrates attention mechanisms at multiple levels to provide insights into the decision-making process. Our HAN model consists of a hierarchical feature extractor, attention-based state representation, and a policy network. Experimental results on a simulated driving environment show that our approach outperforms state-of-the-art RL methods in terms of task performance while providing interpretable explanations for the agent's actions.