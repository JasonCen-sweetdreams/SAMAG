Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but the lack of interpretability hinders its adoption in high-stakes applications. This paper presents a novel approach to enhancing the explainability of DRL agents by incorporating hierarchical attention mechanisms. Our method, dubbed 'HierExplain', adaptively focuses on relevant state features and action dimensions, generating contextual explanations for the agent's decisions. We empirically demonstrate HierExplain's effectiveness in improving transparency and trustworthiness of DRL models in a range of Atari games and real-world robotics tasks.