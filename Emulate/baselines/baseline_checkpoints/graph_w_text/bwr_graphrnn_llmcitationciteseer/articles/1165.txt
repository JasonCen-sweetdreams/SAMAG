Explainable recommendation systems have gained increasing attention in recent years, as users seek transparency in personalized suggestions. This paper proposes a novel hierarchical attention graph convolutional network (HAGCN) model that leverages both node-level and graph-level attention mechanisms to generate interpretable recommendations. Our approach learns to identify influential users and items in the graph, and their relationships, to provide personalized explanations for top-N recommendations. Experimental results on multiple benchmark datasets demonstrate the effectiveness of HAGCN in improving recommendation accuracy and explanation quality.