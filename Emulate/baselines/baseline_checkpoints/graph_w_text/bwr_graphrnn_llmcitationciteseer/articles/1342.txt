Coordinating multiple agents to achieve common goals in dynamic environments is a challenging problem in AI research. This paper presents a novel hierarchical graph attention network (HGAT) architecture that enables agents to learn cooperative strategies in complex, partially observable environments. HGAT combines graph attention mechanisms with hierarchical reinforcement learning to model agent interactions and adapt to changing environmental conditions. Our experiments demonstrate that HGAT outperforms existing state-of-the-art methods in several multi-agent benchmarks, including pursuit-evasion and resource allocation tasks.