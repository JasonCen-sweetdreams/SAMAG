Node classification is a fundamental task in graph-structured data, where the goal is to predict the labels of nodes based on their features and connections. While Graph Neural Networks (GNNs) have achieved state-of-the-art performance, they often suffer from computational bottlenecks and over-smoothing issues. To address these limitations, this paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages hierarchical attention mechanisms to selectively focus on relevant nodes and subgraphs. Our experiments on benchmark datasets demonstrate that HGAT achieves superior performance and efficiency compared to existing GNN models, especially on large-scale graphs.