Neural ranking models have revolutionized Information Retrieval (IR) by learning complex document representations. However, most existing approaches rely on flat, sequential encoding of documents, neglecting their inherent hierarchical structure. This paper proposes Hierarchical Attention-based Neural Ranking (HANR), a novel framework that leverages both local and global context to represent documents. HANR employs a hierarchical attention mechanism to selectively focus on relevant passages, sentences, and words, leading to improved retrieval performance. Experiments on several benchmarks demonstrate the effectiveness of HANR, outperforming state-of-the-art neural ranking models by a significant margin.