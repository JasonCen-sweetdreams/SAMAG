Multi-hop question answering (MHQA) models have achieved state-of-the-art performance on various benchmarks, but their interpretability remains a major challenge. This paper proposes a novel hierarchical attention network (HAN) for MHQA, which recursively applies attention mechanisms to capture complex reasoning patterns. Our approach leverages a graph-based reasoning framework to identify relevant entities and relationships, and incorporates an explainability module to generate faithful explanations for the predicted answers. Experimental results on the HotPotQA and WikiHop datasets demonstrate that our HAN model outperforms existing MHQA models while providing insightful explanations for its predictions.