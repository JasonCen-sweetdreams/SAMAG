This paper presents a novel approach to distributed task allocation in multi-agent systems, leveraging hierarchical reinforcement learning (HRL) to optimize task assignments and improve overall system efficiency. Our proposed method, dubbed 'HierAgent', employs a two-level hierarchy of agents, where high-level agents learn to allocate tasks to low-level agents based on their capabilities and availability. We demonstrate the effectiveness of HierAgent through simulations of a disaster response scenario, showing significant improvements in task completion rates and resource utilization compared to baseline methods.