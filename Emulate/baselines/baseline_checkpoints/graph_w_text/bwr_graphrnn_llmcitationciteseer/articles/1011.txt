Time series forecasting has numerous applications in finance, healthcare, and climate science. While AI-driven models have achieved state-of-the-art performance, they often lack interpretability. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates explainability mechanisms into time series forecasting. Our HAN model adaptively focuses on relevant segments of the input sequence, providing insights into the underlying dynamics. We demonstrate the effectiveness of our approach on four benchmark datasets, achieving significant improvements in forecasting accuracy and providing meaningful explanations of the predicted outcomes.