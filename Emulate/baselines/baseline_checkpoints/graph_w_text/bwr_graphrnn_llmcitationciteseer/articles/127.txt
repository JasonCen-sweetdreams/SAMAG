Recent advancements in autonomous vehicles rely heavily on reinforcement learning (RL) to optimize control policies. However, existing RL methods struggle to scale to complex, multi-agent scenarios. This paper proposes a novel framework, 'MARL-Ctrl', which leverages decentralized, multi-agent RL to learn cooperative control policies for autonomous vehicles. We introduce a hierarchical architecture that combines graph neural networks with off-policy RL to efficiently learn optimal control strategies. Experimental results on a realistic traffic simulation demonstrate MARL-Ctrl's ability to improve traffic flow and reduce congestion in urban environments.