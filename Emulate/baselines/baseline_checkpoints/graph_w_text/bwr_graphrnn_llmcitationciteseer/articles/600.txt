The proliferation of edge devices has created a pressing need for efficient deep learning models that can operate within stringent resource constraints. This paper presents 'EcoNAS', a novel neural architecture search (NAS) framework that leverages a surrogate-based optimization strategy to identify compact, high-performance models for edge deployment. Our approach incorporates a device-aware fitness function that considers both accuracy and resource utilization, enabling the discovery of models that achieve state-of-the-art performance on edge benchmarks while reducing memory footprint and energy consumption by up to 50%. We demonstrate EcoNAS's efficacy on various edge computing tasks, including image classification and object detection.