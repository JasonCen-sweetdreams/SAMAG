Conversational search systems aim to provide more accurate results by incorporating context from previous interactions. However, existing methods struggle to effectively capture long-range dependencies and semantic relationships within conversations. This paper proposes a novel context-aware re-ranking framework, 'ConverGA', which leverages hierarchical graph attention to model conversation structures. ConverGA employs a two-level graph attention mechanism to capture both local and global contextual information, allowing for more accurate re-ranking of search results. Experimental results on the TREC Conversational Assistance Track dataset demonstrate significant improvements in retrieval performance and conversation coherence.