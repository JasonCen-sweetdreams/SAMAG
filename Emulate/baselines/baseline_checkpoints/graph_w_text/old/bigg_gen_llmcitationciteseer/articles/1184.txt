Voice assistants have become ubiquitous, but their limitations in understanding emotional cues and conversational nuances can lead to frustration and exclusion. This paper presents an HCI-driven approach to designing more empathetic and inclusive voice assistants. We propose an emotional intelligence framework that integrates machine learning-based sentiment analysis with dialogue management strategies inspired by human conversational patterns. A user study with 30 participants demonstrated improved user satisfaction and emotional engagement with our prototype, particularly among individuals with disabilities. Our findings have implications for the development of more accessible and compassionate conversational AI systems.