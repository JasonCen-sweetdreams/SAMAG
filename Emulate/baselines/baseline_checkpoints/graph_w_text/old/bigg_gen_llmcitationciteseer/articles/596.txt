Autonomous vehicles require complex control policies that balance safety, efficiency, and adaptability to diverse environments. We present 'HierRL', a hierarchical reinforcement learning framework that leverages a novel, curriculum-based learning approach to optimize vehicle control. HierRL decomposes the control problem into a series of nested, increasingly abstract tasks, allowing the agent to focus on high-level decision-making while delegating low-level control to specialized sub-policies. Our experiments demonstrate significant improvements in both training speed and driving performance compared to flat, monolithic reinforcement learning architectures.