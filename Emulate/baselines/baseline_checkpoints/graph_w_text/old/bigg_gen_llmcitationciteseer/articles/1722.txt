Coordinating multiple agents in complex environments is a long-standing challenge in artificial intelligence. This paper presents a novel hierarchical reinforcement learning approach to address this problem. Our method, called Hierarchical Agent Coordination (HAC), uses a two-level architecture where a high-level controller learns to coordinate agents at a macro level, while low-level controllers learn to optimize individual agent policies. We demonstrate the effectiveness of HAC in a simulated multi-robot warehouse management scenario, achieving improved coordination and reduced communication overhead compared to existing decentralized methods.