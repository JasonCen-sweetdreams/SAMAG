Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables understanding of complex agent interactions. This paper proposes a novel hierarchical attention network (HAN) architecture for MARL, which learns to focus on relevant agents and their interactions to make decisions. Our approach includes a hierarchical attention mechanism that recursively applies attention at different levels of abstraction, allowing the model to capture complex relationships between agents. Experimental results on three MARL benchmarks demonstrate that our HAN-based approach outperforms state-of-the-art methods in terms of both performance and interpretability.