Neural retrieval models have achieved state-of-the-art performance in various information retrieval tasks. However, they often struggle to effectively incorporate relevance feedback from users. This paper proposes a novel query expansion approach that leverages pseudo-relevance feedback to improve the retrieval accuracy of neural models. Our method, called PRF-Net, generates synthetic relevance labels using a teacher-student framework and incorporates them into the query representation. Experimental results on the TREC-CAR dataset demonstrate that PRF-Net outperforms existing query expansion methods, achieving a significant improvement in terms of nDCG@10 and MAP.