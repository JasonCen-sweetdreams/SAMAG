Neural retrieval models have revolutionized information retrieval (IR) by leveraging deep learning techniques to capture semantic relationships between queries and documents. However, these models often struggle with vocabulary mismatch and query drift, leading to suboptimal performance. This paper proposes a novel query expansion approach that leverages pseudo-relevance feedback to adaptively select expansion terms. We introduce a neural ranking model that incorporates a feedback loop to iteratively refine the query representation, resulting in significant improvements in retrieval effectiveness. Experimental results on several benchmark datasets demonstrate the efficacy of our approach, outperforming state-of-the-art neural IR models.