Autonomous navigation in dynamic environments poses significant challenges for AI systems. This paper proposes a hierarchical reinforcement learning (HRL) framework that enables efficient and adaptive navigation in complex scenarios. Our approach combines a high-level planning module with a low-level control policy, leveraging a novel attention mechanism to focus on relevant environmental features. We demonstrate the effectiveness of our method in simulated and real-world experiments, showcasing improved navigation efficiency and robustness in the presence of obstacles and uncertainties.