In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel approach that leverages graph convolutional networks (GCNs) to model agent interactions and allocate tasks in a distributed manner. By representing the agent communication graph as a GCN, we can learn a task allocation policy that takes into account the agents' capabilities, preferences, and constraints. Experimental results on a simulated rescue scenario demonstrate that our approach outperforms state-of-the-art methods in terms of task completion rate and overall system efficiency.