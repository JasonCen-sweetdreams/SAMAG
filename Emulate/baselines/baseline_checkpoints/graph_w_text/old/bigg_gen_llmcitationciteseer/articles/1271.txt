As autonomous systems become increasingly prevalent, understanding the decision-making processes of multi-agent systems is crucial. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in complex multi-agent scenarios. Our approach leverages a bottom-up attention mechanism to selectively focus on relevant agents and their interactions, while a top-down attention module provides contextual information to guide decision-making. Experimental results on a simulated autonomous vehicle dataset demonstrate improved interpretability and performance compared to existing methods, highlighting the potential of HANs for transparent and trustworthy AI.