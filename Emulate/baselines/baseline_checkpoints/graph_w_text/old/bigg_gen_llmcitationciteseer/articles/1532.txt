Online learning with deep neural networks (DNNs) is a crucial task in many applications, such as image classification and natural language processing. However, existing methods often struggle with changing data distributions and suffer from overfitting. This paper proposes an efficient online learning algorithm, 'AdaReg', which adaptively adjusts the regularization strength based on the data uncertainty. We theoretically analyze the convergence properties of AdaReg and demonstrate its effectiveness on several benchmark datasets. Experimental results show that AdaReg achieves significant improvements in model accuracy and stability compared to state-of-the-art online learning methods.