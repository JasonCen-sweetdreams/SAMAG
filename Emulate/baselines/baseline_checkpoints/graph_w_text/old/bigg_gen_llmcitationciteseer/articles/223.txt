Deep learning models have been widely adopted in various applications, but they are vulnerable to adversarial attacks that can manipulate their outputs. Existing methods for detecting such attacks often rely on statistical analysis or anomaly detection, which may not be effective in complex scenarios. This paper proposes a novel approach, 'XAI-Defend', that leverages explainable AI techniques to identify adversarial attacks. By analyzing the feature importance and attention weights in deep neural networks, XAI-Defend can detect subtle perturbations in the input data and alert the system to potential attacks. Our experimental results on several benchmark datasets demonstrate the effectiveness of XAI-Defend in detecting various types of adversarial attacks, including those crafted using state-of-the-art methods.