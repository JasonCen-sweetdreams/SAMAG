Deep reinforcement learning (DRL) has achieved state-of-the-art performance in various applications, but it is vulnerable to adversarial attacks that can manipulate the agent's behavior. This paper proposes a novel graph-based anomaly detection framework, 'GADRL', to identify and detect adversarial attacks in DRL. We model the agent's behavior as a graph and leverage graph-based anomaly detection techniques to identify abnormal patterns. Experimental results on popular DRL benchmarks show that GADRL outperforms existing detection methods in terms of accuracy and robustness, demonstrating its effectiveness in enhancing the security of DRL systems.