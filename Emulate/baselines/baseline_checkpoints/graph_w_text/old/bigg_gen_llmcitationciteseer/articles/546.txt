As augmented reality (AR) technology becomes more pervasive in public spaces, there is a growing need to design intuitive and accessible interaction methods. This paper presents a gesture-based interaction framework for AR experiences in public spaces, which leverages computer vision and machine learning to recognize and interpret user gestures. We conducted a user study with 30 participants to evaluate the usability and effectiveness of our framework in a real-world setting. Results show that our approach enables users to seamlessly interact with AR content while minimizing distractions and improving overall user experience.