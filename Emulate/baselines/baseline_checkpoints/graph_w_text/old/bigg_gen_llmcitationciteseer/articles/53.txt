Query expansion is a crucial step in information retrieval (IR) systems, as it aims to reformulate the original query to better capture user intent. While traditional methods rely on manual feature engineering and term weighting, we propose a novel approach that leverages deep neural networks to learn query expansion strategies. Our model, dubbed 'QNLP', integrates a sentence encoder with a graph-based attention mechanism to generate context-aware expansion terms. Experimental results on several benchmark datasets demonstrate that QNLP outperforms state-of-the-art methods in terms of retrieval effectiveness, with significant improvements in precision and recall.