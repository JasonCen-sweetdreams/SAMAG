Ad-hoc retrieval systems often struggle to effectively capture the nuances of user queries, leading to suboptimal retrieval performance. This paper introduces a novel unsupervised query expansion approach, 'RL-QE', that leverages reinforcement learning to adaptively select expansion terms. Our method employs aDeep Q-Network (DQN) to learn a query-term scoring policy, which is trained using a reward function that balances precision and recall. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art query expansion techniques, particularly for queries with limited context or ambiguous terms.