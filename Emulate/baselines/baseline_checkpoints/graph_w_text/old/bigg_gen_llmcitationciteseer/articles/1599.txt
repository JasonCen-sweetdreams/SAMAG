Neural retrieval models have shown impressive results in ad-hoc retrieval tasks, but their computational complexity hinders scalability. This paper proposes a novel semantic indexing approach, 'NeuralHub', which leverages knowledge graph embeddings to efficiently prune the search space. By encoding document semantics into a dense vector space, NeuralHub reduces the retrieval latency by an order of magnitude while maintaining retrieval effectiveness. Experiments on the MS MARCO passage ranking dataset demonstrate the efficacy of NeuralHub in large-scale retrieval scenarios.