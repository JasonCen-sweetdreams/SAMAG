Autonomous vehicles rely on complex decision-making algorithms to navigate real-world scenarios. This paper presents a hierarchical reinforcement learning framework, 'HierRL', which enables efficient exploration and exploitation of high-dimensional state spaces. We introduce a novel temporal abstraction mechanism that decomposes the decision-making process into shorter-term and longer-term objectives, allowing the agent to adapt to changing environments. Experimental results demonstrate that HierRL outperforms existing flat RL methods in simulated urban driving scenarios, achieving improved safety and efficiency metrics.