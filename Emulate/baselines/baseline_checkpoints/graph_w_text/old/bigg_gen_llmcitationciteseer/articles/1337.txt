Online reviews often contain multi-modal data, including text, images, and ratings. However, existing sentiment analysis methods struggle to effectively integrate and weigh the importance of these modalities. This paper introduces HAN-MMSA, a hierarchical attention network that learns to selectively focus on relevant modalities and aspects of the input data. Our model utilizes a novel attention mechanism that propagates importance weights across modalities, enabling more accurate sentiment predictions. Experimental results on a large-scale review dataset demonstrate the superiority of HAN-MMSA over state-of-the-art approaches, particularly in scenarios with noisy or incomplete data.