Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks, but its lack of transparency hinders trust and adoption. This paper introduces 'Attentive-XRL', a novel approach to explainability in DRL. By incorporating attention mechanisms into model interpretation, we enable adaptive focusing on salient state features that drive policy decisions. Our method provides more accurate and informative explanations than existing techniques, as demonstrated on a series of Atari games and a real-world robotics control task. We also show that Attentive-XRL can facilitate more efficient policy improvement through targeted refinement of the attention weights.