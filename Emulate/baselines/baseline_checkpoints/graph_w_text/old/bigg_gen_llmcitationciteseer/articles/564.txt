Coordinating multiple agents in dynamic environments is a challenging problem in artificial intelligence. This paper presents a novel hierarchical attention network (HAN) architecture that enables efficient communication and cooperation among agents. Our approach integrates graph attention mechanisms with hierarchical reinforcement learning, allowing agents to focus on relevant teammates and adapt to changing environmental conditions. We evaluate our method in a simulated urban search and rescue scenario, demonstrating improved team performance and robustness compared to state-of-the-art methods.