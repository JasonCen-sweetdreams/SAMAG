Explainability is a crucial aspect of AI-driven recommendation systems, as it builds trust and transparency with users. This paper proposes a novel hierarchical attention-based graph neural network (HAGNN) framework that incorporates both item and user embeddings to generate personalized recommendations. Our model leverages attention mechanisms to focus on relevant features and items, providing interpretable explanations for the recommended items. We conduct extensive experiments on real-world datasets, demonstrating that HAGNN outperforms state-of-the-art methods in terms of recommendation accuracy and explanation quality.