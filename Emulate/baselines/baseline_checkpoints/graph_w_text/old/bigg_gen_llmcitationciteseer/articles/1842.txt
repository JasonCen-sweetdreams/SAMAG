In multi-agent systems, task allocation is a crucial problem that involves assigning tasks to agents to maximize overall system efficiency. This paper presents a decentralized task allocation framework using hierarchical reinforcement learning (HRL). Our approach consists of a high-level task allocation policy that learns to allocate tasks to agents based on their capabilities and availability, and a low-level control policy that learns to execute the allocated tasks. We evaluate our framework in a simulated multi-robot scenario and demonstrate improved task completion rates and reduced communication overhead compared to existing decentralized task allocation methods.