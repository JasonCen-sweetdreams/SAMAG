This paper presents a novel multi-agent reinforcement learning framework for distributed resource allocation in smart grids. We model the problem as a decentralized Markov decision process, where each agent represents a microgrid and learns to optimize its resource allocation strategy based on local observations and communication with neighboring agents. Our approach leverages a hierarchical decomposition of the global reward function, enabling agents to balance individual and collective objectives. Experimental results on a simulated smart grid environment demonstrate improved convergence rates and robustness to uncertainty compared to traditional optimization methods.