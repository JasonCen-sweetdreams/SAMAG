The vulnerability of deep neural networks to adversarial attacks has become a significant concern in machine learning. This paper proposes a novel approach to detect adversarial attacks using graph-based anomaly detection. We represent the neural network's input data as a graph, where nodes denote individual features and edges capture their correlations. By analyzing the graph structure, we identify anomalous patterns indicative of adversarial attacks. Our approach, dubbed 'GraphGuard', outperforms existing detection methods in terms of accuracy and robustness, as demonstrated on several benchmark datasets.