Open-domain question answering (ODQA) has seen significant advancements with the rise of transformer-based models. However, existing approaches often struggle to effectively utilize relevant documents from a large corpus. We propose a novel hierarchical re-ranking framework that incorporates document expansion to improve ODQA performance. Our approach first ranks a subset of passages from the corpus using a dense retriever, and then expands the context of top-ranked passages by incorporating neighboring sentences. The expanded documents are then re-ranked using a transformer-based reader model. Experiments on the Natural Questions benchmark demonstrate that our approach outperforms state-of-the-art models by 3.5% in terms of exact match accuracy.