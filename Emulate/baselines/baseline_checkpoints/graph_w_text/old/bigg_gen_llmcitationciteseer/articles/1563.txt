This paper addresses the problem of cooperative task allocation in multi-agent systems, where agents with varying capabilities must work together to accomplish complex tasks. We propose a novel deep reinforcement learning framework, 'CATALYST', which enables agents to learn cooperative strategies and allocate tasks effectively in dynamic environments. Our approach combines a graph neural network with a decentralized actor-critic method, allowing agents to share knowledge and adapt to changing task requirements. Experimental results on a simulated search-and-rescue scenario demonstrate that CATALYST outperforms traditional planning-based methods in terms of task completion rate and agent utility.