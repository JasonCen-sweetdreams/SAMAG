Task allocation in multi-agent systems is a challenging problem, especially when agents have diverse capabilities and tasks have varying priorities. This paper proposes a novel cooperative task allocation framework using deep reinforcement learning. We model the problem as a decentralized Markov decision process and train a multi-agent deep Q-network to allocate tasks efficiently. Our approach leverages attention mechanisms to capture agent interactions and prioritize tasks based on their urgency. Experimental results on a simulated disaster response scenario demonstrate that our approach outperforms traditional optimization-based methods in terms of task completion time and agent utilization.