Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can compromise their accuracy and reliability. This paper presents a novel defense strategy, 'EnsembleShield', that leverages ensemble diversity to improve the robustness of DNNs against such attacks. By combining multiple DNNs with diverse architectures and training protocols, EnsembleShield creates an ensemble model that is more resilient to attacks. We demonstrate the effectiveness of our approach on several benchmark datasets, showing significant improvements in robustness against state-of-the-art attacks while maintaining competitive accuracy on clean data.