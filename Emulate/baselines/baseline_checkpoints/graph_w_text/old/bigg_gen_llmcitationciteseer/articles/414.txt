Deep reinforcement learning (DRL) has achieved impressive successes in complex decision-making tasks. However, the lack of transparency in DRL models hinders their adoption in high-stakes applications. This paper proposes a novel approach to explainability in DRL, leveraging model-based state abstraction to identify a compact and meaningful representation of the environment. Our method, 'AbstrExplain', learns to abstract the state space into a lower-dimensional manifold, enabling the generation of interpretable explanations for the agent's decisions. Experimental results on several Atari games demonstrate that AbstrExplain improves upon existing explainability techniques while maintaining the performance of the underlying DRL policy.