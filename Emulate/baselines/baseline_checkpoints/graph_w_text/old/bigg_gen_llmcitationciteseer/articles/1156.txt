We propose a novel approach to distributed task allocation in multi-agent systems, leveraging meta-reinforcement learning to adapt to changing task distributions and agent capabilities. Our method, called MATRL, learns a meta-policy that can be fine-tuned for new tasks and agents with minimal additional training data. We demonstrate MATRL's effectiveness in a simulated robotic warehouse environment, where it outperforms state-of-the-art methods in terms of task completion time and agent utilization. Our approach has potential applications in real-world domains such as logistics, search and rescue, and smart manufacturing.