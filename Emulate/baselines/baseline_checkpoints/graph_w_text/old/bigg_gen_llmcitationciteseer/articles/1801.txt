Multi-agent reinforcement learning (MARL) has gained popularity in recent years, but the lack of interpretability hinders its widespread adoption. This paper introduces a novel Hierarchical Attention Network (HAN) architecture that learns to selectively focus on relevant agents and their interactions. Our approach enables explainable decision-making in MARL by providing attention weights that indicate the contribution of each agent to the joint policy. Experimental results on a variety of cooperative and competitive domains demonstrate that HAN outperforms state-of-the-art MARL methods while providing insights into the decision-making process.