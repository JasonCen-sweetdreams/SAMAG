State-of-the-art neural ranking models for information retrieval (IR) often require significant computational resources and large amounts of training data. This paper proposes a novel hierarchical neural ranking model, 'HydraRank', which leverages a multi-stage ranking architecture to efficiently retrieve relevant documents. HydraRank combines a lightweight document encoder with a hierarchical attention mechanism, enabling it to effectively capture both local and global contextual information. Experimental results on several benchmark datasets demonstrate that HydraRank achieves comparable ranking performance to state-of-the-art models while reducing computational costs by up to 40%.