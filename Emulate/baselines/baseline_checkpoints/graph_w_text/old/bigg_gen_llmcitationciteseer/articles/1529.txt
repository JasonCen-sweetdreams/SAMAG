We present a novel approach to gaze-based interaction with augmented reality (AR) displays, leveraging machine learning techniques to improve accuracy and user experience. Our system uses a convolutional neural network (CNN) to detect and classify eye movements, enabling users to select virtual objects and navigate AR environments with high precision. We evaluate our approach on a dataset of 30 participants and demonstrate significant improvements in interaction speed and accuracy compared to traditional gaze-tracking methods. Our findings have implications for the design of more intuitive and accessible AR interfaces.