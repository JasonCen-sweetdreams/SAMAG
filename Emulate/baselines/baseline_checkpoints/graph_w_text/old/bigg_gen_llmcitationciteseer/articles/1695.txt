Ad-hoc retrieval often relies on query expansion (QE) to improve retrieval effectiveness. However, traditional QE methods suffer from the vocabulary mismatch problem, where the expanded query terms may not align with the document vocabulary. This paper proposes a neural QE approach, called NeuQE, which leverages document embeddings to capture semantic relationships between terms. NeuQE uses a transformer-based architecture to learn a shared representation space for queries and documents, enabling effective expansion of the original query. Experimental results on several benchmark datasets demonstrate that NeuQE outperforms state-of-the-art QE methods, achieving significant improvements in retrieval accuracy and efficiency.