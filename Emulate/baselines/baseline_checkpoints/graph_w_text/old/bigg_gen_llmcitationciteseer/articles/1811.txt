Open-domain question answering (ODQA) systems rely on passage retrieval to identify relevant contexts for answering user queries. However, existing methods often struggle to retrieve passages that contain the correct answer. This paper proposes a query-driven document expansion approach, which expands the input query by incorporating relevant keywords and entities from the top-retrieved passages. Our experimental results on the Natural Questions dataset demonstrate that the proposed method improves passage retrieval accuracy by 12.5% compared to state-of-the-art models, leading to a 7.2% increase in end-to-end question answering performance.