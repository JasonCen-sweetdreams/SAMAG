This paper introduces a decentralized multi-agent reinforcement learning framework for coordinating autonomous vehicles in complex traffic scenarios. We propose a novel algorithm, 'MAVRL', which enables vehicles to learn optimal policies for lane changing, merging, and intersection navigation while minimizing conflicts and maintaining safety. Our approach leverages graph neural networks to model vehicle interactions and incorporates a decentralized actor-critic architecture to facilitate real-time decision-making. Experimental results using a large-scale traffic simulator demonstrate that MAVRL outperforms traditional rule-based approaches and centralized optimization methods in terms of traffic efficiency, safety, and scalability.