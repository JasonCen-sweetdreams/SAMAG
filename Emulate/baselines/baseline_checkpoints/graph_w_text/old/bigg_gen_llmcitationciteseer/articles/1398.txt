This paper proposes a multi-agent deep reinforcement learning framework for coordinating autonomous vehicles in complex urban scenarios. We introduce a novel architecture that combines graph neural networks with deep Q-networks to learn cooperative policies for lane changing, merging, and intersection navigation. Our approach enables vehicles to adapt to dynamic environments, avoid collisions, and optimize traffic flow. Experimental results in simulation demonstrate improved safety, efficiency, and scalability compared to state-of-the-art methods.