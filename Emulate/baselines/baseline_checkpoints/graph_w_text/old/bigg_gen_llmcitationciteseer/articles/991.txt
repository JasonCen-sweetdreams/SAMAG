This paper presents a decentralized multi-agent reinforcement learning (MARL) approach for adaptive traffic signal control in complex urban networks. We propose a novel communication framework that enables agents to share local observations and learn from each other's experiences. Our method, dubbed 'TrafficMAgent', utilizes a graph attention mechanism to selectively incorporate information from neighboring agents, improving overall network efficiency. Experimental results on a realistic traffic simulator demonstrate that TrafficMAgent outperforms traditional optimization methods, reducing congestion and travel times by up to 25%