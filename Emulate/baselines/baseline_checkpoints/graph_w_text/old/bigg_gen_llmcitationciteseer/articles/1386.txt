Knowledge graph embedding (KGE) has become a crucial component in various AI applications. However, most existing KGE methods struggle to capture complex relationships between entities. This paper proposes a novel hierarchical attention network (HAN) based KGE approach, which learns to focus on relevant relational patterns and entity interactions. Our method, HAKE, leverages a multi-level attention mechanism to encode both local and global structural information in the knowledge graph. Experimental results on benchmark datasets demonstrate that HAKE outperforms state-of-the-art KGE methods in link prediction and triple classification tasks.