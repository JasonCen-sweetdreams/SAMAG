Explainability is crucial in multi-agent reinforcement learning (MARL) to understand agent interactions and decision-making. We propose a Hierarchical Attention Network (HAN) framework that integrates attention mechanisms at both the agent and team levels. HAN enables agents to selectively focus on relevant teammates and environmental features, leading to improved coordination and policy explainability. We evaluate HAN on a range of MARL benchmarks, demonstrating significant improvements in performance and interpretability compared to state-of-the-art methods.