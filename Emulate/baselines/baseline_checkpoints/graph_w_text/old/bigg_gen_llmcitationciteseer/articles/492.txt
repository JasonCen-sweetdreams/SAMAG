Multi-agent reinforcement learning (MARL) has achieved remarkable success in complex scenarios, but the lack of interpretability hinders its adoption in real-world applications. This paper presents a novel hierarchical graph attention network (HGAT) architecture that enables explainable MARL. By incorporating attention mechanisms at both the local and global levels, HGAT learns to highlight critical agent interactions and communicate relevant information between agents. Experimental results on a suite of cooperative MARL benchmarks demonstrate that HGAT significantly improves the explainability of agent policies while maintaining competitive performance.