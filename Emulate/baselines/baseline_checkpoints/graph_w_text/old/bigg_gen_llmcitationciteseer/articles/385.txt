Explainable recommendation systems (ERS) have gained significant attention in recent years, but existing methods often rely on simplistic feature attribution techniques or overlook the complex relationships between users and items. This paper proposes a novel Hierarchical Attention Graph Neural Network (HAGNN) architecture that models user-item interactions as a hierarchical graph, enabling the discovery of multi-hop relationships and nuanced feature dependencies. Our approach leverages self-attention mechanisms to adaptively weight importance scores and generate interpretable explanations for recommended items. Experimental results on several benchmark datasets demonstrate that HAGNN outperforms state-of-the-art ERS methods in terms of both recommendation accuracy and explanation quality.