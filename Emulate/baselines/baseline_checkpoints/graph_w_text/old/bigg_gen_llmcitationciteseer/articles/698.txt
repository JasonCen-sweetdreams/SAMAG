Individuals with motor disabilities face significant challenges in interacting with computing systems. This paper presents 'GESTalt', an adaptive gesture recognition system that leverages machine learning and sensor fusion to accommodate varying levels of motor impairment. GESTalt uses a probabilistic framework to model user gestures, incorporating data from electromyography, computer vision, and inertial sensors. Our system adapts to user abilities through an online learning mechanism, enabling accurate gesture recognition even in the presence of motor variability. A user study with 20 participants demonstrates the effectiveness of GESTalt in enhancing user experience and improving gesture recognition accuracy.