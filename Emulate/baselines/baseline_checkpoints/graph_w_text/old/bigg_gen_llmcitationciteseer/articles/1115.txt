Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its lack of interpretability hinders its adoption in high-stakes domains. This paper proposes a novel hierarchical attention mechanism, 'HAT', that enhances the explainability of DRL agents. HAT learns to selectively focus on relevant state features and abstract representations, generating attention masks that provide insights into the decision-making process. We evaluate HAT on multiple Atari games and demonstrate improved interpretability, robustness, and performance compared to state-of-the-art DRL methods.