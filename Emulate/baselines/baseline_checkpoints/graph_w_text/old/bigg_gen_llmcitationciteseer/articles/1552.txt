Multi-agent autonomous systems (MAAS) have garnered significant attention in recent years, with applications in domains like robotics and smart cities. However, the complexity of MAAS demands novel approaches to decision-making and control. This paper presents a hierarchical reinforcement learning (HRL) framework for MAAS, where a high-level policy learns to coordinate agent actions and a low-level policy focuses on localized control. We introduce a novel attention-based mechanism to facilitate information sharing among agents and demonstrate improved performance in a simulated urban traffic management scenario. Our results show that HRL outperforms traditional decentralized and centralized control methods in terms of system efficiency and adaptability.