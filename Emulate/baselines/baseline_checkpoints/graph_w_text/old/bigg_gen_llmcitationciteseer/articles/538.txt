Autonomous vehicles rely on reinforcement learning (RL) to optimize control policies. However, existing RL methods suffer from high sample complexity and slow adaptation to changing environments. This paper proposes a hierarchical RL framework, ' HierRL', which leverages a novel layer-wise attention mechanism to selectively focus on relevant state features and abstract away from irrelevant ones. We demonstrate HierRL's effectiveness in a simulated autonomous driving environment, achieving faster adaptation to changing road conditions and improved overall vehicle control compared to state-of-the-art RL baselines.