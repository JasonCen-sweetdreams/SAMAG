In multi-agent systems, norm emergence enables agents to coordinate and achieve collective goals. However, existing approaches often rely on centralized control or explicit communication. This paper proposes a decentralized norm emergence framework, 'DNERL', which leverages reinforcement learning to enable agents to learn and adapt to social norms in a distributed manner. We introduce a novel reward function that incentivizes agents to conform to emergent norms, while also encouraging exploration and innovation. Experimental results demonstrate that DNERL achieves higher norm adoption rates and improved system efficiency compared to existing decentralized approaches.