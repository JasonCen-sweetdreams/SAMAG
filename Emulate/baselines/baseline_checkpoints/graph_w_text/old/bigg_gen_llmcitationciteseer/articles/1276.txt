Neural architecture search (NAS) has revolutionized the field of deep learning by automating the design of neural networks. However, existing NAS methods are computationally expensive and require vast resources, making them infeasible for edge devices with limited resources. This paper proposes a novel, efficient NAS framework, 'EdgeNAS', which leverages a differentiable search space and a knowledge distillation-based optimization strategy to reduce the search cost by an order of magnitude. Experimental results on various edge computing benchmarks demonstrate that EdgeNAS discovers high-performance models with significantly reduced latency and energy consumption.