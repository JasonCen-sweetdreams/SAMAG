Ad-hoc retrieval remains a challenging task in information retrieval, particularly when dealing with ambiguous queries. This paper proposes a novel query expansion approach that leverages reinforcement learning to optimize the selection of expansion terms. Our method, called QERL, uses a deep Q-network to learn a policy that balances the trade-off between query drift and term relevance. Experimental results on the TREC Ad-hoc dataset demonstrate that QERL outperforms state-of-the-art query expansion techniques, achieving significant improvements in mean average precision and normalized discounted cumulative gain.