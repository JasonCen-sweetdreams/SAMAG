Explainability is crucial in multi-agent systems, where autonomous agents make decisions that impact human lives. We propose a novel hierarchical attention network (HAN) framework, which enables explainable decision making in multi-agent settings. Our approach leverages attention mechanisms to model complex relationships between agents and their environment, while providing interpretable explanations for agent decisions. We evaluate our HAN framework on a simulated traffic management scenario, demonstrating improved decision-making performance and explainability compared to state-of-the-art baselines.