Deep neural networks have achieved remarkable success in image classification tasks, but their lack of transparency hinders trust and adoptability. This paper proposes a Hierarchical Attention Network (HAN) framework that incorporates attention mechanisms at multiple scales to provide insights into the decision-making process. By visualizing attention heatmaps, we demonstrate that HAN models focus on relevant regions and features, leading to improved explainability and interpretability. Experimental results on benchmark datasets show that HAN models achieve state-of-the-art performance while providing meaningful explanations for their predictions.