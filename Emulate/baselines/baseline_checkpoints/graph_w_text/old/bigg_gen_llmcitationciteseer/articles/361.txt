Explainability in multi-agent reinforcement learning (MARL) is crucial for real-world applications. This paper proposes a novel hierarchical attention network (HAN) framework that enables interpretable decision-making in MARL. Our approach leverages attention mechanisms to model inter-agent dependencies and incorporates a hierarchical structure to capture complex relationships between agents. We demonstrate the effectiveness of HAN in various MARL scenarios, including competitive and cooperative tasks, and show that it outperforms existing methods in terms of performance and interpretability.