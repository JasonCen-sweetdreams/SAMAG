Explainable AI (XAI) is crucial in medical imaging, where model interpretability can improve trust and decision-making. This paper proposes a novel hierarchical attention-based multimodal fusion framework, 'HybridFusion', which integrates radiology reports, image features, and clinical data for XAI in disease diagnosis. Our approach leverages attention mechanisms to selectively weigh modality-specific features and generate saliency maps, providing insights into the decision-making process. Experimental results on a large-scale medical imaging dataset demonstrate improved diagnostic accuracy and explainability compared to state-of-the-art multimodal fusion methods.