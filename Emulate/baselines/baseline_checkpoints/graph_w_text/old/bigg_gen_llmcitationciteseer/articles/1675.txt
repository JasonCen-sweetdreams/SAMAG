Augmented reality (AR) has the potential to revolutionize human-computer interaction, but current interfaces often rely on manual input methods that can be cumbersome and limiting. This paper explores the use of gaze-based interaction as a more natural and intuitive way to interact with virtual objects in AR environments. We present a novel gaze-tracking algorithm that leverages machine learning techniques to accurately detect and interpret user gaze patterns. Our user study demonstrates that gaze-based interaction can significantly improve task efficiency and user satisfaction in AR applications, with implications for fields such as gaming, education, and healthcare.