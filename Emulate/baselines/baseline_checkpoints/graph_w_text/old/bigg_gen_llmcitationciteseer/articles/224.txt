Deep reinforcement learning (DRL) has achieved significant success in real-world robotics, but the lack of transparency in decision-making processes hinders trust and accountability. This paper proposes a novel explainability framework, 'RL-Explain', which leverages model-based reinforcement learning and attention mechanisms to generate interpretable explanations for DRL policies. We evaluate RL-Explain on a range of robotic tasks, demonstrating improved explanation quality and reduced computational overhead compared to existing methods. Our approach has important implications for the deployment of DRL in high-stakes applications, such as autonomous vehicles and robotic surgery.