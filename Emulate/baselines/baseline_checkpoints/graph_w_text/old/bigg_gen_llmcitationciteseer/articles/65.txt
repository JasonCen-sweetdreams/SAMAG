Explainability is a crucial aspect of multi-agent reinforcement learning (MARL), where agents learn to make decisions in complex, dynamic environments. This paper introduces HAN-MARL, a novel hierarchical attention network architecture that enables interpretable decision-making in MARL. Our approach leverages attention mechanisms to selectively focus on relevant agents and states, generating explicit importance weights that explain the decision-making process. Experimental results on a range of MARL benchmarks demonstrate the effectiveness of HAN-MARL in improving both performance and explainability, outperforming state-of-the-art MARL methods.