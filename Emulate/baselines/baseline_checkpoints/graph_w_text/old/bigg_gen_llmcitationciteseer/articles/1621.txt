Despite recent advances in reinforcement learning (RL) for autonomous vehicle control, the lack of transparency and interpretability in RL models hinders their adoption in safety-critical applications. This paper proposes a novel explainable RL framework, 'XLRL', which incorporates model-based and model-free approaches to provide insights into the decision-making process. We introduce a hierarchical attention mechanism that highlights the most relevant sensory inputs and internal state variables contributing to the control decisions. Experimental results on a simulated autonomous driving platform demonstrate the efficacy of XLRL in improving control performance while providing meaningful explanations for its actions.