In multi-agent systems, task allocation is a crucial problem that requires efficient and decentralized decision-making. This paper proposes a novel approach using graph convolutional networks (GCNs) to learn task allocation policies. We model the agent interaction graph as a dynamic graph and utilize GCNs to embed the agents' states and tasks. Our approach, dubbed Dec-GCN, enables agents to make decentralized decisions based on local information and neighbor interactions. We evaluate Dec-GCN on a series of simulated task allocation scenarios and demonstrate improved performance and scalability compared to traditional centralized and decentralized methods.