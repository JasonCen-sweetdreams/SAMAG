Query optimization is a crucial component of database systems, but traditional rule-based approaches often struggle to adapt to dynamic workloads and distributed architectures. This paper proposes a novel query optimization framework, 'RL-QO', which leverages reinforcement learning to learn efficient query plans. By formulating the optimization problem as a Markov decision process, RL-QO adapts to changing system conditions and identifies near-optimal query plans. Our experiments on a distributed database system demonstrate that RL-QO outperforms traditional optimization techniques by up to 30% in terms of query latency and resource utilization.