In multi-agent systems, cooperation is crucial for achieving complex tasks. However, the lack of transparency in decision-making processes hinders trust and understanding among agents. We propose a Hierarchical Attention Network (HAN) framework that enables explainable cooperation among agents. HAN integrates attention mechanisms at both local and global levels, allowing agents to selectively focus on relevant information and communicate effectively. Our experiments on a simulated urban search and rescue scenario demonstrate that HAN outperforms traditional cooperation strategies in terms of task completion rate and explainability, providing insights into the decision-making process of individual agents.