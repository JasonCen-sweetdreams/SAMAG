Query optimization remains a crucial challenge in distributed database systems, where the complexity of query plans can significantly impact performance. This paper proposes a novel approach that leverages machine learning to optimize query plans for distributed databases. We develop a graph neural network-based model that learns to predict optimal query plans based on historical query patterns and database statistics. Our experimental evaluation on a real-world distributed database system demonstrates an average reduction of 30% in query execution time and 25% in resource utilization compared to traditional optimization techniques.