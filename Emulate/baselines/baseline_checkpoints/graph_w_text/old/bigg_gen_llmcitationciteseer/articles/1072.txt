Proactive assistive systems aim to anticipate and support users' needs, but often rely on explicit input or retrospective analysis. This paper presents a novel approach to gaze-based intention recognition, leveraging eye-tracking data to predict users' goals in real-time. Our method, 'GazeProx', combines convolutional neural networks with graph-based models to capture subtle patterns in gaze behavior. Evaluations on a dataset of users performing daily tasks demonstrate that GazeProx outperforms state-of-the-art methods in intention recognition accuracy, paving the way for more responsive and personalized assistive systems.