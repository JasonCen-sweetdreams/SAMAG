Explainability is crucial in multi-agent systems, where agents' decisions can have significant consequences. We propose HAN-MARL, a hierarchical attention network that integrates reinforcement learning with interpretable decision-making. HAN-MARL employs a two-level attention mechanism, focusing on both agent-specific and global state features. Our approach enables the identification of key factors influencing agents' decisions and improves overall team performance. Experimental results on a cooperative robotic soccer domain demonstrate the effectiveness of HAN-MARL in achieving both explainability and improved decision-making.