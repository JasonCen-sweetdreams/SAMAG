Explainability is a crucial aspect of multi-agent reinforcement learning (MARL) as it enables understanding the decision-making processes of agents. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that integrates graph attention mechanisms with hierarchical reinforcement learning. HGAT models complex agent interactions and identifies influential agents in the decision-making process. We evaluate HGAT on a range of MARL benchmarks and demonstrate improved explainability and policy performance compared to state-of-the-art methods. Furthermore, we provide visualizations of attention weights, revealing insights into the coordination and cooperation dynamics among agents.