Explainable AI (XAI) has gained significant attention in medical imaging, where model interpretability is crucial for decision-making. However, existing XAI methods often incur significant computational overhead, limiting their applicability in real-world scenarios. This paper proposes a novel hierarchical attention network (HAN) framework that leverages both local and global feature importance to provide accurate and efficient explanations for medical image analysis tasks. We evaluate our approach on a large-scale breast cancer diagnosis dataset, demonstrating improved explanation quality and reduced inference time compared to state-of-the-art XAI methods.