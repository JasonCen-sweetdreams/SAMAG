In multi-agent decision-making, understanding the reasoning behind joint actions is crucial for trust and accountability. This paper introduces Hierarchical Attention Networks (HANs), a novel architecture that enables explainable decision-making in cooperative multi-agent systems. HANs leverage attention mechanisms to model complex relationships between agents and their actions, allowing for interpretable visualizations of decision-making processes. We demonstrate the effectiveness of HANs in a simulated search-and-rescue scenario, showcasing improved teamwork performance and enhanced explainability compared to existing methods.