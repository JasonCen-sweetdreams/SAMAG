Open-domain question answering (ODQA) systems rely on efficient passage retrieval to identify relevant documents containing the answer. This paper proposes a novel hierarchical document representation (HDR) approach, which leverages both local and global context to encode documents. Our method represents each document as a hierarchical graph, where nodes correspond to passages, and edges capture semantic relationships between them. We demonstrate that HDR outperforms traditional sparse retrieval methods on several ODQA benchmarks, achieving a 15% increase in precision while reducing retrieval time by 30%. Furthermore, we show that HDR can be seamlessly integrated with existing neural rankers to improve overall ODQA system performance.