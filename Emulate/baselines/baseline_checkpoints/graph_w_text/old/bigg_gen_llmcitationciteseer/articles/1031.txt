Recent advances in contrastive learning have shown impressive performance in learning visual representations. However, these methods often suffer from fragility to nuisance factors and domain shifts. This paper proposes a hierarchical contrastive learning framework, 'HiCLR', which leverages a novel hierarchical sampling strategy to learn more robust and transferable representations. We demonstrate the effectiveness of HiCLR on various benchmark datasets, including ImageNet and CIFAR-10, and show significant improvements over state-of-the-art contrastive learning methods in terms of robustness and generalizability.