Multi-agent reinforcement learning (MARL) has shown promise in various applications, but existing methods often lack interpretability. We propose a hierarchical attention network (HAN) framework that enables explainable MARL by modeling inter-agent relationships and attention mechanisms. HAN consists of two components: an attention-based communication module that facilitates information sharing among agents, and a hierarchical reasoning module that captures complex dependencies between agents. Experimental results on a range of MARL benchmarks demonstrate that HAN outperforms state-of-the-art methods while providing insightful explanations of agent behavior and decision-making processes.