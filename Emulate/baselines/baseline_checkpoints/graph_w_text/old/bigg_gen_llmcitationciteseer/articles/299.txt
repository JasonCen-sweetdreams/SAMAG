In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a decentralized task allocation framework, 'MATRL', which leverages deep reinforcement learning to learn optimal task assignments. We propose a novel multi-agent Q-network architecture that incorporates graph attention mechanisms to model agent interactions and task dependencies. Experimental results on a simulated logistics domain demonstrate that MATRL outperforms traditional centralized and decentralized task allocation methods in terms of task completion time and resource utilization.