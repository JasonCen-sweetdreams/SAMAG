Autonomous drones operating in uncertain environments require efficient and safe navigation strategies. We propose an explainable reinforcement learning (XRL) approach, 'DroneX', which integrates model-based and model-free reinforcement learning to adapt to changing environmental conditions. DroneX utilizes a novel attention mechanism to focus on relevant sensory inputs, allowing for interpretable decision-making. We evaluate DroneX in a series of simulation experiments and real-world flight trials, demonstrating improved navigation performance and robustness compared to state-of-the-art methods.