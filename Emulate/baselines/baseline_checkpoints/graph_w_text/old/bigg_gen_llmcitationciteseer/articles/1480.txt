Explainability is crucial in multi-agent reinforcement learning (MARL) systems, where decision-making involves complex interactions among agents. This paper proposes a novel hierarchical attention network (HAN) framework that learns to identify and highlight critical agent interactions driving the decision-making process. Our HAN consists of a hierarchical attention mechanism that recursively selects the most informative agents, followed by a graph neural network that models their interactions. We demonstrate the efficacy of our approach on a range of MARL benchmarks, showcasing improved explainability and decision-making performance compared to state-of-the-art methods.