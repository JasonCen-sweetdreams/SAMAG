Virtual reality (VR) systems rely heavily on manual controllers, which can be cumbersome and detract from the immersive experience. This paper explores the feasibility of gaze-based interaction in VR using deep learning techniques. We propose a novel convolutional neural network (CNN) architecture that can accurately predict user intent from eye movement data. Our approach achieves a significant reduction in error rates compared to traditional machine learning methods, enabling users to interact with virtual objects more naturally and intuitively. We demonstrate the effectiveness of our system through a user study, showcasing its potential for enhancing the VR experience.