Multi-agent reinforcement learning (MARL) has shown promise in various real-world applications, but the lack of transparency in decision-making processes hinders its adoption. We propose a novel Hierarchical Attention Network (HAN) architecture that enables explainable MARL by selectively emphasizing relevant agents' experiences and interactions. Our approach leverages attention mechanisms to identify influential agents and focus on their contributions to the joint policy. We evaluate HAN on several MARL benchmarks, demonstrating improved performance and interpretability compared to state-of-the-art methods.