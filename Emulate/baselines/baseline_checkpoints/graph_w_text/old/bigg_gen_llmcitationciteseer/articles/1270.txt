This paper tackles the challenge of coordinating heterogeneous agents in urban traffic control systems. We propose a novel multi-objective reinforcement learning framework that integrates traffic signal control agents, autonomous vehicles, and pedestrian agents. Our approach leverages a decentralized actor-critic architecture to optimize multiple objectives, including traffic flow, safety, and pedestrian comfort. We evaluate our approach using a realistic simulator and demonstrate significant improvements in traffic efficiency and safety compared to traditional traffic signal control methods.