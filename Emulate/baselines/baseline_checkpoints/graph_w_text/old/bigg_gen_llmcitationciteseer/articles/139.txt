In multi-agent systems, decision-making processes become increasingly complex as the number of agents grows. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent environments. Our approach leverages attention mechanisms to model inter-agent relationships and generate interpretable explanations for agent decisions. Experimental results on a simulated multi-agent task allocation domain demonstrate improved decision-making performance and reduced ambiguity compared to existing methods.