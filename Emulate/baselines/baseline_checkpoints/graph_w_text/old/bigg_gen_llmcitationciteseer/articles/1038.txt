Explainable recommendation systems (ERS) aim to provide transparent and interpretable results, which is crucial for building trust in AI-driven decision-making. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework for ERS, which leverages graph neural networks to model complex item relationships and user preferences. Our HGAT framework comprises a hierarchical attention mechanism that adaptively selects relevant item features and user behavior, generating personalized explanations for recommended items. Experimental results on several real-world datasets demonstrate the effectiveness of HGAT in improving recommendation accuracy and explanation quality.