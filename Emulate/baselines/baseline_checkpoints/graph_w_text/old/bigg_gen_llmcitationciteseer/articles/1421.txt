In multi-agent systems, decision-making often relies on complex, black-box models that lack transparency and accountability. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable multi-agent decision-making. Our approach integrates attention mechanisms at both the agent and system levels, enabling the identification of influential agents and features that drive collective decisions. Experimental results on a simulated autonomous vehicle scenario demonstrate improved explainability and decision quality compared to traditional neural network-based approaches.