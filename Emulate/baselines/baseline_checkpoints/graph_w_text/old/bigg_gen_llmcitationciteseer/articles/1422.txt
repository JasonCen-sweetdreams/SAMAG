Explainability in multi-agent reinforcement learning (MARL) is crucial for real-world applications, as it enables understanding of agent behavior and decision-making. We propose Hierarchical Attention Networks (HANs) to address this challenge. HANs incorporate attention mechanisms at both the agent and joint action levels, allowing for interpretable representations of agent intentions and interactions. Our approach outperforms state-of-the-art MARL methods on a suite of cooperative and competitive tasks, while providing insights into agent coordination and strategy adaptation. We demonstrate the effectiveness of HANs in a real-world robotics scenario, showcasing their potential for explainable MARL in complex, dynamic environments.