As graph databases continue to grow in size and complexity, query optimization becomes increasingly important for efficient data retrieval. This paper proposes a novel approach to query optimization using reinforcement learning, specifically designed for distributed graph databases. We introduce a Deep Q-Network (DQN) that learns to optimize query plans by interacting with the database and receiving rewards based on execution time and resource utilization. Our experiments on a real-world graph dataset demonstrate that the proposed approach outperforms traditional query optimization techniques by up to 30% in terms of query execution time and reduces resource utilization by up to 25%.