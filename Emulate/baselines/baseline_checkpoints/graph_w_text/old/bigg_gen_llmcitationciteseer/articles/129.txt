Designing effective multi-agent systems requires understanding the complex interactions between agents. This paper presents a novel hierarchical graph attention mechanism, 'HiGAT', which learns to represent agents as nodes in a graph and infer their relationships. HiGAT consists of two stages: (1) intra-agent attention, which models individual agent behavior, and (2) inter-agent attention, which captures the interactions between agents. Our approach enables explainable decision-making by providing insights into the contribution of each agent to the collective outcome. Experimental results on a traffic control scenario demonstrate improved cooperation and interpretability compared to existing methods.