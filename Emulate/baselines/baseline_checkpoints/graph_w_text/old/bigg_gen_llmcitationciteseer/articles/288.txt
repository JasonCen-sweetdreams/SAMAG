Virtual reality (VR) has the potential to revolutionize human-computer interaction, but understanding users' emotional states is crucial for creating immersive experiences. This paper presents a novel approach to recognizing emotional states in VR using physiological signal analysis. We propose a machine learning-based framework that combines electroencephalography (EEG), electrocardiography (ECG), and galvanic skin response (GSR) signals to classify users' emotional states into four categories: neutral, happy, sad, and anxious. Our results show that the proposed framework achieves an accuracy of 87.5% in recognizing emotional states, outperforming existing methods that rely on self-reported surveys or facial expression analysis.