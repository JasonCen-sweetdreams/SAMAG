Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its vulnerability to adversarial attacks raises concerns about its reliability. This paper proposes a novel Bayesian regularization technique to improve the robustness of DRL policies against adversarial perturbations. By incorporating a Bayesian neural network into the policy architecture, we introduce uncertainty estimates that enable the agent to adapt to changing environment dynamics. Our experiments demonstrate that the proposed approach significantly enhances the attack resistance of DRL policies in various Atari games and robotic control tasks.