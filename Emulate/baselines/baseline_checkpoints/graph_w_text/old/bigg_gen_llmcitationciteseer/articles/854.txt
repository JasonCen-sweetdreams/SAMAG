Multi-agent reinforcement learning (MARL) has gained popularity in various domains, but the lack of interpretability hinders its adoption in real-world applications. We propose a novel hierarchical attention network (HAN) architecture that enables explainable MARL. HAN consists of two attention mechanisms: an intra-agent attention module that focuses on relevant state features within each agent, and an inter-agent attention module that captures the interactions between agents. We evaluate HAN on a series of cooperative and competitive MARL tasks, demonstrating improved performance and interpretability compared to state-of-the-art baselines. Furthermore, we provide visualizations of the attention weights, offering insights into the decision-making process of each agent.