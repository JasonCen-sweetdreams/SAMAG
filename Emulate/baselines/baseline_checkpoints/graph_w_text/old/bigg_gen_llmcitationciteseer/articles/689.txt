In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a decentralized task allocation framework that leverages reinforcement learning to adapt to dynamic environments. Our approach, called 'RL-TA', enables individual agents to learn from their experiences and communicate with each other to allocate tasks optimally. We evaluate RL-TA on a simulated robotic search and rescue scenario, demonstrating improved task completion rates and reduced communication overhead compared to traditional centralized allocation methods.