Reinforcement learning (RL) has achieved remarkable successes in complex decision-making tasks, but the lack of interpretability hinders its adoption in safety-critical domains. This paper proposes a novel Hierarchical Attention Network (HAN) framework for Explainable RL (ERL). Our approach embeds attention mechanisms at multiple levels, enabling the agent to selectively focus on relevant state features, actions, and abstract concepts. We demonstrate the effectiveness of HAN-ERL on a range of Atari games and a real-world robotics task, showcasing improved performance and explainability compared to state-of-the-art RL baselines.