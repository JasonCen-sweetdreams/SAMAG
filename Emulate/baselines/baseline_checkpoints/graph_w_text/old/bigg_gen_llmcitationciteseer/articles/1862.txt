Individuals with motor impairments often face challenges interacting with gestural interfaces, which can exacerbate existing social and economic inequalities. This paper presents a novel, inclusive gestural interface design framework that incorporates insights from disability studies, human-computer interaction, and machine learning. We propose a probabilistic gesture recognition model that adapts to the unique motor patterns of individuals with impairments, and demonstrate its effectiveness in a user study with participants with cerebral palsy and spinal muscular atrophy. Our results show significant improvements in gesture recognition accuracy and user satisfaction compared to existing interfaces.