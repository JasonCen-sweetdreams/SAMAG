Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its lack of transparency hinders trust and adoption. This paper focuses on developing efficient explainability techniques for DRL in partially observable environments. We introduce a novel model-agnostic method, 'PO-EXPLAIN', which leverages attention mechanisms to identify relevant state features and quantify their contributions to the agent's decision-making process. Experimental results on several Atari games demonstrate that PO-EXPLAIN outperforms existing explainability methods in terms of computational efficiency and fidelity to the learned policy.