Deep neural ranking models have achieved state-of-the-art performance in ad-hoc information retrieval tasks. However, the impact of query expansion techniques on these models remains understudied. This paper conducts a comprehensive evaluation of various query expansion methods, including lexical, semantic, and hybrid approaches, on several deep neural ranking models, including BERT and Transformer-based architectures. Our experiments on three benchmark datasets demonstrate that query expansion can significantly improve the retrieval performance of these models, especially for queries with low term frequency. We provide insights into the strengths and weaknesses of each query expansion method and discuss their implications for future research.