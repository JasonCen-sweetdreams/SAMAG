Query optimization is a crucial task in graph databases, particularly in distributed settings. This paper proposes a novel approach that leverages reinforcement learning to optimize query execution plans. We design a graph-aware state representation and a reward function that captures the trade-off between query latency and resource utilization. Our experimental results on a real-world graph dataset demonstrate that our approach outperforms traditional query optimization techniques, achieving an average speedup of 2.5x while reducing resource consumption by 30%. We also provide theoretical analysis to guarantee the convergence of our algorithm.