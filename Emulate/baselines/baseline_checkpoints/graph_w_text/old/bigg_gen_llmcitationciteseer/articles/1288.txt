In multi-agent systems, decision making often relies on complex interactions between agents. While reinforcement learning has shown promise, interpretability remains a major challenge. This paper introduces HAN-MAD, a hierarchical attention network that learns to attend to relevant agents and their features, providing insights into decision-making processes. We evaluate HAN-MAD on a simulated robotic soccer domain and demonstrate improved performance and explainability compared to state-of-the-art methods. Our approach has implications for real-world applications, such as autonomous vehicles and smart grids, where transparency is crucial.