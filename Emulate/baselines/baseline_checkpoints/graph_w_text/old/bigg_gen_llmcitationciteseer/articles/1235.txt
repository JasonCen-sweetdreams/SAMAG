Coordinating multiple agents with heterogeneous capabilities and goals is a challenging problem in multi-agent systems. This paper presents a novel approach that leverages deep reinforcement learning to learn effective coordination strategies. We propose a hierarchical framework that combines a high-level planning module with low-level execution modules, enabling agents to adapt to dynamic environments and changing goals. Experimental results on a simulated search-and-rescue scenario demonstrate the proposed approach's ability to outperform traditional planning-based methods and achieve improved coordination and task completion rates.