Coordinating multiple autonomous agents to achieve a common goal is a challenging problem in AI research. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that enables explainable multi-agent cooperation. HGAT combines graph attention mechanisms with hierarchical reasoning to model complex agent interactions and infer cooperative strategies. We demonstrate the effectiveness of HGAT in two challenging domains: multi-robot task allocation and traffic signal control. Our results show that HGAT outperforms existing cooperative methods while providing interpretable insights into agent decision-making processes.