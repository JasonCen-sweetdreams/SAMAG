Explainable recommendation systems have gained significant attention in recent years, as they provide insights into the decision-making process and increase user trust. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework that integrates graph attention mechanisms with hierarchical explainability. We leverage graph neural networks to model complex user-item interactions and incorporate hierarchical attention to identify influential factors driving the recommendations. Our experiments on multiple benchmark datasets demonstrate that HGAT outperforms state-of-the-art explainable recommendation models while providing interpretable explanations for the recommended items.