Real-time traffic signal control is a complex problem that requires efficient decision-making to minimize congestion and reduce travel times. This paper proposes a novel multi-agent deep reinforcement learning framework, 'MARL-TSC', which enables cooperative learning among traffic signals to optimize traffic flow. We introduce a hierarchical architecture that combines graph attention networks with recurrent neural networks to capture spatiotemporal dependencies among signals. Experiments on a large-scale traffic simulation platform show that MARL-TSC achieves significant reductions in travel times and congestion compared to state-of-the-art methods, while adapting to dynamic traffic conditions.