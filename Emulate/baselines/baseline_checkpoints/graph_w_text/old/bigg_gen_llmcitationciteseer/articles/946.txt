Multi-agent systems often rely on centralized decision-making architectures, which can be opaque and difficult to interpret. This paper proposes a novel hierarchical attention network (HAN) framework for explainable decision-making in multi-agent systems. Our approach aggregates agent-level features using attention mechanisms, enabling the model to focus on relevant information and provide interpretability. We evaluate our method on a real-world autonomous vehicle dataset, demonstrating improved decision-making performance and enhanced explainability compared to traditional reinforcement learning approaches.