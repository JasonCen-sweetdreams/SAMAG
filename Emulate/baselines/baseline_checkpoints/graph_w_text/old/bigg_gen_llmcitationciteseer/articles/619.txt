Multi-agent reinforcement learning (MARL) has shown promise in tackling complex tasks, but scalability remains a significant challenge. This paper proposes a novel hierarchical attention network (HAN) architecture that efficiently handles large numbers of agents and high-dimensional state spaces. Our approach exploits the inherent hierarchical structure of many MARL problems, using attention mechanisms to selectively focus on relevant agents and features. Experiments on a range of benchmark environments demonstrate significant improvements in both learning speed and final policy performance, making HAN a promising solution for large-scale MARL applications.