Autonomous vehicles require fast and accurate control systems to navigate complex environments. This paper presents a novel hierarchical reinforcement learning (HRL) framework, 'HierRL', which leverages a combination of model-free and model-based reinforcement learning to achieve real-time control for autonomous vehicles. HierRL decomposes the control problem into a hierarchical structure of tasks, allowing for efficient exploration and improved learning convergence. We demonstrate the effectiveness of HierRL in a high-fidelity simulation environment, achieving significant improvements in control latency and vehicle stability compared to state-of-the-art reinforcement learning methods.