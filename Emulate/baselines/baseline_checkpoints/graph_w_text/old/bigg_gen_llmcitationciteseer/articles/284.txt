Graph neural networks (GNNs) have become increasingly popular for modeling complex graph-structured data. However, their vulnerability to adversarial attacks raises concerns about their reliability in real-world applications. This paper proposes a novel hierarchical attention mechanism to enhance the adversarial robustness of GNNs. Our approach leverages attention weights to identify and down-weight the influence of perturbed nodes, thereby improving the model's robustness to targeted attacks. We demonstrate the effectiveness of our approach on several benchmark datasets, achieving state-of-the-art performance under various attack scenarios.