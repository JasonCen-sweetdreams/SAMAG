Decentralized task allocation is a fundamental problem in multi-agent systems, where agents need to cooperate to accomplish complex tasks. This paper proposes a novel approach using graph neural networks (GNNs) to learn decentralized task allocation policies. We model the agent communication network as a graph and utilize GNNs to learn a distributed policy that allocates tasks to agents based on their capabilities and the graph structure. Experimental results on a simulated robot swarm demonstrate that our approach outperforms traditional decentralized methods and achieves near-optimal performance in various scenarios.