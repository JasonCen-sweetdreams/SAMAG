Voice assistants have become ubiquitous, but their effectiveness for users with dysarthria, a speech disorder characterized by impaired articulation, remains limited. This paper presents a novel, inclusive voice assistant framework that leverages machine learning and HCI principles to improve recognition accuracy and user experience for individuals with dysarthria. We conducted a user study with 20 participants with dysarthria, identifying key design recommendations for personalized speech recognition models, adaptive feedback mechanisms, and accessible interface design. Our results show that the proposed framework achieves a significant reduction in error rates and improves user satisfaction compared to commercial voice assistants.