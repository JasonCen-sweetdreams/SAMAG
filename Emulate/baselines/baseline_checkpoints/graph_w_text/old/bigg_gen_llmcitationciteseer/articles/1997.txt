Gesture recognition systems have become increasingly popular in various applications, including healthcare and gaming. However, existing systems often struggle to recognize gestures performed by older adults, who may have reduced motor skills or cognitive impairments. This paper presents a novel approach to designing inclusive gesture recognition systems that cater to the needs of older adults. We propose a multimodal fusion framework that combines computer vision, machine learning, and sensor-based approaches to recognize gestures. Our system is evaluated on a dataset of 50 older adults and achieves an average recognition accuracy of 92.5%, outperforming state-of-the-art systems. We also conducted a user study to gather feedback from older adults, which informed the design of our system and provided insights into their gesture recognition needs.