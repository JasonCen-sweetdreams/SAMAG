Autonomous vehicles require efficient decision-making algorithms to navigate complex scenarios. This paper introduces a hierarchical reinforcement learning framework, 'HRL-Nav', that integrates high-level mission planning with low-level motion control. HRL-Nav leverages a novel attention-based state representation that selectively focuses on relevant features in the environment, enabling more informed decision-making. We evaluate HRL-Nav on a suite of simulated urban driving scenarios, demonstrating improved performance and reduced computational overhead compared to flat reinforcement learning baselines.