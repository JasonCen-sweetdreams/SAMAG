Few-shot node classification remains a challenging problem in graph-structured data, particularly when dealing with scarce labeled nodes. This paper proposes a novel hierarchical graph attention network (HGAT) that leverages both node and graph-level attention mechanisms to improve performance. Our approach first aggregates node features using a self-attention mechanism, then applies a graph attention layer to selectively focus on relevant neighboring nodes. Experimental results on several benchmark datasets demonstrate that HGAT outperforms state-of-the-art methods, including graph neural networks and meta-learning approaches, in few-shot node classification scenarios.