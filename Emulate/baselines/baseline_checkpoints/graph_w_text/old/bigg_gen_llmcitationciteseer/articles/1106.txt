In multi-agent reinforcement learning, understanding the decision-making process of individual agents is crucial for effective coordination and cooperation. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable multi-agent reinforcement learning. Our approach learns to focus on relevant agents and their interactions, generating interpretable attention weights that reveal the underlying decision-making process. We evaluate our method on a range of cooperative and competitive multi-agent environments, demonstrating improved performance and transparency compared to existing state-of-the-art methods.