In multi-agent systems, coordinated exploration is crucial for efficient learning and adaptation. This paper introduces a novel approach to reward shaping, which adaptively adjusts the reward function based on theAgents' exploration dynamics. Our method, dubbed 'CoEx', leverages graph-based metrics to quantify the agents' coordination and generates rewards that encourage cooperative behavior. We demonstrate the efficacy of CoEx in a variety of multi-agent environments, including robotics and traffic control scenarios, and show significant improvements in task completion rates and overall system performance.