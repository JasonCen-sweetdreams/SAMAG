Knowledge graph embedding (KGE) is a crucial step in many AI applications, but existing methods often lack interpretability. This paper proposes a novel KGE framework, 'HAT-KGE', which leverages hierarchical attention to model complex relationships between entities and their attributes. Our approach enables the identification of salient attributes contributing to the predicted relationships, thereby providing explainability in AI systems. Experimental results on benchmark datasets demonstrate that HAT-KGE outperforms state-of-the-art methods in terms of both link prediction and attribute-based explanation quality.