Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but the lack of transparency in decision-making processes hinders trust and adoption. This paper proposes a novel hierarchical attention mechanism, called HAX, to facilitate the explainability of DRL policies. HAX embeds attention weights into a hierarchical structure, enabling the identification of critical state features and action influences at multiple levels of abstraction. We evaluate HAX on several Atari games and a real-world robotics task, demonstrating improved interpretability and faithfulness to the underlying decision-making process.