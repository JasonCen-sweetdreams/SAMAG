Task-oriented conversational agents require sophisticated dialogue management to efficiently resolve user queries. This paper introduces 'HATDMA', a hierarchical attention-based framework that integrates contextual understanding, intent detection, and response generation. We propose a novel attention mechanism that selectively focuses on relevant dialogue history and contextual features, enabling more accurate and informative responses. Experiments on the DSTC2 and CamRest datasets demonstrate that HATDMA outperforms state-of-the-art models in terms of task success rate, response relevance, and overall user satisfaction.