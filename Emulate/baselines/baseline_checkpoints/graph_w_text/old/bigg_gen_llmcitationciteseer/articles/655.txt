Node classification is a fundamental task in graph-structured data, but existing methods often suffer from high computational complexity and limited scalability. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that leverages a hierarchical clustering approach to reduce the graph size and attention complexity. Our model learns to selectively focus on relevant nodes and edges at each layer, leading to improved classification accuracy and reduced inference time. Experimental results on multiple benchmark datasets demonstrate that HGAT outperforms state-of-the-art methods while achieving up to 3x speedup.