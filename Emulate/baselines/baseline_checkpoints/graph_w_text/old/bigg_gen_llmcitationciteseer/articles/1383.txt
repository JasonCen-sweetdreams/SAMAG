Distributed knowledge graphs (DKGs) have emerged as a scalable solution for large-scale semantic data management. However, query optimization in DKGs remains a challenging problem due to the complex interactions between graph partitions and the dynamic nature of query workloads. This paper proposes a novel reinforcement learning-based approach, 'RL-QOpt', which learns to optimize query execution plans for DKGs. Our approach leverages a graph-structured state representation and a reward function that balances query latency and resource utilization. Experimental results on a real-world DKG dataset demonstrate that RL-QOpt outperforms traditional query optimization techniques by up to 35% in terms of query latency and 20% in terms of resource utilization.