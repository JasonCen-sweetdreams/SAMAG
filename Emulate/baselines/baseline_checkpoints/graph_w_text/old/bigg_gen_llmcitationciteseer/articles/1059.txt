Task allocation is a fundamental problem in multi-agent systems, where agents with different capabilities need to be assigned to tasks to maximize system efficiency. This paper proposes a novel reinforcement learning approach to distributed task allocation, which enables agents to learn from their experiences and adapt to changing task requirements and agent availability. Our method, called RTAL, uses a decentralized, asynchronous learning framework that allows agents to share information and coordinate their actions. Experimental results on a simulated logistics domain demonstrate that RTAL outperforms existing methods in terms of task completion rate and system throughput, even in the presence of agent failures and communication delays.