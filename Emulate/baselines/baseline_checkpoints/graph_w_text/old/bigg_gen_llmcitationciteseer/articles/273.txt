Explainability is crucial in multi-agent systems where autonomous agents make decisions that impact human lives. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable multi-agent decision-making. Our approach integrates attention mechanisms at both local and global levels to enable agents to focus on relevant features and interactions. We evaluate our method on a traffic management scenario and demonstrate improved decision quality and interpretability compared to existing reinforcement learning approaches. The proposed HAN architecture provides a transparent and modular framework for multi-agent decision-making, facilitating trust and collaboration in complex systems.