Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but the lack of transparency in decision-making processes hinders trust and wider adoption. This paper addresses this challenge by proposing a novel model-agnostic explainability framework, 'RL-Explain', which generates interpretable explanations for DRL policies. RL-Explain leverages feature importance and attention mechanisms to identify key state features and actions contributing to the agent's decision. We demonstrate the effectiveness of RL-Explain on several Atari games and real-world robotic control tasks, showing that it improves the understanding of DRL policies without compromising performance.