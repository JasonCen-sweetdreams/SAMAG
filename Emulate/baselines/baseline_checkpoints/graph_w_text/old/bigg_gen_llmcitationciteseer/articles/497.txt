Visual Question Answering (VQA) models often rely on complex neural architectures, making it challenging to understand their decision-making processes. This paper proposes a novel Hierarchical Attention Network (HAN) for VQA, which incorporates attention mechanisms at multiple scales to selectively focus on relevant image regions and question words. We introduce a novel interpretability module that generates visual and textual explanations for the model's predictions, providing insights into its reasoning process. Experimental results on the VQA 2.0 dataset demonstrate that our HAN model achieves state-of-the-art performance while providing meaningful explanations for its answers.