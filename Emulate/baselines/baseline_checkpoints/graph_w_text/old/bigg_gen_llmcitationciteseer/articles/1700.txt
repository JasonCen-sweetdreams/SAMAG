In multi-agent systems, task allocation is a crucial problem that has been traditionally addressed using centralized approaches. However, these methods often suffer from scalability issues and single points of failure. This paper presents a decentralized task allocation framework that leverages reinforcement learning to enable agents to learn optimal task assignments based on local observations and interactions. We propose a novel algorithm, 'DRL-TA', that combines graph neural networks with decentralized Q-learning to efficiently allocate tasks in large-scale systems. Experimental results on a simulated logistics scenario demonstrate that DRL-TA outperforms state-of-the-art methods in terms of task completion rate and system efficiency.