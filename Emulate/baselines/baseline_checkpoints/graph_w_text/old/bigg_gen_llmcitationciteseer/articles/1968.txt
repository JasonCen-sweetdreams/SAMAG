Graph Neural Networks (GNNs) have achieved state-of-the-art performance in various graph-based tasks. However, their vulnerability to adversarial attacks remains a significant concern. This survey provides a comprehensive overview of the current state of adversarial attacks on GNNs, including poisoning and evasion attacks. We also introduce a new benchmark, GraphAttack, which comprises a diverse set of graph datasets and attack scenarios. Our experimental evaluation of existing defense mechanisms reveals their limitations and highlights the need for more robust and efficient defense strategies. This work aims to facilitate further research in this critical area and promote the development of more secure GNN models.