Cloud computing platforms face the challenge of efficiently allocating resources to meet dynamic workload demands. This paper proposes a novel deep hierarchical reinforcement learning (DHRL) framework that learns to optimize resource allocation in cloud data centers. The DHRL agent consists of a hierarchical structure of deep Q-networks (DQN) that learn to allocate resources at multiple levels of granularity, from individual virtual machines to entire data center clusters. Experimental results on a real-world cloud traces dataset demonstrate that our approach achieves significant improvements in resource utilization, response time, and energy efficiency compared to state-of-the-art heuristics.