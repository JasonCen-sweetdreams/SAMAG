Knowledge graph embedding (KGE) has become a crucial task in many AI applications, but existing methods struggle to scale with large, multi-relational graphs. This paper proposes a novel hierarchical graph attention network (HGAT) for KGE, which leverages both node- and relation-level attention mechanisms to learn expressive representations. HGAT hierarchically aggregates information from neighboring nodes and relations, enabling it to capture complex patterns and contextual dependencies in the graph. Experimental results on multiple benchmark datasets demonstrate that HGAT outperforms state-of-the-art KGE methods in terms of both computational efficiency and embedding quality.