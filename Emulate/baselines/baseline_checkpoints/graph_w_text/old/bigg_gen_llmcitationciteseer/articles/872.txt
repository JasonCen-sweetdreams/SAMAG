Distributed database systems have become increasingly popular for handling large-scale data storage and querying. However, optimizing query performance in these systems remains a significant challenge. This paper proposes a novel approach to query optimization using learned indexes, which leverage machine learning models to predict the optimal query plan. We introduce a framework that integrates learned indexes with traditional query optimization techniques, resulting in significant improvements in query performance and efficiency. Experimental results on a real-world dataset demonstrate the effectiveness of our approach in reducing query latency and improving system throughput.