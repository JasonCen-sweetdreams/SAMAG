Individuals with motor impairments face significant challenges in interacting with digital systems. This paper presents a novel gesture recognition system, 'AdaptiGesture', which leverages machine learning and computer vision to adapt to the unique abilities of each user. Our approach incorporates a personalized calibration phase, where the system learns to recognize a user's gestures based on their strengths and limitations. We evaluate AdaptiGesture on a dataset of 20 participants with varying motor impairments and demonstrate significant improvements in recognition accuracy and user satisfaction compared to existing systems.