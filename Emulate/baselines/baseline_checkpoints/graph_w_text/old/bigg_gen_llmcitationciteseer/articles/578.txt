Real-time data warehousing has become crucial for many applications, but optimizing queries for dynamic workloads remains a significant challenge. This paper proposes an adaptive query optimization framework, 'AQRL', that leverages reinforcement learning to navigate the complex query optimization space. AQRL uses a novel reward function that balances query performance, resource utilization, and data freshness, and learns to adapt to changing workload patterns. Experimental results on a real-world dataset demonstrate that AQRL outperforms state-of-the-art query optimizers by up to 30% in query latency and 25% in resource utilization.