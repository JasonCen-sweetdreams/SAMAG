In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a decentralized approach using deep reinforcement learning to allocate tasks among agents. Our proposed method, 'MATRL', enables agents to learn from their experiences and adapt to changing environment conditions. We utilize a multi-agent Q-network to estimate the expected rewards for each task-agent pair and develop a distributed allocation algorithm that minimizes communication overhead. Experimental results demonstrate that MATRL outperforms traditional methods in terms of task completion time and resource utilization.