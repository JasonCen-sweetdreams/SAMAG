Virtual reality (VR) has vast potential for human-computer interaction, but current gesture recognition systems rely heavily on visual cues, neglecting the importance of embodiment. We present an empirical study examining the impact of embodiment on gesture recognition in VR. Our results show that embodied experiences, such as proprioception and haptic feedback, significantly improve gesture recognition accuracy and user experience. We propose a novel framework, 'Embodiment-Aware Gesture Recognition' (EAGR), which incorporates embodied cues into the recognition pipeline. EAGR outperforms state-of-the-art vision-based approaches in various VR scenarios, highlighting the importance of considering embodiment in future HCI systems.