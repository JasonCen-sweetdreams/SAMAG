Multi-agent reinforcement learning (MARL) has seen significant progress in recent years, but interpreting the decision-making process of agents remains a challenge. We propose a novel hierarchical attention network (HAN) architecture that enables explainable MARL in complex, dynamic environments. Our approach combines a hierarchical graph attention mechanism with a policy attention module to focus on relevant agents and their interactions. We demonstrate the effectiveness of our method on a range of MARL benchmarks, showcasing improved interpretability and robustness compared to state-of-the-art methods.