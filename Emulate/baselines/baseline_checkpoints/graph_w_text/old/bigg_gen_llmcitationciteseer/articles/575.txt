Hierarchical clustering is a fundamental task in data analysis, but existing methods struggle with high-dimensional data due to the curse of dimensionality. This paper proposes a novel deep neural network architecture, 'HiDeNN', that learns a hierarchical representation of the data by iteratively applying dimensionality reduction and clustering. We introduce a novel loss function that encourages the formation of hierarchical clusters while preserving local structure. Experiments on various high-dimensional datasets demonstrate that HiDeNN outperforms state-of-the-art methods in terms of clustering quality and scalability.