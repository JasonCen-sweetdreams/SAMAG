Time-series anomaly detection is a crucial task in many applications, but existing methods often lack interpretability, making it difficult to identify the root cause of anomalies. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that detects anomalies while providing explainable insights. Our approach consists of a hierarchical encoder that captures long-term dependencies and a attention-based decoder that highlights relevant segments contributing to the anomaly. We evaluate HAN on three real-world datasets and demonstrate superior detection performance and improved interpretability compared to state-of-the-art methods.