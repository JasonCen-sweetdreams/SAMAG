Virtual reality (VR) systems often rely on cumbersome input devices, hindering user experience. We propose a novel gaze-based interaction method, GazeRL, which leverages deep reinforcement learning to infer user intentions from eye movements. Our approach uses a hierarchical policy architecture, combining a gaze-based attention mechanism with a reinforcement learning framework. We evaluate GazeRL in a VR gaming environment, demonstrating improved interaction accuracy and reduced user fatigue compared to traditional input methods.