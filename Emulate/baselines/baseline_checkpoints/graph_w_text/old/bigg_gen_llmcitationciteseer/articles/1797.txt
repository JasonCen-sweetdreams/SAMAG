Explainability is crucial in multi-agent reinforcement learning (MARL) for real-world applications. This paper introduces Hierarchical Attention Networks (HANs) to learn interpretable, hierarchical representations of agent interactions. HANs employ attention mechanisms to selectively focus on relevant agents and their relationships, enabling the discovery of meaningful patterns and behaviors. We evaluate HANs on a variety of MARL scenarios, demonstrating improved performance and enhanced explainability compared to state-of-the-art methods.