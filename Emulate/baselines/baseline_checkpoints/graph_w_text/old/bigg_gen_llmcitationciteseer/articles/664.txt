Multi-agent systems often struggle to provide transparent and interpretable decision-making processes. This paper introduces Hierarchical Attention Networks (HANs), a novel deep learning architecture that enables explainable decision-making in multi-agent environments. HANs employ a hierarchical attention mechanism to selectively focus on relevant agents, states, and actions, generating a interpretable attention map that justifies the collective decision. We evaluate HANs on a simulated robotic soccer domain, demonstrating improved teamwork performance and enhanced explainability compared to existing methods.