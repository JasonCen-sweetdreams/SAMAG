Distributed database systems have become increasingly popular due to their scalability and fault-tolerance. However, query optimization remains a significant challenge in these systems. In this paper, we propose a novel approach to query optimization using reinforcement learning. We model the query optimization problem as a Markov decision process and use Q-learning to learn an optimization policy. Our approach, called 'RL-Optimizer', adaptively adjusts the optimization strategy based on the system's workload and performance metrics. Experimental results on a real-world dataset show that RL-Optimizer outperforms traditional query optimization techniques by up to 30% in terms of execution time and resource utilization.