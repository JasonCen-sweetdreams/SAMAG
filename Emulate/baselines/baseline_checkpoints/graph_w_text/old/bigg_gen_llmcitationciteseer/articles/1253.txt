Autonomous vehicles (AVs) in urban environments face complex scenarios requiring rapid decision-making. This paper presents a hierarchical reinforcement learning (HRL) framework for AV control, comprising a high-level decision-making module and a low-level control module. The high-level module utilizes a graph-based representation of the environment to plan navigation, while the low-level module employs a deep Q-network to execute control actions. We demonstrate the effectiveness of our approach in a simulated urban setting, showcasing improved safety and efficiency compared to traditional rule-based control methods.