Explainability is a crucial aspect of multi-agent reinforcement learning (MARL), as it enables humans to understand and trust autonomous decision-making systems. This paper introduces Hierarchical Attention Networks for Explainable MARL (HANEM), a novel architecture that integrates attention mechanisms to selectively focus on relevant interactions between agents. HANEM learns to extract hierarchical representations of agent policies, facilitating interpretability of joint actions and outcomes. Empirical results on several MARL benchmarks demonstrate that HANEM outperforms state-of-the-art methods in terms of explainability and policy performance.