Distributed database systems have become increasingly popular for handling large-scale data storage and querying. However, optimizing query performance in these systems remains a significant challenge. This paper proposes a novel approach that leverages machine learning techniques to optimize query plans in distributed database systems. We develop a query optimizer that utilizes a graph neural network to learn the query execution patterns and predict the optimal query plan. Our experimental results on a real-world dataset demonstrate that our approach outperforms traditional query optimization techniques by up to 30% in terms of query execution time.