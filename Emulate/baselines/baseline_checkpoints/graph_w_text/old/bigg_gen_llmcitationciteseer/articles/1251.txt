Neural retrieval models have shown promising results in information retrieval tasks, but their performance can be limited by the quality of the input queries. This paper investigates the effectiveness of various query expansion techniques in improving the retrieval performance of neural models. We experiment with different expansion methods, including word embeddings, pseudo-relevance feedback, and generative adversarial networks, and evaluate their impact on retrieval metrics such as MAP and NDCG. Our results show that query expansion can significantly improve the performance of neural retrieval models, but the choice of expansion method and hyperparameters can have a significant impact on the outcome.