As autonomous vehicles increasingly rely on AI-driven perception systems, they become vulnerable to adversarial attacks that can manipulate sensor data to deceive the vehicle's decision-making process. This paper proposes a novel approach to detect such attacks using graph neural networks (GNNs). We model the complex relationships between sensor data and the vehicle's state as a graph, and train a GNN to identify anomalies indicative of adversarial attacks. Experimental results on a large-scale autonomous driving dataset demonstrate the effectiveness of our approach in detecting attacks with high accuracy and low false positive rates.