Voice assistants have become ubiquitous in modern life, but their accessibility remains a significant concern for people with disabilities. This paper presents a novel multimodal interaction framework, 'AccessibleVA', which integrates speech, gesture, and gaze-based inputs to enable more inclusive interactions. We conducted a participatory design study with 20 participants with disabilities, informing the development of a prototype that accommodates diverse abilities and preferences. Our evaluation shows that AccessibleVA significantly improves task completion rates and user satisfaction compared to existing voice assistants.