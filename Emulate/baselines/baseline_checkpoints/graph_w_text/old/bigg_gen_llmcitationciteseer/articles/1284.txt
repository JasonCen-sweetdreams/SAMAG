The increasing adoption of autonomous vehicles (AVs) on public roads necessitates efficient coordination mechanisms to ensure safety and traffic flow. This paper presents a novel multi-agent deep reinforcement learning (MADRL) framework, 'AV-Coordinator', which learns to coordinate AVs in complex, dynamic environments. By employing a decentralized, actor-critic architecture, AV-Coordinator enables AVs to adapt to diverse scenarios, such as Lane-Change, Merging, and Intersection-Traversal, while minimizing collisions and reducing travel time. Our simulation results demonstrate the scalability and effectiveness of AV-Coordinator in real-world-inspired scenarios, outperforming traditional rule-based approaches.