Edge computing has introduced new challenges in resource allocation, particularly in dynamic environments. This paper proposes a decentralized multi-agent reinforcement learning (MARL) framework for efficient resource allocation in edge computing. Our approach, dubbed 'EdgeMAgent', leverages a hierarchical architecture comprising multiple cooperative agents that learn to optimize resource allocation in response to changing workload demands. Experimental results on a simulated edge computing platform demonstrate that EdgeMAgent achieves significant improvements in resource utilization and latency reduction compared to traditional centralized approaches.