Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables humans to understand agent decision-making. We introduce HAN-MARL, a novel hierarchical attention network that learns to explain agent policies in cooperative MARL settings. HAN-MARL employs a hierarchical attention mechanism to identify relevant agents, states, and actions that influence policy decisions. We evaluate HAN-MARL on several MARL benchmarks and demonstrate improved explainability and policy performance compared to state-of-the-art methods. Our approach has potential applications in real-world domains such as autonomous vehicles and smart grids.