Voice assistants have transformed the way people interact with technology, but their accessibility limitations exclude many individuals with disabilities. This paper presents a multimodal approach to designing inclusive voice assistants, focusing on users with visual, hearing, motor, and cognitive impairments. We propose a framework that integrates speech, gesture, and gaze-based input modalities, allowing users to choose their preferred interaction method. Our user study with 30 participants demonstrates that our approach improves task completion rates, user satisfaction, and perceived accessibility compared to traditional voice-only assistants.