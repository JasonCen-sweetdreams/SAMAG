Hierarchical task networks (HTNs) are a powerful framework for representing complex tasks in AI systems. However, learning HTNs from experience remains a challenging problem. This paper presents a novel online learning approach that leverages deep reinforcement learning to learn HTNs from sparse rewards. Our method, called HTN-DRL, uses a hierarchical policy representation to efficiently explore the space of possible HTNs and a novel reward function to guide the learning process. We evaluate HTN-DRL on a set of benchmarks and demonstrate its ability to learn effective HTNs in a variety of domains, outperforming state-of-the-art methods in terms of sample efficiency and solution quality.