Decentralized task allocation is a fundamental problem in multi-agent systems, where agents need to allocate tasks among themselves without a central authority. This paper proposes a novel approach using graph neural networks (GNNs) to learn decentralized task allocation policies. Our model, called GraphAgent, represents the agent network as a graph and uses GNNs to learn task allocation policies that optimize system-level performance. We evaluate GraphAgent on a simulated disaster response scenario and demonstrate its ability to adapt to changing environmental conditions and agent failures, outperforming traditional decentralized allocation methods.