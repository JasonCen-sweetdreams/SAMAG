This paper presents a novel gaze-based interaction system for augmented reality (AR) applications using deep learning. We propose a convolutional neural network (CNN) architecture that detects eye movements from video frames and predicts the user's intended interaction target in real-time. Our approach eliminates the need for explicit calibration and achieves high accuracy even with varying lighting conditions and eye movement speeds. We evaluate our system on a public AR dataset and demonstrate its effectiveness in reducing interaction time and improving user experience.