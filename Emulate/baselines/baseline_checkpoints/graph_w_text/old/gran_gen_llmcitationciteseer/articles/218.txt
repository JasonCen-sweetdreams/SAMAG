Decentralized task allocation is a fundamental problem in multi-agent systems, where agents must coordinate to perform tasks efficiently. We propose a novel reinforcement learning approach, 'DMA-RL', which enables agents to learn decentralized task allocation policies in a distributed manner. DMA-RL utilizes a graph neural network to model agent interactions and a decentralized actor-critic algorithm to optimize task allocation. Experimental results on a variety of task allocation scenarios demonstrate that DMA-RL outperforms traditional methods in terms of task completion time and system efficiency.