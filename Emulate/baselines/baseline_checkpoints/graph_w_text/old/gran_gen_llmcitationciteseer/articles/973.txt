This paper presents a novel decentralized multi-agent reinforcement learning framework for adaptive traffic signal control. Our approach, called 'MA-TSC', leverages the concept of autonomous agents to learn optimal traffic signal control policies in real-time, without relying on centralized coordination. We introduce a novel communication protocol that enables agents to share local observations and coordinate their actions, while maintaining scalability and fault tolerance. Experimental results on a simulated traffic network demonstrate that MA-TSC outperforms traditional traffic signal control methods, reducing congestion and travel times by up to 25% and 30%, respectively.