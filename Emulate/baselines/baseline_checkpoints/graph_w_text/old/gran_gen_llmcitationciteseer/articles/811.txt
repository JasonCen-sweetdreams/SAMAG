In multi-agent reinforcement learning, understanding the decision-making process is crucial for real-world applications. This paper proposes a hierarchical attention network (HAN) architecture that integrates attention mechanisms at both the agent and team levels. Our approach enables the identification of critical agents, actions, and states contributing to the team's policy. We evaluate HAN on a range of multi-agent tasks, demonstrating improved explainability and performance compared to existing methods. Additionally, we introduce a novel explanation metric, 'influence score', to quantify the impact of individual agents on the team's outcome.