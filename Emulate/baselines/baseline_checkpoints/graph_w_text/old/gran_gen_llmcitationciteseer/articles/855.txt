As AI-powered disease diagnosis systems become increasingly prevalent, there is a growing need for explainable models that provide insights into their decision-making processes. This paper proposes a novel Hierarchical Graph Attention Network (HiGAT) architecture that leverages graph-based representations of medical knowledge to identify informative patterns in patient data. HiGAT incorporates attention mechanisms at multiple scales to highlight relevant symptoms, disease correlations, and biomarkers, enabling interpretable diagnosis predictions. Experimental results on a large-scale electronic health record dataset demonstrate that HiGAT outperforms state-of-the-art models in both diagnostic accuracy and explainability.