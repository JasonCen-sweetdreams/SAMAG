Question answering over knowledge graphs (KGs) is a fundamental task in natural language processing. However, existing KG embedding methods struggle to capture complex semantic relationships and scale to large graphs. This paper proposes HyperQA, a novel KG embedding framework that leverages hyperbolic geometry to model hierarchical and asymmetric relationships. By learning embeddings in the Poincar√© ball, HyperQA achieves improved performance on benchmark question answering datasets, while reducing the required number of parameters and computational resources. Experiments demonstrate the effectiveness of HyperQA in capturing compositional relationships and generalizing to unseen entities and relations.