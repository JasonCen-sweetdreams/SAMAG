Query expansion is a crucial component in ad-hoc retrieval systems, as it helps to disambiguate user queries and improve retrieval performance. However, existing methods often rely on static term weighting schemes or manual feature engineering, which can be suboptimal. This paper proposes a novel reinforcement learning-based approach, 'RL-QE', which learns to adaptively expand queries by interacting with a simulated retrieval environment. RL-QE leverages a deep Q-network to predict the expected retrieval improvement for each expansion term, and uses a hierarchical exploration strategy to balance exploration and exploitation. Experimental results on several standard benchmarks demonstrate that RL-QE outperforms state-of-the-art query expansion methods, achieving significant improvements in mean average precision and normalized discounted cumulative gain.