This paper presents a decentralized task allocation framework for multi-agent systems using reinforcement learning. Our approach, called MATRL, enables agents to learn optimal task assignments in a distributed manner, without relying on a centralized controller. We model the task allocation problem as a Markov decision process and employ deep Q-networks to learn the optimal policy. Experimental results on a simulated robotic swarm demonstrate that MATRL outperforms traditional, centralized algorithms in terms of task completion efficiency and adaptability to dynamic environments.