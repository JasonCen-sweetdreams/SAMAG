Knowledge graph embedding has become a crucial technique for various AI applications. However, existing methods often suffer from high computational costs and fail to capture hierarchical relationships in graphs. This paper proposes a novel approach, Hierarchical Graph Attention Networks (HGAT), which leverages a hierarchical attention mechanism to selectively focus on relevant nodes and edges. Experimental results on benchmark datasets demonstrate that HGAT outperforms state-of-the-art methods in terms of link prediction and node classification tasks, while reducing computational costs by up to 30%.