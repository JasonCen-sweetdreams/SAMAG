Real-time traffic signal control is a complex problem that requires efficient decision-making to mitigate congestion and reduce travel times. This paper presents an adaptive multi-agent reinforcement learning (MARL) framework, 'SMARTS', which enables decentralized, real-time traffic signal control. SMARTS employs a graph neural network to model traffic signal interactions and a deep Q-network to learn optimal control policies. We evaluate SMARTS on a large-scale, real-world traffic network and demonstrate significant improvements in average travel time, traffic volume, and signal coordination compared to traditional, fixed-time control methods.