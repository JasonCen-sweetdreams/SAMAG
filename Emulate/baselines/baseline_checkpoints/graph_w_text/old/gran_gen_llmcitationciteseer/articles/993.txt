This paper introduces Hierarchical Attention Networks (HANs) for Explainable Multi-Agent Reinforcement Learning (MARL). HANs learn to selectively focus on relevant agents and their interactions, providing interpretable policies for cooperative MARL tasks. We propose a novel hierarchical attention mechanism that models agent-agent and agent-environment interactions, enabling the learned policies to adapt to complex scenarios. Experimental results on a range of MARL benchmarks demonstrate that HANs outperform state-of-the-art methods in terms of both task performance and interpretability.