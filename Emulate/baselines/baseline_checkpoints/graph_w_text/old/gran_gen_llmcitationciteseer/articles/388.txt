Voice assistants have become ubiquitous, but their performance is often biased towards users with standard accents. This paper investigates the impact of accent variability on voice assistant accuracy and proposes a novel accent recognition and mitigation framework. Our empirical study on a diverse user population reveals that existing systems struggle with non-standard accents, leading to significant accuracy drops. We design and evaluate a multi-task learning approach that jointly optimizes accent recognition and speech recognition tasks, resulting in improved performance for users with diverse accents. Our findings have implications for designing more inclusive and equitable voice assistants.