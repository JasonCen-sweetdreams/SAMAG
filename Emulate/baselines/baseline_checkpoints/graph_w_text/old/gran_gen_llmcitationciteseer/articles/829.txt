This paper introduces a novel hierarchical attention mechanism for multi-agent reinforcement learning, enabling explainable decision-making in complex, dynamic environments. Our approach, Hierarchical Attention for Multi-Agent Reinforcement Learning (HAMARL), learns to selectively focus on relevant agents, states, and actions to improve cooperation and coordination. We demonstrate HAMARL's effectiveness in several benchmark environments, including a realistic autonomous driving scenario, and show that it outperforms existing methods in terms of both task performance and interpretability.