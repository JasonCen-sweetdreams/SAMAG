Cooperative task allocation is a challenging problem in multi-agent systems, particularly in dynamic environments where tasks and agent capabilities change over time. This paper proposes a novel multi-agent reinforcement learning framework, 'CoopRL', that enables agents to learn cooperative policies for task allocation in such environments. We introduce a decentralized credit assignment mechanism that incentivizes agents to share knowledge and adapt to changing task requirements. Experimental results in a simulated disaster response scenario demonstrate that CoopRL outperforms existing methods in terms of task completion rate and overall system efficiency.