Node classification is a fundamental task in graph-based machine learning, but existing methods often struggle with scalability. We propose Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages hierarchical graph representations to improve node classification performance on large graphs. HGAT employs a hierarchical attention mechanism to selectively aggregate features from neighboring nodes at multiple scales, reducing computational complexity while preserving contextual information. Experimental results on several benchmark datasets demonstrate HGAT's ability to achieve state-of-the-art performance while scaling to graphs with millions of nodes.