Time series forecasting models often struggle to provide interpretable insights into their predictions. To address this limitation, we introduce Hierarchical Attention Networks (HAN), a novel architecture that incorporates both local and global attention mechanisms to selectively focus on relevant time series segments and features. We demonstrate the effectiveness of HAN on a range of benchmark datasets, achieving state-of-the-art performance while providing visual explanations of the forecasting process. Our approach has significant implications for real-world applications, such as stock market prediction and energy demand forecasting, where model interpretability is crucial.