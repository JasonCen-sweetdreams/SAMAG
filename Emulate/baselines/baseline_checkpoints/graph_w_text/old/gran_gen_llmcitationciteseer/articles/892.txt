In this paper, we propose a decentralized approach to coordinating multi-agent systems using Partially Observable Markov Decision Processes (POMDPs). We consider a setting where each agent has partial observations of the environment and aims to maximize a shared reward function. Our approach, called Dec-POMDP-Coordinated, leverages decentralized POMDP solvers and introduces a novel communication protocol to enable agents to share information and coordinate their actions. We show that Dec-POMDP-Coordinated outperforms existing methods in a variety of scenarios, including robotic soccer and autonomous drone coordination. Our results demonstrate the potential of decentralized POMDPs for large-scale multi-agent systems.