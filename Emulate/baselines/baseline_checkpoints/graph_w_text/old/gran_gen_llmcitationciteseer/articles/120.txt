Multi-agent systems (MAS) have garnered significant attention in AI research, but their decision-making processes often lack transparency. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework, which enables explainable cooperation among agents in MAS. By incorporating graph attention mechanisms at multiple scales, HGAT captures complex relationships between agents and their environments. We evaluate our approach on a suite of benchmark MAS tasks, demonstrating improved cooperation outcomes and interpretable decision-making processes. Our results have implications for real-world applications, such as autonomous traffic management and smart grid control.