Traditional query expansion techniques for document retrieval rely on manual feature engineering and often fail to capture the nuances of natural language. This paper proposes a novel neural query expansion approach, 'NeuQE', which leverages pre-trained language models to generate context-aware query embeddings. Our method adaptively weights the importance of expansion terms based on their semantic relevance to the original query, leading to significant improvements in retrieval efficiency and accuracy. Experimental results on several benchmark datasets demonstrate the effectiveness of NeuQE in retrieving relevant documents from large, unstructured data repositories.