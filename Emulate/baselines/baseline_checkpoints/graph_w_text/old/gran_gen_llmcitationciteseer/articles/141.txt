Deep reinforcement learning (DRL) has achieved state-of-the-art performance in various applications, but it remains vulnerable to adversarial attacks. This paper proposes a novel approach to detect adversarial attacks in DRL using graph-based anomaly detection. We model the agent's behavior as a graph and identify anomalies in the graph structure, which indicate potential attacks. Our approach is robust to various types of attacks and outperforms existing detection methods. We evaluate our approach on several DRL environments and demonstrate its effectiveness in detecting attacks with high accuracy.