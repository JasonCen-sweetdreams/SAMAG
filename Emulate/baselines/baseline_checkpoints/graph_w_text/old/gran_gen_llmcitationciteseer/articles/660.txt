In multi-agent systems, task allocation is a crucial problem that involves assigning tasks to agents with varying capabilities. This paper proposes a distributed task allocation approach using deep reinforcement learning. We formulate the task allocation problem as a decentralized partially observable Markov decision process (Dec-POMDP) and develop a novel algorithm, 'HRL-MA', that learns to allocate tasks effectively in heterogeneous multi-agent environments. Our approach leverages graph neural networks to model agent interactions and incorporates a multi-agent Q-network to learn cooperative policies. Experimental results demonstrate that HRL-MA outperforms existing task allocation algorithms in terms of task completion efficiency and adaptability to changing agent capabilities.