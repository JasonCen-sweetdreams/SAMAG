In multi-agent systems, efficient task allocation is crucial for achieving collective goals. Existing approaches often rely on centralized solutions, which can be vulnerable to single-point failures and limited scalability. This paper proposes a decentralized task allocation framework, 'GCN-Alloc', that leverages graph convolutional networks (GCNs) to learn agent embeddings and allocate tasks in a distributed manner. Our approach incorporates agent capabilities, task requirements, and communication constraints to optimize task assignment. Experimental results on a simulated disaster response scenario demonstrate that GCN-Alloc outperforms traditional methods in terms of task completion rate, latency, and robustness.