Multi-label classification is a fundamental problem in machine learning, where each sample can have multiple labels. Existing methods often suffer from high computational complexity and limited scalability. In this paper, we propose a novel hierarchical attention network (HAN) that efficiently tackles multi-label classification. Our HAN model employs a hierarchical structure to selectively focus on relevant labels and features, reducing the computational cost and improving prediction accuracy. Experimental results on several benchmark datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance with significant speedup.