Explainability is crucial in multi-agent reinforcement learning (MARL) for real-world applications. We propose a novel Hierarchical Graph Attention Network (HGAT) framework that integrates attention mechanisms with hierarchical graph representations to learn interpretable policies. HGAT enables agents to selectively focus on relevant teammates and tasks, improving both overall performance and interpretability. Our experiments on a MARL benchmark demonstrate HGAT's superiority over existing methods in terms of both task completion rates and explainability metrics.