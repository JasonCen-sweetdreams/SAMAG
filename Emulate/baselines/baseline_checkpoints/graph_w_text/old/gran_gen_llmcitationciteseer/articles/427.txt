Explainable recommendation systems have garnered significant attention in recent years due to their ability to provide transparency into the decision-making process. This paper proposes a novel hierarchical attention-based graph neural network (HAGNN) architecture that learns to generate recommendations while providing interpretable explanations. Our approach leverages graph attention mechanisms to model user-item interactions and incorporates a hierarchical attention framework to capture complex relationships between items. Experimental results on multiple benchmark datasets demonstrate the effectiveness of HAGNN in terms of recommendation accuracy and explanation quality.