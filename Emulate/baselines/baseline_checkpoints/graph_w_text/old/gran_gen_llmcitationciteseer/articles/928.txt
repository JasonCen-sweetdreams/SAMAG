State-of-the-art recommendation systems rely on graph-based methods, but their scalability is limited by the quadratic complexity of attention mechanisms. We propose a novel hierarchical graph attention network (HGAT) that leverages a recursive clustering approach to reduce the attention complexity from O(n^2) to O(n log n). Our experiments on three large-scale benchmark datasets demonstrate that HGAT outperforms existing graph-based methods in terms of both recommendation accuracy and inference speed. We also provide theoretical guarantees on the approximation error of our hierarchical attention mechanism.