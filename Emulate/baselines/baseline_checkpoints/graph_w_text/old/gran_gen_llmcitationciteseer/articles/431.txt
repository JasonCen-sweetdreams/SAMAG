Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables understanding of agent behaviors and decision-making processes. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that facilitates explainable MARL by modeling agent interactions and relationships. Our approach integrates attention mechanisms at both intra-agent and inter-agent levels, allowing for the identification of key factors influencing agent policies. Experimental results on a range of MARL benchmarks demonstrate improved explainability and performance compared to state-of-the-art methods.