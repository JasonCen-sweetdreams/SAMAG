Swarm robotics has the potential to revolutionize various applications, including search and rescue, environmental monitoring, and agriculture. However, decentralized task allocation remains a significant challenge in swarm robotics. This paper proposes a novel multi-agent reinforcement learning framework, 'MARS', which enables decentralized task allocation in swarm robotics. MARS leverages a decentralized actor-critic architecture, where each robot learns to allocate tasks based on local observations and communication with neighboring robots. We demonstrate the effectiveness of MARS in simulations and real-world experiments, showcasing improved task allocation efficiency and adaptability compared to traditional centralized approaches.