Explainability is crucial in multi-agent reinforcement learning (MARL) to ensure transparency and accountability. This paper proposes a novel Hierarchical Attention Network (HAN) architecture to learn interpretable policies for MARL. Our approach combines attention mechanisms to model agent interactions and a hierarchical structure to capture complex dependencies. We evaluate HAN on a range of MARL benchmarks, demonstrating improved explainability and competitive performance compared to state-of-the-art methods. Furthermore, we provide visualizations and quantitative metrics to illustrate the interpretability of our approach.