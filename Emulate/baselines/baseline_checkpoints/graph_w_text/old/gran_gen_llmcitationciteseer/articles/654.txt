Real-time analytics in distributed database systems (DDS) requires efficient query optimization techniques to minimize latency and maximize throughput. This paper presents a novel query optimization framework, 'RTOpt', which leverages a combination of machine learning-based cost estimation and dynamic query rewriting. Our approach adaptively adjusts to changing workload patterns and system resource availability, leading to improved query response times and resource utilization. Experimental results on a real-world DDS prototype demonstrate that RTOpt outperforms state-of-the-art query optimizers in terms of average query latency and system throughput.