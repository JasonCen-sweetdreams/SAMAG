Neural architecture search (NAS) has emerged as a promising approach for automating the design of deep neural networks. However, the majority of existing NAS methods rely on costly and time-consuming architecture evaluations. This paper introduces a novel hierarchical graph-based encoding scheme, 'HierGraph', which reduces the search space by aggregating and abstracting architecture components. We propose a reinforcement learning-based search algorithm that leverages HierGraph to efficiently explore the architecture space. Experimental results on benchmark datasets demonstrate that our approach achieves state-of-the-art performance while reducing search time by up to 75% compared to existing NAS methods.