This paper presents a novel hierarchical attention network (HAN) framework for explainable multi-agent reinforcement learning. Our approach enables agents to selectively focus on relevant information from their observations and other agents' actions, leading to improved cooperation and coordination in complex scenarios. We introduce a novel attention mechanism that captures both spatial and temporal relationships between agents, allowing for more accurate credit assignment and better decision-making. Experimental results on several multi-agent environments demonstrate the effectiveness of our approach in achieving superior performance and interpretability compared to existing methods.