Traditional document representation methods in information retrieval (IR) rely on bag-of-words or dense vector embeddings, which often fail to capture complex semantic relationships between documents. We propose a novel graph-based nearest neighbor embedding approach, GraphNNE, which models document relationships as a graph and learns compact, informative representations via a nearest neighbor-based objective. Experimental results on several benchmark datasets demonstrate that GraphNNE outperforms state-of-the-art document representation methods in ad-hoc retrieval tasks, while reducing computational costs.