Resource allocation in cloud computing is a complex problem due to the dynamic nature of workloads and limited resources. This paper proposes a hierarchical reinforcement learning (HRL) framework, 'CloudAllocator', that learns to allocate resources efficiently by decomposing the problem into a hierarchy of tasks. The framework consists of a high-level scheduler that allocates resources to virtual machines and a low-level controller that manages resource utilization within each machine. We evaluate CloudAllocator on a real-world cloud dataset and show that it achieves significant improvements in resource utilization and job completion times compared to existing heuristic-based approaches.