Distributed database systems pose significant challenges for query optimization, particularly in scenarios with complex queries and large datasets. This paper explores the application of machine learning techniques to improve the efficiency of query optimization in distributed databases. We propose a novel approach, 'QOptML', that leverages supervised learning to predict optimal query plans based on historical query patterns and system performance metrics. Experimental results on a real-world distributed database system demonstrate that QOptML reduces query execution times by up to 35% compared to traditional optimization methods.