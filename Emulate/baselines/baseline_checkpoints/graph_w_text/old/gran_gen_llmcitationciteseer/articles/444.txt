Multi-agent reinforcement learning (MARL) has achieved remarkable success in various applications. However, the lack of explainability in MARL hinders its widespread adoption. We propose a novel hierarchical attention network (HAN) architecture that facilitates explainable MARL. Our HAN model consists of two stages: an attention-based feature extractor and a hierarchical policy network. The attention mechanism allows us to identify the most relevant agents and their corresponding actions, providing insights into the decision-making process. We evaluate our approach on several MARL benchmarks and demonstrate improved performance and interpretability compared to state-of-the-art methods.