Voice assistants have become ubiquitous, but their one-size-fits-all design neglects the diverse needs of users with disabilities. This paper presents a user-centered approach to designing inclusive voice assistants. We conducted a mixed-methods study involving 30 participants with disabilities, identifying key challenges and preferences for personalized assistance. Our findings inform the development of a novel framework, 'AccessibilityLens', which integrates user profiling, adaptive dialogue management, and multimodal output. A pilot evaluation demonstrates significant improvements in user satisfaction and task completion rates for users with disabilities, highlighting the potential of personalized voice assistants to promote digital inclusion.