Explainable recommendation systems have garnered significant attention in recent years due to the need for transparency in AI-driven decision-making. This paper proposes a novel hierarchical graph attention network (HGAT) framework that not only achieves state-of-the-art recommendation performance but also provides personalized explanations for each user's recommended items. By modeling user-item interactions as a hierarchical graph, our approach captures complex relationships between users, items, and attributes, enabling the generation of interpretable and relevant explanations. Experimental results on three real-world datasets demonstrate the effectiveness of HGAT in both recommendation accuracy and explanation quality.