Autonomous vehicles rely on reinforcement learning (RL) to optimize control policies, but the lack of transparency in RL models hinders trust and reliability. This paper proposes an explainable RL framework, 'XRL', which incorporates attention-based feature importance and model-based reasoning to provide insights into policy decisions. We demonstrate the effectiveness of XRL in a simulated autonomous driving environment, showing improved interpretability and robustness to perturbations compared to state-of-the-art RL methods.