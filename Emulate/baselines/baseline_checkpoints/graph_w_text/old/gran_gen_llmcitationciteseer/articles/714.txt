Voice assistants have become ubiquitous in modern life, but their design often neglects the needs of users with disabilities. This paper presents a multimodal approach to enhance the accessibility of voice assistants for users with visual, hearing, motor, or cognitive impairments. We propose a novel framework that incorporates visual, tactile, and haptic feedback, as well as personalized language models to accommodate diverse communication styles. Our user study with 30 participants demonstrates significant improvements in user satisfaction, task completion rate, and error reduction compared to existing voice assistants.