Autonomous vehicles require efficient decision-making strategies to navigate complex scenarios. We propose a hierarchical reinforcement learning framework, 'HRL-Nav', which decomposes decision-making into a high-level planning module and a low-level control module. The planning module learns to identify critical situations and select appropriate maneuvers, while the control module refines the selected maneuvers through fine-grained trajectory planning. We evaluate HRL-Nav on a realistic simulation platform and demonstrate improved decision-making performance compared to traditional flat reinforcement learning approaches. Our approach enables more efficient exploration of the action space and adapts to changing environment conditions.