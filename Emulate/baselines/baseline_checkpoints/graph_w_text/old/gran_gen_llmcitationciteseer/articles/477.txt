Multi-agent systems often struggle to provide transparent decision-making processes, hindering trust and accountability. We propose a novel Hierarchical Attention Network (HAN) architecture that enables explainable decision-making in multi-agent environments. Our approach leverages attention mechanisms to selectively focus on relevant agent interactions, generating interpretable importance scores. We evaluate HAN on a variety of multi-agent scenarios, demonstrating improved decision-making accuracy and enhanced transparency compared to traditional reinforcement learning methods.