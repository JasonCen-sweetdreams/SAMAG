Retrieval-based question answering (RBQA) systems rely on effective query expansion to retrieve relevant passages from a large corpus. This paper proposes a novel neural ranking model, 'NeuQE', which learns to expand queries by predicting relevant terms and their weights. NeuQE incorporates a deep neural network to model the semantic relationships between query terms and candidate expansion terms, and is trained using a ranking-based objective function. Experimental results on the SQuAD and HotPotQA datasets demonstrate that NeuQE outperforms traditional query expansion methods, achieving significant improvements in retrieval accuracy and downstream QA performance.