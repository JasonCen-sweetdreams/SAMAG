Deep neural networks are prone to accuracy degradation when faced with dataset shifts, which can occur due to changes in the data distribution, domain, or style. This paper explores the efficacy of adversarial training in improving the robustness of image classification models against such shifts. We propose a novel method, 'ShiftAdv', which generates adversarial examples that mimic the distributional changes expected in real-world scenarios. Our experiments on benchmark datasets demonstrate that ShiftAdv significantly enhances the model's robustness to dataset shifts, outperforming state-of-the-art methods in terms of accuracy and stability.