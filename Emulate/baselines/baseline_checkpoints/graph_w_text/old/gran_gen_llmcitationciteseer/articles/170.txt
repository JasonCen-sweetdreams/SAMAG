Traditional ranking models in information retrieval rely on dense document representations, which are computationally expensive and ineffective for sparse documents. We propose a novel neural ranking model, 'SparseRank', that leverages the strengths of both sparse and dense representations. SparseRank employs a hierarchical attention mechanism to selectively aggregate sparse features and dense contextualized embeddings, achieving significant improvements in ranking accuracy and efficiency. Our experiments on several benchmark datasets demonstrate the superior performance of SparseRank over state-of-the-art ranking models on sparse document retrieval tasks.