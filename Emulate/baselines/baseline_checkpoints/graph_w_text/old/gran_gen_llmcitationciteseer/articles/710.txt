Coordinating multi-agent systems (MAS) to achieve a common goal is a challenging problem in artificial intelligence. This paper presents a novel approach that combines reinforcement learning with graph-based inference to enable efficient coordination in MAS. We introduce a decentralized policy iteration algorithm that uses graph neural networks to model the joint action space of agents and reinforcement learning to optimize their policies. Experimental results on a variety of MAS domains demonstrate that our approach outperforms existing methods in terms of coordination efficiency and scalability.