Cooperative task allocation in dynamic environments is a challenging problem that requires agents to adapt to changing conditions and coordinate their actions to achieve common goals. This paper presents a novel multi-agent reinforcement learning framework that enables agents to learn cooperative policies in decentralized settings. Our approach integrates deep Q-networks with graph-based communication protocols to facilitate efficient information sharing and decision-making. Experimental results in simulated scenarios demonstrate the effectiveness of our approach in improving task allocation efficiency and adaptability in dynamic environments.