Link prediction in knowledge graphs is a fundamental task in many AI applications. However, existing methods struggle to model complex relationships between entities. We propose a novel hierarchical graph attention network (HGAT) that leverages multi-relational information to improve link prediction accuracy. HGAT employs a hierarchical attention mechanism to selectively focus on relevant relationships at different levels of abstraction. Experimental results on benchmark datasets show that HGAT outperforms state-of-the-art methods, achieving a 12.5% relative improvement in mean reciprocal rank.