Individuals with dysarthria often face significant barriers when interacting with voice assistants, leading to feelings of frustration and isolation. This paper presents a novel approach to designing more accessible voice assistants by incorporating personalized speech recognition models and adaptive dialogue management. We conducted a user study with 20 participants with dysarthria, demonstrating a 35% reduction in error rates and a 25% increase in user satisfaction when using our system compared to commercial voice assistants. Our results highlight the importance of inclusive design in HCI and provide insights for future research in this area.