We propose a novel approach to scalable multi-agent planning using hierarchical reinforcement learning (HRL). Our method, called Hierarchical Agent Planning (HAP), leverages a two-level hierarchy of agents, where high-level agents coordinate tasks and low-level agents execute actions. HAP uses a novel reward function that balances individual agent rewards with global team objectives. We demonstrate the effectiveness of HAP in a range of complex domains, including robotic soccer and disaster response, showcasing improved scalability and adaptability compared to state-of-the-art methods.