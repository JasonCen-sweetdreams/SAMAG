Neural architecture search (NAS) has emerged as a promising technique for automating the design of deep neural networks. However, existing methods often rely on computationally expensive search strategies or require significant domain expertise. This paper proposes a novel graph-based reinforcement learning (GBRL) approach for efficient NAS. By representing the search space as a graph, our method can leverage graph-based exploration strategies to identify high-performing architectures. We demonstrate the effectiveness of GBRL-NAS on several benchmark datasets, achieving state-of-the-art performance with significantly reduced computational overhead.