Explainability is crucial in multi-agent reinforcement learning (MARL) to ensure trustworthiness in real-world applications. We propose a novel hierarchical attention network (HAN) architecture that learns to selectively focus on relevant agents and their interactions to make decisions. Our approach enables the identification of influential agents and their contributions to the overall reward. We demonstrate the effectiveness of HAN in several MARL benchmarks, showcasing improved performance and interpretability. Furthermore, we provide a theoretical analysis of the attention mechanism, establishing its connection to auction theory and providing insights into the learned attention patterns.