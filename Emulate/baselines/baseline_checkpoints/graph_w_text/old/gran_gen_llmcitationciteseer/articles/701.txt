Explainability is crucial in multi-agent reinforcement learning (MARL) to understand the decision-making process of agents in complex environments. This paper presents a Hierarchical Attention Network (HAN) to improve the transparency of MARL policies. HAN incorporates attention mechanisms at both the agent and team levels, enabling the model to focus on relevant information and provide interpretable explanations. We evaluate HAN on a variety of MARL benchmarks and demonstrate improved explainability and performance compared to state-of-the-art methods. Furthermore, we provide visualizations of attention weights to illustrate the decision-making process of agents.