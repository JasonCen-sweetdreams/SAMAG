In multi-agent systems, effective task allocation is crucial for achieving global objectives. This paper presents a decentralized task allocation framework that leverages graph neural networks (GNNs) to model agent interactions and task dependencies. Our approach, called AgentGNN, allows agents to learn a distributed allocation policy that maximizes system utility while respecting resource constraints. Experimental results on a simulated disaster response scenario demonstrate that AgentGNN outperforms traditional optimization-based methods in terms of task completion rate and response time, while adapting to dynamic changes in the environment.