This paper presents EmoReact, a novel affective gesture recognition system that utilizes electromyography (EMG) signals to detect and classify emotional states in real-time. EmoReact leverages machine learning techniques to recognize subtle muscle contractions in the face and arms, enabling more natural and intuitive human-computer interaction. Our user study involving 30 participants demonstrates that EmoReact achieves an accuracy of 85.6% in recognizing six basic emotions, outperforming existing computer vision-based approaches. We envision EmoReact to be integrated into various HCI applications, including gaming, virtual reality, and affective computing interfaces.