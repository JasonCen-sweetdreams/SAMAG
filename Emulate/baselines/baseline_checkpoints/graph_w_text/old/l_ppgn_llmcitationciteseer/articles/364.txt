Virtual reality (VR) systems have limited input modalities, hindering user experience. We propose a novel gaze-based interaction framework, 'GazeVR', which leverages machine learning to detect and classify user gaze patterns. Our approach uses a convolutional neural network (CNN) to process eye-tracking data and recognize user intentions. We evaluate GazeVR on a public dataset and demonstrate its ability to accurately detect gaze-based commands, enabling seamless interaction with virtual objects. Our results show that GazeVR outperforms existing methods, achieving a 25% reduction in command recognition errors.