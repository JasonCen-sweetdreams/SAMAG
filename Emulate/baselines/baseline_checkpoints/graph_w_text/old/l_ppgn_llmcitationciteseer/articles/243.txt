Voice assistants have become ubiquitous, but their interaction modalities often exclude users with disabilities. This paper presents a novel multimodal interaction framework for voice assistants that incorporates visual, tactile, and haptic feedback to enhance accessibility. We conducted a participatory design study with users with visual, hearing, motor, and cognitive disabilities to inform the design of our system. Our evaluation shows that our approach improves task completion rates and user satisfaction for users with disabilities, while also providing a more inclusive experience for all users. We discuss the implications of our findings for the development of more accessible voice assistants.