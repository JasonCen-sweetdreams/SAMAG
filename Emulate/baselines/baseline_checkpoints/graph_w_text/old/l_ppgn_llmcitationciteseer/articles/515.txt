Distributed graph databases have become increasingly popular for storing and querying large-scale graph data. However, optimizing queries in such systems is a complex task, especially when dealing with complex graph patterns and varying data distributions. This paper proposes a novel approach to query optimization using reinforcement learning. We design a deep Q-network that learns to optimize query plans based on feedback from the execution environment. Our experiments on a real-world graph dataset show that our approach outperforms traditional query optimizers by up to 30% in terms of execution time, while also adapting to changing data distributions and query patterns.