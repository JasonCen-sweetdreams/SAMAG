Intelligent virtual assistants (IVAs) have become increasingly prevalent, but their accuracy can be compromised by user errors. This paper presents a novel gaze-based approach to detect errors in IVA interactions. We developed a machine learning model that leverages eye-tracking data to identify when users correct or repeat commands due to IVA mistakes. Our results show that the proposed approach achieves an error detection accuracy of 87.2%, outperforming traditional speech-based error detection methods. We also explore the impact of gaze features on error detection and discuss implications for improving IVA design.