Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can lead to catastrophic failures in safety-critical applications. Existing detection methods often rely on statistical features or model-agnostic techniques, which can be evaded by sophisticated attackers. This paper proposes a novel graph-based anomaly detection approach, 'GraphGuard', which models the DNN's internal representations as a graph and detects anomalies using graph-based metrics. We demonstrate the effectiveness of GraphGuard in detecting state-of-the-art attacks on various benchmark datasets, achieving a significant improvement over existing detection methods.