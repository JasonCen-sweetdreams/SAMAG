Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its lack of interpretability hinders trust and adoption. We propose a novel Hierarchical Attention Network (HAN) architecture that incorporates attention mechanisms at multiple levels to provide explainable DRL. Our approach learns to focus on relevant state features, actions, and temporal segments, enabling the identification of key decision-making factors. Experimental results on Atari games and robotic control tasks demonstrate that HAN outperforms state-of-the-art DRL methods while providing insightful visualizations and feature importance scores.