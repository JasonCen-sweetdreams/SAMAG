Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can manipulate model predictions. This paper proposes a novel Bayesian defense strategy, 'BayesDef', that leverages uncertainty estimates to detect and mitigate attacks. By incorporating a Bayesian neural network (BNN) within the defense framework, we can quantify the uncertainty of the model's predictions and identify potential attacks. Experimental results on multiple benchmark datasets demonstrate that BayesDef significantly improves the robustness of DNNs against various types of adversarial attacks, including white-box and black-box attacks.