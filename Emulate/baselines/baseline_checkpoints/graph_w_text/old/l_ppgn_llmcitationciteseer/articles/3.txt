Urban traffic management is a complex problem that requires coordinating multiple agents, such as traffic lights and autonomous vehicles, to optimize traffic flow and reduce congestion. This paper proposes a hierarchical reinforcement learning framework that enables agents to learn decentralized policies while accounting for global traffic objectives. Our approach utilizes a two-level hierarchy, where high-level agents learn to coordinate with each other, and low-level agents execute local traffic control actions. We evaluate our approach using a realistic traffic simulator and demonstrate significant reductions in travel time and congestion compared to state-of-the-art methods.