In this paper, we present a decentralized task allocation framework for heterogeneous multi-agent systems. We propose a novel deep reinforcement learning approach that allows each agent to learn its own task allocation policy based on local observations and interactions with neighboring agents. Our approach leverages a graph attention mechanism to model complex dependencies between agents and tasks, and a hierarchical policy architecture to balance exploration and exploitation. Experimental results on a simulated search-and-rescue scenario demonstrate the scalability and effectiveness of our approach in allocating tasks to agents with diverse capabilities and preferences.