Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its vulnerability to adversarial attacks remains a significant concern. This paper introduces 'AdExR', a novel adversarial experience replay mechanism that robustifies DRL agents against targeted attacks. By injecting carefully crafted adversarial experiences into the replay buffer, AdExR enhances the agent's ability to generalize across diverse scenarios and improves its robustness to unforeseen attacks. Our experiments on several benchmark environments demonstrate that AdExR significantly outperforms state-of-the-art DRL methods in terms of both performance and robustness.