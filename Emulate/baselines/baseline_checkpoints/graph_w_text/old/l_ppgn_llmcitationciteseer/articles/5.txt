Autonomous vehicles (AVs) require efficient coordination to navigate complex urban environments. This paper presents a decentralized multi-agent reinforcement learning (MARL) framework, 'AV-CORD', which enables AVs to learn cooperative policies for traffic signal control, lane merging, and collision avoidance. We introduce a novel graph attention mechanism that allows agents to selectively focus on relevant neighboring agents, improving learning efficiency and robustness to diverse traffic scenarios. Experimental results on a large-scale traffic simulator demonstrate that AV-CORD outperforms traditional centralized control methods in terms of travel time, safety, and traffic throughput.