Deep reinforcement learning (DRL) has achieved remarkable success in complex control tasks, but the lack of interpretability hinders its widespread adoption. We propose a novel approach, 'Abstraction-Explain', which leverages model-based state abstraction to provide efficient explanations for DRL policies. By identifying a compact set of abstract states, our method reduces the dimensionality of the explanation space, allowing for faster and more accurate attribution of policy decisions. We evaluate Abstraction-Explain on several benchmark environments, demonstrating improved explanation quality and reduced computational overhead compared to existing explanation methods.