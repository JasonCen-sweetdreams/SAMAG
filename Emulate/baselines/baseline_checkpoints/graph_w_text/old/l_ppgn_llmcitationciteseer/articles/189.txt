Multi-agent systems rely on effective decision-making to achieve collective goals. However, the increasing complexity of these systems necessitates explainable AI techniques to ensure transparency and trust. This paper proposes Hierarchical Attention Networks (HAN) for interpretable multi-agent decision-making. HAN integrates attention mechanisms at both the intra-agent and inter-agent levels, allowing the model to focus on relevant information and relationships between agents. We evaluate HAN on a simulated traffic management scenario, demonstrating improved decision-making performance and providing visualizations of attention weights to facilitate understanding of the decision-making process.