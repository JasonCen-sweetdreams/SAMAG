Recent advances in graph neural networks have significantly improved the performance of recommendation systems. However, the lack of interpretability in these models hinders their widespread adoption. This paper proposes a novel hierarchical graph attention network (HGAT) that incorporates attention mechanisms at multiple scales to provide explainable recommendations. We demonstrate the effectiveness of HGAT on several benchmark datasets, achieving state-of-the-art performance while providing insights into the model's decision-making process. Our approach has important implications for building trustworthy AI systems that can be deployed in real-world applications.