Time series forecasting models often rely on complex neural architectures, making it challenging to interpret their predictions. This paper proposes a novel hierarchical attention network (HAN) that incorporates both local and global contextual information to improve forecasting accuracy and explainability. Our approach learns to focus on relevant segments of the input sequence and identify influential features, enabling model interpretability. We evaluate HAN on several benchmark datasets and demonstrate its effectiveness in capturing non-linear patterns and improving forecasting performance. Additionally, we provide visualizations of the attention weights to facilitate understanding of the model's decision-making process.