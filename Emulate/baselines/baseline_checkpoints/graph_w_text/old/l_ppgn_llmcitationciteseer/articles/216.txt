Explainable AI is crucial for real-world deployment of multi-agent reinforcement learning (MARL) systems. We propose HGAT-MARL, a hierarchical graph attention network that learns to identify and emphasize critical agents, actions, and communication patterns in complex MARL scenarios. By incorporating explainability metrics into the training objective, our approach generates interpretable policies that improve cooperation and performance in diverse environments. Experimental results on the StarCraft II and Multi-Agent Mujoco benchmarks demonstrate the superiority of HGAT-MARL over state-of-the-art MARL algorithms in terms of both performance and explainability.