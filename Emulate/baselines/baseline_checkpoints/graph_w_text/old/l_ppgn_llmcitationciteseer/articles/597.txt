Explainable recommendation systems (ERS) have gained significant attention in recent years. While graph neural networks (GNNs) have shown promising results in ERS, they often struggle to provide interpretable explanations for their recommendations. This paper proposes a novel hybrid attention-based GNN framework, 'HAGN', which leverages both graph structure and node features to generate personalized explanations for users. We introduce a hierarchical attention mechanism that adaptively weights node importance based on user preferences and item relationships. Experimental results on several benchmark datasets demonstrate that HAGN outperforms state-of-the-art ERS methods in terms of both recommendation accuracy and explanation quality.