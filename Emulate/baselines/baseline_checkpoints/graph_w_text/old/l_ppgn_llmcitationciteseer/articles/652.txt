Dense passage retrieval (DPR) has shown remarkable performance in open-domain question answering tasks. However, its efficiency is hindered by the need to compute dense representations for a large number of passages. This paper proposes a hierarchical query expansion approach, termed 'HQE-DPR', which reduces the number of passages required for retrieval by up to 70%. HQE-DPR leverages a shallow neural network to learn a hierarchical representation of the query, which is then used to selectively prune irrelevant passages. Our experiments on the Natural Questions dataset demonstrate that HQE-DPR achieves comparable retrieval performance to state-of-the-art DPR models while significantly reducing computational overhead.