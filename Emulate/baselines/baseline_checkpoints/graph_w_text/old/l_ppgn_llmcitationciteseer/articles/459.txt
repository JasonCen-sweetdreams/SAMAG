In multi-agent systems, efficient task allocation is crucial for accomplishing complex goals. This paper proposes a decentralized approach using deep reinforcement learning, where agents learn to allocate tasks based on their capabilities, availability, and environmental factors. Our framework, 'AgentTA', utilizes a graph neural network to represent agent interactions and a deep Q-network to select optimal task assignments. Experimental results on a simulated disaster response scenario demonstrate that AgentTA outperforms traditional centralized and decentralized methods in terms of task completion time and overall system efficiency.