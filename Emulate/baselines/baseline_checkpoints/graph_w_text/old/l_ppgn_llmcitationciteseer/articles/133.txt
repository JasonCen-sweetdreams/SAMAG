Meta-learning has emerged as a powerful paradigm for few-shot adaptation in various machine learning tasks. However, existing online meta-learning methods often suffer from slow convergence and unstable updates. This paper proposes a novel meta-gradient descent algorithm, dubbed 'MGD+', which leverages a provably convergent online learning framework to adapt to changing task distributions. Our method incorporates a carefully designed meta-regularizer that encourages smooth updates and improves stability. We provide theoretical guarantees for MGD+'s convergence and demonstrate its effectiveness on several benchmark datasets, including Omniglot and Mini-ImageNet.