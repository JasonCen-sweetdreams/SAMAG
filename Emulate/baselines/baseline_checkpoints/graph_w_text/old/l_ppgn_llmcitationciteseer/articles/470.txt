The increasing adoption of autonomous vehicles (AVs) necessitates efficient coordination mechanisms to ensure safe and efficient traffic flow. This paper presents a decentralized multi-agent reinforcement learning (MARL) framework, 'AV-Coord', which enables AVs to learn cooperative behaviors in real-time. Our approach leverages graph neural networks to model complex traffic scenarios and incorporates a novel communication protocol to facilitate information exchange between AVs. Experimental results on a simulated urban traffic network demonstrate that AV-Coord achieves significant reductions in travel time and collision rates compared to traditional traffic signal control methods.