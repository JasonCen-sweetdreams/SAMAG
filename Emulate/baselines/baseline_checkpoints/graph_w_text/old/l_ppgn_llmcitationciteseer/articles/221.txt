Explainability is crucial in multi-agent systems where autonomous decision-making can have significant consequences. This paper presents a novel hierarchical attention network (HAN) framework for interpretable decision-making in multi-agent settings. Our approach leverages attention mechanisms to selectively focus on relevant agents, attributes, and contexts, generating transparent and informative explanations for agent decisions. We evaluate HAN on a real-world autonomous vehicle dataset, demonstrating improved explainability and decision accuracy compared to existing methods.