Explainable recommendation systems (ERS) aim to provide transparency into the decision-making process of AI-driven recommender models. We introduce Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages graph attention mechanisms to model complex user-item relationships. HGAT learns to identify influential nodes and edges in the graph, enabling the generation of interpretable explanations for recommended items. Our experiments on real-world datasets demonstrate improved recommendation accuracy and enhanced explainability compared to state-of-the-art ERS models.