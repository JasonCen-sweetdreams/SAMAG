This paper presents a novel approach to dynamic task allocation in multi-agent systems using reinforcement learning. We propose a decentralized framework, 'MAgentRL', that enables agents to learn to coordinate with each other and adapt to changing task requirements in real-time. Our approach combines deep Q-networks with a graph-based representation of the agent-task network, allowing agents to learn effective task allocation strategies that balance individual rewards with global system efficiency. Experimental results on a simulated disaster response scenario demonstrate the effectiveness of MAgentRL in improving response times and reducing task conflicts compared to traditional centralized allocation methods.