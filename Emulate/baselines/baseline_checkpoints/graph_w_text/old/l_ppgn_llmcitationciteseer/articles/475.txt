Time-series anomaly detection is a crucial task in various domains, including healthcare and finance. While deep learning models have shown promise, they often lack interpretability, making it challenging to identify the root cause of anomalies. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that leverages both local and global attention mechanisms to detect anomalies in time-series data. We introduce a novel explainability module that generates visualizations of the attention weights, enabling the identification of relevant features contributing to the anomaly. Experimental results on three real-world datasets demonstrate the effectiveness of HAN in detecting anomalies and providing insightful explanations.