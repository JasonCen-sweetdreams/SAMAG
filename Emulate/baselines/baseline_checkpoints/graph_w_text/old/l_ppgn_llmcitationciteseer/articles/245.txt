The cold start problem in search engines refers to the challenge of ranking documents for novel queries with limited relevant data. We propose a novel approach that leverages deep neural networks to learn a robust ranking model from a small set of labeled data. Our method, called NeuralCold, incorporates a transfer learning strategy to fine-tune a pre-trained language model on a small set of relevant documents. We evaluate NeuralCold on a large-scale dataset and demonstrate significant improvements in ranking accuracy and efficiency compared to traditional methods. Our approach has the potential to enhance the user experience in search engines, especially for long-tail queries.