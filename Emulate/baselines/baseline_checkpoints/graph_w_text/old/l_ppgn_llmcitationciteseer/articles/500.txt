In multi-agent systems, decision-making often relies on complex interactions between agents. This paper introduces a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in such systems. Our approach leverages attention mechanisms to model inter-agent relationships and reason about their decisions. We evaluate HAN on a real-world autonomous vehicle dataset and demonstrate improved performance and interpretability compared to state-of-the-art methods. The proposed framework has significant implications for the development of transparent and trustworthy AI systems in various domains.