Neural information retrieval (IR) models have shown promising results in various search tasks. However, existing document representation methods often rely on simple bag-of-words or term frequency-inverse document frequency (TF-IDF) features, which may not capture complex document structures. This paper proposes a novel document representation approach using graph convolutional networks (GCNs), which can effectively model document-level relationships and semantic dependencies. Our experiments on several benchmark datasets demonstrate that the proposed GCN-based document representation outperforms state-of-the-art neural IR models, achieving significant improvements in retrieval accuracy and efficiency.