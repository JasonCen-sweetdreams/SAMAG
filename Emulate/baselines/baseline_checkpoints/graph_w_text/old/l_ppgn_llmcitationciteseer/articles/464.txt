Explainability is crucial in multi-agent reinforcement learning (MARL) systems, where agents' decisions impact each other and the environment. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that learns to focus on relevant agents, states, and actions to improve explainability and performance in MARL. We introduce a hierarchical attention mechanism that captures complex dependencies between agents and a reward decomposition method to provide interpretable explanations for agent decisions. Experimental results on several MARL benchmarks demonstrate that HAN outperforms state-of-the-art methods in terms of both performance and explainability.