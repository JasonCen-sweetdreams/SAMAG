Explainability is a crucial aspect of multi-agent reinforcement learning (MARL) systems, as they are increasingly being deployed in real-world applications. This paper introduces Hierarchical Attention Networks (HANs), a novel architecture that enables agents to focus on relevant teammates and opponents during decision-making. We propose a hierarchical attention mechanism that learns to weight the importance of other agents' observations and actions at different levels of abstraction. Our approach improves upon state-of-the-art MARL methods in terms of both task performance and explainability, as demonstrated through extensive experiments in cooperative and competitive scenarios.