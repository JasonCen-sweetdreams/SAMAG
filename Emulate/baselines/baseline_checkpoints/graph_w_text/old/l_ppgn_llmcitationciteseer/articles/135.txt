Explainability is a crucial aspect of AI-driven recommendation systems, as it enables users to understand the reasoning behind suggested items. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that integrates graph attention mechanisms with hierarchical graph representations to provide transparent and interpretable recommendations. HGAT captures complex item relationships and user preferences by learning hierarchical graph structures, and then applies attention mechanisms to selectively focus on relevant item features. Our experiments on multiple benchmark datasets demonstrate that HGAT outperforms state-of-the-art recommendation models in terms of both accuracy and explainability.