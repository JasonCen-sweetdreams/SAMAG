As multi-agent systems become increasingly prevalent, there is a growing need to develop reinforcement learning methods that can effectively handle complex interactions between agents. We propose a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent reinforcement learning. Our approach leverages attention mechanisms to selectively focus on relevant agents and their interactions, yielding improved coordination and cooperation. We evaluate our method on a range of multi-agent environments, demonstrating significant improvements in performance and interpretability compared to existing methods.