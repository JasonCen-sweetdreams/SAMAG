Neural information retrieval (IR) models have become increasingly popular, but they often struggle with vocabulary mismatch and limited contextual understanding. This paper proposes a novel query expansion approach that leverages context-aware embeddings to improve the performance of neural IR models. Our method, called CAQE, generates expanded queries by incorporating contextualized semantic representations of query terms and their relationships. Experimental results on several benchmark datasets demonstrate that CAQE outperforms state-of-the-art query expansion techniques, achieving significant improvements in retrieval effectiveness and efficiency.