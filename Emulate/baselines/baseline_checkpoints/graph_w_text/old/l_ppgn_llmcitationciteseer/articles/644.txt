Multi-label node classification is a fundamental problem in graph-based learning, where each node can have multiple labels. Existing methods often suffer from label correlation neglect or scalability issues. We propose a novel Hierarchical Graph Attention Network (HGAT) that leverages a hierarchical representation of nodes, enabling attention-based label correlation modeling. HGAT consists of graph attention layers at multiple scales, capturing both local and global node dependencies. Experiments on several benchmark datasets demonstrate that HGAT outperforms state-of-the-art methods in terms of node classification accuracy and F1-score, especially on datasets with a large number of labels.