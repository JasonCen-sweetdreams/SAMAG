In multi-agent systems, decision-making often involves complex interactions between agents with diverse goals and preferences. Existing approaches to explaining agent decisions rely on simplistic models that fail to capture these interactions. We propose a novel hierarchical attention network (HAN) architecture that integrates agent-level and system-level attention mechanisms to provide transparent and interpretable decision-making explanations. Our approach outperforms state-of-the-art methods on a suite of benchmark domains, including autonomous vehicle navigation and resource allocation problems.