Multi-agent dialogue systems have become increasingly prevalent in various applications, but their opacity hinders trust and understanding. This paper presents a novel hierarchical attention network (HAN) architecture that enables explainable multi-agent dialogue systems. Our approach leverages agent-specific attention mechanisms to capture contextual dependencies and generate interpretable dialogue flows. Experimental results on a large-scale dialogue dataset demonstrate that HAN outperforms state-of-the-art models in terms of conversational coherence, fluency, and explainability. We also provide visualizations of attention weights to illustrate the decision-making process of each agent, facilitating transparency and accountability in human-agent interactions.