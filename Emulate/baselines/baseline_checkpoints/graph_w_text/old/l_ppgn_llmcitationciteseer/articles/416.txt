Explainability in multi-agent reinforcement learning (MARL) is crucial for real-world applications. This paper introduces Hierarchical Attention Networks (HANs), a novel architecture that integrates attention mechanisms at both the agent and system levels. HANs enable the identification of influential agents and their interactions, facilitating interpretability in complex MARL scenarios. Experimental results on a variety of multi-agent environments demonstrate that HANs outperform existing methods in terms of both performance and explainability, providing new insights into the decision-making process of autonomous agents.