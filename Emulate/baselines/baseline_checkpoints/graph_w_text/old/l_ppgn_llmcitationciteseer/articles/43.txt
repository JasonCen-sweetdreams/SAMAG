Distributed database systems are increasingly used to support large-scale applications, but optimizing query execution plans remains a challenging problem. This paper presents a novel approach to query optimization using reinforcement learning. Our framework, 'RL-Optimizer', learns to select efficient execution plans by interacting with the database system and receiving rewards based on query performance. We propose a hierarchical state representation and a customized reward function that incorporates both query latency and resource utilization. Experimental results on a real-world distributed database system demonstrate that RL-Optimizer outperforms traditional optimization techniques and adapts to changing workload characteristics.