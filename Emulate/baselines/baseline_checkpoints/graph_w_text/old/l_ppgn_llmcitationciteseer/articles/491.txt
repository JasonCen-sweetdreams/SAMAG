Explainability is crucial in multi-agent reinforcement learning (MARL) environments, where agents interact with each other and their environment. We propose a hierarchical attention network (HAN) architecture that provides insights into the decision-making process of agents. Our approach comprises two stages: (1) a local attention mechanism that highlights relevant features for each agent, and (2) a global attention mechanism that captures the interactions between agents. We evaluate HAN on a variety of MARL benchmarks and demonstrate improved explainability, interpretability, and performance compared to state-of-the-art methods.