Ad-hoc retrieval systems struggle to effectively filter irrelevant documents, leading to decreased retrieval performance. This paper proposes a novel neural query expansion approach, 'NeuQE', which leverages a transformer-based architecture to learn context-aware query representations. NeuQE incorporates a focused attention mechanism that adaptively weights query terms based on their relevance to the query context. Experimental results on the TREC-8 dataset demonstrate that NeuQE outperforms state-of-the-art query expansion techniques by 12.5% in terms of mean average precision, while reducing filtering time by 30%