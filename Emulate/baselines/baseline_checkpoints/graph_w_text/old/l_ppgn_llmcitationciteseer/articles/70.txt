Explainable AI (XAI) has become a crucial aspect of trustworthy AI decision making. This paper presents a novel hierarchical attention-based multi-task learning framework, 'HAT-MTL', which jointly learns to predict outcomes and generate explanations for AI-driven decisions. Our approach leverages task-specific attention mechanisms to selectively focus on relevant input features and identify salient patterns. We evaluate HAT-MTL on a diverse set of benchmark datasets, demonstrating improved predictive performance and enhanced explainability compared to state-of-the-art XAI methods. Furthermore, user studies reveal that our approach leads to increased trust and understanding in AI-driven decision-making systems.