Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its lack of interpretability hinders widespread adoption. This paper presents a novel approach, 'Hierarchical Explainable RL' (HERL), which leverages hierarchical attention mechanisms to provide insights into DRL decision-making processes. HERL generates contextual explanations by identifying key state and action features that influence policy decisions. We evaluate HERL on several Atari games and a real-world robotic grasping task, demonstrating improved explainability without compromising policy performance.