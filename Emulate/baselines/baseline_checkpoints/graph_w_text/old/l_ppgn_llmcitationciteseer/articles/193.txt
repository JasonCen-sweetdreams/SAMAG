Virtual reality (VR) interfaces often struggle to accurately track users' gaze, leading to frustrating interactions and decreased immersion. This paper presents 'GazeRefine', a novel eye-tracking system that adaptively corrects for gaze errors in real-time. Our approach leverages machine learning to identify and compensate for individual differences in eye movement patterns, resulting in a 35% reduction in gaze error compared to state-of-the-art solutions. We evaluate GazeRefine in a user study, demonstrating improved task performance and subjective user experience in VR applications.