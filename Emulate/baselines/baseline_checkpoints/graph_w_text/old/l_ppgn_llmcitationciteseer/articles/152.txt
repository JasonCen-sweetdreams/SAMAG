In multi-agent systems, coalition formation enables agents to achieve common goals through cooperation. However, incomplete information about other agents' capabilities and preferences hinders the formation of optimal coalitions. This paper proposes a decentralized coalition formation algorithm, 'CoopLearn', which leverages multi-agent reinforcement learning and probabilistic graphical models to reason about incomplete information. CoopLearn enables agents to learn and adapt to changing environments, improving coalition stability and overall system performance. Experimental results on a simulated disaster response scenario demonstrate the effectiveness of CoopLearn in forming robust coalitions despite incomplete information.