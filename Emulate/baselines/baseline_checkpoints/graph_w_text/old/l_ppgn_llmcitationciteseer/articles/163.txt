Visual question answering (VQA) models often rely on black-box attention mechanisms, making it challenging to understand their decision-making process. We propose a novel hierarchical attention network (HAN) that incorporates multi-level attention and interpretability techniques to generate explanations for VQA predictions. Our approach exploits both visual and semantic features to reason about the question and image, producing more accurate and interpretable answers. Experimental results on the VQA-CP v2 dataset demonstrate the effectiveness of HAN in achieving state-of-the-art performance while providing insightful explanations.