The proliferation of heterogeneous IoT devices has created a need for efficient resource allocation strategies. This paper proposes a novel multi-agent reinforcement learning framework, 'IoT-Adapt', which enables adaptive resource allocation in IoT networks. IoT-Adapt leverages a decentralized, partially observable Markov decision process to model the interactions between agents, each representing a device or gateway. Our approach learns to allocate resources dynamically, taking into account the varying demands and capabilities of devices, and adapts to changes in the network topology. Experimental results on a real-world IoT testbed demonstrate that IoT-Adapt outperforms traditional, centralized allocation methods in terms of network efficiency and device satisfaction.