In IoT networks, efficient task allocation is crucial for resource utilization and response time. This paper presents a novel distributed task allocation framework using multi-agent reinforcement learning (MARL). We model the IoT network as a decentralized partially observable Markov decision process (DEC-PODMDP) and propose a MARL algorithm that learns to allocate tasks based on device capabilities, network topology, and real-time sensor data. Our approach outperforms traditional centralized and distributed allocation methods in simulated IoT environments, achieving a 25% reduction in task completion time and 30% improvement in resource utilization.