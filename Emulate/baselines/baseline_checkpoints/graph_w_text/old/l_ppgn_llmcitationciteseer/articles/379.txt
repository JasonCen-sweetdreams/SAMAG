Neural retrieval models have achieved state-of-the-art performance in various information retrieval tasks. However, they often suffer from the vocabulary mismatch problem, where the query and document representations fail to capture the underlying semantic relationship. This paper proposes a novel query expansion approach, 'NeuroXPand', which leverages pseudo-relevance feedback to generate high-quality expansion terms. Our method uses a neural encoder to model the query and document interactions, and then selects the most informative expansion terms based on a novel relevance scoring function. Experimental results on several benchmark datasets demonstrate that NeuroXPand significantly improves the retrieval performance of neural models, outperforming existing query expansion methods.