Query expansion is a crucial component in ad-hoc retrieval systems, aiming to bridge the vocabulary gap between users' queries and relevant documents. In this paper, we propose a novel reinforcement learning framework, 'RL-QE', which learns to select optimal expansion terms by maximizing a reward function that balances relevance and diversity. Our approach leverages a deep Q-network to estimate the expected utility of each expansion term and adaptively adjusts the exploration-exploitation trade-off. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art query expansion methods in terms of retrieval effectiveness and efficiency.