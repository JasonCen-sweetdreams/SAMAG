Explainability is a crucial aspect of time series forecasting, as it enables model interpretability and trustworthiness. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that integrates both local and global attention mechanisms to selectively focus on relevant temporal and spatial patterns in time series data. We evaluate our approach on several real-world datasets, demonstrating improved forecasting performance and insightful feature attributions. Additionally, we provide a theoretical analysis of the proposed attention mechanisms, highlighting their role in enhancing model explainability.