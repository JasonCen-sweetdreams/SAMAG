Distributed database systems (DDS) have become increasingly popular in modern data storage and processing. However, query optimization in DDS remains a challenging problem due to the complexity of data distribution and communication overhead. This paper proposes a novel approach to query optimization using machine learning techniques. We develop a predictive model that learns from historical query patterns and system performance metrics to optimize query execution plans. Our experiments on a real-world DDS setup demonstrate significant improvements in query response time and system throughput compared to traditional optimization methods.