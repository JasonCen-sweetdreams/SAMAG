In this paper, we present a novel approach to distributed task allocation for multi-agent systems using deep reinforcement learning. Our method, dubbed 'MATRL', leverages a decentralized actor-critic framework to learn efficient task assignment policies in complex, dynamic environments. We evaluate MATRL on a variety of benchmark scenarios, including robotic search and rescue, and demonstrate significant improvements in task completion rates and resource utilization compared to traditional optimization-based methods. Furthermore, we provide theoretical guarantees on the convergence and stability of our algorithm.