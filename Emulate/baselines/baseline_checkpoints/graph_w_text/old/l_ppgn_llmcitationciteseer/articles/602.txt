Ad-hoc retrieval systems rely on query expansion to improve retrieval effectiveness. However, existing methods often suffer from noise and irrelevant terms. This paper proposes a neural re-ranking approach, 'NeuQE', which leverages BERT-based language models to re-rank query expansion terms. We introduce a novel scoring function that combines semantic similarity and term importance, allowing NeuQE to effectively filter out noisy terms. Experiments on the TREC benchmark show that NeuQE outperforms state-of-the-art query expansion methods, achieving significant improvements in mean average precision and normalized discounted cumulative gain.