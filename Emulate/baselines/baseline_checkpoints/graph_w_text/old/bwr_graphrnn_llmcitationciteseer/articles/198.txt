exasperated the need for explainability in multi-agent reinforcement learning (MARL) systems. This paper introduces Hierarchical Attention Networks (HANs) to provide interpretable policy decisions in MARL. HANs incorporate hierarchical attention mechanisms to selectively focus on relevant agents, actions, and states, enabling the identification of key factors influencing policy decisions. We evaluate our approach on a range of MARL benchmarks, demonstrating improved explainability and comparable performance to state-of-the-art methods.