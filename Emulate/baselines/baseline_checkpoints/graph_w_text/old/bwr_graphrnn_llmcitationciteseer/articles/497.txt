In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a decentralized task allocation framework that leverages reinforcement learning to enable autonomous agents to adapt to changing environmental conditions. Our approach, dubbed 'RL-ATA', uses a hierarchical structure to balance local exploration and global coordination. We demonstrate the effectiveness of RL-ATA in a simulated search-and-rescue scenario, showcasing improved task completion rates and reduced communication overhead compared to traditional planning-based approaches.