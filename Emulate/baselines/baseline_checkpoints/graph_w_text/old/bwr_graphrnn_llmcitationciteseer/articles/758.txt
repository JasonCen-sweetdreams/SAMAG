Explainable recommendation systems (ERS) have gained significant attention in recent years due to the need for transparency and accountability in AI-driven decision-making. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) model that integrates graph neural networks and attention mechanisms to provide personalized recommendations with explicit explanations. We demonstrate the effectiveness of HGAT on several benchmark datasets, achieving state-of-the-art performance while providing insightful explanations for recommended items. Our approach has significant implications for developing trustworthy and interpretable ERS in various applications.