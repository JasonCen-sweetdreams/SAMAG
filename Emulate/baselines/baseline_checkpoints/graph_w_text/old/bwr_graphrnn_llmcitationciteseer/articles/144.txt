The increasing scale and complexity of big data analytics pose significant challenges to query optimization. This paper proposes a novel machine learning-based approach, 'QOPT-ML', that leverages learned patterns in query execution to optimize query plans. We develop a graph neural network model that learns to represent queries as graphs and predicts optimal join orders based on historical execution statistics. Experimental results on a real-world big data analytics workload demonstrate that QOPT-ML outperforms traditional cost-based optimization techniques by up to 30% in terms of query execution time.