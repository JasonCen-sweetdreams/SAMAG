This paper presents a novel multi-agent reinforcement learning framework, 'TrafficMaster', designed for real-time traffic control in large-scale transportation networks. TrafficMaster leverages a hierarchical architecture, where each agent learns to optimize traffic signal control at individual intersections, while a central controller coordinates agents to optimize network-wide traffic flow. We propose a decentralized exploration strategy, which enables agents to adapt to changing traffic patterns while minimizing communication overhead. Experimental results on a simulated traffic network demonstrate that TrafficMaster outperforms traditional traffic control methods, reducing travel time by up to 25% and decreasing congestion by 30%.