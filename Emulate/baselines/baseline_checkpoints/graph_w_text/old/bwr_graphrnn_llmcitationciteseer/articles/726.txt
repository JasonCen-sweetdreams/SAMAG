Reinforcement learning has achieved remarkable successes in multi-agent systems, but the lack of transparency in decision-making processes hinders trust and adoption. This paper introduces HAN-MARL, a novel hierarchical attention network that enables explainable multi-agent reinforcement learning. By incorporating attention mechanisms at both intra-agent and inter-agent levels, HAN-MARL improves cooperation and communication among agents while providing interpretable insights into their decision-making processes. Experimental results on a simulated traffic management scenario demonstrate the effectiveness of HAN-MARL in improving system performance and facilitating human understanding of agent behaviors.