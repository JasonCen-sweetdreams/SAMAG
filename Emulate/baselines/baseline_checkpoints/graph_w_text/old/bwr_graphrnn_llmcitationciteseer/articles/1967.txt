Multi-agent reinforcement learning (MARL) has made significant progress in recent years, but the lack of interpretability hinders its adoption in high-stakes applications. This paper proposes a novel hierarchical attention network (HAN) that enables explainable MARL by identifying influential agents and their interactions. Our HAN model consists of two stages: an attention-based graph neural network that models agent relationships and a hierarchical reinforcement learning framework that integrates attention weights into policy updates. Experimental results on a real-world traffic management scenario demonstrate that our approach improves both overall performance and explainability compared to state-of-the-art MARL methods.