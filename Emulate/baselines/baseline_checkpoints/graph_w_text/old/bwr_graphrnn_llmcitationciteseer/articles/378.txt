This paper proposes a decentralized multi-agent reinforcement learning framework for autonomous traffic signal control. We model the problem as a Markov game, where each agent represents a traffic signal and makes decisions based on local observations. We introduce a novel communication protocol that enables agents to share information and coordinate their actions, while maintaining scalability and robustness to partial observability. Experimental results on a realistic traffic simulator demonstrate that our approach outperforms traditional timing plans and centralized optimization methods, reducing congestion and travel times by up to 25%.