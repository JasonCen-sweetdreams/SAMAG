Knowledge graph embedding (KGE) is a crucial task in artificial intelligence, but existing methods struggle to capture complex relationships between entities. We propose a novel KGE approach, Hierarchical Graph Attention (HGA), which leverages a hierarchical graph neural network to model entity relationships at different granularity levels. HGA incorporates attention mechanisms to focus on relevant neighbors and reduces over-smoothing issues. Our experiments on benchmark datasets demonstrate that HGA outperforms state-of-the-art methods in link prediction and triple classification tasks, while exhibiting improved interpretability and computational efficiency.