Traditional human-computer interfaces often fail to capture the emotional nuances of users, leading to incomplete understanding of their needs and preferences. This paper presents an innovative approach to eliciting emotional feedback through adaptive gestural interfaces. Our system, EmoGest, employs machine learning-driven gesture recognition and emotional state inference to tailor the interaction to the user's affective state. We conducted a user study with 30 participants, demonstrating that EmoGest significantly improves the accuracy of emotional feedback collection and enhances overall user experience. The findings have implications for designing more empathetic and effective human-computer interfaces in various domains.