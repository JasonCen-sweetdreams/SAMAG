Traditional bag-of-words representations in ad-hoc retrieval suffer from ignoring document structure and semantic relationships between terms. This paper proposes a novel hierarchical attention network (HAN) for learning efficient document representations. Our approach captures global and local contextual information through multi-level attention mechanisms, enabling the model to focus on salient phrases and sentences. Experimental results on several benchmark datasets demonstrate significant improvements in retrieval effectiveness, with our HAN-based method outperforming state-of-the-art neural ranking models.