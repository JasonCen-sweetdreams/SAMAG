Entity disambiguation is a crucial step in knowledge graph construction, but existing approaches struggle with scalability and accuracy on large-scale graphs. We propose a novel graph-based neural embedding method, 'EmbedDisambig', which leverages both local and global graph structures to learn entity representations. Our approach utilizes a graph attention mechanism to selectively incorporate relevant context information, enabling efficient disambiguation of entities with high accuracy. Experimental results on several benchmark datasets demonstrate that EmbedDisambig outperforms state-of-the-art methods in terms of both speed and accuracy, making it a promising solution for large-scale knowledge graph construction.