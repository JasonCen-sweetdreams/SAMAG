Multi-agent reinforcement learning (MARL) has shown promise in various applications, but the lack of interpretability hinders its adoption in real-world scenarios. We propose a novel hierarchical attention network (HAT) architecture that enables explainable MARL. HAT integrates attention mechanisms at both the agent and system levels, allowing it to identify critical agents, actions, and interactions that contribute to the overall system performance. We evaluate HAT on a set of cooperative and competitive MARL benchmarks, demonstrating improved performance and interpretability compared to state-of-the-art methods.