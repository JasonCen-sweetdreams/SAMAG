Explainability is crucial in multi-agent reinforcement learning (MARL) to understand agent behavior and improve cooperation. We propose Hierarchical Attention Networks (HANs) to learn explicit communication protocols and attention mechanisms that facilitate interpretable decision-making. HANs consist of two levels of attention: intra-agent attention for encoding local observations and inter-agent attention for aggregating information across agents. Our experiments on a variety of MARL benchmarks demonstrate that HANs outperform state-of-the-art methods in terms of both task performance and explainability, as measured by attribution methods and human evaluations.