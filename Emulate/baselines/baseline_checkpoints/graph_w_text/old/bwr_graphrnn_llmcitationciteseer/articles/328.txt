Distributed databases often employ multi-version concurrency control (MVCC) to ensure transactional consistency and isolation. However, query optimization in MVCC systems remains a challenging problem, particularly in the presence of concurrent updates. This paper presents a novel query optimization framework, 'MVCOpt', which leverages a combination of static analysis, dynamic profiling, and machine learning-based cost estimation to minimize query latency and improve system throughput. Our experimental evaluation on a distributed PostgreSQL cluster demonstrates that MVCOpt outperforms state-of-the-art query optimizers by up to 30% in terms of query response time.