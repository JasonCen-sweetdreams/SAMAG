Virtual reality (VR) systems often rely on manual controllers for navigation, which can be cumbersome and detract from the immersive experience. This paper presents a novel gaze-based navigation system using deep reinforcement learning. Our approach, 'GazeNav', uses a convolutional neural network to analyze the user's gaze patterns and predict their intended navigation direction. We introduce a reward function that encourages the model to prioritize smooth, efficient movements while minimizing collisions and oscillations. Experimental results show that GazeNav outperforms traditional manual navigation in terms of task completion time and user satisfaction.