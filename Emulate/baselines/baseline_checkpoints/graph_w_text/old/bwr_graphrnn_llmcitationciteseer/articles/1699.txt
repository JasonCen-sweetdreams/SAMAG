Explainability is a crucial aspect of multi-agent reinforcement learning (MARL) systems, where agents' decision-making processes need to be transparent and interpretable. We propose a novel hierarchical attention network (HAN) architecture that incorporates attention mechanisms at both the agent and joint action levels. Our approach enables the identification of influential agents and actions in the decision-making process, thereby providing explainability in MARL systems. Experimental results on a range of benchmark environments demonstrate the effectiveness of HAN in improving the explainability of MARL systems while maintaining competitive performance.