In multi-agent systems, decision making often involves complex interactions and trade-offs between agents. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision making in such systems. Our HAN model learns to selectively focus on relevant agents and their interactions, generating interpretable attention weights that provide insights into the decision-making process. We evaluate our approach on a real-world multi-agent traffic simulation dataset and demonstrate improved performance and interpretability compared to state-of-the-art models.