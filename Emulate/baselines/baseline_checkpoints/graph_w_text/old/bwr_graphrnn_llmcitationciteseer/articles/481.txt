In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel framework, 'CATALYST', which leverages deep reinforcement learning to coordinate task assignments among agents. Our approach employs a decentralized actor-critic architecture, where each agent learns to adapt its task selection based on local observations and communication with neighboring agents. We demonstrate the effectiveness of CATALYST in simulations of a multi-robot warehouse management scenario, showcasing improved task completion rates and reduced communication overhead compared to traditional heuristic-based methods.