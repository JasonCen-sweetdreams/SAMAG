Multi-label classification is a fundamental problem in machine learning, where each instance can be associated with multiple labels. Existing approaches often suffer from high computational complexity and ignore label correlations. We propose a novel hierarchical attention network (HAN) that leverages label hierarchies to efficiently capture label dependencies. Our HAN model comprises a label-aware attention mechanism and a hierarchical label encoder, which jointly learn to predict labels and their relationships. Experimental results on several benchmark datasets demonstrate that our approach achieves state-of-the-art performance while reducing computational costs by up to 40% compared to existing methods.