In multi-robot systems, task allocation is a critical problem that requires efficient and adaptive decision-making. This paper presents a decentralized task allocation framework that leverages multi-agent reinforcement learning to optimize task assignments in dynamic environments. Our approach, called 'MARL-TA', uses a distributed deep Q-network to learn cooperative policies that maximize system-wide rewards. We evaluate MARL-TA on a simulated warehouse scenario and demonstrate improved task completion rates and reduced communication overhead compared to traditional centralized allocation methods.