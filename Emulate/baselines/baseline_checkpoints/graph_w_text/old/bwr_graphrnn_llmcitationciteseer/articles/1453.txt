In multi-agent systems, decision-making processes often involve complex interactions and negotiations among agents. This paper introduces a novel hierarchical attention network (HAN) architecture to enhance explainability in multi-agent decision making. Our approach leverages attention mechanisms to selectively focus on relevant agent interactions and internal state representations, generating interpretable explanations for agent decisions. Experimental results on a real-world autonomous vehicle dataset demonstrate improved decision-making performance and enhanced transparency, providing insights into the decision-making process of individual agents.