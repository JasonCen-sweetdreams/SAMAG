Open-domain question answering (ODQA) models rely on efficient passage retrieval to answer questions from a massive corpus. Existing methods use sparse representations or dense retrieval models that are computationally expensive. We propose a novel hierarchical dense representation approach, HDR-QA, which learns to represent passages at multiple granularities. Our method leverages a hierarchical attention mechanism to capture context-aware passage embeddings, enabling faster and more accurate passage retrieval. Experimental results on the Natural Questions dataset demonstrate significant improvements in retrieval efficiency and downstream QA performance.