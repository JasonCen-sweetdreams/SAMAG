This paper proposes a novel hierarchical multi-agent reinforcement learning framework for autonomous urban traffic control. We model the traffic network as a hierarchical graph, where each intersection is a node and agents learn to cooperatively optimize traffic flow. Our approach, 'HERMES', leverages a two-level hierarchy: local agents learn to control traffic signals at individual intersections, while a global agent coordinates their actions to optimize network-wide traffic flow. We evaluate HERMES on a realistic simulation of the San Francisco traffic network, demonstrating improved traffic throughput and reduced congestion compared to state-of-the-art decentralized approaches.