The growing complexity of multi-agent systems necessitates the development of explainable decision-making models. This paper proposes a novel hierarchical attention network (HAN) architecture that integrates reinforcement learning with attention mechanisms to facilitate interpretable decision-making in cooperative and competitive multi-agent scenarios. Our approach enables the identification of key agent interactions and environment features that influence the decision-making process. Experimental results on a series of multi-agent benchmark tasks demonstrate the effectiveness of HAN in improving both task performance and explainability.