As multi-agent reinforcement learning (MARL) systems are increasingly deployed in real-world applications, there is a growing need to provide explanations for their decision-making processes. This paper presents a novel hierarchical graph attention network (HGAT) framework that enables explainable MARL. By incorporating graph attention mechanisms at multiple scales, HGAT selectively focuses on relevant interactions between agents and their environment, leading to improved cooperation and interpretability. We evaluate HGAT on a suite of MARL benchmarks, demonstrating significant improvements in both performance and explainability over existing state-of-the-art methods.