Multi-agent reinforcement learning has made significant progress in recent years, but the lack of interpretability hinders its adoption in real-world applications. This paper introduces HAN-MARL, a hierarchical attention network that enables explainable decision-making in cooperative multi-agent environments. Our approach leverages attention mechanisms to identify influential agents and actions, providing insights into the decision-making process. We demonstrate the effectiveness of HAN-MARL in several benchmark environments, showcasing improved explainability and robustness compared to state-of-the-art methods.