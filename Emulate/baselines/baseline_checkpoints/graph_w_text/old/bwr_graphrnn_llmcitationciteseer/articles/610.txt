Query expansion is a crucial step in document retrieval, but existing techniques often struggle with large-scale collections. This paper presents a novel neural query expansion approach, 'NQE', which leverages a transformer-based architecture to learn semantic relationships between query terms and documents. NQE incorporates a hierarchical attention mechanism to capture both local and global context, enabling the model to selectively expand queries and retrieve relevant documents more efficiently. Experiments on the TREC-8 dataset demonstrate that NQE outperforms traditional query expansion methods, achieving a 25% increase in mean average precision while reducing computational overhead by 30%.