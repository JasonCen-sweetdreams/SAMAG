Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its lack of interpretability hinders its adoption in high-stakes applications. This paper proposes a novel hierarchical attention network (HAN) architecture that provides explainable DRL by selectively focusing on relevant state and action features. We introduce a hierarchical attention mechanism that recursively attends to lower-level features, enabling the model to capture complex, multi-scale relationships. Experimental results on several Atari games demonstrate that HAN-DRL achieves comparable performance to state-of-the-art methods while providing transparent, feature-based explanations for its decision-making.