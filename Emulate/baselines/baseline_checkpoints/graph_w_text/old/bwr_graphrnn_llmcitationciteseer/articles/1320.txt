Distributed column-stores have become increasingly popular for analytical workloads, but query optimization remains a significant challenge. This paper proposes a novel approach to query optimization using reinforcement learning. We design a scalable framework, 'RL-QOpt', that learns to optimize query plans by interacting with the database and receiving feedback in the form of execution times. RL-QOpt leverages a combination of exploration-exploitation strategies and reward shaping to efficiently search the vast space of possible query plans. Experimental results on a real-world dataset demonstrate that RL-QOpt achieves significant performance improvements over state-of-the-art query optimizers, particularly for complex queries and large datasets.