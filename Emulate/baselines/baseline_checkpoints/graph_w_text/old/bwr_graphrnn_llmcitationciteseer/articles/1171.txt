As Virtual Reality (VR) technology advances, there is a growing need for intuitive and natural interaction methods. This paper presents a novel gaze-based interaction system that leverages deep learning to accurately predict user intentions in VR environments. Our approach employs a convolutional neural network (CNN) to analyze eye movement patterns and classify user actions, such as selection, navigation, and manipulation. We evaluate our system on a dataset of 30 participants and demonstrate significant improvements in interaction accuracy and user experience compared to traditional controller-based methods. The proposed system has implications for various VR applications, including gaming, education, and healthcare.