Virtual reality (VR) systems often rely on cumbersome controller-based interfaces, hindering user immersion. This paper proposes a novel gaze-based interaction framework, 'GazeVR', which leverages deep learning to accurately predict user intentions from eye movements. We develop a convolutional neural network (CNN) that processes eye-tracking data and learns to recognize gaze patterns associated with specific actions, such as selecting objects or navigating through virtual environments. Our evaluation shows that GazeVR achieves high accuracy and low latency, enabling seamless and intuitive interaction in VR applications.