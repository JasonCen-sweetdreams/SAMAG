Multi-agent systems have gained increasing attention in various applications, such as robotics, traffic management, and smart grids. However, task allocation remains a significant challenge, especially in dynamic environments. This paper proposes a novel framework that leverages reinforcement learning to coordinate agents and allocate tasks efficiently. We introduce a decentralized actor-critic algorithm that enables agents to learn from each other and adapt to changing task requirements. Experimental results on a simulated factory scenario show that our approach outperforms traditional methods in terms of task completion rate, agent utilization, and overall system efficiency.