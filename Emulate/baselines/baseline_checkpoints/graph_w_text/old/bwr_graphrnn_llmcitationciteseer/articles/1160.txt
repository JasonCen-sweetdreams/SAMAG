Virtual reality (VR) systems often neglect the emotional and social aspects of human interaction, leading to a sense of disconnection and isolation. This paper presents EmoReact, a machine learning-based framework that recognizes and interprets affective gestures in VR environments. By detecting subtle changes in hand and finger movements, EmoReact enables more empathetic and inclusive virtual interactions. Our user study demonstrates that EmoReact significantly improves user engagement and social presence in VR-based collaborative tasks, particularly for individuals with autism spectrum disorder.