Time series forecasting models often lack transparency, making it challenging to understand their decision-making processes. This paper proposes a novel Hierarchical Attention Network (HAN) architecture for explainable time series forecasting. Our approach leverages self-attention mechanisms to capture complex temporal dependencies and hierarchical representations to identify influential features. We evaluate HAN on multiple real-world datasets, demonstrating improved forecasting accuracy and interpretability compared to state-of-the-art methods. Visualizations of attention weights provide insights into the model's decision-making process, enabling users to identify key contributing factors to forecasted values.