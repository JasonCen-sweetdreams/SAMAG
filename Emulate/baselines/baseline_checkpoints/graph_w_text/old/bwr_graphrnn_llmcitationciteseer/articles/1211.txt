Coordinating multi-agent systems is a challenging task, particularly in dynamic and uncertain environments. This paper presents a novel approach to adaptive communication protocols for coordinating multi-agent systems. Our protocol, called 'AdaComm', uses reinforcement learning to adapt the communication strategy based on the current system state and the agents' objectives. We evaluate AdaComm in a simulated search-and-rescue scenario and show that it outperforms existing communication protocols in terms of task completion time and communication efficiency. Furthermore, we demonstrate the scalability of AdaComm by applying it to a large-scale agent-based simulation.