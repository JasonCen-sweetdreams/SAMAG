Human-robot interaction (HRI) has become increasingly prevalent, but robots struggle to recognize human emotions accurately. This paper presents a deep transfer learning approach, 'EmoTrans', that leverages pre-trained convolutional neural networks (CNNs) on image datasets to improve emotion recognition in multimodal HRI. We propose a novel attention mechanism that fuses features from facial expressions, speech, and body language, achieving state-of-the-art performance on the EMOTIC dataset. Our approach outperforms traditional machine learning methods and enables robots to respond empathetically to human emotions in real-time.