This paper explores the impact of query expansion techniques on the performance of deep neural ranking models for ad-hoc retrieval tasks. We propose a novel approach to query expansion using a combination of word embeddings and pseudo-relevance feedback. Our experiments on the TREC Robust04 dataset demonstrate that our approach leads to significant improvements in retrieval effectiveness, outperforming state-of-the-art neural ranking models. We also provide an in-depth analysis of the effects of query expansion on the learned representations of the ranking model, shedding light on the underlying mechanisms that drive its performance.