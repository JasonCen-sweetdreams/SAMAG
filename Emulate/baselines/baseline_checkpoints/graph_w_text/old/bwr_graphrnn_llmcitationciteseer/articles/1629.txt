With the increasing scale and complexity of modern database systems, query optimization has become a critical challenge. This paper proposes a novel approach to query optimization using machine learning. We introduce a framework that leverages historical query data and workload patterns to train a predictive model, which is then used to optimize query execution plans. Our experiments on real-world datasets demonstrate significant improvements in query performance and resource utilization compared to traditional rule-based optimization techniques. We also discuss the applicability of our approach to distributed database systems, where query optimization is even more critical due to network latency and data fragmentation.