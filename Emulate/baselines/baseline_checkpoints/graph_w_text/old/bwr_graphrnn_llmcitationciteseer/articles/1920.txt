Immersive virtual reality (VR) systems rely heavily on intuitive and natural interaction modalities. This paper presents a novel gaze-based interaction framework for VR, leveraging deep learning techniques to predict user intent from eye movement patterns. Our approach combines convolutional neural networks (CNNs) with recurrent neural networks (RNNs) to model the complex relationships between gaze behavior, user context, and interaction goals. Experimental results demonstrate significant improvements in interaction accuracy and user experience compared to traditional gaze-based methods, paving the way for more immersive and engaging VR experiences.