Multi-agent systems (MAS) face the challenge of making collective decisions while ensuring explainability and accountability. This paper proposes a novel hierarchical attention network (HAN) architecture that enables agents to selectively focus on relevant information from other agents and the environment. Our approach, called 'ExplainMAS', incorporates attention mechanisms at both the intra-agent and inter-agent levels, allowing for transparent and interpretable decision-making. We evaluate ExplainMAS on a range of MAS benchmarks and demonstrate its effectiveness in improving decision quality and reducing conflicts compared to existing methods.