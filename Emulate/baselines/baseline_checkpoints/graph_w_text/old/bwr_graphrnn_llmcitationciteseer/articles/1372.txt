Explainable recommendation systems are crucial for building trust and transparency in AI-driven decision-making. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that learns to generate personalized explanations for recommendations. HGAT leverages graph attention mechanisms to capture complex item relationships and hierarchically aggregates user preferences. We demonstrate the effectiveness of HGAT on two real-world datasets, achieving state-of-the-art performance in terms of recommendation accuracy and explanation quality.