Recent advances in deep reinforcement learning (DRL) have led to the development of policies that achieve state-of-the-art performance in complex environments. However, these policies are often vulnerable to adversarial attacks, which can be catastrophic in real-world applications. This paper proposes a novel method to improve the adversarial robustness of DRL policies by training them in a multi-agent setting. We introduce a framework, 'AdverPlay', which pits multiple agents against each other, encouraging them to develop robust strategies that generalize across diverse scenarios. Our experiments demonstrate that AdverPlay significantly enhances the robustness of DRL policies against a range of attacks, including those leveraging advanced techniques such as model inversion and gradient masking.