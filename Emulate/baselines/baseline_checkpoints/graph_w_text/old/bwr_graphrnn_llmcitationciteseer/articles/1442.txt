Autonomous vehicles (AVs) require advanced control systems to navigate dynamic environments. This paper presents a hierarchical reinforcement learning (HRL) framework for AV control, comprising a high-level decision-maker and low-level controllers. The decision-maker leverages a graph neural network to model the environment and predict future states, while the controllers employ deep deterministic policy gradients to execute actions. We demonstrate the effectiveness of our approach in various scenarios, including highway merging and pedestrian-rich urban environments. Experimental results show improved safety, efficiency, and adaptability compared to traditional model-based control methods.