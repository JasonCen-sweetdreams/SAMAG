Virtual reality (VR) technology has the potential to enhance user experiences, but existing gesture recognition systems often fail to accommodate users with disabilities. This paper presents a novel adaptive gesture recognition framework, 'IncluVR', which leverages machine learning and computer vision techniques to recognize and adapt to diverse user gestures. We design a gesture lexicon that incorporates variations in hand shape, size, and movement, and evaluate IncluVR using a dataset of users with and without disabilities. Results show that IncluVR achieves higher recognition accuracy and user satisfaction compared to state-of-the-art gesture recognition systems.