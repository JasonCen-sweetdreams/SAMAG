Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables humans to understand agent decision-making. This paper presents a novel hierarchical attention network (HAN) architecture, which integrates attention mechanisms at both the agent and team levels. Our approach enables the identification of key factors influencing agent policies and facilitates the explanation of emergent team behaviors. We evaluate HAN on a range of MARL benchmarks, demonstrating improved explainability and competitiveness with state-of-the-art methods. We also provide insights into the learned attention patterns, offering a new perspective on MARL.