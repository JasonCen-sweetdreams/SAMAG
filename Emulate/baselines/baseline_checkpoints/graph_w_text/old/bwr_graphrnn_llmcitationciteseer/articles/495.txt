Explainability is crucial in multi-agent systems, particularly in high-stakes applications like autonomous vehicles or smart grids. This paper introduces Hierarchical Attention Networks (HANs), a novel architecture that integrates attention mechanisms with hierarchical Bayesian networks to model complex agent interactions. HANs enable the identification of influential agents and the visualization of decision-making processes, thereby enhancing transparency and trustworthiness in multi-agent systems. We evaluate HANs on a variety of benchmarks, demonstrating improved interpretability and decision quality compared to existing methods.