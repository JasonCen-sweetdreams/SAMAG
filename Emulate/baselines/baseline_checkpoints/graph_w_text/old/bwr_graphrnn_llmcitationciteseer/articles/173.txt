As multi-agent reinforcement learning (MARL) systems become increasingly complex, explainability is crucial for trust and safety. This paper introduces Hierarchical Attention Networks (HANs) to MARL, enabling agents to selectively focus on relevant neighbors and communicate their intentions. HANs consist of two stacked attention layers: an intra-agent layer for feature extraction and an inter-agent layer for social influence modeling. We evaluate HANs on a suite of cooperative and competitive MARL benchmarks, demonstrating improved interpretability, scalability, and performance compared to existing methods.