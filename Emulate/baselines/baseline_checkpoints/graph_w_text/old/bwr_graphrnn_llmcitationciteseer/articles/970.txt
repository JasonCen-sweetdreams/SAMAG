As autonomous vehicles (AVs) become increasingly prevalent, ensuring their decision-making processes are transparent and accountable is crucial. This paper presents an explainable reinforcement learning framework, 'ExplainAV', which integrates attention mechanisms and model-based reasoning to provide insights into AV decision-making. We demonstrate the efficacy of ExplainAV on a real-world autonomous driving dataset, showcasing improved interpretability without compromising driving performance. Our approach paves the way for developing trustworthiness and accountability in AI-driven AV systems.