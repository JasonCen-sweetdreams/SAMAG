Real-time object detection is a critical component of autonomous vehicle systems. This paper proposes a novel multi-task learning framework, 'MTL-OD', which jointly optimizes object detection, tracking, and attribute prediction tasks. By sharing feature representations across tasks, MTL-OD improves detection accuracy and reduces computational overhead. We introduce a modified YOLOv5 architecture with task-specific heads and demonstrate its effectiveness on the KITTI and Cityscapes datasets. Experimental results show that MTL-OD outperforms state-of-the-art single-task object detectors in various scenarios, including night-time and adverse weather conditions.