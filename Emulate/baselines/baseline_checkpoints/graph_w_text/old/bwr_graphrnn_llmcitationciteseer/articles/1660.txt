As distributed relational databases become increasingly prevalent, optimizing query performance remains a significant challenge. This paper presents a novel parallel query optimization framework, 'Parquet', which leverages data partitioning and pipelined execution to minimize overhead and maximize throughput. We propose a cost-based optimization algorithm that dynamically adjusts query plans based on real-time system monitoring and workload analysis. Experimental evaluation on a 16-node cluster shows that Parquet outperforms existing state-of-the-art optimizers by up to 3.5x for complex queries, making it a promising solution for large-scale data analytics.