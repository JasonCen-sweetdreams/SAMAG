This paper presents a novel hierarchical reinforcement learning (HRL) framework for autonomous drone navigation in uncertain environments. Our approach, called 'HierNav', incorporates a high-level planning module that adapts to changing environmental conditions, such as wind patterns or obstacles, and a low-level control module that executes precise navigation actions. We demonstrate the effectiveness of HierNav in a series of simulated and real-world experiments, showcasing improved navigation efficiency and robustness compared to traditional reinforcement learning methods.