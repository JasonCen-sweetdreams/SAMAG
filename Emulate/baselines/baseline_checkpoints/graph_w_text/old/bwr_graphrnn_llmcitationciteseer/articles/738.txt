Multi-hop question answering (QA) tasks require models to reason over multiple sentences to answer a question. While recent models have achieved impressive results, they often lack transparency and interpretability. We propose a novel hierarchical attention-based model, 'HARE', which incorporates explicit reasoning modules to identify relevant sentences and entities. Our model uses a hybrid attention mechanism that combines sentence-level and entity-level attention to identify relevant information. We evaluate HARE on multiple multi-hop QA benchmarks, achieving state-of-the-art results while providing interpretable explanations for its predictions.