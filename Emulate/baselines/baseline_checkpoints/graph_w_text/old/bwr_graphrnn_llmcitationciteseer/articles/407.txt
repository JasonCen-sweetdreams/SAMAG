Decentralized task allocation in multi-agent systems is a challenging problem, particularly in dynamic environments. This paper presents a novel approach that leverages deep reinforcement learning to learn decentralized policies for task allocation. We propose a multi-agent deep Q-network (MADQN) architecture that enables agents to learn from their local observations and make decisions without relying on a centralized controller. We evaluate our approach in a simulated disaster response scenario and demonstrate improved task allocation efficiency and adaptability compared to traditional methods. Our results show that MADQN can effectively handle changes in the environment and agent capabilities, making it a promising solution for real-world multi-agent systems.