Multi-agent systems (MAS) have become increasingly prevalent in various domains, including robotics, smart cities, and autonomous vehicles. A crucial challenge in MAS is task allocation, which involves assigning tasks to agents with varying capabilities and resources. This paper proposes a novel deep reinforcement learning (DRL) framework, 'HTAS', that learns to allocate tasks in heterogeneous MAS. HTAS leverages a hierarchical architecture to capture complex agent interactions and task dependencies, and utilizes a novel reward function that encourages efficient task allocation. Experimental results on a range of synthetic and real-world scenarios demonstrate that HTAS achieves significant improvements in task completion rates and system efficiency compared to state-of-the-art methods.