Explainability is crucial in multi-agent reinforcement learning (MARL) to understand the decision-making process of autonomous agents. This paper introduces HAN-MARL, a hierarchical attention network (HAN) framework that facilitates explainable MARL. HAN-MARL learns to focus on relevant agents and their interactions, enabling the identification of key factors influencing the agents' decisions. We evaluate HAN-MARL on a variety of MARL benchmarks, demonstrating improved explainability and competitive performance compared to state-of-the-art methods. Our approach has significant implications for real-world applications, such as autonomous driving and robotics, where transparency and accountability are essential.