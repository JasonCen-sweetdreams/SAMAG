Individuals with motor impairments face significant barriers in interacting with digital systems. This paper presents a novel approach to designing adaptive gesture recognition systems that can accommodate varying levels of motor ability. We introduce a machine learning-based framework that leverages multimodal sensor data to recognize gestures and adapt to individual differences in movement patterns. Our user study with 20 participants with motor impairments demonstrates that our system achieves an average recognition accuracy of 92.5%, outperforming existing gesture recognition systems. We discuss the implications of our findings for inclusive HCI design and provide guidelines for developing accessible gesture-based interfaces.