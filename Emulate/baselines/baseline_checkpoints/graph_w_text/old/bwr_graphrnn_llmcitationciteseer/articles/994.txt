This paper presents a novel multi-agent reinforcement learning framework for cooperative task allocation in dynamic environments. We propose a decentralized, communication-efficient approach that enables agents to adapt to changing task requirements and environmental conditions. Our algorithm, called MARLA, combines deep Q-networks with a consensus-based protocol to facilitate cooperative decision-making. Experimental results in a simulated search-and-rescue scenario demonstrate that MARLA outperforms baseline methods in terms of task completion rate and overall system efficiency.