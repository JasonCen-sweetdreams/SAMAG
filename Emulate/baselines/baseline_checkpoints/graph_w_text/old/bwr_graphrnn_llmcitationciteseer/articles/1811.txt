Virtual reality (VR) systems have the potential to revolutionize accessibility for individuals with motor impairments. This paper presents an eye-gaze-based gesture recognition system, 'EyeGest', which enables users to interact with VR environments using only their eye movements. We propose a novel machine learning pipeline that combines convolutional neural networks with recurrent neural networks to classify gaze patterns into distinct gestures. Our approach achieves an accuracy of 92.5% on a dataset of 20 participants, outperforming existing state-of-the-art methods. We also conduct a user study to evaluate the usability and accessibility of EyeGest in a VR gaming scenario.