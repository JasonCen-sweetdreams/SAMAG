Multi-modal dialogue systems rely on effectively integrating knowledge from various sources to generate context-aware responses. This paper presents a novel knowledge graph embedding approach, 'HAttKG', which leverages hierarchical attention to capture complex entity relationships and structural dependencies. We demonstrate the efficacy of HAttKG in improving response accuracy and contextual relevance in a multi-modal dialogue setting, outperforming state-of-the-art graph-based methods. Our experiments on a large-scale dialogue dataset show that HAttKG achieves significant gains in response quality, particularly in scenarios involving ambiguous or nuanced user requests.