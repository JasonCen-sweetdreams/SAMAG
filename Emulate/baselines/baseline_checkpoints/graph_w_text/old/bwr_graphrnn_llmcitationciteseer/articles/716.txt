Time series forecasting is a crucial task in various domains, but the lack of interpretability in state-of-the-art models hinders their adoption in real-world applications. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates both local and global attention mechanisms to selectively focus on relevant time series features. We introduce an explainability module that generates visualizations of the attention weights, enabling model interpretability. Our experiments on several benchmark datasets demonstrate that HAN outperforms existing methods in terms of forecasting accuracy while providing insights into the underlying data patterns.