This paper presents a novel approach to coordinating autonomous agents for smart city traffic management using hierarchical reinforcement learning. Our framework, 'HRL-Traffic', consists of a high-level planning module that allocates tasks to agents and a low-level execution module that adaptively adjusts agent behavior based on real-time traffic conditions. We evaluate HRL-Traffic on a realistic traffic simulation platform and demonstrate improved traffic flow, reduced congestion, and enhanced safety compared to traditional decentralized approaches. Our results provide insights into the potential of autonomous agents for efficient and sustainable urban transportation systems.