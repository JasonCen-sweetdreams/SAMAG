Voice assistants have become ubiquitous, but their accessibility features often fall short for users with disabilities. This paper presents a multimodal framework, 'IncluVA', that integrates speech, gesture, and gaze-based input to facilitate more inclusive interactions. We conducted a user study with 20 participants with varying abilities, revealing that our approach improves task completion rates and user satisfaction compared to traditional voice-only interfaces. We also propose a set of design guidelines for inclusive voice assistant development, highlighting the importance of user-centered design and iterative testing with diverse user groups.