In multi-agent systems, task allocation is a critical problem that requires efficient and adaptive decision-making. This paper presents a decentralized task allocation framework that leverages reinforcement learning to optimize task assignments among agents. Our approach, called 'Dec-TARL', uses a distributed Q-learning algorithm to learn task-specific policies for each agent, taking into account the agent's capabilities, task requirements, and communication constraints. We evaluate Dec-TARL on a simulated disaster response scenario and demonstrate its effectiveness in achieving higher task completion rates and reduced communication overhead compared to traditional centralized allocation methods.