Explainable AI (XAI) is crucial for real-world applications, but existing knowledge graph embedding (KGE) methods often lack interpretability. We propose 'KG-EXPLAIN', a novel KGE framework that jointly optimizes entity and relation embeddings with explanation-generation objectives. KG-EXPLAIN leverages attention mechanisms to identify relevant triples and generates natural language explanations for link predictions. Extensive experiments on benchmark datasets demonstrate that KG-EXPLAIN outperforms state-of-the-art KGE methods in both link prediction and explanation quality, facilitating trustworthiness in AI systems.