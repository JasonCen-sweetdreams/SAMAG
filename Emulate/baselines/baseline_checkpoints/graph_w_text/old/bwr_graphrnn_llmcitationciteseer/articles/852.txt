In multi-agent reinforcement learning, understanding the decision-making process of agents is crucial for safe and efficient coordination. This paper introduces HAT-MARL, a novel hierarchical attention network that enables explainable policy learning in complex, dynamic environments. HAT-MARL incorporates attention mechanisms at both the agent and system levels, allowing for the identification of critical agents, actions, and state features that influence the overall system behavior. We evaluate HAT-MARL in a simulated traffic control scenario, demonstrating improved interpretability and a 25% increase in overall system performance compared to state-of-the-art MARL methods.