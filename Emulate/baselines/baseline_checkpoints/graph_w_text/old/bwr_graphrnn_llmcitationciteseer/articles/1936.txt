Explainability is crucial for AI decision-making systems to gain trust and transparency. This paper presents a novel hierarchical attention-based multi-modal fusion framework, 'ExplainNet', which integrates visual, textual, and numerical features to provide interpretable AI decisions. ExplainNet employs a hierarchical attention mechanism to selectively focus on relevant features and modalities, generating attention weights that indicate feature importance. We evaluate ExplainNet on a real-world healthcare dataset, demonstrating improved explainability and decision accuracy compared to state-of-the-art multimodal fusion methods.