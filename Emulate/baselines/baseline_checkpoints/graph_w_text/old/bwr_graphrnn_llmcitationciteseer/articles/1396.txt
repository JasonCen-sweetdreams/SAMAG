Virtual Reality (VR) has the potential to revolutionize social interactions, but existing VR systems often exclude users with disabilities. This paper presents an embodied conversational agent (ECA) framework that enables users with mobility or speech impairments to engage in immersive VR experiences. Our ECA, 'AvatarMate', uses machine learning-based gesture recognition and natural language processing to facilitate social interactions between users and virtual agents. We evaluate AvatarMate in a user study with participants with disabilities, demonstrating improved social presence, emotional engagement, and overall VR experience.