Deep neural networks are vulnerable to adversarial attacks, which pose significant threats to their reliability in safety-critical applications. Adversarial training is an effective defense strategy, but it can be computationally expensive. This paper proposes a novel hierarchical noise injection method that efficiently generates diverse adversarial examples, enabling robust model training with reduced computational overhead. Our approach leverages a hierarchical representation of the input data to inject noise at multiple scales, resulting in more effective and efficient adversarial training. Experimental results on various benchmark datasets demonstrate the efficacy of our method in improving model robustness against diverse attacks.