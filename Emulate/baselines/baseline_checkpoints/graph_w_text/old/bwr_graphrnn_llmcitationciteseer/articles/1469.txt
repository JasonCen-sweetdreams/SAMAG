Deep learning models have been shown to be vulnerable to adversarial attacks, which can have devastating consequences in safety-critical applications. This paper proposes a novel self-supervised contrastive learning approach to robustify deep learning models against such attacks. Our method, dubbed 'Contrastive Adversarial Training' (CAT), leverages the idea of contrasting positive and negative samples to learn robust representations. We demonstrate the effectiveness of CAT on several benchmark datasets, showing significant improvements in model robustness against state-of-the-art attacks. Furthermore, we provide theoretical insights into the underlying mechanisms, shedding light on the role of contrastive learning in adversarial robustness.