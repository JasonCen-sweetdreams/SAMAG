Multi-agent systems are increasingly employed in complex, real-world domains, but their decision-making processes often lack transparency and interpretability. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable multi-agent decision-making. Our approach leverages attention mechanisms to selectively focus on relevant agent interactions and contextual information, generating interpretable explanations for joint decisions. Experimental results on a multi-agent robotics dataset demonstrate improved decision-making performance and enhanced explainability compared to traditional reinforcement learning methods.