In multi-agent systems, understanding the decision-making process of individual agents is crucial for overall system performance and trustworthiness. This paper introduces Hierarchical Attention Networks (HANs) to facilitate explainable decision-making in multi-agent scenarios. Our approach uses a hierarchical attention mechanism to identify the most influential agents and their interactions, which enables the generation of interpretable explanations for agent decisions. Experimental results on a real-world autonomous driving dataset demonstrate the effectiveness of HANs in improving decision-making transparency and system performance.