In multi-agent systems, autonomous negotiation is crucial for achieving efficient and effective collaboration. This paper proposes a novel framework, 'DynAgree', which enables agents to adapt their negotiation strategies in response to changes in the environment. We introduce a reinforcement learning approach that leverages graph neural networks to model complex dependencies between agents and incorporate domain knowledge to guide the negotiation process. Experimental results in a simulated disaster response scenario demonstrate that DynAgree outperforms existing negotiation protocols in terms of convergence speed and social welfare.