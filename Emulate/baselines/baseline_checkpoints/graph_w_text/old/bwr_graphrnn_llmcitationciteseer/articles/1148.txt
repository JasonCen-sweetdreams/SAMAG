Multi-agent reinforcement learning (MARL) has shown promise in various applications, but the lack of interpretability hinders its adoption in real-world scenarios. This paper introduces HATMARL, a novel hierarchical attention network architecture that enables explainable decision-making in MARL. HATMARL combines a hierarchical attention mechanism with a graph neural network to learn interpretable representations of agent interactions and joint actions. We demonstrate the effectiveness of HATMARL in a variety of MARL environments, showcasing improved performance and interpretability compared to existing state-of-the-art methods.