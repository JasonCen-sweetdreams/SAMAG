This paper proposes a novel hierarchical reinforcement learning (HRL) framework for autonomous vehicle decision-making, which incorporates explainability techniques to improve transparency and trustworthiness. Our approach combines a high-level task planner with a low-level motion controller, where the task planner generates a sequence of tasks and the motion controller learns to execute each task using deep reinforcement learning. We employ a model-agnostic explanation technique to provide insights into the decision-making process, enabling the identification of critical situations and improvement of the overall system. Experimental results on a realistic simulation platform demonstrate the effectiveness of our HRL framework in complex urban scenarios.