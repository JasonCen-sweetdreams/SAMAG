Autonomous vehicles rely on accurate object detection to navigate complex environments. This paper proposes a novel hierarchical attention network (HAN) for real-time object detection in autonomous vehicles. HAN leverages a multi-scale feature fusion mechanism to capture objects at varying distances and scales. We introduce a sparse attention mechanism that adaptively focuses on relevant regions of the input data, reducing computational overhead. Experimental results on the KITTI dataset demonstrate that HAN outperforms state-of-the-art methods in terms of accuracy and speed, achieving a frame rate of 30 FPS on a NVIDIA Jetson Xavier NX platform.