Distributed databases have become increasingly popular for handling large-scale data storage and processing. However, query performance remains a significant challenge due to data distribution and replication. This paper presents a novel approach to optimizing query performance by adaptively replicating data across nodes based on query patterns and workload characteristics. Our technique, called 'AQR', leverages machine learning-based prediction models to identify hotspots and dynamically adjust replication factors to minimize query latency. Experimental results on a real-world dataset demonstrate that AQR outperforms existing replication strategies by up to 30% in terms of query response time.