Graph neural networks (GNNs) have achieved state-of-the-art performance in node classification tasks, but their computational complexity and memory requirements can be prohibitive for large graphs. This paper proposes a novel hierarchical graph attention network (HGAN) that leverages a hierarchical graph representation to reduce the computational cost of attention mechanisms. Our approach applies a graph pooling operator to coarsen the graph at multiple scales, allowing for efficient node feature aggregation and attention computation. Experimental results on several benchmark datasets demonstrate that HGAN achieves competitive performance to state-of-the-art GNNs while reducing computational time by up to 50%