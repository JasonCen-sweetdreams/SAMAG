Skeleton-based action recognition has gained popularity in recent years, but existing methods often rely on hand-crafted features or oversimplify the human skeleton's complex structure. We propose a novel Hierarchical Graph Attention Network (HGAT) that leverages the hierarchical nature of human skeletons to capture nuanced action patterns. Our approach uses graph attention to selectively focus on relevant joints and bones, and incorporates a hierarchical fusion mechanism to aggregate features across different scales. Experimental results on the NTU-RGBD and Kinetics datasets demonstrate that HGAT outperforms state-of-the-art methods in action recognition accuracy, while requiring fewer parameters and computations.