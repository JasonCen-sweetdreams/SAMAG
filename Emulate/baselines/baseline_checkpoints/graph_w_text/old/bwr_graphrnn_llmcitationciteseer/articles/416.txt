Deep learning models are vulnerable to adversarial attacks, which can be catastrophic in safety-critical applications. This paper proposes an explainable AI-based approach, 'XAI-AD', to detect such attacks. XAI-AD leverages attention-based feature importance and saliency maps to identify anomalous input patterns indicative of adversarial attacks. We evaluate our approach on several benchmark datasets and demonstrate its effectiveness in detecting both white-box and black-box attacks. Our results show that XAI-AD outperforms existing detection methods, achieving high accuracy and robustness even in the presence of varying attack strengths and types.