This paper presents a novel multi-agent reinforcement learning framework for real-time traffic signal control. Our approach, 'MA-RL-TSC', leverages a decentralized actor-critic architecture to enable simultaneous learning and adaptation of individual traffic signals. We introduce a hierarchical communication mechanism that facilitates information exchange between agents, allowing them to adapt to changing traffic patterns and minimize congestion. Experimental results on a large-scale traffic simulator demonstrate significant improvements in traffic flow and reduced congestion compared to traditional signal control methods.