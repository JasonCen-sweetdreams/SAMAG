This paper presents a decentralized task allocation framework for autonomous vehicles using multi-agent reinforcement learning. We propose a novel algorithm, 'MATRL', which enables vehicles to learn optimal task assignments and routes in real-time, without relying on a centralized controller. MATRL leverages graph neural networks to model vehicle interactions and incorporates a reward function that balances task completion with safety and energy efficiency. Experimental results using a simulated urban environment demonstrate that MATRL outperforms traditional centralized approaches in terms of task completion time, energy consumption, and safety metrics.