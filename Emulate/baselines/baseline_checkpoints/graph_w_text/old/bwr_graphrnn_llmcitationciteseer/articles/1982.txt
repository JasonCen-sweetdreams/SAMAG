This paper presents a novel approach to traffic signal control using multi-agent systems and reinforcement learning. We propose a decentralized framework, 'MAS-TSC', where each traffic signal is represented as an autonomous agent that learns to optimize its signal timing based on real-time traffic conditions. Our approach leverages deep Q-networks to enable agents to adapt to changing traffic patterns and coordinate with neighboring agents to minimize congestion and reduce travel times. Experimental results using real-world traffic data from Pittsburgh demonstrate the effectiveness of MAS-TSC in reducing traffic congestion and improving overall traffic efficiency.