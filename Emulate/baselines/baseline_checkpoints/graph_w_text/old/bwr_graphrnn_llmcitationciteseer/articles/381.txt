Bayesian neural network (BNN) pruning has received increasing attention due to its potential to reduce model complexity and improve interpretability. However, existing methods often rely on approximate inference techniques or sampling-based approaches, which can be computationally expensive. This paper proposes a novel variational inference framework for efficient BNN pruning, leveraging a tractable evidence lower bound (ELBO) and a structured sparse prior. We demonstrate the efficacy of our approach on several benchmark datasets, achieving state-of-the-art performance in terms of model compression and accuracy.