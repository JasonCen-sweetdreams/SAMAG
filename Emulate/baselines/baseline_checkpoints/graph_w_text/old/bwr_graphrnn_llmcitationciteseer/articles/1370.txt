Traditional document ranking models often neglect the context in which search queries are issued. This paper proposes a novel proximity-aware document ranking framework that incorporates graph-based contextual embeddings to capture the relationships between queries, documents, and their surroundings. We leverage a graph attention mechanism to encode the proximity information from the query-document graph and integrate it with a BERT-based ranking model. Experimental results on the TREC-19 benchmark demonstrate significant improvements in ranking accuracy and robustness to query ambiguity, outperforming state-of-the-art neural ranking models.