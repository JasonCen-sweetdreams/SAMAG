In multi-agent systems, decision-making processes often rely on complex interactions between agents. This paper proposes a novel hierarchical attention network (HAN) architecture to improve explainability in such systems. Our approach leverages attention mechanisms to selectively focus on relevant agents and interactions, enabling the model to provide interpretable explanations for its decisions. Experimental results on a simulated multi-agent environment demonstrate the effectiveness of HAN in achieving better decision-making outcomes while providing transparent and explainable insights into the decision-making process.