Recent advances in multi-agent reinforcement learning have shown promise in solving complex tasks, but their black-box nature hinders their adoption in real-world applications. This paper introduces HAN-MARL, a novel hierarchical attention network that enables explainable decision-making in cooperative multi-agent systems. By aggregating attention weights across agents, our approach generates interpretable representations of joint actions and state transitions. Experimental results on a suite of multi-agent benchmarks demonstrate that HAN-MARL achieves comparable performance to state-of-the-art methods while providing insights into agent coordination and decision-making processes.