Explainable recommendation systems (ERS) have gained increasing attention in recent years, as they provide users with transparent and trustworthy explanations for their recommendations. This paper proposes a novel graph attention network (GAT) architecture, dubbed 'ExplainGAT', which integrates both item and user relationships to generate personalized explanations. We leverage attention mechanisms to selectively focus on the most relevant items and user preferences, thereby improving recommendation accuracy and explanation quality. Experimental results on two real-world datasets demonstrate the effectiveness of ExplainGAT in generating coherent and informative explanations, surpassing state-of-the-art ERS methods.