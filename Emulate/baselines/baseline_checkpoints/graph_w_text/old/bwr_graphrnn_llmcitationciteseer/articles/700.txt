Explainable recommendation systems are crucial for building trust in AI-driven decision-making processes. This paper introduces HIGAN, a novel hierarchical graph attention network that incorporates both user-item interactions and side information to generate personalized explanations for recommendations. We propose a multi-level attention mechanism that captures complex relationships between users, items, and attributes, and demonstrate its effectiveness in improving recommendation accuracy and explanation quality. Experimental results on three real-world datasets show that HIGAN outperforms state-of-the-art approaches in both top-N recommendation and explanation generation tasks.