Open-domain question answering (ODQA) relies on efficient passage retrieval to identify relevant contexts for answer extraction. This paper presents a novel approach, 'DeepSparse', which leverages deep sparse representations to index and retrieve passages. We propose a hierarchical sparse encoder that compresses passages into compact, sparse vectors, enabling fast similarity search and reducing memory requirements. Experimental results on the Natural Questions dataset demonstrate that DeepSparse outperforms state-of-the-art retrieval methods, achieving a 15% increase in top-1 passage accuracy while reducing memory usage by 75%.