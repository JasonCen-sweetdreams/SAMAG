Multi-agent reinforcement learning (MARL) has shown promise in various applications, but its lack of transparency hinders its adoption in high-stakes domains. We propose a novel hierarchical attention network (HAN) architecture that enables explainable MARL. Our approach learns to focus on relevant agents and their interactions, generating attention weights that provide insights into the decision-making process. Experimental results on a suite of MARL benchmarks demonstrate that HAN outperforms state-of-the-art methods while providing interpretable solutions. We further analyze the attention mechanisms to uncover emergent behaviors and cooperation strategies in multi-agent systems.