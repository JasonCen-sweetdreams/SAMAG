Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its vulnerability to adversarial attacks raises significant concerns. Existing detection methods focus on identifying anomalies in the input space, which may not be effective against sophisticated attacks. This paper proposes a novel graph-based anomaly detection approach, 'GADRL', which models the agent's decision-making process as a graph and detects anomalies in the graph structure. Our experiments on Atari games and robotic control tasks demonstrate that GADRL outperforms state-of-the-art methods in detecting adversarial attacks while maintaining a low false positive rate.