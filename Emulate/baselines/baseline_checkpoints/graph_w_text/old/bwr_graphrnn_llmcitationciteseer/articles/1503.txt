In multi-agent systems, coordinating agents to achieve a common goal is a challenging problem, especially when agents have incomplete information about the environment. This paper presents a novel approach to distributed constraint optimization (DCOP) that addresses this issue. We introduce a probabilistic framework that models agents' uncertain knowledge and beliefs, and develop a distributed algorithm that enables agents to iteratively refine their estimates and converge to a solution. Experimental results on a logistics planning domain demonstrate the effectiveness of our approach in achieving better coordination and reducing conflicts among agents.