This paper presents a novel multi-agent reinforcement learning framework for coordinating autonomous vehicles in urban traffic networks. Our approach, called 'TrafficMAgent', incorporates real-time traffic data and vehicle dynamics to optimize traffic flow and reduce congestion. We develop a decentralized policy gradient method that enables vehicles to learn cooperative behaviors, such as lane-changing and merging, while adapting to changing traffic conditions. Simulation results demonstrate that TrafficMAgent outperforms traditional traffic signal control methods, achieving an average reduction of 25% in travel time and 30% in fuel consumption.