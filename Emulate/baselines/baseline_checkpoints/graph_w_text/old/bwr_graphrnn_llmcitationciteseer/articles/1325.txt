Multi-agent reinforcement learning (MARL) has achieved significant success in various domains, but the lack of interpretability hinders its applicability in real-world scenarios. This paper proposes a novel Hierarchical Attention Network (HAN) framework that enables explainable MARL. HAN consists of two levels of attention: agent-level attention, which models the interactions between agents, and task-level attention, which focuses on the most relevant tasks. We demonstrate the effectiveness of HAN in a variety of MARL environments, showcasing improved performance and interpretability compared to state-of-the-art methods.