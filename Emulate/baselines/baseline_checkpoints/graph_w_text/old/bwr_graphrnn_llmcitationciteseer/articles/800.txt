This paper presents a novel neural document ranking approach that integrates query-driven relevance feedback into a BERT-based ranking model. The proposed architecture, called QRaft, employs a feedback loop that iteratively refines the ranking model by incorporating user relevance judgments. We introduce a new loss function that combines the traditional ranking loss with a feedback-aware regularization term, which encourages the model to adapt to the user's information needs. Experimental results on several benchmark datasets demonstrate that QRaft outperforms state-of-the-art neural ranking models and achieves significant improvements in search effectiveness.