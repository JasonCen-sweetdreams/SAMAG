Emotion recognition in conversational dialogue is a challenging task due to the complexity of emotional cues and contextual dependencies. This paper introduces a novel multi-task learning framework that leverages hierarchical attention mechanisms to jointly model emotion recognition, sentiment analysis, and dialogue act classification. Our proposed approach, 'HERMES', adaptively weights the importance of different dialogue contexts and emotional cues to improve recognition accuracy. Experimental results on the IEMOCAP and MELD datasets demonstrate that HERMES outperforms state-of-the-art models in recognizing emotions and capturing nuanced emotional shifts in conversational dialogue.