The proliferation of IoT devices has led to an explosion of time-series data, making real-time analytics a crucial aspect of various applications. However, existing query optimization techniques struggle to handle the sheer scale and velocity of this data. This paper presents a novel query optimization framework, 'TSOptimizer', which leverages a hybrid approach combining machine learning-based cost estimation and a novel data partitioning scheme. We demonstrate that TSOptimizer achieves an average query response time reduction of 3.5x compared to state-of-the-art optimization techniques on a large-scale IoT dataset.