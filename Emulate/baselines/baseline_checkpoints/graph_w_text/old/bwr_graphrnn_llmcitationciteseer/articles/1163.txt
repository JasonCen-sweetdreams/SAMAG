In multi-agent systems, decision-making processes often involve complex interactions and trade-offs. This paper introduces a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in such systems. Our approach leverages attention mechanisms to selectively weight the importance of individual agents' observations and intentions, allowing for more interpretable and transparent decision-making processes. We evaluate our approach on a real-world autonomous vehicle benchmark, demonstrating improved decision quality and increased explainability compared to traditional reinforcement learning methods.