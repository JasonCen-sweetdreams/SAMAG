Virtual reality (VR) technology has the potential to revolutionize various aspects of our lives, but its adoption is hindered by the lack of accessibility for users with visual impairments. This paper presents an inclusive VR interface design framework that leverages multimodal feedback and machine learning-based user modeling to enable visually impaired users to effectively interact with VR environments. We conducted a user study with 20 participants to evaluate the effectiveness of our approach, demonstrating significant improvements in task completion time and user satisfaction compared to traditional VR interfaces.