Coordinating multi-agent systems to perform complex tasks in real-time is a challenging problem. This paper proposes a novel approach, 'DeepMAC', that leverages deep reinforcement learning to allocate tasks efficiently among agents. We design a hierarchical architecture consisting of a global coordinator and local agents, each equipped with a deep Q-network to learn optimal task assignment policies. Experimental results on a simulated disaster response scenario demonstrate that DeepMAC outperforms traditional methods in terms of task completion time and resource utilization, while adapting to dynamic changes in the environment.