Coordinating multi-agent systems in complex, dynamic environments is a challenging problem. This paper proposes a decentralized approach to multi-agent decision-making using partially observable Markov decision processes (POMDPs). We introduce a novel algorithm, 'Dec-POMDP-MA', which enables agents to make decentralized decisions while sharing information and coordinating actions. Our approach is evaluated in a series of simulation experiments, demonstrating improved task completion rates and reduced communication overhead compared to existing decentralized POMDP methods.