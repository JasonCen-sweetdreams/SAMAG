This paper proposes a novel distributed task allocation framework for multi-agent systems, leveraging reinforcement learning to optimize task assignments. Our approach, dubbed 'MASTA', utilizes a decentralized actor-critic architecture to learn a policy that adapts to dynamic task environments and agent capabilities. MASTA outperforms traditional graph-based allocation methods in simulations, achieving up to 25% improvement in task completion rates and 30% reduction in communication overhead. We demonstrate the efficacy of MASTA in a real-world multi-robot warehouse scenario, highlighting its potential for real-time task allocation in complex, dynamic systems.