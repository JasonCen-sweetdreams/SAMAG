Individuals with motor impairments face significant challenges when interacting with gesture recognition systems, which are often designed with able-bodied users in mind. This paper presents an adaptive gesture recognition framework that leverages machine learning and computer vision techniques to accommodate varying levels of motor ability. Our system, called 'GESTalt', uses a novel combination of feature extraction and transfer learning to recognize gestures from a diverse range of users, including those with motor impairments. We evaluate GESTalt using a dataset of gestures from users with varying levels of impairment and demonstrate improved recognition accuracy and user satisfaction compared to existing systems.