This paper proposes a decentralized task allocation framework for multi-agent systems using reinforcement learning. We formulate the task allocation problem as a Markov decision process and develop a decentralized Q-learning algorithm that enables agents to learn optimal task assignments in a distributed manner. Our approach leverages communication graphs to share information between agents, ensuring scalability and adaptability in dynamic environments. Experimental results demonstrate improved task completion rates and reduced communication overhead compared to traditional centralized approaches.