Open-domain question answering (ODQA) systems rely on effective passage retrieval to identify relevant contexts for answering questions. This paper presents a neural re-ranking approach, 'NeuPass', which leverages a pre-trained language model to re-rank the top-K passages retrieved by a traditional IR system. We introduce a novel scoring function that combines semantic similarity, relevance, and novelty metrics to better capture the contextual relationships between questions and passages. Experiments on the Natural Questions dataset demonstrate that NeuPass achieves significant improvements in retrieval accuracy and efficiency compared to state-of-the-art ODQA models.