Explainability is crucial in multi-agent reinforcement learning (MARL) to ensure trust and transparency in decision-making. This paper presents a novel hierarchical attention network (HAN) architecture that enables explainable MARL. HAN consists of two attention mechanisms: intra-agent attention for feature selection and inter-agent attention for communication. Our approach achieves state-of-the-art performance in cooperative MARL tasks while providing interpretable insights into agent interactions and decision processes. We evaluate HAN on three MARL benchmarks, demonstrating improved explainability and robustness compared to existing methods.