Question answering over knowledge graphs (KGs) has gained significant attention in recent years. However, existing methods suffer from high computational costs and limited scalability. This paper proposes a novel graph attention network-based approach, 'GATE-QA', which learns efficient knowledge graph embeddings for question answering. GATE-QA leverages graph attention mechanisms to selectively focus on relevant graph structures and entities, reducing the computational overhead of traditional KG embedding methods. Experimental results on several benchmark datasets demonstrate that GATE-QA achieves state-of-the-art performance while requiring fewer computational resources.