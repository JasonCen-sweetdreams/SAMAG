This paper proposes a novel hierarchical attention network (HAN) architecture for explainable multi-agent reinforcement learning. Our approach, called HAN-MARL, integrates attention mechanisms at both the agent and team levels to selectively focus on relevant state information and agent interactions. We demonstrate that HAN-MARL outperforms existing MARL methods in terms of both task performance and interpretability, providing transparent insights into agent decision-making processes. Experimental results on a variety of multi-agent environments show the effectiveness of our approach in promoting cooperation and improving overall team performance.