Virtual reality (VR) systems rely on precise user input to provide an immersive experience. This paper presents a novel gaze-based interaction technique using deep neural networks. We propose a convolutional neural network (CNN) architecture that takes eye-tracking data as input and predicts the user's intended action in the virtual environment. Our approach leverages transfer learning from a large eye-tracking dataset and achieves high accuracy in identifying user intentions. We demonstrate the effectiveness of our approach in a VR gaming scenario, showing improved user experience and reduced latency compared to traditional interaction methods.