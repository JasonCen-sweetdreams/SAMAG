State-of-the-art information retrieval systems rely on complex ranking models that are computationally expensive to evaluate, leading to high latency and energy consumption. This paper proposes a novel query-adaptive document ranking framework that leverages deep reinforcement learning to optimize the ranking process. Our approach learns to select the most informative features and documents for a given query, reducing the computational overhead while maintaining retrieval effectiveness. Experimental results on several benchmark datasets demonstrate significant improvements in efficiency and accuracy compared to traditional ranking models.