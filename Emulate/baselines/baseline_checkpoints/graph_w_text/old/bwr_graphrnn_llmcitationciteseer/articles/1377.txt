As autonomous vehicles (AVs) become increasingly prevalent, it is essential to develop decision-making frameworks that are both effective and transparent. This paper presents an explainable reinforcement learning (XRL) approach that integrates model-based and model-free techniques to enable AVs to make informed decisions in complex scenarios. Our XRL framework consists of a novel attention-based encoder that extracts relevant features from multi-modal sensor data, and a hierarchical reinforcement learning module that generates interpretable policies. We evaluate our approach on a realistic simulation platform and demonstrate improved performance and explainability compared to state-of-the-art RL methods.