Task allocation is a fundamental problem in multi-agent systems, where agents with varying capabilities must coordinate to achieve complex goals. This paper proposes a decentralized task allocation framework, 'GraphAgent', which leverages graph neural networks (GNNs) to learn distributed representations of agent capabilities and task requirements. By aggregating local information and adapting to changing environmental conditions, GraphAgent achieves near-optimal task allocation performance while minimizing communication overhead. Experimental results on a range of simulated scenarios demonstrate the scalability and robustness of our approach, outperforming traditional centralized optimization methods.