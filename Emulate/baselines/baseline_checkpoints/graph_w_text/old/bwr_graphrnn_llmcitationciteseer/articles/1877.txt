Ad-hoc retrieval systems rely on effective query representation to retrieve relevant documents. We propose a novel neural query document interaction model, 'NQDI', which learns to generate context-aware query expansions. NQDI employs a multi-head self-attention mechanism to capture intricate relationships between query terms and document contexts. Our approach achieves significant improvements in retrieval performance, particularly for complex queries, as demonstrated through extensive experiments on TREC datasets. We further analyze the interpretability of NQDI using visualizations and attention-weight distributions.