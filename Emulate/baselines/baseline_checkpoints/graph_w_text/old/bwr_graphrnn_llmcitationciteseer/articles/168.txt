In multi-agent systems, coordinating heterogeneous agents with varying capabilities and goals is a challenging problem. This paper presents a novel framework for coordinating such agents using partially observable Markov decision processes (POMDPs). Our approach, called COORD, models each agent's decision-making process as a POMDP and introduces a decentralized coordination mechanism that enables agents to share information and adapt to changing environmental conditions. We evaluate COORD in a simulated disaster response scenario, demonstrating improved response times and resource allocation compared to existing decentralized coordination methods.