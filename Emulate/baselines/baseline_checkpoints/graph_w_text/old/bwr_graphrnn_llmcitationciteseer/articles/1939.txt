Explainable AI has gained significant attention in recent years, particularly in recommendation systems where model interpretability is crucial. This paper proposes a novel hierarchical attention network (HAN) framework that integrates both item-level and user-level attention mechanisms to provide personalized explanations for recommendations. Our approach leverages the strengths of both content-based and collaborative filtering methods, enabling the model to capture complex relationships between users and items. Experimental results on several benchmark datasets demonstrate the effectiveness of HAN in improving recommendation accuracy and providing meaningful explanations.