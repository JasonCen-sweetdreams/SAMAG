Virtual reality (VR) technology has the potential to revolutionize various aspects of our lives, but its adoption is hindered by the lack of accessible interfaces. This paper presents a novel approach to enhance accessibility in VR using multimodal feedback. We propose a framework that combines haptic, auditory, and visual cues to provide users with a more immersive and inclusive experience. Our system uses machine learning algorithms to adapt the feedback to individual users' needs and preferences. We evaluate our approach through a user study with participants with varying abilities and demonstrate significant improvements in user engagement and task completion rates.