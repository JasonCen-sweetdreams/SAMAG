Neural retrieval models have shown promising results in ad-hoc search, but their computational overhead hinders their adoption in real-world applications. This paper proposes a novel query optimization framework, 'NeuroOpt', that leverages knowledge graph embeddings and query rewriting techniques to reduce the computational cost of neural ranking models. We demonstrate that NeuroOpt achieves an average speedup of 3.5x over baseline neural models while maintaining search accuracy on a large-scale web corpus. Our approach has significant implications for the deployment of neural IR models in production environments.