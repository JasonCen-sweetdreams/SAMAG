Passage retrieval has become a crucial component in many natural language processing applications, including question answering and text summarization. However, existing ranking models often suffer from inefficiencies in handling long documents and capturing nuanced context. This paper presents a novel hierarchical attention network (HAN) architecture that addresses these limitations. Our HAN model learns to selectively focus on relevant passages and sentences within a document, reducing computational overhead and improving retrieval accuracy. Experimental results on benchmark datasets demonstrate significant gains over state-of-the-art models, particularly in terms of precision and recall at the top-k ranks.