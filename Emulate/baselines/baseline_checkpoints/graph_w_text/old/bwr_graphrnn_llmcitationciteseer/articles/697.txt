This paper proposes a novel distributed task allocation framework for multi-agent systems using reinforcement learning. The framework, called 'MA-RL-TA', enables agents to learn effective task allocation strategies in dynamic environments with limited communication. We introduce a decentralized Q-network architecture that allows agents to learn from their local observations and coordinate with each other to optimize global rewards. Experimental results on a simulated robotic search and rescue scenario demonstrate that MA-RL-TA outperforms traditional allocation algorithms in terms of task completion rate and resource utilization.