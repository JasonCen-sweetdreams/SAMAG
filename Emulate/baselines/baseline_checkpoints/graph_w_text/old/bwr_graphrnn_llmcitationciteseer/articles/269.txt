Multimodal data, which combines features from different sources, has become increasingly prevalent in various applications. However, traditional clustering algorithms struggle to handle high-dimensional, heterogeneous data. This paper proposes a novel hierarchical clustering framework, 'DeepHier', that leverages deep neural networks to learn a shared representation across modalities. We introduce a multitask learning objective that jointly optimizes clustering and dimensionality reduction, enabling efficient clustering of large datasets. Experimental results on several benchmark datasets demonstrate the superiority of DeepHier over state-of-the-art clustering algorithms in terms of clustering quality and computational efficiency.