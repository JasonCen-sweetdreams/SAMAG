Coordinating multiple agents in complex environments is a challenging problem in artificial intelligence. This paper presents a novel hierarchical decision-making framework that leverages reinforcement learning to optimize agent interactions. Our approach, called Hierarchical Agent Coordination (HAC), consists of two phases: (1) high-level planning, where agents learn to communicate and negotiate goals, and (2) low-level execution, where agents execute actions to achieve the agreed-upon goals. We evaluate HAC in a simulated robotic soccer domain, demonstrating improved coordination and goal achievement compared to existing decentralized approaches.