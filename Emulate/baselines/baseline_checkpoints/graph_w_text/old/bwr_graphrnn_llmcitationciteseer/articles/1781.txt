In multi-agent reinforcement learning, agents must learn to coordinate and make decisions in partially observable environments. We propose a novel hierarchical graph attention mechanism, 'HGA-MA', that integrates both local and global graph structures to reason about agent interactions and observations. Our approach leverages attention weights to selectively focus on relevant agents and their observations, enabling more effective information sharing and improved coordination. Experimental results on several benchmark environments demonstrate that HGA-MA outperforms state-of-the-art methods in terms of team reward and convergence speed.