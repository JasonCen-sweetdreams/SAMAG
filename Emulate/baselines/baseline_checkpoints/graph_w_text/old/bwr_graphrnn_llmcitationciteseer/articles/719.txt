Autonomous vehicles require efficient and adaptive control policies to navigate complex scenarios. This paper presents a novel hierarchical reinforcement learning framework, 'HRL-AV', which leverages a multi-level abstraction of the control problem. HRL-AV combines a high-level intention planner with a low-level neural network controller, enabling efficient exploration and exploitation of the action space. We demonstrate improved performance and sample efficiency compared to flat reinforcement learning methods on a suite of simulated autonomous driving tasks, highlighting the potential of HRL-AV for real-world autonomous vehicle control.