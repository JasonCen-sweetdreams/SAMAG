Query optimization is a critical component of distributed graph databases, as it significantly impacts query performance. Traditional optimization techniques rely on heuristics and rule-based approaches, which may not adapt well to dynamic graph structures. This paper explores the application of reinforcement learning (RL) to query optimization in distributed graph databases. We propose a novel RL framework, 'GraphOpt', which leverages a graph-structured state representation and a reward function that balances query execution time and resource utilization. Experimental results on a large-scale graph dataset demonstrate that GraphOpt outperforms state-of-the-art optimization techniques by up to 30% in terms of query execution time while reducing resource utilization by 25%.