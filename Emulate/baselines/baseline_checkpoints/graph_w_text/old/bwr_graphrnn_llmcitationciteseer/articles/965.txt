In multi-agent systems, decision-making often relies on complex interactions between agents. While deep reinforcement learning has shown promise, it lacks transparency and interpretability. This paper introduces HAN-MAD, a hierarchical attention network that explicitly models agent-agent and agent-environment interactions to facilitate explainable decision-making. HAN-MAD uses a novel attention mechanism to selectively focus on relevant agents and contextual features, enabling the identification of critical factors influencing collective behavior. Experimental results on a real-world autonomous vehicle dataset demonstrate improved decision-making performance and enhanced explainability compared to state-of-the-art methods.