Effective human-robot interaction (HRI) relies on efficient dialogue management between agents. This paper presents an adaptive dialogue management framework that enables multiple agents to engage in natural, goal-oriented conversations with humans. Our approach leverages a probabilistic graphical model to represent the conversation context, and a reinforcement learning module to optimize the dialogue flow. Experimental results demonstrate the efficacy of our framework in a real-world HRI scenario, improving task completion rates by 25% compared to traditional rule-based approaches.