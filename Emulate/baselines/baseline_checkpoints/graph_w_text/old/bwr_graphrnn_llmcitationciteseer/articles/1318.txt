Ad-hoc retrieval remains a challenging problem in information retrieval, particularly when dealing with ambiguous or incomplete queries. This paper proposes a novel approach to query expansion, leveraging reinforcement learning to optimize the selection of expansion terms. Our method, RL-QE, learns to balance the trade-off between query drift and relevance improvement by interacting with a simulated environment. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art query expansion techniques, achieving significant improvements in mean average precision and normalized discounted cumulative gain.