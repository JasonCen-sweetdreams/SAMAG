This paper proposes a novel hierarchical attention network (HAN) architecture for explainable multi-agent reinforcement learning. Our approach uses a hierarchical graph structure to model agent relationships and attention mechanisms to focus on relevant agents and states. We also introduce a novel explanation module that generates interpretable features for agent decision-making. Experiments on a variety of multi-agent environments demonstrate that HAN outperforms state-of-the-art methods in terms of performance and interpretability. We also provide a comprehensive analysis of the learned attention patterns, shedding light on the underlying decision-making processes of the agents.