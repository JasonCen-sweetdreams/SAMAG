Multi-agent systems often rely on complex decision-making processes, which can be challenging to interpret and explain. This paper introduces a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent settings. Our approach leverages attention mechanisms to selectively focus on relevant agents, features, and interactions, providing transparent and interpretable decision-making outcomes. We evaluate our method on a variety of multi-agent scenarios, including traffic management and robotics, and demonstrate significant improvements in both decision-making accuracy and explainability compared to existing approaches.