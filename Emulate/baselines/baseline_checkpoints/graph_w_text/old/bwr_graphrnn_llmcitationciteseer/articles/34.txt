Multi-agent systems (MAS) are increasingly deployed in real-world applications, but their decision-making processes often lack transparency and interpretability. This paper introduces a novel hierarchical attention network (HAN) architecture for explainable MAS decision-making. Our approach integrates agent-level attention mechanisms with a hierarchical policy framework, enabling the identification of critical agents and their contributions to collective decisions. We evaluate our approach on a suite of benchmark MAS scenarios, demonstrating improved explainability and decision quality compared to state-of-the-art methods.