This paper proposes a novel neural ranking model, DeepMIR, which leverages deep retrieval-based learning to effectively rank multi-modal documents in information retrieval systems. In contrast to traditional text-based ranking methods, DeepMIR utilizes a multi-modal encoder to jointly learn textual and visual representations of documents. Our experiments on a large-scale dataset demonstrate that DeepMIR significantly outperforms state-of-the-art ranking models in terms of retrieval accuracy and efficiency. Furthermore, we show that our model is robust to noisy or incomplete data, making it a promising solution for real-world information retrieval applications.