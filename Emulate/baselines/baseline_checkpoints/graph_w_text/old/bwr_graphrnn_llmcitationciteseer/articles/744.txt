Explainability in multi-agent reinforcement learning (MARL) is crucial for real-world applications. This paper proposes a novel hierarchical attention network (HAN) architecture that enables interpretable MARL policies. Our HAN model incorporates agent-specific attention mechanisms to selectively focus on relevant communication signals and environment states. We demonstrate the effectiveness of our approach on a range of cooperative and competitive MARL benchmarks, providing insights into the learned attention patterns and their correlation with policy performance.