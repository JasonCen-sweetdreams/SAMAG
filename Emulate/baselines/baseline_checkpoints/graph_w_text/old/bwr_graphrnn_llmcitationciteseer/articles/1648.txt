Explainability is crucial in multi-agent systems, where decisions can have far-reaching consequences. This paper proposes a novel hierarchical attention network (HAN) framework for interpretable decision-making in multi-agent environments. Our approach leverages attention mechanisms to selectively focus on relevant agents and their interactions, enabling the model to learn contextual dependencies and provide transparent explanations for its decisions. Experimental results on a range of multi-agent scenarios demonstrate the effectiveness of HAN in improving decision-making accuracy while providing actionable insights into agent behavior.