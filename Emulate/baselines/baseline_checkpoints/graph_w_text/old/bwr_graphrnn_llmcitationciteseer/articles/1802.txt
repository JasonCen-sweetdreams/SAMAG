In this paper, we address the problem of decentralized task allocation in heterogeneous multi-agent systems. We propose a novel approach that leverages deep reinforcement learning to learn a decentralized task allocation policy. Our method, called 'DMA', utilizes a decentralized actor-critic framework to learn a task allocation policy that maximizes the overall system utility. We evaluate DMA on a set of benchmarks and demonstrate its effectiveness in allocating tasks efficiently in heterogeneous multi-agent systems. We also show that DMA outperforms traditional decentralized task allocation methods in terms of system utility and task completion time.