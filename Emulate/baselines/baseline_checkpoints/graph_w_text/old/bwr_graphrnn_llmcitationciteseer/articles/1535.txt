Ad-hoc search query expansion is a critical step in retrieving relevant documents. Traditional methods rely on heuristics or supervised learning, which may not generalize well to unseen queries. We propose a novel hierarchical reinforcement learning (HRL) framework, 'QueryExplorer', that learns to expand queries by iterating over a query-document graph. The HRL agent consists of a high-level query expansion policy and a low-level word selection policy, which work together to maximize the expected relevance of retrieved documents. Experiments on the TREC-8 ad-hoc search dataset demonstrate that QueryExplorer outperforms state-of-the-art methods, including those using deep learning-based query expansion techniques.