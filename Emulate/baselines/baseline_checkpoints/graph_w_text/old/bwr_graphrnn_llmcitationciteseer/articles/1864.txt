Few-shot node classification is a challenging problem in graph-structured data, where a model must classify new nodes based on limited labeled data. This paper proposes a novel hierarchical graph attention network (HiGAT) that leverages both local and global node representations to improve few-shot learning performance. HiGAT uses a hierarchical attention mechanism to selectively focus on relevant nodes and subgraphs, allowing it to adapt to new classes with limited labeled data. Experimental results on several benchmark datasets demonstrate that HiGAT outperforms state-of-the-art few-shot node classification methods and is more robust to varying label scarcity.