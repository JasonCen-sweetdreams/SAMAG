Multi-agent decision-making is a crucial aspect of various real-world applications, such as autonomous vehicles, smart grids, and healthcare systems. However, the lack of transparency in complex decision-making processes hinders trust and accountability. This paper presents a novel hierarchical attention network (HAN) architecture that integrates attention mechanisms with multi-agent reinforcement learning. Our approach enables explainable decision-making by identifying critical agents, states, and actions that influence the overall system behavior. Experimental results on a real-world traffic management scenario demonstrate the effectiveness of HAN in improving decision quality and interpretability.