Neural architecture search (NAS) has emerged as a promising technique for automating the design of deep neural networks. However, existing methods often rely on expensive and time-consuming evaluations of candidate architectures. This paper proposes a novel graph-based reinforcement learning approach, 'GraphNAS', which leverages the structural properties of neural networks to guide the search process. By representing architectures as graphs and learning a policy to navigate the search space, GraphNAS achieves state-of-the-art results on popular NAS benchmarks while reducing the search time by up to 75%. Our approach also enables the discovery of novel architectures that outperform human-designed models on several image classification tasks.