Explainability is a crucial aspect of multi-agent reinforcement learning, where understanding the decision-making process is essential for trust and accountability. This paper proposes a novel hierarchical attention network (HAN) architecture that enables interpretable policy learning in cooperative multi-agent environments. Our HAN model utilizes attention mechanisms at both the agent and team levels, allowing for the identification of key agents and their contributions to team performance. We evaluate our approach on a suite of multi-agent benchmark tasks and demonstrate improved explainability and performance compared to state-of-the-art methods.