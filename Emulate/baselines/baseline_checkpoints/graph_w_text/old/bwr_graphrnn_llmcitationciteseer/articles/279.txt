Anomaly detection in time-series data is crucial for various applications, including predictive maintenance and healthcare. While deep learning models have shown promising results, their lack of transparency hinders their adoption in high-stakes domains. This paper proposes a hierarchical attention network (HAN) that not only detects anomalies but also provides interpretable explanations. Our HAN architecture consists of two levels of attention: a segment-level attention that identifies anomalous regions and a feature-level attention that highlights relevant input features. Experimental results on three benchmark datasets demonstrate that our approach outperforms state-of-the-art methods in terms of detection accuracy and explanation quality.