This paper proposes a novel decentralized task allocation framework for multi-agent systems, leveraging graph neural networks (GNNs) to model agent interactions and task dependencies. Our approach, dubbed 'GraphTask', enables agents to learn efficient task assignments in a distributed manner, without relying on a centralized controller. We demonstrate the effectiveness of GraphTask in simulated scenarios, showcasing improved task completion rates and reduced communication overhead compared to traditional methods. Theoretical analysis and empirical results validate the scalability and robustness of our approach in various multi-agent settings.