Passage retrieval is a critical component of many information retrieval systems, but its computational cost can be prohibitive for large document collections. We propose a novel approach, 'Q-Rep', which adapts document representations to the query context at inference time. By leveraging a neural attention mechanism, Q-Rep selectively highlights relevant document regions and reduces the dimensionality of the representation space. Experiments on several benchmark datasets demonstrate that Q-Rep outperforms state-of-the-art passage retrieval models while requiring significantly fewer computations.