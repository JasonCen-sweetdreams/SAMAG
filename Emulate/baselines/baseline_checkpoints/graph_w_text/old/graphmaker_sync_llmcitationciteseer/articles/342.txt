Individuals with motor impairments often face significant challenges in interacting with digital systems. This paper presents an augmented reality (AR) based gesture recognition system designed to facilitate accessible interaction for this population. Our system utilizes a novel combination of computer vision and machine learning algorithms to recognize and interpret gestures performed by individuals with varying levels of motor impairment. We evaluate our system through a user study with 20 participants, demonstrating significant improvements in gesture recognition accuracy and user experience compared to existing systems. Our findings have important implications for the development of inclusive and accessible HCI systems.