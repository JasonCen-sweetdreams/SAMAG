Query optimization is a crucial task in distributed graph databases, where complex queries can lead to significant performance degradation. This paper introduces 'GraphRL', a novel query optimization framework that leverages reinforcement learning to identify efficient execution plans. GraphRL models the query optimization problem as a Markov decision process, where the agent learns to navigate the space of possible execution plans to minimize execution time. Our experimental evaluation on a large-scale graph dataset demonstrates that GraphRL outperforms state-of-the-art query optimizers by up to 3x, while adapting to changing workload patterns and database schema evolution.