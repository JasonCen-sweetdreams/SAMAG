In virtual reality (VR) environments, accurate inference of user intent is crucial for seamless interaction. This paper presents EyeGazeSense, a machine learning-based approach that leverages eye movement patterns to infer user intent. Our method combines convolutional neural networks (CNNs) and long short-term memory (LSTM) networks to analyze eye movement data and predict user goals. We evaluate EyeGazeSense on a dataset of 30 users performing various tasks in a VR environment, achieving an average accuracy of 87.2% in intent inference. The results demonstrate the potential of EyeGazeSense to enhance user experience and interaction in VR applications.