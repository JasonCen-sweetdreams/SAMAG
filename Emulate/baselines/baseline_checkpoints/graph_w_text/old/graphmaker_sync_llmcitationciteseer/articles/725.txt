We present a novel approach to distributed task allocation for autonomous agents, leveraging deep reinforcement learning to optimize task assignments in complex, dynamic environments. Our method, dubbed 'Agent-RL', employs a decentralized, hierarchical framework wherein agents learn to allocate tasks based on partial observations and communicate through a stochastic message-passing protocol. Experimental results on a simulated robotic swarm demonstrate significant improvements in task completion rates and reduced communication overhead compared to existing, model-based approaches.