Ad-hoc retrieval systems often struggle to effectively capture user intent, leading to suboptimal query representations. We propose a novel query expansion framework that leverages deep reinforcement learning to optimize the selection of expansion terms. Our approach, 'RL-QE', learns to balance the trade-off between query drift and relevance improvement by interacting with a simulated retrieval environment. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art query expansion techniques in terms of retrieval effectiveness, while reducing the computational overhead.