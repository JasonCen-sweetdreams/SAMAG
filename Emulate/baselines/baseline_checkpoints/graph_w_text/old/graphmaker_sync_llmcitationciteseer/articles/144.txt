As multi-agent systems become increasingly prevalent, there is a growing need for explainable reinforcement learning (RL) methods that can facilitate human understanding and trust. This paper presents HAN-MARL, a novel hierarchical attention network architecture for explainable multi-agent RL. HAN-MARL utilizes attention mechanisms to selectively focus on relevant agents and their interactions, enabling the identification of key contributors to the system's behavior. We demonstrate the effectiveness of HAN-MARL in a series of experiments on cooperative and competitive tasks, showcasing improved interpretability and performance compared to state-of-the-art RL methods.