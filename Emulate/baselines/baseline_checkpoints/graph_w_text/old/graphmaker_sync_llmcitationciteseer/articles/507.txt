Cooperative task allocation in dynamic environments is a challenging problem that requires agents to adapt to changing conditions and collaborate effectively. This paper proposes a hierarchical multi-agent reinforcement learning framework that enables agents to learn both high-level task allocation policies and low-level control actions. Our approach leverages a hierarchical structure to decompose the complex task allocation problem into manageable sub-problems, and incorporates environment-driven attention mechanisms to focus on relevant tasks and agents. Experimental results in a simulated search-and-rescue scenario demonstrate improved task completion rates and reduced communication overhead compared to existing decentralized methods.