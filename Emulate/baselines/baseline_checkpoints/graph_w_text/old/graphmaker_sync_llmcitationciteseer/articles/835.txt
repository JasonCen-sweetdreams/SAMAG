Knowledge graph embedding (KGE) is a crucial step in link prediction tasks, but existing methods often struggle with handling multiple relations and complex entity hierarchies. This paper proposes a novel KGE framework, 'HierAtt', which leverages hierarchical attention mechanisms to model dependencies between entities and relations. We demonstrate that HierAtt significantly outperforms state-of-the-art methods on benchmark datasets, achieving a relative improvement of 15% in mean reciprocal rank and 12% in hits@10. Our experiments also show that HierAtt is more interpretable and scalable than existing approaches.