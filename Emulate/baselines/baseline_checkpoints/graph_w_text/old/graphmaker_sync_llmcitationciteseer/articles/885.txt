Deep learning models are vulnerable to adversarial attacks, which can compromise their reliability and security. Existing detection methods often rely on feature-based approaches, which can be evaded by sophisticated attacks. This paper proposes a novel graph-based anomaly detection framework, 'GraphGuard', to identify adversarial attacks on deep neural networks. By modeling the input data as a graph and leveraging graph-based anomaly detection algorithms, GraphGuard can detect attacks with high accuracy and robustness. Experimental results on several benchmark datasets demonstrate the effectiveness of GraphGuard in detecting various types of attacks, including gradient-based and optimization-based attacks.