Explainability is a crucial aspect of multi-agent reinforcement learning (MARL) as it enables understanding of agent decision-making processes. This paper presents a novel hierarchical attention network (HAN) architecture that facilitates explainable MARL. Our approach integrates attention mechanisms at both the intra-agent and inter-agent levels, allowing agents to selectively focus on relevant features and communicate effectively. We evaluate HAN on a suite of cooperative and competitive MARL benchmarks, demonstrating improved performance and interpretability compared to state-of-the-art methods.