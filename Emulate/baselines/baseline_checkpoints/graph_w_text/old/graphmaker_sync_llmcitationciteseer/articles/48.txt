Explainable recommendation systems (ERS) aim to provide transparency into the decision-making process of AI-driven recommender models. This paper introduces a novel hierarchical graph attention network (HGAN) architecture, which leverages graph neural networks to model user-item interactions and attention mechanisms to identify influential factors. Our approach enables the generation of personalized, interpretable explanations for recommended items. Experimental results on real-world datasets demonstrate that HGAN outperforms state-of-the-art ERS methods in terms of both recommendation accuracy and explanation quality.