This paper presents a novel hierarchical multi-agent reinforcement learning framework for adaptive traffic signal control. Our approach, 'HiMAC', consists of a centralized manager that coordinates the actions of multiple intersection agents, each responsible for controlling a traffic signal. We introduce a hierarchical policy representation that enables the manager to adapt to changing traffic patterns and optimize signal timings in real-time. Experimental results using a simulated traffic network demonstrate that HiMAC outperforms state-of-the-art methods in reducing congestion and travel times, while also improving scalability and robustness.