Voice assistants have become ubiquitous in smart homes, but their interaction modalities often exclude users with disabilities. This paper presents a novel multimodal interaction framework, 'AccessibleVoice', that combines speech, gesture, and gaze-based input to enable more inclusive interactions. We conducted a user study with 20 participants with varying disabilities and found that AccessibleVoice improved task completion rates by 35% and reduced interaction time by 27% compared to traditional voice assistants. Our framework is adaptable to different assistive technologies and can be integrated into existing smart home systems.