Ad-hoc retrieval systems often rely on query expansion to improve retrieval performance. However, existing methods suffer from high computational costs and limited semantic understanding. This paper proposes a novel neural semantic embedding-based query expansion framework, 'NeuQE', which leverages pre-trained language models to capture nuanced semantic relationships between query terms and documents. Our approach uses a graph attention mechanism to selectively expand the query while preserving its original intent. Experimental results on several benchmark datasets demonstrate significant improvements in mean average precision and normalized discounted cumulative gain over state-of-the-art methods.