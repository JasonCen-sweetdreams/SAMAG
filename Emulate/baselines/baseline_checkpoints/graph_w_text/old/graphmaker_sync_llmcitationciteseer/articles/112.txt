Multi-agent systems require efficient decision-making strategies that can adapt to dynamic environments. However, the explainability of these decisions remains a major challenge. We propose HAT-MAD, a hierarchical attention network that integrates reinforcement learning with attention mechanisms to facilitate interpretable decision-making in multi-agent systems. HAT-MAD learns to focus on relevant agents, actions, and context features, generating attention weights that provide insights into the decision-making process. Experimental results on a real-world traffic management scenario demonstrate improved decision quality and explainability compared to baseline methods.