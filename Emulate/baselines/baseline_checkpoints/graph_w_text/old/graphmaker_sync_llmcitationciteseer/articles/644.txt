Multi-agent reinforcement learning (MARL) has shown promise in various applications, but the lack of interpretability hinders its adoption in real-world scenarios. This paper presents HAN-MARL, a hierarchical attention network-based framework that enables explainable decision-making in MARL. Our approach incorporates attention mechanisms to selectively focus on relevant agents and features, leading to improved cooperation and communication among agents. We evaluate HAN-MARL on a suite of benchmarks, demonstrating its ability to provide transparent and insightful explanations for agent decisions while achieving state-of-the-art performance.