Multi-agent reinforcement learning (MARL) is a crucial aspect of AI research, but existing methods often lack interpretability, hindering their adoption in real-world applications. We propose a novel hierarchical graph attention network (HGAN) architecture that enables explainable MARL by incorporating attention mechanisms at both the local and global levels. Our approach facilitates the identification of influential agents and their interactions, thereby improving cooperation and decision-making in complex MARL scenarios. Experimental results on three benchmark environments demonstrate the effectiveness of HGAN in achieving improved task performance and enhanced interpretability.