Coordinating multiple agents to achieve a common goal is a fundamental challenge in AI research. Existing approaches often rely on complex, black-box models that hinder interpretability. We propose Hierarchical Graph Attention Networks (HGAT), a novel framework that integrates graph attention mechanisms with hierarchical reinforcement learning to facilitate explainable multi-agent cooperation. HGAT enables agents to selectively focus on relevant neighbors and abstract away irrelevant information, leading to improved cooperation and interpretability. Experimental results on the Multi-Agent Particle Environment demonstrate that HGAT outperforms state-of-the-art methods in terms of cooperation efficiency and interpretability.