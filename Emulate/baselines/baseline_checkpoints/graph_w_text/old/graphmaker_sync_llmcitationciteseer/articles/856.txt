As deep reinforcement learning (DRL) is increasingly applied to real-world robotics, explainability techniques are crucial to ensure transparency and trust in decision-making processes. This paper proposes a novel, model-agnostic explainability framework, 'RL-Explainer', which leverages attention mechanisms and feature importance to provide interpretable explanations for DRL policies. We demonstrate the effectiveness of RL-Explainer on a robotic grasping task, showcasing its ability to identify key features contributing to the agent's decisions. Our approach enables efficient explanation generation, facilitating the development of more reliable and trustworthy DRL systems in real-world robotics applications.