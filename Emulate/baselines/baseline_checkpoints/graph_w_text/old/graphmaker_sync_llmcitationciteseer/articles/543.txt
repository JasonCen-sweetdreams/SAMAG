Few-shot relation extraction (FSRE) aims to identify relationships between entities in a sentence with limited training data. Existing approaches rely on complex meta-learning or transfer learning frameworks, which can be computationally expensive. We propose a novel hierarchical attention network (HAN) architecture that leverages entity-aware attention mechanisms to focus on relevant context and reduce the need for extensive training. Our experiments on benchmark FSRE datasets demonstrate that HAN achieves state-of-the-art performance while requiring significantly fewer parameters and computations compared to existing approaches.