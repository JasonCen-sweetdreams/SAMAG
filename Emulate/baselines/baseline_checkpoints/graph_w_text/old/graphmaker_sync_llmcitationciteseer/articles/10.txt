Explainability is a crucial aspect of multi-agent reinforcement learning, as it enables humans to understand and trust the decision-making processes of autonomous agents. This paper proposes a novel hierarchical attention network (HAN) architecture that integrates attention mechanisms at both the agent and system levels. Our approach enables the identification of key factors influencing the agents' decisions and facilitates the interpretation of complex multi-agent interactions. We evaluate our HAN model on a real-world traffic control scenario, demonstrating improved explainability and enhanced coordination among agents compared to state-of-the-art reinforcement learning methods.