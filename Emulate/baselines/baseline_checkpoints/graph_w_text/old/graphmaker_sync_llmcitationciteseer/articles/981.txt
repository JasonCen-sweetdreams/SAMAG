In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a novel hierarchical reinforcement learning framework, 'HTA', which enables coordinated task allocation among agents. HTA leverages a high-level coordinator to allocate tasks to agents based on their capabilities and preferences, while individual agents learn to execute tasks using deep reinforcement learning. We demonstrate the effectiveness of HTA in a simulated disaster response scenario, where agents must collaborate to rescue victims and allocate resources. Experimental results show that HTA outperforms traditional decentralized allocation methods, achieving faster response times and improved resource utilization.