Explainable recommendation systems are crucial for building trust in AI-driven decision-making processes. This paper introduces HGAN-Explainer, a novel hierarchical graph attention network architecture that generates interpretable recommendations. We leverage graph attention mechanisms to capture complex relationships between users, items, and attributes. The hierarchical structure enables the model to focus on relevant subgraphs and provide personalized, context-aware explanations for each recommendation. Our experiments on real-world datasets demonstrate significant improvements in recommendation accuracy and explanation quality compared to state-of-the-art baselines.