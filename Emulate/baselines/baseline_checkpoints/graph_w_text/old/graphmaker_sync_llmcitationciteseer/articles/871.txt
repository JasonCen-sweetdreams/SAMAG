Virtual reality (VR) systems often rely on manual controllers for user input, limiting the sense of immersion. This paper presents a novel gaze-based interaction framework for VR, leveraging deep learning-based eye tracking to accurately estimate user gaze. Our approach combines convolutional neural networks (CNNs) with graphical models to detect and track eye movements in real-time. We evaluate our system on a dataset of VR user interactions, demonstrating improved accuracy and latency compared to state-of-the-art methods. Our framework enables intuitive, hands-free interaction in VR, enhancing user experience and opening up new possibilities for VR applications in fields such as education and healthcare.