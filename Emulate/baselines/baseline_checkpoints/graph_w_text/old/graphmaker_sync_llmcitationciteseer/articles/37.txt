Ad-hoc retrieval systems often struggle to effectively capture user intent, leading to suboptimal search results. This paper proposes a novel hierarchical query expansion framework that leverages reinforcement learning to adaptively refine query representations. Our approach, termed HQE-RL, employs a hierarchical policy to selectively expand query terms, balancing trade-offs between relevance and diversity. Experimental results on the TREC 2019 ad-hoc retrieval benchmark demonstrate that HQE-RL significantly outperforms state-of-the-art query expansion methods, achieving a 15% improvement in mean average precision.