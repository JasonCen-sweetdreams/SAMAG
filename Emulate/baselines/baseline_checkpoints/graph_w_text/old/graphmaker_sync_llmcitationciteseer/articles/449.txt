This paper proposes a novel hierarchical attention network (HAN) architecture for explainable time-series anomaly detection. Our approach leverages a combination of self-attention and hierarchical aggregation to capture long-range dependencies and identify anomalous patterns in multivariate time series data. We introduce a novel explanation module that generates interpretable attention weights, enabling visualization of the anomaly detection process. Experimental results on real-world datasets demonstrate the effectiveness of HAN in detecting anomalies and providing insightful explanations compared to state-of-the-art baselines.