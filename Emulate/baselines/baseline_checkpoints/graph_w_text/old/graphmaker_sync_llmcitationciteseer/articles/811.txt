Coordinating multiple agents in complex environments requires efficient communication and decision-making strategies. This paper presents a novel hierarchical attention network (HAN) architecture for explainable multi-agent cooperation. Our approach leverages graph attention mechanisms to model inter-agent relationships and learn cooperative policies. We demonstrate the effectiveness of HAN in several benchmarks, including a real-world traffic management scenario, showcasing improved coordination and interpretability compared to existing methods. The proposed framework enables the identification of critical agent interactions and decision-making factors, facilitating the development of more transparent and trustworthy AI systems.