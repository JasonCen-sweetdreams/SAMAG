Graph neural networks (GNNs) have shown remarkable success in node classification tasks. However, most existing GNN models are transductive, meaning they require the entire graph during training. This paper proposes a novel hierarchical attention-based GNN framework, 'HAT-GNN', which enables inductive node classification. Our approach leverages a hierarchical attention mechanism to selectively aggregate features from neighboring nodes, allowing the model to generalize to unseen nodes and graphs. We evaluate HAT-GNN on several benchmark datasets and demonstrate significant improvements over state-of-the-art inductive GNN models.