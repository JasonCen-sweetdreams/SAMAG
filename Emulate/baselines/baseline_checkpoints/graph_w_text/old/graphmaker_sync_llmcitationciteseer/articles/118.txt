Multi-hop question answering (MHQA) requires models to reason across multiple sentences and identify relevant information. While existing MHQA models achieve high accuracy, they often lack interpretability and transparency. We propose a novel Hierarchical Attention Network (HAN) that incorporates attention mechanisms at multiple levels to capture contextual relationships between sentences and entities. Our approach enables the model to generate explicit explanations for its predictions, improving model trustworthiness and facilitating error analysis. Experimental results on the HotPotQA dataset demonstrate that HAN achieves state-of-the-art performance while providing insightful explanations for its reasoning process.