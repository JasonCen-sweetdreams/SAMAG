Autonomous agents operating in partially observable environments often struggle to achieve their goals due to incomplete information. We present a novel cooperative goal-based planning framework that enables agents to share information and coordinate their actions to achieve common objectives. Our approach leverages a decentralized partially observable Markov decision process (Dec-POMDP) model and incorporates a goal-based planning algorithm that adapts to changing environmental conditions. Experimental results demonstrate that our framework outperforms existing approaches in complex scenarios, resulting in improved task completion rates and reduced communication overhead.