Multi-agent reinforcement learning (MARL) has shown promise in various applications, but the lack of transparency in decision-making processes hinders trust and understanding. This paper proposes a novel hierarchical attention network (HAN) framework for explainable MARL. HAN integrates attention mechanisms at both agent and joint action levels, enabling the identification of influential agents and actions in the decision-making process. Our experiments on a set of cooperative and competitive MARL benchmarks demonstrate improved interpretability and policy transparency, while maintaining competitive performance with state-of-the-art MARL methods.