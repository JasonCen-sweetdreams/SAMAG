Voice assistants have become ubiquitous in modern life, but their lack of personalization hinders accessibility for users with disabilities. This paper presents a novel framework, 'Aria', which integrates user modeling and adaptive dialogue management to provide tailored assistance for individuals with visual, hearing, or motor impairments. We conducted a user study with 30 participants, demonstrating significant improvements in task completion rates and user satisfaction when using Aria compared to commercial voice assistants. Our findings emphasize the need for inclusive design in HCI and provide guidelines for future development of accessible voice interfaces.