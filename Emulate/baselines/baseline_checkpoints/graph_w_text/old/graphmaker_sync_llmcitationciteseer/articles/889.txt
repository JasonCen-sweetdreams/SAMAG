E-commerce search queries often lack context, leading to suboptimal retrieval results. This paper introduces 'NQE-MR', a neural query expansion framework that incorporates visual and textual features from product images and descriptions to enhance retrieval performance. Our approach leverages a multimodal transformer to learn joint embeddings of queries and documents, and generates expanded queries that better capture user intent. Experimental results on a large e-commerce dataset demonstrate significant improvements in retrieval precision and recall, especially for queries with ambiguous keywords.