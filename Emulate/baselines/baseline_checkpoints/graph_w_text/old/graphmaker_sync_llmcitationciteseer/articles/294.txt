Graph neural networks (GNNs) have shown promising results in node classification tasks, but their scalability remains a significant challenge. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that leverages a multi-resolution graph representation to reduce computational complexity. HGAT uses a hierarchical clustering algorithm to group nodes into clusters, and then applies attention mechanisms to selectively aggregate features from neighboring clusters. Experimental results on several large-scale graph datasets demonstrate that HGAT achieves state-of-the-art performance while reducing computation time by up to 70% compared to existing GNN models.