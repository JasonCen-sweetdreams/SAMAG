Traditional information retrieval (IR) systems rely on lexical matching and handcrafted features to rank documents. This paper proposes a novel neural approach, 'QueryGraph', which learns to embed queries as graph structures to capture semantic relationships between entities and keywords. Our model leverages a graph attention mechanism to weigh the importance of query nodes and their connections, enabling more accurate document ranking. Experimental results on the TREC benchmarks demonstrate that QueryGraph outperforms state-of-the-art neural IR models, achieving a 12% increase in NDCG@10.