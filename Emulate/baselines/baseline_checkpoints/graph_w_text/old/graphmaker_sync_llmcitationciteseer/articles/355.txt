Autonomous vehicles require efficient and adaptive control systems to navigate complex real-world scenarios. This paper presents a novel deep hierarchical reinforcement learning framework, 'HierRL', which integrates model-based and model-free reinforcement learning to achieve real-time autonomous vehicle control. Our approach leverages a high-level policy to select among a set of pre-trained, specialized controllers, while a low-level policy fine-tunes control outputs based on real-time sensor data. Experimental results on a simulated autonomous driving platform demonstrate that HierRL outperforms state-of-the-art model-free reinforcement learning methods in terms of control smoothness, stability, and adaptability to changing environmental conditions.