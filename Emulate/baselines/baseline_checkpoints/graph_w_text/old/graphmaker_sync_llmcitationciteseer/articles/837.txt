This paper proposes a decentralized multi-agent reinforcement learning framework for autonomous traffic signal control. Our approach, dubbed 'MASTRIC', enables independent agents to learn optimal traffic signal control policies in real-time, without requiring centralized coordination or explicit communication. We introduce a novel graph-based state representation that captures spatial and temporal dependencies between adjacent intersections. Experimental results on a realistic traffic simulator demonstrate that MASTRIC outperforms traditional traffic signal control methods, reducing congestion and travel times by up to 25% in high-traffic scenarios.