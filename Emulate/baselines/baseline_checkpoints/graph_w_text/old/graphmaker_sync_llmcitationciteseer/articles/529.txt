Deep reinforcement learning (DRL) has achieved remarkable success in robotics, but its opaque decision-making process hinders trust and interpretability. This paper presents a novel explainability framework, 'RL-Explain', which leverages attention mechanisms and model-based reasoning to provide insights into DRL policies. We introduce a hierarchical explanation approach that decomposes the policy into understandable components, enabling the identification of critical state features and action influences. Experimental results on robotic grasping and manipulation tasks demonstrate the effectiveness of RL-Explain in improving transparency and trustworthiness of DRL agents.