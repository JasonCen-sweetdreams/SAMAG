This paper explores the design of adaptive gesture-based interfaces for older adults with cognitive impairments. We propose a novel framework that leverages machine learning algorithms to dynamically adjust interface parameters, such as gesture recognition sensitivity and feedback modality, based on individual user performance and cognitive abilities. A user study with 20 participants revealed significant improvements in gesture recognition accuracy and user satisfaction compared to traditional one-size-fits-all approaches. Our findings have implications for the development of more inclusive and accessible human-computer interaction systems.