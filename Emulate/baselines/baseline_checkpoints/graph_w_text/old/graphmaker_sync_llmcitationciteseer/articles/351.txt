Explainability in multi-agent reinforcement learning (MARL) is crucial for real-world applications, but existing methods often lack interpretability. We propose a hierarchical attention network (HAN) framework, which integrates attention mechanisms at both agent-level and system-level to provide insights into agent decision-making. Our method, called HAN-MARL, outperforms state-of-the-art methods in terms of both task performance and explainability metrics on several MARL benchmarks. We demonstrate the effectiveness of HAN-MARL in a real-world robotic swarm control scenario, showcasing its potential for real-world applications.