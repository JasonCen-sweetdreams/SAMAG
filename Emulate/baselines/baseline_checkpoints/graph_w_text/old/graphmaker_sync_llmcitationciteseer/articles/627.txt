Neural retrieval models have shown promising results in information retrieval tasks, but they often rely on manual query formulation and expansion. This paper proposes a novel approach to automate query expansion using contrastive learning. By learning to differentiate between relevant and non-relevant documents, our method generates high-quality expansion terms that improve the retrieval performance of neural models. Experimental results on several benchmark datasets demonstrate the effectiveness of our approach, achieving a 15% increase in mean average precision compared to state-of-the-art query expansion techniques.