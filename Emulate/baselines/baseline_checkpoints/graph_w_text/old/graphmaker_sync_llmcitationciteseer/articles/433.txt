Time series forecasting has become a crucial task in many domains, including finance, healthcare, and climate science. While deep learning models have achieved state-of-the-art performance, they often lack interpretability, making it challenging to understand their predictions. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates both local and global attention mechanisms to model complex temporal dependencies. Our approach enables explainable forecasting by providing insights into the contribution of different time series segments to the predictions. Experimental results on several benchmark datasets demonstrate the effectiveness of HAN in improving forecasting accuracy and providing transparent interpretations.