Ad-hoc retrieval faces the challenge of accurately capturing user intent from short queries. Query expansion techniques can improve retrieval performance, but often rely on manual feature engineering or complex models. This paper proposes a neural semantic embedding approach, 'NeuroQE', which leverages pre-trained language models to generate dense query representations. We introduce a novel semantic similarity metric that integrates both local and global context, enabling more effective expansion of relevant terms. Experimental results on the TREC-8 dataset demonstrate significant improvements in mean average precision and NDCG scores compared to state-of-the-art query expansion methods.