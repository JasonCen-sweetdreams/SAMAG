Individuals with motor impairments often struggle with traditional human-computer interaction methods. This paper explores the potential of gaze-based interfaces as an alternative. We designed an eye-tracking system that leverages machine learning algorithms to detect and classify gazes, enabling users to interact with a graphical user interface. Our user study involving 20 participants with motor impairments reveals significant improvements in interaction speed and accuracy compared to traditional keyboard-mouse interfaces. We also discuss the challenges and limitations of our approach and propose future directions for improving the accessibility of gaze-based interfaces.