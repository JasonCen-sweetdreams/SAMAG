Neural information retrieval (NIR) models have demonstrated impressive performance gains, but often struggle to generalize to unseen queries. This paper proposes a novel query-driven document expansion (QDDE) approach, which leverages a transformer-based query encoder to generate synthetic documents tailored to the query context. We show that QDDE improves the robustness of NIR models to out-of-vocabulary queries and domain shifts, while also reducing the need for expensive re-indexing and re-training. Experimental results on the TREC-CAR and WikiPassage benchmarks demonstrate the effectiveness of QDDE in improving ranking performance and retrieval efficiency.