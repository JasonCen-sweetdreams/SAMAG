Neural retrieval models have achieved state-of-the-art performance in various information retrieval tasks. However, their computational cost hinders their deployment in real-world search engines. This paper presents a novel re-ranking approach that leverages query-specific document embeddings to efficiently select the top-ranked documents. Our method, called QR-Embed, learns to generate query-dependent document representations that capture the semantic relationships between queries and documents. Experimental results on the TREC-CAR dataset demonstrate that QR-Embed reduces the computational cost of re-ranking by 75% while maintaining a 10% increase in retrieval effectiveness compared to the baseline model.