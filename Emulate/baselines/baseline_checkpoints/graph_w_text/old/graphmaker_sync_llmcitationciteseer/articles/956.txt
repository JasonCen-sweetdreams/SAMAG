This paper explores the application of embodied cognition theory to virtual reality (VR) environments, focusing on gesture-based interaction. We designed an immersive VR system that leverages hand tracking and machine learning algorithms to recognize and interpret user gestures. Our user study involving 30 participants demonstrates that the embodied cognition approach significantly enhances user engagement, spatial awareness, and task performance in VR. The results have implications for the design of more intuitive and effective VR interfaces, particularly in domains such as education, training, and therapy.