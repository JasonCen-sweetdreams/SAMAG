Explainable recommendation systems (ERS) have gained popularity in recent years due to the need for transparency in AI-driven decision-making. This paper proposes a novel hierarchical attention network (HAN) architecture for ERS, which incorporates both item-level and user-level attention mechanisms to provide personalized explanations for recommended items. Our approach leverages the strengths of multitask learning and graph neural networks to model complex user-item relationships and generate interpretable explanations. Experimental results on three real-world datasets demonstrate the effectiveness of our approach in improving recommendation accuracy and explanation quality.