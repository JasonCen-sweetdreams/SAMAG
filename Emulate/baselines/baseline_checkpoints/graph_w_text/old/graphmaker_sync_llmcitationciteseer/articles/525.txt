As robots increasingly enter human-centric environments, effective human-robot collaboration (HRC) is crucial. This paper investigates the role of embodied cognition in HRC, focusing on gesture-based interaction. We designed an experiment where human participants collaborated with a robot to assemble a puzzle, using either gesture-based or screen-based interfaces. Our results show that gesture-based interaction improves collaboration outcomes, enhances user experience, and increases cognitive load. We discuss implications for HRC systems that leverage embodied cognition and gesture recognition, highlighting the need for more nuanced understanding of human-robot interaction dynamics.