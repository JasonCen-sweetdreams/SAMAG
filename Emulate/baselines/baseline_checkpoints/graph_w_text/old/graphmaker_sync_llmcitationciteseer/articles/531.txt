Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its black-box nature hinders its adoption in high-stakes domains. This paper presents a novel explainability framework, 'RL-EXPLAIN', which generates interpretable feature importance scores for DRL models. We introduce a hierarchical attention mechanism that disentangles the contribution of different input features to the policy's decisions. Our approach reduces the need for expensive retraining and provides real-time explainability, making it suitable for time-critical applications. Experiments on the Atari 2600 benchmark demonstrate the effectiveness of RL-EXPLAIN in unveiling the decision-making process of DRL agents.