In multi-agent reinforcement learning, learning to cooperate and communicate with other agents is crucial for achieving complex tasks. This paper proposes a novel hierarchical graph attention network (HGAT) architecture, which integrates graph attention mechanisms with hierarchical reinforcement learning. HGAT learns to represent agents as nodes in a graph and selectively focuses on relevant agents and their interactions to make decisions. We demonstrate the effectiveness of HGAT in several multi-agent environments, including traffic management and robot soccer, and show significant improvements over existing methods in terms of cooperation and task completion rate.