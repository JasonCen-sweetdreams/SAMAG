As multi-agent systems become increasingly prevalent, there is a growing need for transparent and explainable decision-making processes. We propose a novel hierarchical attention network (HAN) architecture that enables agents to selectively focus on relevant information and communicate their intentions to other agents. Our approach leverages attention mechanisms to generate interpretable explanations for joint action selection. Experimental results on a simulated multi-agent environment demonstrate that HAN-based agents outperform traditional reinforcement learning methods in terms of both task performance and explanation quality.