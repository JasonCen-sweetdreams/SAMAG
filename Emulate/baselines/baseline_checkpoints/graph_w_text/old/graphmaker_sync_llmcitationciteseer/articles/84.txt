Autonomous vehicles require efficient route planning to minimize travel time and reduce congestion. This paper presents a hierarchical reinforcement learning framework, 'HierRL', that decomposes the route planning problem into a set of interconnected sub-problems. HierRL uses a high-level policy to select the most promising routes and a low-level policy to locally optimize the trajectory. We demonstrate the effectiveness of HierRL on a realistic traffic simulator, showing improved travel times and reduced congestion compared to traditional graph-based methods.