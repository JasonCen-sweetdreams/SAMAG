This paper presents an adaptive multimodal interface framework, 'AccessibleMix', designed to improve the usability and accessibility of digital systems for visually impaired users. We propose a novel fusion of gesture recognition, speech processing, and haptic feedback to create a more inclusive and responsive interaction experience. Our user study involving 30 visually impaired participants demonstrates that AccessibleMix outperforms traditional screen-reader-based interfaces in terms of task completion time and user satisfaction. We also discuss the implications of our findings for the development of more accessible HCI systems.