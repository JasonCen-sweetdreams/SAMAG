Few-shot node classification on graph-structured data remains a challenging task, especially when label information is scarce. This paper proposes a novel hierarchical graph attention network (HiGAT) that leverages self-supervised learning to adapt to new classes with limited labeled data. HiGAT employs a nested attention mechanism to capture hierarchical relationships between nodes, and a meta-learning framework to fine-tune the model for few-shot learning. Our experiments on benchmark graph datasets demonstrate that HiGAT outperforms state-of-the-art methods in few-shot node classification tasks, while requiring minimal labeled data.