Video summarization has gained prominence with the proliferation of online video content. However, existing methods often sacrifice interpretability for the sake of performance. This paper proposes a novel hierarchical attention network, 'HAN-SUM', which generates concise and informative summaries while providing explanations for the selected frames. HAN-SUM employs a two-stage attention mechanism that captures both local and global context, allowing for more accurate summarization and enhanced interpretability. Experimental results on the SumMe and TVSum datasets demonstrate improved performance and human-in-the-loop evaluation confirms the effectiveness of HAN-SUM's explanations.