In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper proposes a novel deep reinforcement learning framework, 'MATAR', which enables autonomous agents to learn task allocation policies in complex, dynamic environments. We introduce a hierarchical architecture that leverages both local and global state information to make decisions, and demonstrate its effectiveness in a simulated disaster response scenario. Experimental results show that MATAR outperforms traditional approaches in terms of task completion rate, response time, and overall system efficiency.