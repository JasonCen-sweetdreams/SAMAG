We propose a decentralized task allocation framework for autonomous agents that leverages multi-agent reinforcement learning (MARL). Our approach, called 'DAGMA', enables agents to learn to coordinate and allocate tasks in a distributed manner, without relying on a centralized controller. We formulate the task allocation problem as a decentralized partially observable Markov decision process (Dec-POMDP) and employ a MARL algorithm that incorporates a communication mechanism to facilitate cooperation among agents. Experimental results demonstrate that DAGMA outperforms traditional centralized and distributed allocation methods in terms of task completion time and resource utilization.