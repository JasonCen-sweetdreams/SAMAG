This paper presents a novel approach to gaze-based interaction in virtual reality (VR) environments using deep reinforcement learning. We propose a policy gradient-based method that leverages the user's gaze patterns to infer their intent and perform corresponding actions in the VR scene. Our approach is capable of adapting to individual users' behavior and preferences, resulting in improved interaction accuracy and reduced user fatigue. We evaluate our method using a custom-built VR platform and demonstrate significant performance gains compared to traditional gaze-based interaction techniques.