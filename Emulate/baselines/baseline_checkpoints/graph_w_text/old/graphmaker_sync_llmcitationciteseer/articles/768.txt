Explainability is crucial in multi-agent cooperative reinforcement learning (MACRL) as it enables understanding agent behaviors and decision-making processes. We introduce Hierarchical Attention Networks (HANs), a novel architecture that integrates attention mechanisms at both the agent and team levels to provide interpretable insights into agent coordination and cooperation. HANs outperform state-of-the-art MACRL methods on several cooperative tasks, demonstrating improved explainability and robustness. We also propose a novel evaluation metric, Explainability Score (ES), to quantify the interpretability of MACRL models.