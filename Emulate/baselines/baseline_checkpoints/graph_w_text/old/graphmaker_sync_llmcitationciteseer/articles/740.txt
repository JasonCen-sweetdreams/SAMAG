Deep neural ranking models have shown great promise in information retrieval tasks, but their computational complexity and memory requirements can be prohibitive. This paper proposes a novel document representation technique, termed 'Doc2Vec-SIFT', which combines the strengths of dense vector representations and sparse, interpretable features. We demonstrate that Doc2Vec-SIFT can reduce the dimensionality of document embeddings by up to 90% while maintaining or improving ranking performance on several benchmark datasets. Our approach enables the efficient deployment of deep neural ranking models in large-scale information retrieval systems.