In multi-agent systems, decision-making processes are often opaque and difficult to interpret. This paper presents a novel Hierarchical Attention Network (HAN) architecture that enables explainable decision-making in multi-agent settings. Our approach incorporates attention mechanisms at both the agent and system levels, allowing for transparent attribution of decisions to individual agents and their interactions. We evaluate the proposed HAN framework on a suite of benchmark environments, demonstrating improved decision-making performance and enhanced explainability compared to state-of-the-art baselines.