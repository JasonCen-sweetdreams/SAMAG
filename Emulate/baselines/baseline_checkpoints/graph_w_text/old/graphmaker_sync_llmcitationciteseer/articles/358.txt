Graph neural networks (GNNs) have shown remarkable success in node representation learning tasks. However, existing methods often suffer from high computational complexity and scalability issues. In this paper, we propose a novel hierarchical GNN architecture, HierGraph, which leverages a hierarchical clustering approach to reduce the graph size while preserving node relationships. We demonstrate that HierGraph achieves state-of-the-art performance on several benchmark datasets, including Reddit and Flickr, while reducing the computational cost by up to 70%. Our experiments also show that HierGraph is more robust to graph perturbations and outliers compared to existing methods.