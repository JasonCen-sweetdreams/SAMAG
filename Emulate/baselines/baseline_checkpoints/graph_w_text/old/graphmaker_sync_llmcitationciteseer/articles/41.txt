Decentralized task allocation is a fundamental problem in multi-agent systems, where agents must coordinate to accomplish complex tasks. This paper proposes a novel approach using graph neural networks (GNNs) to learn decentralized task allocation policies. Our method, called DAGAT, represents the agent-task graph as a heterogeneous graph and uses a GNN to learn a policy that maximizes the overall utility of the system. We demonstrate the effectiveness of DAGAT in a series of experiments on synthetic and real-world datasets, showing improved performance compared to traditional decentralized algorithms. Our approach enables the deployment of large-scale multi-agent systems in real-world applications such as disaster response and smart cities.