Time series forecasting is a crucial task in various domains, but most state-of-the-art models lack interpretability. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that incorporates explainability into time series forecasting. HAN leverages multi-scale attention mechanisms to identify relevant patterns and dependencies across different time granularities. We introduce a novel attention-based feature importance metric that provides insights into the model's decision-making process. Experimental results on several benchmark datasets demonstrate that HAN outperforms existing state-of-the-art models while providing transparent and interpretable predictions.