Time series forecasting has become a crucial task in various domains, but the lack of transparency in traditional neural network models hinders trust and reliability. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable time series forecasting. Our model utilizes a hierarchical encoder to extract features at multiple scales, and incorporates a attention mechanism to weigh the importance of different temporal segments. We further introduce a novel interpretability module that generates local and global attribution scores, enabling users to understand the contributing factors to the forecasted values. Experimental results on several benchmark datasets demonstrate the superiority of our HAN model in terms of forecasting accuracy and interpretability.