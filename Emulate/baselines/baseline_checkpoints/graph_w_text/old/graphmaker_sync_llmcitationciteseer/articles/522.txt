Wearable devices have become increasingly popular, but their gesture recognition capabilities are often limited by the complexity of user interactions. This paper presents a novel machine learning-based approach to adaptive gesture recognition, which leverages a hybrid convolutional-recurrent neural network (CRNN) to learn robust patterns from sensor data. Our approach incorporates a transfer learning strategy that enables the model to adapt to new users and gestures with minimal retraining. We evaluate our approach on a benchmark dataset and demonstrate significant improvements in recognition accuracy and latency compared to traditional machine learning and rule-based methods.