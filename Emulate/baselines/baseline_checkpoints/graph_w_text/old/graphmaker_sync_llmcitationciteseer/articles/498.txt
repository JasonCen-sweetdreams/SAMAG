Multi-agent reinforcement learning (MARL) has applications in various domains, including robotics and finance. However, the lack of transparency in MARL models hinders their adoption in high-stakes scenarios. This paper proposes a novel hierarchical attention framework, 'HAT-MARL', which incorporates explainability into MARL. Our approach uses attention mechanisms to highlight the importance of individual agents and their interactions, enabling interpretable decision-making. We evaluate HAT-MARL on a suite of cooperative and competitive MARL benchmarks, demonstrating improved performance and explainability compared to state-of-the-art methods.