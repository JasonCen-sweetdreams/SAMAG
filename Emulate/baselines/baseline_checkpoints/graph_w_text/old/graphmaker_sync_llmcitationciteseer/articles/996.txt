This paper proposes a novel approach to coordinated task allocation in multi-agent systems using deep reinforcement learning. Our method, called 'CATALYST', leverages a decentralized actor-critic framework to learn effective task assignment policies in complex, dynamic environments. We demonstrate the efficacy of CATALYST in a simulated disaster response scenario, where multiple agents must cooperate to allocate tasks and resources in real-time. Experimental results show that CATALYST outperforms traditional, centralized optimization methods in terms of task completion efficiency and robustness to agent failures.