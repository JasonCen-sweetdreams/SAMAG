Decentralized task allocation is a fundamental problem in multi-agent systems, where agents must coordinate to achieve a common goal without a central authority. This paper proposes a novel approach using deep reinforcement learning to learn decentralized policies for task allocation. We introduce a new algorithm, 'Dec-TAC', which utilizes a decentralized actor-critic architecture to learn coordination strategies from scratch. Our experimental results demonstrate that Dec-TAC outperforms state-of-the-art decentralized methods in various task allocation scenarios, achieving improved efficiency, scalability, and adaptability in dynamic environments.