Deep neural ranking models have shown remarkable performance in ad-hoc retrieval tasks, but the effectiveness of query expansion techniques in these models remains understudied. This paper investigates the impact of query expansion on the performance of state-of-the-art neural ranking models, including BERT-based and convolutional neural network (CNN) architectures. We propose a novel query expansion method based on contextualized embeddings and evaluate its effectiveness on several standard TREC datasets. Experimental results demonstrate that our approach significantly improves the retrieval performance of neural ranking models, especially when combined with relevance feedback.