Decentralized task allocation is a fundamental problem in multi-agent systems, where agents must coordinate to optimize task assignments without a central authority. This paper presents a novel reinforcement learning approach, 'Dec-TARL', which enables agents to learn decentralized task allocation policies through self-play. We introduce a hierarchical architecture that integrates graph neural networks with deep Q-networks, allowing agents to reason about task dependencies and agent capabilities. Experimental results on a variety of task allocation scenarios demonstrate that Dec-TARL outperforms traditional decentralized allocation methods while adapting to changes in task requirements and agent availability.