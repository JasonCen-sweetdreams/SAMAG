Individuals with motor impairments often face difficulties interacting with gesture-based systems. This paper presents a novel adaptive gesture recognition approach, 'GESTalt', which leverages machine learning and HCI principles to accommodate diverse motor abilities. GESTalt incorporates a user profiling module that dynamically adjusts gesture recognition thresholds based on the individual's motor capabilities, allowing for more accurate and efficient gesture recognition. Our user study with 20 participants with motor impairments demonstrates significant improvements in gesture recognition accuracy and user satisfaction compared to traditional gesture recognition systems.