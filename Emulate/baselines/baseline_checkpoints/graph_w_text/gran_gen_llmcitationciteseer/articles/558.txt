Augmented reality (AR) has transformed the way we interact with virtual objects, but current input methods, such as voice commands or manual gestures, have limitations. This paper presents a novel gaze-based interaction system for AR using deep learning. Our approach leverages convolutional neural networks (CNNs) to classify gaze patterns and detect user intentions. We introduce a new gaze dataset and demonstrate the effectiveness of our system in various AR scenarios, including object selection and manipulation. Experimental results show that our approach outperforms state-of-the-art methods in terms of accuracy and user experience.