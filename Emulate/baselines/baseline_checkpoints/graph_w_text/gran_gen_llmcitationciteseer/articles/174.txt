Urban traffic management is a complex problem that requires efficient coordination of autonomous agents to minimize congestion and reduce travel times. This paper proposes a hierarchical reinforcement learning framework for coordinating autonomous agents in urban traffic management. Our approach consists of two levels: a high-level planner that allocates agents to different regions of the city and a low-level controller that determines the optimal actions for each agent. We evaluate our approach using a simulated urban traffic environment and demonstrate significant improvements in traffic flow and travel times compared to traditional approaches.