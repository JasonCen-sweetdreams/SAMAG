Resource allocation in multi-agent systems is a complex problem that requires efficient coordination among agents. This paper proposes a hierarchical reinforcement learning framework, 'HRL-MA', that enables agents to learn optimal resource allocation strategies in a decentralized manner. We introduce a novel hierarchical architecture that decomposes the global problem into smaller sub-problems, allowing agents to focus on local resource allocation while coordinating with other agents through a higher-level coordination layer. Experimental results on a simulated resource allocation scenario demonstrate that HRL-MA outperforms traditional reinforcement learning methods in terms of convergence speed and allocation efficiency.