Deep reinforcement learning (DRL) has shown remarkable success in various autonomous systems, but its lack of explainability hinders trust and wide adoption. This paper proposes a novel framework, 'ExplainDRL', which integrates model-based and model-free reinforcement learning to provide interpretable policies for real-world autonomous systems. We introduce a attention-based explanation module that visualizes the decision-making process of the DRL agent, enabling humans to understand and correct its behavior. Experimental results on a real-world autonomous driving dataset demonstrate the effectiveness of ExplainDRL in improving transparency, safety, and performance.