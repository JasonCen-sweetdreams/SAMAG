Efficient task allocation is a crucial problem in multi-agent systems, where agents with diverse capabilities need to be assigned to tasks with varying requirements. This paper proposes a novel distributed task allocation framework that leverages graph convolutional networks (GCNs) to model agent-task interactions. Our approach, called GraphAgent, uses a decentralized architecture where agents communicate with their neighbors to learn a shared representation of the task graph. Experimental results on several benchmark datasets demonstrate that GraphAgent outperforms state-of-the-art methods in terms of task completion rate, makespan, and communication overhead.