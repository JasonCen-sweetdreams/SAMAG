Traditional ranking models in information retrieval rely on lexical matching, which can be limited by the vocabulary gap between queries and documents. This paper proposes a novel adaptive ranking approach that leverages hierarchical embeddings to capture semantic relationships between queries and documents. Our method, HierRank, integrates a graph-based neural network with a probabilistic relevance model to estimate document relevance. Experimental results on the ClueWeb09 dataset demonstrate that HierRank outperforms state-of-the-art neural ranking models in terms of ranking accuracy and efficiency, particularly for long-tail queries.