In multi-agent systems, coordinated exploration is crucial for efficient task allocation and planning. This paper introduces a novel hierarchical graph attention mechanism, 'HGA-MAS', which enables agents to selectively focus on relevant nodes in the environment graph. HGA-MAS combines graph convolutional neural networks with attention weights learned through reinforcement learning. Experimental results in a simulated warehouse robotics scenario demonstrate that HGA-MAS outperforms existing methods in terms of exploration efficiency and task completion rate, especially in large-scale and dynamic environments.