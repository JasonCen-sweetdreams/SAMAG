This paper presents a novel approach to coordinating multi-agent systems for dynamic task allocation using reinforcement learning. We propose a decentralized framework, 'MA-RL-Allocator', which enables agents to learn optimal task allocation policies based on their local observations and interactions. Our approach integrates a deep Q-network with a graph neural network to model agent relationships and task dependencies. Experimental results on a simulated urban transportation scenario demonstrate that MA-RL-Allocator outperforms traditional planning-based methods in terms of task completion rate and agent utility.