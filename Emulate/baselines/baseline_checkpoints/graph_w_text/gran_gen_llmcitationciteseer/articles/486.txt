Voice assistants have become ubiquitous in modern life, but their conversational understanding is often limited by a lack of embodiment and social context. This paper presents an embodied cognition approach to designing more inclusive voice assistants, focusing on the role of multimodal cues and social priming in shaping conversational understanding. We conducted a series of user studies to investigate how users' mental models of voice assistants influence their interaction behaviors and perceived understanding. Our findings inform the design of a novel voice assistant framework that incorporates embodied cognition principles, demonstrating improved conversational understanding and user satisfaction.