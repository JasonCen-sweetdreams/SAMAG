Conventional learning-to-rank models for information retrieval often prioritize relevance over diversity, leading to redundant search results. This paper proposes a novel reinforcement learning framework, 'DIVERSE', that optimizes document ranking to balance relevance and diversity. Our approach employs a hierarchical reinforcement learning architecture, where a high-level policy learns to select a diverse set of documents, and a low-level policy refines the ranking within each selected set. Experimental results on the ClueWeb09 dataset demonstrate significant improvements in both relevance and diversity metrics compared to state-of-the-art baselines.