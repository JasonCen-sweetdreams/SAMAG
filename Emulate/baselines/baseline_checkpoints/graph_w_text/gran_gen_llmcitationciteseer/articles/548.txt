Explainable reinforcement learning (XRL) is crucial for trustworthy autonomous vehicle decision-making. This paper proposes 'HierXRL', a hierarchical framework that integrates XRL with deep reinforcement learning to improve transparency and interpretability in complex driving scenarios. Our approach involves (1) feature importance-based attention, (2) hierarchical abstraction of state and action spaces, and (3) model-based reinforcement learning. We evaluate HierXRL on a realistic driving simulator and demonstrate improved explainability, safety, and overall performance compared to state-of-the-art XRL methods.