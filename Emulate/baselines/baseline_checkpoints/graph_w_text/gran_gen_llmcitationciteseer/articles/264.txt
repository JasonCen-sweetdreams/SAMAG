Neural ranking models have achieved state-of-the-art performance in information retrieval tasks, but they often struggle with limited training data. This paper proposes a novel query expansion method that leverages pseudo-relevance feedback to improve the effectiveness of neural ranking models. Our approach, called 'PRF-Net', uses a neural network to predict the relevance of expansion terms and integrates them into the original query. We evaluate PRF-Net on several benchmark datasets and demonstrate significant improvements in ranking quality compared to traditional query expansion methods. Our analysis shows that PRF-Net is particularly effective in scenarios with limited training data, making it a promising approach for real-world IR applications.