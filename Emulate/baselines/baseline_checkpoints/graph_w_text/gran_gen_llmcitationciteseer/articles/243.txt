Coordinating heterogeneous agents in complex environments is a fundamental challenge in multi-agent systems. This paper proposes a novel framework that leverages hierarchical task decomposition and reinforcement learning to enable effective coordination among agents with diverse capabilities and goals. We introduce a hierarchical task graph that captures the relationships between high-level tasks and low-level actions, and a deep reinforcement learning algorithm that learns to allocate tasks to agents based on their strengths and weaknesses. Experimental results on a simulated search-and-rescue scenario demonstrate the effectiveness of our approach in achieving global objectives while adapting to dynamic environments and agent failures.