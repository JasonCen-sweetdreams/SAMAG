Deep reinforcement learning (DRL) has achieved remarkable success in robotics, but its lack of interpretability hinders trust and adoptability. This paper proposes a novel hierarchical attention mechanism, 'HierAttn', which selectively focuses on relevant state and action features to improve DRL explainability. We demonstrate the effectiveness of HierAttn on a robotic arm grasping task, where it outperforms state-of-the-art DRL methods in terms of both performance and interpretability. Furthermore, we provide visualizations and feature importance analysis to illustrate the attention mechanism's decision-making process.