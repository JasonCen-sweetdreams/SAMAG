In this paper, we address the problem of distributed task allocation in heterogeneous multi-agent systems, where agents have varying capabilities and task requirements. We propose a novel reinforcement learning-based approach, called HRL-TA, which learns to allocate tasks effectively by considering the agents' strengths, weaknesses, and task dependencies. Our approach leverages a hierarchical Q-network architecture to handle the complexities of large-scale systems. Experimental results on a variety of robotic task allocation scenarios demonstrate that HRL-TA outperforms state-of-the-art methods in terms of task completion efficiency and system adaptability.