As autonomous vehicles (AVs) become increasingly prevalent, coordinating their actions to ensure safe and efficient traffic flow is a crucial challenge. This paper presents a novel approach to distributed multi-agent reinforcement learning for coordinating AVs in complex scenarios. Our method, dubbed 'MARL-Co', leverages a decentralized actor-critic framework to enable AVs to learn cooperative policies in real-time. We demonstrate MARL-Co's effectiveness in reducing congestion and improving travel times in a simulated urban environment, outperforming traditional rule-based approaches.