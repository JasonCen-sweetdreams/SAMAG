Coordinating autonomous agents in complex, dynamic environments is a challenging problem. This paper proposes a novel approach using decentralized partially observable Markov decision processes (Dec-POMDPs) to model and solve the coordination problem. We introduce a decentralized planning algorithm that allows agents to learn and adapt to their local observations and communicate with each other to achieve a common goal. Experimental results in a simulated search-and-rescue scenario demonstrate the effectiveness of our approach in improving coordination and reducing collisions among agents.