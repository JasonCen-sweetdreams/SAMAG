Coordinating multiple agents in complex, dynamic environments is a challenging problem in Artificial Intelligence. While recent advances in deep reinforcement learning have shown promise, they often lack transparency and interpretability. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that enables explainable multi-agent cooperation. By incorporating attention mechanisms at both the agent-level and team-level, HANs can selectively focus on relevant communication channels and task-oriented features, leading to improved cooperation and decision-making. We evaluate our approach on a simulated search-and-rescue scenario, demonstrating significant performance gains and providing insights into the coordination strategies learned by the HAN.