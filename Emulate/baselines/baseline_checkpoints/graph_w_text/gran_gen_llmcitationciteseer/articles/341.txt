Virtual reality (VR) has the potential to revolutionize accessibility, but current interaction methods can be cumbersome for users with disabilities. This paper presents 'EyeGuide', an adaptive VR interaction system that leverages eye-tracking to enable users to navigate and interact with virtual environments using gaze-based commands. We conducted a user study with 20 participants, including individuals with mobility and visual impairments, to evaluate the effectiveness of EyeGuide. Results show that EyeGuide significantly improves interaction accuracy and speed, while reducing user fatigue and discomfort. Our approach has implications for enhancing accessibility in VR-based applications, including gaming, education, and healthcare.