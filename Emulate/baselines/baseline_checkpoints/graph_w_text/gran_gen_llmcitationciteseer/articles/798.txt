This paper presents a decentralized multi-agent reinforcement learning approach for coordinating traffic signal control in urban transportation networks. We model the problem as a Markov game, where each agent represents a traffic signal and learns to optimize its control policy based on local observations and communication with neighboring agents. Our proposed algorithm, 'MAST', incorporates a novel attention mechanism to focus on critical intersections and adapt to changing traffic patterns. Simulation results on a large-scale traffic network demonstrate that MAST outperforms traditional optimization methods and state-of-the-art reinforcement learning baselines, reducing congestion and travel times by up to 25%.