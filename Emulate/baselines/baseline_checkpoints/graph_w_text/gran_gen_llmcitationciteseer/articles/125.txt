As multi-agent systems become increasingly pervasive, understanding the decision-making processes of AI agents is crucial. This paper presents a novel hierarchical attention network (HAN) architecture for explainable multi-agent reinforcement learning. Our approach enables agents to selectively focus on relevant information from other agents and the environment, leading to improved cooperation and task performance. We evaluate our method on a set of challenging multi-agent environments, demonstrating significant gains in interpretability and adaptability compared to state-of-the-art methods.