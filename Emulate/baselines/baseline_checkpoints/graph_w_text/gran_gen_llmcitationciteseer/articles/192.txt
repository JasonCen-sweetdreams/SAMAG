This paper addresses the problem of decentralized task allocation in multi-agent systems, where agents with varying capabilities and preferences need to coordinate to accomplish complex tasks. We propose a novel approach based on deep reinforcement learning, where each agent learns to optimize its task allocation policy using a decentralized, asynchronous actor-critic framework. Our algorithm, called 'Dec-TAR', leverages graph neural networks to model agent interactions and achieves state-of-the-art performance in a variety of benchmark scenarios. We demonstrate the effectiveness of Dec-TAR in a simulated disaster response scenario, where agents need to coordinate to rescue victims and allocate resources.