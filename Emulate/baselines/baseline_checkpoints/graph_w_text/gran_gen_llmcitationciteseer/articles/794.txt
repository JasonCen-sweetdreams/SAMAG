Cloud computing providers face the challenge of efficiently allocating resources to meet dynamic user demands. This paper presents a hierarchical reinforcement learning (HRL) framework, 'CloudOpt', that learns to optimize resource allocation in cloud data centers. CloudOpt employs a two-level hierarchy, where a high-level policy selects a subset of resources and a low-level policy allocates those resources to specific tasks. We introduce a novel reward function that incorporates both performance and energy efficiency metrics. Experimental results on a real-world cloud dataset demonstrate that CloudOpt outperforms existing approaches in terms of resource utilization, task completion time, and energy consumption.