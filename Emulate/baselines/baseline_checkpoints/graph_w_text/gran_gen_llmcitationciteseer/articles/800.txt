Event extraction from multi-modal data sources has become a crucial task in various applications. However, existing methods struggle to capture complex relationships between entities and events. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) that integrates graph neural networks with hierarchical attention mechanisms. HGAT learns to represent events as graph structures and attends to relevant entities and modalities (e.g., text, images) at multiple scales. Experimental results on a benchmark dataset demonstrate that HGAT outperforms state-of-the-art methods in event extraction accuracy and robustness to noise.