As virtual reality (VR) technology becomes increasingly prevalent, ensuring accessibility for users with disabilities remains a critical challenge. This paper presents 'AdaptGest', a machine learning-based framework that dynamically adjusts gesture recognition parameters to accommodate individual differences in motor abilities. Our approach leverages a novel combination of skeletal tracking and electromyography data to recognize gestures, achieving a 35% improvement in recognition accuracy for users with motor impairments compared to existing state-of-the-art methods. We evaluate AdaptGest through a user study with 20 participants, demonstrating its potential to enhance VR accessibility and usability.