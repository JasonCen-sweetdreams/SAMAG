Multi-label node classification is a fundamental problem in graph-structured data, where each node can belong to multiple classes. Existing approaches suffer from scalability issues and fail to capture complex relationships between labels. We propose a hierarchical graph attention network (HGAT) that learns to recursively aggregate node features and attentional weights at multiple scales. HGAT outperforms state-of-the-art methods on several benchmark datasets, achieving significant improvements in F1-score and AUC-ROC. Additionally, we provide theoretical insights into the expressive power of HGAT and its robustness to label noise.