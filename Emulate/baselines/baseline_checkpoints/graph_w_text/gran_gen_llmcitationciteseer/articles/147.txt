Query expansion (QE) is a crucial component in ad-hoc retrieval systems, but existing methods often rely on handcrafted rules or simplistic machine learning models. This paper proposes a novel QE approach, 'RL-QE', which leverages reinforcement learning to optimize the expansion process. By formulating QE as a Markov decision process, our model learns to select the most informative expansion terms and adapt to varying query contexts. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art methods, achieving significant improvements in retrieval effectiveness and efficiency.