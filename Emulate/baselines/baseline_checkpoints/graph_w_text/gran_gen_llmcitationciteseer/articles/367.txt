Deep reinforcement learning (DRL) has achieved remarkable success in various domains, including multi-agent systems. However, the vulnerability of DRL policies to adversarial attacks remains a significant concern. This paper investigates the adversarial robustness of DRL policies in the presence of multi-agent interactions. We propose a novel framework, 'MARL-ROBUST', which incorporates adversarial training and attention mechanisms to enhance the robustness of DRL policies. Experimental results demonstrate that MARL-ROBUST significantly improves the robustness of DRL policies against various types of adversarial attacks, while maintaining competitive performance in complex multi-agent environments.