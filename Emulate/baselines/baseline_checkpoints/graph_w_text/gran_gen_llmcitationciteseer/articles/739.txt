Relational knowledge graphs (RKGs) are a crucial component of many AI applications. However, existing graph neural networks (GNNs) struggle to effectively capture the complex relational structures present in RKGs. We propose a novel Hierarchical Attention-based Graph Neural Network (HAGNN) framework that leverages attention mechanisms to selectively focus on relevant relational paths during embedding. Our experiments on the WN18RR and FB15K-237 datasets demonstrate significant improvements in link prediction and triple classification tasks compared to state-of-the-art GNN-based methods.