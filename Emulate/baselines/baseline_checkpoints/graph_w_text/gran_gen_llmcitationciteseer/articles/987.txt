Knowledge graph embeddings have become a crucial component in various AI applications, but their interpretability remains a significant challenge. This paper presents a novel hierarchical graph attention network (HGAN) for learning explainable knowledge graph embeddings. HGAN leverages a hierarchical attention mechanism to selectively focus on relevant entities and relationships, enabling the model to provide interpretable explanations for its predictions. We evaluate HGAN on several benchmark datasets and demonstrate its effectiveness in improving embedding quality and interpretability. Furthermore, we provide a thorough analysis of the learned attention weights, revealing insightful patterns in the knowledge graph structure.