Graph neural networks (GNNs) have become increasingly popular for node classification tasks, but their robustness to adversarial attacks remains largely unexplored. This paper presents a comprehensive evaluation of the robustness of popular node embedding techniques, including GraphSAGE, GCN, and GIN, against various adversarial attack strategies. Our experiments on multiple benchmark datasets reveal that GNNs are vulnerable to targeted attacks, which can significantly degrade their performance. We also propose a novel defense mechanism based on adversarial training and graph purification, which demonstrates improved robustness against such attacks.