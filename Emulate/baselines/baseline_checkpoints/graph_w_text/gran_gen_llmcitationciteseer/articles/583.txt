Query expansion is a crucial technique to improve the retrieval effectiveness of search engines. However, traditional methods often rely on manual rules or simplistic statistical models, which may not capture the semantic relationships between query terms and documents. This paper proposes a novel context-aware embedding approach, dubbed 'CAQE', which leverages pre-trained language models to learn dense vector representations of query terms and documents. By incorporating contextual information from the query and document collections, CAQE can adaptively generate expansion terms that better match the user's search intent. Experimental results on the TREC-8 dataset demonstrate that CAQE significantly outperforms state-of-the-art query expansion methods in terms of retrieval precision and recall.