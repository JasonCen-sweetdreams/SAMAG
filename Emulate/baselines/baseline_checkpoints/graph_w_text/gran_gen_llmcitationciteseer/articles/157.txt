Voice assistants have become ubiquitous, but users with dysarthria, a speech disorder characterized by impaired articulation and pronunciation, often struggle to interact with these systems effectively. This paper presents an empirical study investigating the challenges faced by individuals with dysarthria when using commercial voice assistants. We report on a user-centered design approach to develop an inclusive voice assistant prototype that incorporates acoustic models tailored to dysarthric speech patterns. Our results show significant improvements in speech recognition accuracy and user experience, highlighting the importance of inclusive design in HCI.