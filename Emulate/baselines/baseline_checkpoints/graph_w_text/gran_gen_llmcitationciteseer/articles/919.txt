Real-world classification tasks often exhibit long-tailed distributions, where a few dominant classes overshadow the remaining minority classes. This paper introduces a novel Hierarchical Attention Network (HAN) architecture that tackles long-tailed classification by adaptively weighting class attention based on instance similarity. HAN consists of a feature extraction module, a hierarchical attention module, and a classification head. We demonstrate the efficacy of HAN on several benchmark datasets, achieving state-of-the-art performance while reducing computational costs by up to 30%. Our approach is particularly effective for classes with limited training data, improving minority class accuracy by up to 15%.