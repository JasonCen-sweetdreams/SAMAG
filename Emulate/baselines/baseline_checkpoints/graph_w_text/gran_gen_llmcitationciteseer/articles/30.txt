Coordinating multiple agents to achieve common goals is a fundamental problem in multi-agent systems. While deep reinforcement learning has shown promise, interpretability remains a significant challenge. This paper introduces a novel Hierarchical Graph Attention Network (HGAT) architecture that learns to represent agent interactions and intentions in a explainable manner. By aggregating local graph attention mechanisms, HGAT captures hierarchical relationships between agents and their environment. We evaluate HGAT on a range of cooperative tasks, demonstrating improved performance and interpretability compared to state-of-the-art methods.