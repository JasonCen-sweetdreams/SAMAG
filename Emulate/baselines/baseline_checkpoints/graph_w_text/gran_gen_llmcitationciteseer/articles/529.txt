Conversational AI systems rely on accurate intent detection to provide relevant responses. Existing approaches often struggle with complex, multi-turn dialogues and contextual dependencies. We propose a novel hierarchical attention graph neural network (HAGNN) architecture that models conversation structures and captures subtle intent cues. HAGNN leverages graph attention mechanisms to identify salient context nodes and hierarchical attention to integrate information across turns. Experimental results on a large-scale conversational dataset demonstrate significant improvements in intent detection accuracy and robustness compared to state-of-the-art models.