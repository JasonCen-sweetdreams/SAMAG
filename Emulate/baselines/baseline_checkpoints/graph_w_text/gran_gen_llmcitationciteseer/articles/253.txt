Wearable devices have enabled various applications, including gesture recognition, which is crucial for human-computer interaction. However, existing methods suffer from limited generalizability across different users and environments. This paper proposes a novel approach that combines transfer learning and domain adaptation to develop a personalized gesture recognition system. Our method leverages a large-scale gesture dataset to pre-train a deep neural network, which is then fine-tuned on a small amount of user-specific data using adversarial domain adaptation. Experimental results demonstrate that our approach outperforms state-of-the-art methods in terms of recognition accuracy and robustness, while requiring minimal user calibration data.