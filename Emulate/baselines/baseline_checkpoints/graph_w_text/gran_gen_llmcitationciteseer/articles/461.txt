Virtual reality (VR) systems often rely on manual controllers for navigation, which can be cumbersome and detract from the immersive experience. This paper presents EyeGazePath, a gaze-based navigation system that leverages machine learning-driven eye tracking to enable seamless movement in VR environments. Our approach combines convolutional neural networks (CNNs) with saliency maps to accurately predict user gaze targets, achieving a mean navigation error of 12.5Â° in a user study. We also introduce a novel gaze stabilization technique that reduces eye movement noise and enhances overall system performance.