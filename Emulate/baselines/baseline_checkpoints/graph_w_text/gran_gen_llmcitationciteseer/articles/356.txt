This paper presents a decentralized multi-agent reinforcement learning framework for autonomous traffic signal control. We propose a novel communication protocol that enables agents to share local information and coordinate their actions in real-time. Our approach leverages graph neural networks to model the complex interactions between agents and the dynamic traffic environment. Experimental results on a simulated traffic network demonstrate improved traffic flow and reduced congestion compared to traditional, centralized control methods. We also analyze the robustness of our approach to varying agent densities and communication delays.