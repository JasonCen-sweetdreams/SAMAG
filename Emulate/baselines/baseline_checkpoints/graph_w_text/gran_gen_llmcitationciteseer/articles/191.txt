 Gesture recognition systems have transformed human-computer interaction, but their performance varies significantly across individuals, particularly those with motor impairments. This paper presents 'Adapta Gesture', a novel framework that leverages machine learning and computer vision to develop adaptive gesture recognition systems. Our approach combines a deep learning-based gesture recognition model with a user modeling component that dynamically adjusts to an individual's abilities and preferences. We conduct a user study with 25 participants, including 10 with motor impairments, and demonstrate improved recognition accuracy and user satisfaction compared to existing state-of-the-art systems.