Knowledge graph embeddings (KGEs) have become a crucial component in various AI applications. However, existing methods suffer from high computational costs and limited scalability. This paper proposes a novel hierarchical graph attention network (HGAN) for efficient KGEs. HGAN leverages a hierarchical graph structure to adaptively focus on relevant entities and relationships, reducing the computational complexity of attention mechanisms. Experimental results on popular benchmarks demonstrate that HGAN achieves state-of-the-art performance in link prediction and entity classification tasks while requiring significantly fewer parameters and computations.