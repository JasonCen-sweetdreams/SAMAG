Few-shot learning has seen significant progress in recent years, but most approaches focus on a single task or dataset. In real-world scenarios, models often need to adapt to new tasks with limited data. This paper proposes a hierarchical few-shot learning framework, 'HATTE', which leverages adaptive task embeddings to facilitate knowledge transfer across tasks. Our approach uses a meta-learning strategy to learn task-specific embeddings that capture the underlying structure of each task. We demonstrate the effectiveness of HATTE on several benchmark image classification datasets, achieving state-of-the-art performance in few-shot and zero-shot settings.