In this paper, we propose a decentralized task allocation framework for autonomous vehicles using multi-agent reinforcement learning. Our approach, called 'MATRL', enables a team of autonomous vehicles to dynamically allocate tasks in real-time, taking into account their individual capabilities, resources, and environmental constraints. We formulate the task allocation problem as a decentralized Markov decision process and develop a novel multi-agent Q-learning algorithm that incorporates communication and coordination mechanisms. Experimental results in a simulated urban environment demonstrate that MATRL outperforms traditional centralized allocation methods in terms of task completion rate, latency, and system scalability.