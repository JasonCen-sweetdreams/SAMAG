This paper proposes a novel multi-agent reinforcement learning framework for real-time traffic signal control. Our approach, dubbed 'Traffic Harmony', leverages a decentralized actor-critic architecture to optimize signal timing across multiple intersections. By incorporating domain knowledge of traffic flow dynamics into the policy learning process, we demonstrate substantial reductions in congestion and travel times compared to traditional fixed-time control strategies. We evaluate Traffic Harmony on a realistic simulation of the Pittsburgh city network, showcasing its potential for large-scale deployment.