Ad-hoc search systems often struggle to accurately capture user intent, leading to suboptimal retrieval results. Query expansion (QE) techniques can mitigate this issue, but existing methods rely on simplistic term weighting schemes. This paper proposes a novel QE approach, GraphAttention-QE, which leverages graph attention networks to model complex relationships between query terms and their contextual neighbors. Our method learns to focus on the most informative terms and their interactions, resulting in more effective query representations. Experimental evaluations on several TREC datasets demonstrate that GraphAttention-QE outperforms state-of-the-art QE techniques, leading to significant improvements in retrieval performance.