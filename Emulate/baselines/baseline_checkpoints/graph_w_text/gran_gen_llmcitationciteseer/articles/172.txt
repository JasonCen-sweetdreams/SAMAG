Knowledge graph embedding (KGE) has been widely employed in various AI applications, but existing methods suffer from limitations in handling complex graph structures and scalability issues. This paper proposes a novel hierarchical graph attention network (HGAT) for efficient KGE. HGAT leverages a hierarchical clustering approach to group entities into clusters, reducing the graph size while preserving critical structural information. We also introduce a graph attention mechanism to selectively focus on relevant entities and relations during embedding. Experimental results on several benchmark datasets demonstrate that HGAT outperforms state-of-the-art KGE methods in terms of both accuracy and efficiency.