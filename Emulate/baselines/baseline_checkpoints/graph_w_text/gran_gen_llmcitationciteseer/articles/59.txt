Time-series anomaly detection is crucial in various applications, including IoT, finance, and healthcare. However, most existing methods lack interpretability, making it challenging to understand the underlying causes of anomalies. This paper proposes Hierarchical Attention Networks (HAN) for explainable time-series anomaly detection. HAN leverages self-attention mechanisms to capture complex patterns and relationships in time-series data. We introduce a novel hierarchical architecture that combines local and global attention to identify anomalous segments and their contributing features. Experimental results on real-world datasets demonstrate the effectiveness of HAN in detecting anomalies and providing interpretable explanations.