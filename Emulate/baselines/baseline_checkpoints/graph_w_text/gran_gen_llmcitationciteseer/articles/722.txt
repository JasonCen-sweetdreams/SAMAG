Query expansion is a crucial step in information retrieval systems, as it can significantly impact the relevance and diversity of retrieved documents. This paper proposes a novel query expansion approach, 'RL-EXPAND', which leverages reinforcement learning to optimize the trade-off between relevance and diversity. We model the query expansion process as a Markov decision process and employ a deep Q-network to learn the optimal expansion strategy. Experimental results on several benchmark datasets demonstrate that RL-EXPAND outperforms state-of-the-art methods in terms of precision, recall, and novelty metrics, while reducing the computational cost of query expansion.