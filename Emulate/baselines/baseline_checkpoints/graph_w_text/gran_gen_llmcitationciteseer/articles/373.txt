Distributed database systems (DDS) have become increasingly popular for handling large-scale data processing. However, efficient data placement remains a significant challenge. This paper proposes a novel approach that leverages reinforcement learning (RL) to optimize data placement in DDS. We formulate the data placement problem as a Markov decision process and develop an RL-based algorithm that learns to place data chunks in a way that minimizes data retrieval latency and improves system throughput. Experimental results on a real-world dataset demonstrate that our approach outperforms existing data placement strategies by up to 30% in terms of latency reduction.