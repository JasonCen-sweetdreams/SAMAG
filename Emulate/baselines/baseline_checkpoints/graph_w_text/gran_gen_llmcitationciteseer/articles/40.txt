Explainable recommendation systems have gained significant attention in recent years due to the need for transparency and trust in AI-driven decision-making. This paper proposes a novel hierarchical attention graph neural network (HAGNN) architecture that incorporates both item-level and user-level attention mechanisms to generate personalized explanations for recommended items. Our approach leverages graph-based representation learning to capture complex relationships between users and items, while the hierarchical attention module enables the identification of influential factors driving recommendation decisions. Experiments on multiple benchmark datasets demonstrate the effectiveness of HAGNN in improving recommendation accuracy and providing insightful explanations.