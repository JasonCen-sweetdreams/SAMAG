Autonomous vehicles rely on efficient route planning to minimize travel time and energy consumption. This paper introduces a hierarchical reinforcement learning framework, HRL-Route, that learns to optimize route planning by decomposing the problem into a hierarchical structure of tasks and sub-tasks. Our approach leverages a high-level task encoder to identify critical route segments and a low-level action decoder to generate optimal vehicle control signals. Experimental results on a large-scale traffic simulation dataset demonstrate that HRL-Route outperforms state-of-the-art route planning methods in terms of travel time, energy efficiency, and safety.