Explainability is crucial in multi-agent reinforcement learning (MARL) to understand agent interactions and decision-making processes. This paper introduces HGAT, a hierarchical graph attention network that learns to represent complex agent relationships and their impact on joint policy learning. HGAT leverages a novel hierarchical graph structure to capture both local and global dependencies among agents, and incorporates an attention mechanism to selectively focus on relevant agents and their interactions. Experimental results on a variety of MARL benchmarks demonstrate that HGAT outperforms state-of-the-art methods in terms of both policy performance and explainability.