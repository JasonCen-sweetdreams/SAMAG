Explainable time-series forecasting is crucial in many real-world applications. This paper proposes a novel neural architecture search (NAS) framework, 'TS-EXPLAIN', that automatically discovers interpretable and accurate time-series forecasting models. TS-EXPLAIN uses a reinforcement learning-based search strategy to identify the optimal neural architecture, incorporating a novel explainability metric that rewards models with transparent and coherent feature importance. Experimental results on several benchmark datasets demonstrate the superiority of TS-EXPLAIN over state-of-the-art time-series forecasting models, achieving improved accuracy and explainability.