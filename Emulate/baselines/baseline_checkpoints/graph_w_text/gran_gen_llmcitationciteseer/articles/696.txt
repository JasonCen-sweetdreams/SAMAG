Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its lack of transparency hinders trust and understanding. This paper proposes a novel model-agnostic explainability framework, 'RL-Explain', which leverages attention mechanisms and feature importance scores to provide interpretable explanations for DRL policies. We demonstrate the effectiveness of RL-Explain on several Atari games and a real-world autonomous driving scenario, showcasing its ability to identify salient features and provide actionable insights for policy improvement.