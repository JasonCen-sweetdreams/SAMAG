In multi-agent systems, task allocation is a crucial problem that requires efficient and adaptive decision-making. This paper proposes a decentralized task allocation framework that leverages graph neural networks (GNNs) to model agent interactions and task relationships. Our approach, dubbed 'GNN-TA', uses a distributed GNN architecture to learn a task allocation policy that minimizes communication overhead and maximizes system utility. We evaluate GNN-TA on a variety of synthetic and real-world scenarios, demonstrating its scalability and robustness in the presence of agent failures and dynamic task arrivals.