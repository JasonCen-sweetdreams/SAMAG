Explainable recommendation systems are crucial for building trust with users. However, existing methods often sacrifice efficiency for model interpretability. This work proposes a novel Hierarchical Attention Network (HAN) architecture that balances recommendation accuracy with explainability. Our HAN model employs a hierarchical attention mechanism to selectively focus on relevant user and item features, generating personalized explanations for each recommendation. Experimental results on three real-world datasets demonstrate that our approach achieves state-of-the-art performance while providing transparent and actionable explanations.