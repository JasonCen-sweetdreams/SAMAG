Autonomous traffic management systems require efficient decision-making in complex, dynamic environments. This paper proposes a novel multi-agent reinforcement learning framework, 'MARL-ATM', which leverages graph neural networks and attention mechanisms to facilitate cooperation among agents. We introduce a hierarchical reward structure that balances individual agent objectives with global system-level goals, enabling the framework to adapt to diverse traffic scenarios. Experimental results on a simulated traffic network demonstrate that MARL-ATM outperforms traditional reinforcement learning approaches in terms of traffic flow efficiency and reduced congestion.