Autonomous vehicles rely on accurate object detection to navigate complex urban environments. This paper presents a real-time object detection system using YOLOv5, leveraging transfer learning to adapt to diverse scenarios. We fine-tune the pre-trained YOLOv5 model on the KITTI dataset, incorporating domain adaptation techniques to improve performance on unseen environments. Experimental results demonstrate our approach achieves state-of-the-art accuracy (>95%) and speed (>30 FPS) on a NVIDIA Jetson Xavier NX platform, making it suitable for real-world autonomous vehicle applications.