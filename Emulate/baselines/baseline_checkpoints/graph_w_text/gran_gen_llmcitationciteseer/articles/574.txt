Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can be detrimental in safety-critical applications. This paper proposes a novel defense mechanism, 'HierFeat', that leverages hierarchical feature importance to robustify DNNs against adversarial attacks. HierFeat assigns importance scores to features at multiple scales, enabling the model to focus on robust features and ignore vulnerable ones. We demonstrate the effectiveness of HierFeat on several benchmark datasets, achieving state-of-the-art performance in terms of adversarial robustness and clean accuracy. Our approach can be easily integrated into existing DNN architectures, providing a practical solution for real-world applications.