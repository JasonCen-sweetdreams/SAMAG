Conversational search systems require efficient and effective ranking models to retrieve relevant documents in response to user queries. This paper proposes a novel neural ranking model, 'ConverseR', which leverages pre-trained language models and incorporates contextualized query representations. We introduce a hierarchical attention mechanism that captures both local and global dependencies between query terms and document content. Experimental results on the TREC Conversational Assistance Track dataset demonstrate that ConverseR outperforms state-of-the-art models in terms of ranking accuracy and query response time.