The increasing adoption of multimodal conversational AI systems has raised concerns about their vulnerability to adversarial attacks. This paper proposes a novel graph-based anomaly detection approach, 'GraphGuard', to identify suspicious input patterns in multimodal inputs. We leverage graph convolutional networks to model the relationships between modalities and detect anomalies in the graph structure. Experimental results on a dataset of conversational AI interactions demonstrate that GraphGuard achieves a detection accuracy of 95.2% and outperforms existing state-of-the-art methods in identifying adversarial attacks.