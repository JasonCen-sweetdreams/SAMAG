The increasing adoption of autonomous vehicles (AVs) on public roads necessitates efficient coordination mechanisms to ensure smooth traffic flow and minimize congestion. This paper presents a decentralized multi-agent reinforcement learning (MARL) framework, called 'AV-Coord', that enables AVs to learn cooperative behaviors in real-time. AV-Coord leverages graph neural networks to model the interactions between AVs and their surroundings, and employs a novel credit assignment mechanism to incentivize cooperation. Experimental results using a realistic traffic simulator demonstrate that AV-Coord outperforms traditional traffic signal control methods in reducing congestion and travel times.