Autonomous traffic signal control has the potential to significantly reduce congestion and emissions in urban areas. This paper proposes a novel hierarchical multi-agent reinforcement learning framework, 'Hierarchical-MARL', which enables decentralized and adaptive traffic signal control. We model the traffic network as a hierarchical graph, where each intersection is represented by a local agent that coordinates with neighboring agents to optimize traffic flow. Our approach leverages a multi-agent Q-learning algorithm to learn optimal policies for each agent, and a hierarchical graph neural network to facilitate communication and coordination between agents. Simulation results on a real-world traffic dataset demonstrate that Hierarchical-MARL outperforms traditional fixed-time and adaptive signal control methods in terms of average travel time and traffic flow.