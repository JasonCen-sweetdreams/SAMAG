Developing autonomous agents that can engage in effective task-oriented dialogues remains a challenging problem. This paper proposes a novel hierarchical reinforcement learning framework for dialogue management, which leverages a two-level hierarchy to balance task completion and user engagement. The upper level learns a high-level policy to select the next dialogue act, while the lower level refines the policy by generating a specific response. We evaluate our approach on a popular dialogue dataset and demonstrate improved task success rates and user satisfaction compared to existing methods.