Multi-agent systems (MAS) often require effective negotiation strategies to achieve mutually beneficial agreements in dynamic environments. This paper introduces a novel adaptive negotiation framework, 'DynaNeg', which leverages reinforcement learning and graph-based modeling to optimize negotiation outcomes. DynaNeg integrates a dynamic graph structure to represent agent relationships, and a Q-learning algorithm to adapt negotiation strategies based on environment feedback. Experimental results on a supply chain management scenario demonstrate that DynaNeg outperforms traditional negotiation strategies in terms of agreement quality and negotiation efficiency.