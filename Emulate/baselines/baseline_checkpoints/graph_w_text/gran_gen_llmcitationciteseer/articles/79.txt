In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper proposes a decentralized task allocation framework using deep reinforcement learning, where each agent learns to allocate tasks based on its local observations and interactions with neighboring agents. We introduce a novel auction-based mechanism that enables agents to bid for tasks and negotiate with each other to reach a mutually beneficial allocation. Experimental results on a simulated disaster response scenario demonstrate that our approach outperforms traditional centralized allocation methods in terms of task completion rate and communication overhead.