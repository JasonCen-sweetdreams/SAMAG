This paper presents a novel decentralized task allocation framework for heterogeneous agent teams, where agents possess different capabilities and preferences. We propose a multi-agent reinforcement learning approach, called HAT-MARL, that learns to allocate tasks by minimizing a global objective function while respecting individual agent constraints. Our approach leverages graph neural networks to model agent interactions and incorporates a novel attention-based mechanism to focus on the most critical agents in the team. Experimental results on a simulated search-and-rescue scenario demonstrate that HAT-MARL outperforms traditional centralized allocation methods and adapts to changing team compositions.