In multi-agent systems, efficient task allocation is crucial for achieving system-wide objectives. This paper proposes a decentralized task allocation framework, 'AgentTA', that leverages multi-agent reinforcement learning to allocate tasks to autonomous agents. AgentTA utilizes a graph neural network to learn the communication patterns among agents and adapts to dynamic task arrivals and agent failures. We evaluate AgentTA on a simulated warehouse management scenario, demonstrating significant improvements in task completion rates and reduced communication overhead compared to traditional centralized allocation methods.