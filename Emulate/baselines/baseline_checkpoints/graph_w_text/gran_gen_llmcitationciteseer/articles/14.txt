This paper presents a novel approach for coordinating multi-agent systems in complex, dynamic environments. We propose a distributed reinforcement learning framework that allows agents to learn cooperative policies for resource allocation tasks. Our method, called 'MARL-RA', leverages Graph Neural Networks to model agent interactions and incorporates a decentralized trust mechanism to ensure robustness against malicious agents. Experimental results on a simulated smart grid scenario demonstrate that MARL-RA outperforms traditional centralized optimization methods and achieves near-optimal resource allocation while adapting to changing environmental conditions.