In heterogeneous multi-agent systems, tasks with varying complexities and requirements need to be allocated efficiently to agents with diverse capabilities. This paper presents a novel approach to coordinated task allocation using reinforcement learning. We propose a decentralized framework, 'CoMAC', where each agent learns to select optimal tasks based on its own capabilities, task priorities, and interactions with other agents. Experimental results on a simulated search-and-rescue scenario demonstrate that CoMAC outperforms traditional rule-based allocation methods, achieving higher task completion rates and reduced overall system latency.