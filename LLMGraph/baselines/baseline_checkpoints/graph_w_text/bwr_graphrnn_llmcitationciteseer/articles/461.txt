Gesture recognition systems have the potential to improve the quality of life for individuals with motor disabilities. However, existing systems often fail to account for individual differences in motor abilities, leading to poor recognition accuracy. This paper presents a novel approach to adaptive gesture recognition that incorporates physiological and behavioral data to personalize the recognition model. We propose a machine learning-based framework that adapts to the user's abilities and preferences over time, using a combination of electromyography and computer vision data. Our evaluation with 20 participants with motor disabilities shows that our approach improves recognition accuracy by up to 30% compared to traditional gesture recognition systems.