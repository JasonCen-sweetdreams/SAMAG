Autonomous traffic management systems require efficient agent collaboration to optimize traffic flow and reduce congestion. This paper proposes a novel Partial Observable Markov Decision Process (POMDP)-based framework for agent collaboration in autonomous traffic management. We model the traffic environment as a POMDP, where each agent observes a partial state of the environment and makes decisions based on its local observation. We develop a decentralized POMDP algorithm that enables agents to collaborate and share information to improve overall system performance. Experimental results on a simulated traffic network demonstrate that our approach outperforms traditional decentralized approaches and achieves near-optimal performance in terms of average travel time and traffic congestion.