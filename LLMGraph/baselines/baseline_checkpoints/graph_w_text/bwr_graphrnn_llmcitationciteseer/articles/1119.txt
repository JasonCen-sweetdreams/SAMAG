Multi-modal sentiment analysis, which involves jointly processing textual and visual cues, has become increasingly important in social media analytics. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) architecture that captures complex relationships between modalities and sentiment expressions. Our HGAT model consists of two graph attention layers: the first layer aggregates node representations across modalities, while the second layer refines sentiment predictions by modeling relationships between nodes. Experimental results on a large-scale dataset demonstrate that HGAT outperforms state-of-the-art methods in terms of sentiment accuracy and robustness to noisy inputs.