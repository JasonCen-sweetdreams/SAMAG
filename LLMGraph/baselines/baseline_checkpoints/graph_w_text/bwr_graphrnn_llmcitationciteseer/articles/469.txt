Virtual reality (VR) environments require intuitive and accurate gesture recognition systems to provide immersive experiences. This paper presents a novel approach to designing adaptive gesture recognition systems that leverage machine learning and sensor fusion techniques. Our proposed system, 'AdaGest', uses a combination of computer vision, inertial measurement unit, and electromyography sensors to recognize gestures in real-time. We evaluate the performance of AdaGest in a VR-based gaming scenario and demonstrate significant improvements in gesture recognition accuracy and latency compared to existing state-of-the-art systems.