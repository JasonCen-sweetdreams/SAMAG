Real-time traffic control is a challenging problem that requires efficient coordination of multiple agents. This paper proposes a novel approach that leverages Bayesian reinforcement learning to coordinate multi-agent systems for optimized traffic signal control. Our approach, called 'BayesTraffic', models the uncertainty of traffic flow and incorporates domain knowledge to improve exploration-exploitation trade-offs. We evaluate BayesTraffic on a realistic traffic simulator and demonstrate significant improvements in reducing congestion and travel times compared to state-of-the-art approaches. Our results show that BayesTraffic can be applied to large-scale traffic networks, making it a promising solution for smart city infrastructure.