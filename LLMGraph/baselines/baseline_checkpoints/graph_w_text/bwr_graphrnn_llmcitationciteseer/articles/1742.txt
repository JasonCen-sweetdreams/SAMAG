In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel approach to cooperative task allocation using distributed reinforcement learning (DRL). Our method, called 'MARA', enables agents to learn from their experiences and adapt to changing environmental conditions. By leveraging a decentralized actor-critic framework, MARA improves task allocation efficiency and reduces communication overhead compared to traditional centralized optimization methods. We evaluate MARA in a simulated warehouse management scenario, demonstrating its effectiveness in increasing overall system performance and robustness.