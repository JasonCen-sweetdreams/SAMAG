Emotion recognition is a crucial aspect of human-computer interaction (HCI), enabling systems to respond empathetically to users. This paper presents a novel gaze-based emotion recognition approach using deep learning. We propose a convolutional neural network (CNN) that extracts features from eye movement data and classify emotions into seven categories. Our approach leverages a large-scale dataset of gaze patterns annotated with emotional labels. Experimental results show that our model outperforms state-of-the-art methods, achieving an accuracy of 92.1% and an F1-score of 91.5%. We also demonstrate the applicability of our approach in a real-world HCI scenario, where it enables a virtual assistant to respond empathetically to users' emotional states.