Explainable AI (XAI) has gained significant attention in recent years, but most XAI methods rely on complex and computationally expensive neural networks. This paper presents a novel neural architecture search (NAS) framework, dubbed 'ExplainNAS', which targets the discovery of efficient XAI models. Our approach leverages a Differentiable Search Algorithm to optimize the neural architecture, taking into account both model accuracy and interpretability. We demonstrate the effectiveness of ExplainNAS on several benchmark datasets, achieving state-of-the-art results in explainability metrics while reducing computational overhead by up to 50%.