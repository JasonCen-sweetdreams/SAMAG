Autonomous vehicle fleets require efficient task allocation to optimize resource utilization and minimize latency. This paper proposes a novel distributed task allocation framework, 'MARLA', which leverages multi-agent reinforcement learning (MARL) to coordinate task assignments among agents. MARLA incorporates a decentralized MDP framework, enabling agents to learn from local observations and adapt to dynamic environment changes. Experimental results demonstrate that MARLA outperforms traditional centralized approaches in terms of task completion rate and fleet-wide efficiency, while maintaining robustness to agent failures and communication disruptions.