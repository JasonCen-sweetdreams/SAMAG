Ad-hoc search remains a challenging problem in information retrieval, particularly when dealing with short or ambiguous queries. This paper proposes a novel neural retrieval approach for query expansion, which learns to generate relevant expansion terms from a dense vector space. Our model, called NeuralQE, leverages a dual-encoder architecture to jointly optimize query and document embeddings, and is trained using a contrastive loss function. Experimental results on several standard Benchmarks demonstrate that NeuralQE outperforms state-of-the-art methods in terms of retrieval effectiveness, while reducing computational overhead.