Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its vulnerability to adversarial attacks poses a significant threat. This paper proposes a novel framework, 'AdvDet', that leverages explainable AI techniques to detect adversarial attacks in DRL. We introduce a attention-based mechanism that identifies the most influential state features contributing to the agent's decision-making process. By analyzing the feature importance, we detect anomalies indicative of adversarial attacks. Experimental results on popular DRL benchmarks demonstrate the effectiveness of AdvDet in detecting attacks while maintaining the agent's performance. Our approach has significant implications for the development of robust and secure DRL systems.