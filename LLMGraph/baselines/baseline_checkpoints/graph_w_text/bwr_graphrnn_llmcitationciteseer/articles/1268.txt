Graph neural networks (GNNs) have shown promising results in node representation learning, but their scalability remains a significant bottleneck. This paper presents a novel approach, 'GraphLite', which leverages graph clustering and sparse attention mechanisms to reduce computational complexity. We demonstrate that GraphLite achieves state-of-the-art performance on several benchmark datasets, including ogbn-products and ogbn-papers100M, while reducing training time by up to 75%. Our approach is particularly effective for large-scale graphs, enabling efficient node representation learning for real-world applications such as recommendation systems and social network analysis.