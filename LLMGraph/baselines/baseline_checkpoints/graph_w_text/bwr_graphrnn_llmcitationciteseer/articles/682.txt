Autonomous vehicles require efficient control policies to navigate complex scenarios. This paper presents a hierarchical reinforcement learning (HRL) framework for autonomous vehicle control, which decomposes the control problem into a hierarchy of tasks. Our approach combines a high-level policy for route planning with low-level policies for motion control, enabling efficient exploration and exploitation of the environment. We demonstrate the effectiveness of our HRL framework in a realistic simulation environment, achieving improved fuel efficiency and reduced computational overhead compared to flat reinforcement learning approaches.