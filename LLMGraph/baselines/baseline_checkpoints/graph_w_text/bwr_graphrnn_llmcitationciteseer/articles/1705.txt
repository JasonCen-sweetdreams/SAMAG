Virtual reality (VR) has the potential to revolutionize accessibility for individuals with disabilities. However, current VR systems often lack personalized accommodations, hindering their adoption. This paper presents a novel approach to enable personalized accessibility in VR using eye-tracking and machine learning. We develop a deep learning model that analyzes eye movement patterns to detect user preferences and abilities, and adaptively adjusts the VR environment to provide tailored support. Our user study with 30 participants demonstrates significant improvements in user experience and task completion rates. We discuss the implications of our approach for promoting inclusivity in VR and future directions for research.