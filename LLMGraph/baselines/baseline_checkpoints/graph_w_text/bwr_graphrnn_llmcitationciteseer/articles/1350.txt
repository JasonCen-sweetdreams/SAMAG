This paper addresses the problem of decentralized coordination in multi-agent systems, where agents with limited communication and perception capabilities need to collaborate to achieve a common goal. We propose a novel approach that combines distributed reinforcement learning with graph neural networks to enable agents to learn cooperative policies in a decentralized manner. Our approach is scalable, flexible, and robust to changes in the environment or agent failures. Experimental results in a simulated warehouse management scenario demonstrate the effectiveness of our approach in achieving efficient and coordinated agent behavior.