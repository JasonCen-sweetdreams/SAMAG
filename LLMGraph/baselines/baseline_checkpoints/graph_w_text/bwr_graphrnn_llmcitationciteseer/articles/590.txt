Deep reinforcement learning (DRL) has achieved remarkable success in robotics, but the lack of transparency in decision-making processes hinders trust and adoption. This paper proposes a novel explainability framework, 'RL-Explain', which integrates model-agnostic explanations with feature importance metrics to provide insights into DRL policies. We develop an efficient optimization approach that leverages proxy tasks and transfer learning to reduce the computational overhead of explainability. Experimental results on robotic manipulation tasks demonstrate that RL-Explain improves policy understanding and debugging, while maintaining performance competitiveness with state-of-the-art DRL methods.