Autonomous vehicles rely on reinforcement learning (RL) to make critical decisions, but the lack of transparency in these models hinders trust and accountability. This paper proposes XRL, a novel framework that integrates explainability into RL for autonomous vehicle decision-making. XRL employs a model-agnostic explanation technique to provide real-time insights into the decision-making process, thereby improving safety and interpretability. Experimental results on a simulated driving environment demonstrate that XRL achieves comparable performance to state-of-the-art RL methods while providing meaningful explanations for its decisions.