Query expansion is a crucial step in information retrieval, but existing methods often rely on static word embeddings that fail to capture nuanced contextual relationships. This paper proposes ACE-IR, an adaptive contextualized embedding approach that leverages transformer-based language models to encode query terms and their surroundings. ACE-IR dynamically updates the embeddings based on the query context, enabling more effective expansion of relevant terms. Experimental results on the TREC benchmark demonstrate significant improvements in retrieval performance, especially for short and ambiguous queries, compared to state-of-the-art query expansion methods.