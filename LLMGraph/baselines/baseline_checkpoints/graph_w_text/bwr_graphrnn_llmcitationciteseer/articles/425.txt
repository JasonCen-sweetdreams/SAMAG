Autonomous vehicles (AVs) rely on sophisticated decision-making algorithms to navigate complex scenarios. This paper presents a novel deep reinforcement learning (DRL) framework, 'UncerAV', that learns to make robust decisions under uncertainty. By incorporating probabilistic uncertainty estimation and risk-aware reward functions, UncerAV outperforms state-of-the-art DRL methods in simulated AV environments. We demonstrate improved safety and efficiency in scenarios involving pedestrian interactions, roadwork, and adverse weather conditions.