Autonomous vehicles require efficient decision-making policies to navigate complex scenarios. This paper presents a hierarchical reinforcement learning (HRL) framework that decomposes the decision-making process into a high-level task planner and a low-level motion controller. We introduce a novel task representation based on graph neural networks, enabling the planner to reason about abstract tasks and objectives. The motion controller is trained using a model-free reinforcement learning algorithm with a curated reward function that balances safety, efficiency, and comfort. Simulation results demonstrate that our HRL framework outperforms flat reinforcement learning baselines in various urban driving scenarios.