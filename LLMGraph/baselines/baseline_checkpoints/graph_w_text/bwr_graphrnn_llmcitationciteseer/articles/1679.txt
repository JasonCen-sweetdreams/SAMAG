Autonomous vehicles require efficient decision-making to navigate complex scenarios. This paper proposes a hierarchical reinforcement learning framework, 'ADAPT', which decomposes the decision-making process into task-oriented sub-goals. ADAPT leverages a high-level planner to generate sub-goals and a low-level learner to adapt to changing environmental conditions. We demonstrate ADAPT's effectiveness in simulating various driving scenarios, showcasing improved efficiency and adaptability compared to flat reinforcement learning approaches.