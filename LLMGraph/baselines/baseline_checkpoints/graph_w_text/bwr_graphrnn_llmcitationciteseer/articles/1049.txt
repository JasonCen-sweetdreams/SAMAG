Graph neural networks (GNNs) have shown remarkable performance in node classification tasks. However, their computational complexity and memory requirements scale poorly with large graphs. This paper introduces 'GraphSample', a novel graph sampling strategy that reduces the computational cost of GNNs while preserving their predictive power. By adaptively sampling nodes and their neighbors, GraphSample achieves a speedup of up to 10x compared to state-of-the-art GNNs on large-scale graph datasets. We demonstrate the effectiveness of GraphSample on several benchmark datasets, including citation networks and social networks.