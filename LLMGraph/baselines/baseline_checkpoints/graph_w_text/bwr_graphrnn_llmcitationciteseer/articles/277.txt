E-commerce search engines face the challenge of retrieving relevant products from large catalogs, often involving multi-modal queries (e.g., text, images). This paper proposes a novel neural ranking model, 'MMR-NRM', which integrates visual and textual features using a hierarchical attention mechanism. MMR-NRM leverages a triplet-based training approach, enabling efficient optimization and improved ranking performance. Experiments on a large e-commerce dataset demonstrate that MMR-NRM outperforms state-of-the-art models in terms of recall, precision, and computational efficiency.