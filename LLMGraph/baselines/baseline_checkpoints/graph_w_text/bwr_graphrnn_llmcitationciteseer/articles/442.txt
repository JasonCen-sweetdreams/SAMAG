In multi-agent systems, coordinating agents to achieve a common goal is a challenging problem, especially in dynamic environments. This paper presents a novel approach that leverages graph neural networks (GNNs) to learn effective coordination strategies. We propose a framework that represents the agent-environment interaction as a graph, and uses GNNs to learn agent embeddings that capture their spatial relationships and task dependencies. Our approach is evaluated in a simulated search-and-rescue scenario, where we demonstrate improved coordination efficiency and adaptability to changing environmental conditions compared to traditional planning-based methods.