Multi-agent reinforcement learning (MARL) has achieved significant success in various applications, but the complexity of learned policies hinders interpretability. This paper introduces a novel explainable attention mechanism, 'XAttention', which provides insights into the decision-making process of MARL agents. XAttention leverages a hierarchical graph attention network to model agent interactions and a feature importance module to highlight relevant state features. Experimental results on the StarCraft II benchmark demonstrate that XAttention improves the transparency of MARL policies while maintaining competitive performance. We also provide visualizations and case studies to illustrate the explainability benefits of XAttention.