Deep neural networks often require large amounts of labeled data to achieve good performance. Online learning methods can mitigate this issue by adapting to new data streams, but they may suffer from catastrophic forgetting. This paper proposes an efficient online learning framework for deep neural networks, which incorporates adaptive regularization to balance stability and plasticity. Our approach dynamically adjusts the regularization strength based on the gradient norm of the model, allowing it to adapt to changing data distributions. Experimental results on several benchmark datasets demonstrate that our method achieves competitive performance to offline training while reducing computational costs.