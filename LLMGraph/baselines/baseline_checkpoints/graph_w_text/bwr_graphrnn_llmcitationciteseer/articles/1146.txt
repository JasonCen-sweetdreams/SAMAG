In multi-agent systems, task allocation is a crucial problem that requires efficient and adaptive decision-making. This paper proposes a novel approach that leverages deep reinforcement learning to allocate tasks to autonomous agents in a distributed manner. Our method, called 'DRL-TA', uses a decentralized actor-critic framework to learn task allocation policies that maximize system utility and minimize communication overhead. We evaluate DRL-TA in a simulated disaster response scenario and demonstrate its superiority over traditional methods in terms of task completion rate, latency, and robustness to agent failures.