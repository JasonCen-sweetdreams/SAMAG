Individuals with motor impairments often face significant barriers when interacting with digital systems. This paper presents a novel approach to designing adaptive gesture-based interfaces that can accommodate a wide range of motor abilities. We propose a machine learning-based framework that leverages real-time gesture recognition and adaptation to dynamically adjust interface parameters, such as gesture speed and accuracy thresholds. Our user study with 20 participants with motor impairments demonstrates improved interface accessibility and usability, with participants exhibiting a 35% increase in successful gesture recognition and a 25% decrease in interaction time.