Autonomous agents operating in real-world scenarios often face conflicts due to shared resources, conflicting goals, or limited visibility. This paper presents a decentralized multi-agent reinforcement learning framework that enables agents to adaptively learn deconfliction strategies in complex, dynamic environments. Our approach leverages a novel reward function that incorporates both individual and collective performance metrics, promoting cooperation and adaptation among agents. Experimental results in a simulated warehouse scenario demonstrate the efficacy of our approach in reducing conflicts by up to 75% compared to traditional rule-based methods, while improving overall task efficiency.