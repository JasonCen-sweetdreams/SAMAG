This paper presents a novel approach to gaze-based interaction for augmented reality (AR) applications using deep reinforcement learning. We propose a neural network architecture that learns to predict the user's intended gaze target in real-time, allowing for seamless interaction with virtual objects in AR environments. Our approach leverages a combination of eye-tracking data and scene context to improve the accuracy and robustness of the gaze prediction model. Experimental results demonstrate a significant reduction in interaction latency and error rates compared to traditional gaze-based interaction methods, enabling more intuitive and efficient AR experiences.