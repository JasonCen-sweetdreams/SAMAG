In multi-agent systems, efficient task allocation is critical for achieving global objectives. This paper presents a decentralized approach using hierarchical reinforcement learning (HRL) to allocate tasks in a distributed manner. We propose a novel HRL framework, 'Distributed Agent Scheduling' (DAS), which consists of a high-level task allocator and low-level agent controllers. DAS enables agents to learn task-specific skills and adapt to changing environments while ensuring global optimality. Experimental results on a swarm robotics platform demonstrate that DAS outperforms traditional centralized and decentralized methods in terms of task completion rate and system scalability.