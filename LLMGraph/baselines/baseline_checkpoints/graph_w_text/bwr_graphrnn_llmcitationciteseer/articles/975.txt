Deep neural networks are prone to making overconfident predictions on out-of-distribution (OOD) inputs, which can be catastrophic in real-world applications. This paper presents a novel self-supervised contrastive learning approach, 'OOD-SSL', that enables efficient OOD detection without requiring labeled OOD data. Our method leverages the similarity between in-distribution and OOD samples in the representation space, and learns to distinguish between them using a contrastive loss. Experimental results on several benchmark datasets demonstrate that OOD-SSL outperforms existing state-of-the-art methods in OOD detection, while being computationally efficient and easy to implement.