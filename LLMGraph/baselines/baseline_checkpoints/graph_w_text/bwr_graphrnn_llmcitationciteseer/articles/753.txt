In multi-agent systems, coalition formation is crucial for achieving collective goals. However, existing approaches often assume homogeneous objectives among agents, which is unrealistic in many real-world scenarios. This paper proposes an adaptive coalition formation framework that accommodates heterogeneous objectives and dynamic environments. We introduce a novel graph-based algorithm that leverages reinforcement learning to optimize coalition structures and adapt to changing agent objectives. Experimental results on a simulated disaster response scenario demonstrate the effectiveness of our approach in improving overall system performance and robustness.