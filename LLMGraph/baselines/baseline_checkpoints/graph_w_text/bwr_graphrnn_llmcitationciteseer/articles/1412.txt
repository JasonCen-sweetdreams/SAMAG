Knowledge graph embedding (KGE) has become a crucial component in various AI applications. However, existing KGE methods often suffer from high computational complexity and limited scalability. This paper proposes a novel hierarchical attention network (HAN) based KGE framework, dubbed 'KG-HAN', which leverages the hierarchical structure of knowledge graphs to reduce the computational overhead. KG-HAN adaptively focuses on relevant entities and relations, leading to improved embedding quality and inference efficiency. Our extensive experiments on benchmark datasets demonstrate the superior performance of KG-HAN compared to state-of-the-art KGE methods.