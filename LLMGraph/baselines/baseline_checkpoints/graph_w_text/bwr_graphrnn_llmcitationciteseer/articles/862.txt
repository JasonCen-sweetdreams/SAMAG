Individuals with motor impairments face significant barriers when interacting with gesture-recognition systems. This paper presents a co-design approach to developing accessible gesture recognition systems, involving users with motor impairments throughout the design process. We propose a novel gesture recognition framework that leverages a combination of machine learning and computer vision techniques to adapt to the unique abilities and needs of each individual. Our user study involving 20 participants with motor impairments shows that our system achieves an average recognition accuracy of 92.5%, outperforming existing systems by 25%. We also provide design guidelines for inclusive gesture recognition systems, highlighting the importance of user-centered design in HCI.