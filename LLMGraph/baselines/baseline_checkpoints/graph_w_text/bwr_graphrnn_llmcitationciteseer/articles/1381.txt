Virtual Reality (VR) has the potential to revolutionize human-computer interaction, but existing gesture recognition systems often fail to accommodate users with disabilities. This paper presents ' GestureGuide', a novel framework that leverages machine learning to recognize and adapt to diverse gestures, including those made by individuals with motor impairments. Our approach integrates a wearable sensor suite and a probabilistic gesture model to provide real-time feedback and personalized guidance. A user study with participants with and without disabilities demonstrates that GestureGuide significantly improves gesture recognition accuracy and user experience in VR environments.