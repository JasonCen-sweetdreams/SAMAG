As data volumes continue to grow, optimizing query performance becomes crucial for real-time analytics. This paper presents a novel query optimization framework, 'Raptor', designed specifically for distributed column-store databases. Raptor leverages statistical modeling and machine learning techniques to predict query execution times and identify optimal query plans. We propose a cost-based optimization approach that considers both data distribution and computational resources. Experimental results on a large-scale analytics workload demonstrate that Raptor reduces query latency by up to 75% compared to state-of-the-art optimizers, while maintaining high accuracy and scalability.