Autonomous traffic management systems require efficient coordination among multiple agents to optimize traffic flow and reduce congestion. This paper presents a decentralized multi-agent reinforcement learning framework, 'DMARL-ATM', which enables autonomous vehicles to learn cooperative policies for traffic signal control and lane changing. We introduce a novel Graph Attention Network (GAT) architecture to model agent interactions and a decentralized Q-learning algorithm to update policies based on local observations. Experimental results on a simulated urban traffic network demonstrate that DMARL-ATM outperforms traditional rule-based systems and centralized reinforcement learning approaches in terms of reduced travel time and increased network throughput.