Virtual reality (VR) technology has revolutionized the way we interact with digital information, but current interaction methods often rely on manual input devices. This paper explores the use of gaze-based interaction as a more natural and intuitive approach. We conducted a user study to analyze eye movement patterns in VR and developed a machine learning model to predict user intent based on gaze behavior. Our results show that the proposed model achieves high accuracy in intent recognition, outperforming traditional interaction methods. This work has implications for the development of more immersive and accessible VR experiences.