Deep learning-based recommendation systems have become increasingly popular in recent years, but they are vulnerable to adversarial attacks that can manipulate user preferences and recommendations. This paper presents a comprehensive taxonomy of adversarial attacks on deep learning-based recommendation systems, including data poisoning, model poisoning, and query-based attacks. We also propose defense strategies based on anomaly detection, robust optimization, and transfer learning to mitigate these attacks. Experimental results on several benchmark datasets demonstrate the effectiveness of our proposed defense strategies in improving the robustness of recommendation systems against adversarial attacks.