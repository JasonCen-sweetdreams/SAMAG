Knowledge graph embeddings have been widely adopted for various AI applications. However, existing methods often neglect the complex relationships between entities. We propose a novel hierarchical graph attention network (HGAT) to learn multi-relational knowledge graph embeddings. HGAT employs a hierarchical architecture to capture both local and global dependencies among entities, and a relational attention mechanism to selectively focus on relevant relationships. Experimental results on benchmark datasets demonstrate that HGAT outperforms state-of-the-art methods in link prediction, entity classification, and question answering tasks.