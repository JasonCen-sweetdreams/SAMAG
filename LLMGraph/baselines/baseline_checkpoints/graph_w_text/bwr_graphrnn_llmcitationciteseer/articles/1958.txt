Human-robot collaboration (HRC) has the potential to revolutionize industrial manufacturing and healthcare. However, existing HRC systems rely on pre-programmed instructions or explicit communication, limiting their flexibility and adaptability. This paper presents a novel HRC framework that leverages reinforcement learning (RL) and vision-based gesture recognition to enable real-time collaboration. Our approach uses a deep RL algorithm to learn a shared policy between a human and a robot, allowing them to adapt to changing tasks and environments. We demonstrate the effectiveness of our framework in a series of experiments involving assembly tasks and show significant improvements in task completion time and accuracy compared to traditional HRC methods.