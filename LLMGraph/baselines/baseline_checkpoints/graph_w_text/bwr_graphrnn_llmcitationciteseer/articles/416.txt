Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks, which can be crafted by applying small, imperceptible perturbations to the input data. This paper proposes a novel defense mechanism, dubbed 'Hierarchical Input Transformation' (HIT), which leverages a hierarchical representation of the input data to increase the robustness of DNNs against such attacks. Our approach involves applying a series of transformations to the input data at multiple scales, effectively 'denoising' the input and making it more difficult for an adversary to craft effective attacks. We demonstrate the effectiveness of HIT on several benchmark datasets, achieving state-of-the-art results in terms of robustness to adversarial attacks.