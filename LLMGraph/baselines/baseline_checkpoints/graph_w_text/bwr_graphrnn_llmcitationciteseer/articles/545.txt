This paper presents a novel cooperative multi-agent reinforcement learning (MARL) approach for real-time traffic signal control. We design a decentralized framework, 'TrafficSync', where multiple agents, each responsible for a single intersection, learn to coordinate their actions to minimize congestion and reduce travel times. Our method leverages a graph attention mechanism to capture complex traffic patterns and a novel reward function that promotes cooperation among agents. Experimental results using real-world traffic data from Pittsburgh, PA, demonstrate that TrafficSync outperforms state-of-the-art traffic signal control methods, reducing average travel times by 23% and decreasing congestion by 18%.