Coordinating traffic signals to minimize congestion and reduce travel times is a challenging problem, especially in large-scale urban networks. This paper proposes a decentralized multi-agent reinforcement learning framework, 'TrafficSync', that enables real-time coordination among traffic signals. Our approach leverages graph neural networks to model spatial relationships between intersections and learns adaptive policies for signal control. Experimental results on a realistic traffic simulator demonstrate that TrafficSync outperforms traditional fixed-timing and adaptive control methods, reducing average travel times by up to 23%.