Multi-hop question answering (MHQA) models often rely on complex reasoning and contextual understanding, but their decision-making processes remain opaque. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that integrates graph attention mechanisms with hierarchical reasoning to enhance explainability in MHQA. HGAT learns to selectively focus on relevant nodes and edges in the knowledge graph, allowing for interpretable visualizations of the reasoning process. Experimental results on the HotPotQA benchmark demonstrate that HGAT outperforms state-of-the-art models while providing more transparent and faithful explanations.