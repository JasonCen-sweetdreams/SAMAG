Gaze-based interaction has become a popular modality in human-computer interaction, but it is susceptible to errors due to noise in eye-tracking data. This paper presents EyeGaze+, a novel framework that leverages deep learning to correct gaze errors in real-time. Our approach uses a convolutional neural network to learn patterns in gaze data and detect anomalies, which are then corrected using a probabilistic model. We evaluate EyeGaze+ on a publicly available eye-tracking dataset and demonstrate significant improvements in gaze accuracy and interaction performance. Our framework has implications for enhancing accessibility and usability in various applications, including virtual reality, gaming, and assistive technologies.