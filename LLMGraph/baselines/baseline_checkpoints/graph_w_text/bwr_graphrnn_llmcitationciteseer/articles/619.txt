Voice assistants have become increasingly popular, but their usability for older adults is often limited due to cognitive, sensory, and motor impairments. This paper presents a novel multimodal interaction framework that integrates voice, gesture, and visual cues to enhance accessibility for older adults. Our approach leverages machine learning-based gesture recognition and adaptive feedback mechanisms to facilitate intuitive interaction. A user study with 30 older adults demonstrates significant improvements in task completion rates and user satisfaction compared to traditional voice-only interfaces.