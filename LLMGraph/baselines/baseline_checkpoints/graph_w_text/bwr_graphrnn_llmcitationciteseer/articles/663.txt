The proliferation of multi-modal data has necessitated the development of efficient retrieval methods. This paper presents a novel approach, Hierarchical Semantic Indexing (HSI), which leverages the semantic relationships between modalities to facilitate fast and accurate retrieval. HSI constructs a hierarchical index structure that captures the correlations between visual, textual, and audio features, enabling efficient pruning of the search space. Experimental results on a large-scale multi-modal dataset demonstrate that HSI outperforms state-of-the-art methods in terms of retrieval accuracy and query latency.