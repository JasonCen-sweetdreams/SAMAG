In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a novel distributed task allocation framework that leverages graph neural networks (GNNs) to learn agent interactions and task dependencies. Our approach, called GNN-TA, uses a decentralized GNN architecture to infer task assignments based on local observations and communication with neighboring agents. We demonstrate the effectiveness of GNN-TA in simulated environments, showing improved task completion rates and reduced communication overhead compared to traditional optimization-based methods.