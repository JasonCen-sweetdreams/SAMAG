Augmented reality (AR) has the potential to revolutionize industrial workflows, but effective human-computer interaction remains a significant challenge. This paper presents a gesture-based interaction framework for AR in industrial settings, which leverages machine learning algorithms to recognize and interpret worker gestures. We conducted a user study with 20 participants from a manufacturing background, demonstrating improved task efficiency and reduced errors compared to traditional controller-based interaction methods. Our approach enables workers to focus on the task at hand, freeing them from the constraints of traditional input devices.