Virtual reality (VR) systems often rely on controllers or tracking devices to detect user input, limiting the naturalness and expressiveness of interactions. This paper presents 'HandGuide', a novel system that leverages computer vision and machine learning to recognize and interpret hand gestures in VR environments. By analyzing a dataset of annotated hand movements, we develop a gesture recognition model that can accurately classify and predict user intentions. We also propose a set of design guidelines for creating intuitive and immersive VR experiences that incorporate hand gestures, validated through a user study.