Deep neural networks have been shown to be vulnerable to adversarial attacks, which can lead to catastrophic consequences in safety-critical applications. This paper presents a novel defense mechanism, 'HRL-Defend', which leverages hierarchical reinforcement learning to train attack-resistant neural networks. Our approach involves training a hierarchical policy that learns to detect and respond to adversarial attacks in a game-theoretic framework. Experimental results on multiple benchmarks demonstrate that HRL-Defend outperforms state-of-the-art defense methods in terms of robustness and accuracy.