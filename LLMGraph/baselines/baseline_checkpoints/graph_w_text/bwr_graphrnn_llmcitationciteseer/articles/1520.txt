Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks, but the lack of interpretability hinders trust and adoption in high-stakes applications. This paper introduces 'DeepLens', a novel model-agnostic explanation framework for DRL in high-dimensional state spaces. DeepLens leverages attention mechanisms and conditional mutual information to identify influential state features and quantify their contributions to policy decisions. We demonstrate the effectiveness of DeepLens on multiple Atari games and a real-world robotics task, showcasing improved transparency and performance in model-based exploration strategies.