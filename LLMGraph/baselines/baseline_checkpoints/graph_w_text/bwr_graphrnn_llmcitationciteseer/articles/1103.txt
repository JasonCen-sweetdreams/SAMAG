In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a decentralized task allocation framework, 'BLANT', which leverages Bayesian learning to adapt to dynamic environments. Each agent maintains a probabilistic model of task requirements and agent capabilities, and updates its model through local observations and communication with neighboring agents. We show that BLANT outperforms existing decentralized algorithms in terms of task completion rate and communication overhead. Experimental results on a simulated disaster response scenario demonstrate the effectiveness of BLANT in adapting to changing task priorities and agent availability.