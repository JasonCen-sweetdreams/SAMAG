Explainability is crucial in multi-agent systems, where agents' decision-making processes can have significant impacts on the environment and other agents. We propose a novel Hierarchical Graph Attention Network (HGAT) framework that enables explainable multi-agent reinforcement learning. HGAT leverages graph attention mechanisms to capture complex relationships between agents and their environments, while hierarchical abstraction enables the identification of high-level decision-making patterns. Experimental results on a real-world traffic management scenario demonstrate that HGAT outperforms state-of-the-art methods in terms of both task performance and explainability.