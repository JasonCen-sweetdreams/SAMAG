Ad-hoc search engines often struggle to retrieve relevant documents due to incomplete or ambiguous queries. This paper proposes a novel reinforcement learning-based approach to query expansion, which adaptively selects expansion terms based on their predicted relevance to the original query. Our method, dubbed 'RL-QE', leverages a deep Q-network to learn the optimal expansion strategy for a given query, taking into account the trade-off between retrieval efficiency and precision. Experiments on the TREC 2004 Robust Track dataset demonstrate that RL-QE outperforms state-of-the-art query expansion methods, achieving a significant improvement in mean average precision and retrieval time.