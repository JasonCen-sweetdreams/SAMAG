Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can manipulate the output of the model. While various defense mechanisms have been proposed, detecting these attacks remains a challenging task. In this paper, we introduce a novel approach that leverages hierarchical graph attention to identify adversarial attacks. Our method represents the DNN as a hierarchical graph, where each node corresponds to a neuron, and uses attention mechanisms to identify suspicious patterns in the graph. Experimental results on several benchmark datasets demonstrate that our approach achieves state-of-the-art performance in detecting adversarial attacks, outperforming existing methods by a significant margin.