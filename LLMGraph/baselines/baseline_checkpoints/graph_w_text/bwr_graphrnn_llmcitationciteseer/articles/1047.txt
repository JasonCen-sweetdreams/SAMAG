Virtual assistants (VAs) have become ubiquitous, but people with visual impairments (PWVI) often struggle to interact with them. This paper presents an HCI-driven approach to designing intelligent VAs that cater to PWVI. We conducted a user study with 20 participants to identify key challenges and preferences. Our proposed system, 'AccessibleVA', incorporates AI-driven speech recognition, natural language processing, and personalized feedback mechanisms. A usability evaluation with 15 PWVI participants showed significant improvements in task completion rates and user satisfaction compared to existing VA systems.