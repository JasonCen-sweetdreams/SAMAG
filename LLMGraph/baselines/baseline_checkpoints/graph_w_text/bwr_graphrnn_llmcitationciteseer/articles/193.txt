Motion planning for autonomous vehicles (AVs) in dynamic environments is a challenging problem that requires efficient and adaptive decision-making. This paper presents a novel approach that leverages deep reinforcement learning (DRL) to learn motion policies for AVs. We propose a hierarchical framework that integrates a high-level planner with a low-level controller, both trained using a DRL algorithm. The planner generates a sequence of waypoints, while the controller executes the motion plan using a model predictive control (MPC) strategy. We evaluate our approach in a simulated urban environment and demonstrate improved performance compared to traditional model-based planning methods.