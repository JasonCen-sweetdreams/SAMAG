Few-shot image classification remains a challenging task in machine learning, particularly when faced with limited labeled data. This paper introduces a novel hierarchical meta-learning framework, 'MetaHIer', which leverages self-supervised pre-training to improve adaptation to new tasks. We propose a two-level hierarchical structure, where a base model learns to recognize general features from unlabeled data, and a meta-model learns to adapt to new tasks with few labeled examples. Experimental results on popular benchmarks demonstrate that MetaHIer outperforms state-of-the-art methods in few-shot image classification, achieving an average accuracy improvement of 4.5% on the mini-ImageNet dataset.