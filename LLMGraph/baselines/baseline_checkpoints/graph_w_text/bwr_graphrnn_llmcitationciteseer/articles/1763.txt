 Gesture recognition systems have become increasingly prevalent in human-computer interaction, but their performance often degrades for individuals with motor disabilities. This paper presents an inclusive gesture recognition framework that adapts to the unique abilities and needs of users with motor impairments. We propose a machine learning-based approach that leverages a dataset of gestures from individuals with various motor disabilities, and introduces a novel feature extraction technique that emphasizes robustness to variability in movement patterns. Our user study with 20 participants demonstrates significant improvements in gesture recognition accuracy and user satisfaction compared to existing systems.