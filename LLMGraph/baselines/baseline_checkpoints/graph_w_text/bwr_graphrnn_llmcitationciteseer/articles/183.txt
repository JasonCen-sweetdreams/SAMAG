Autonomous traffic management has the potential to significantly reduce congestion and emissions in urban areas. This paper proposes a hierarchical multi-agent reinforcement learning framework, 'HMaRL', which coordinates the actions of multiple autonomous vehicles and traffic signals to optimize traffic flow. We design a decentralized partially observable Markov decision process (Dec-POMDP) to model the complex interactions between agents and the environment. Experimental results on a simulated traffic network demonstrate that HMaRL outperforms traditional centralized optimization methods and other multi-agent reinforcement learning approaches in terms of average travel time and emissions reduction.