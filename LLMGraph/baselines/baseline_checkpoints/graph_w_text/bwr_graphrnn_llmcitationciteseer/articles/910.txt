Autonomous drone exploration is a challenging problem in AI research, particularly in complex and dynamic environments. This paper presents a hierarchical reinforcement learning (HRL) framework, 'DroneExplorer', which leverages a novel decomposition of the exploration task into sub-tasks to improve efficiency and adaptability. Our approach combines a high-level task planner with a low-level motion controller, allowing the drone to adapt to changing environmental conditions and customize its exploration strategy. Experimental results demonstrate that DroneExplorer outperforms state-of-the-art methods in various simulated scenarios, showcasing its potential for real-world applications.