Cloud computing platforms face the challenge of optimizing resource allocation to meet dynamic workload demands. This paper presents a hierarchical reinforcement learning (HRL) framework that learns to allocate resources effectively in cloud environments. Our approach decomposes the resource allocation problem into a hierarchy of tasks, allowing the HRL agent to focus on high-level decisions while delegating low-level tasks to subordinate agents. We evaluate our framework on a realistic cloud simulator and demonstrate significant improvements in resource utilization, response time, and energy efficiency compared to state-of-the-art baselines.