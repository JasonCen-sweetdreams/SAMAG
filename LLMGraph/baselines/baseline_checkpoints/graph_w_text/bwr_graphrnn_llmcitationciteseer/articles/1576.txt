Ad-hoc retrieval systems often struggle to accurately capture user intent, leading to suboptimal search results. This paper proposes a novel query expansion approach that leverages neural word embeddings to better represent query semantics. We develop a dense passage retrieval model that jointly learns to embed queries and documents in a shared vector space, enabling effective expansion of query terms. Experimental results on several benchmark datasets demonstrate significant improvements in retrieval performance, particularly for short and ambiguous queries. Our approach provides a simple yet effective way to enhance the accuracy of ad-hoc retrieval systems without requiring extensive manual tuning or domain-specific knowledge.