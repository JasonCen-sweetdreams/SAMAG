Deep reinforcement learning (DRL) has achieved remarkable success in complex control tasks, but its vulnerability to adversarial attacks raises concerns for real-world deployment. This paper proposes a novel approach to generating adversarial attacks on DRL agents using model-agnostic meta-learning (MAML). We adapt MAML to learn a meta-policy that can adapt to different DRL models and environments, thereby circumventing the need for model-specific knowledge. Experimental results on popular DRL benchmarks demonstrate the effectiveness of our approach in reducing the robustness of state-of-the-art DRL algorithms.