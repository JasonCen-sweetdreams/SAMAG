Graph Neural Networks (GNNs) have achieved state-of-the-art performance on various node classification tasks. However, their robustness against adversarial attacks remains largely unexplored. This paper presents a comprehensive study on the vulnerability of GNNs to adversarial attacks on node attributes and graph structure. We propose a novel attack method, 'GraphFool', which manipulates node features and edge connections to misclassify target nodes. Our experiments on several benchmark datasets demonstrate that GraphFool outperforms existing attacks, and we provide insights into the attack's effectiveness and potential defense strategies.