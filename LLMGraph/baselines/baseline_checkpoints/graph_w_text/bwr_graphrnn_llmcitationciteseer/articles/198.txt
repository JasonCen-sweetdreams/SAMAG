Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its performance is highly dependent on the choice of hyperparameters. This paper proposes a novel Bayesian optimization framework, 'BO-Reinforce', which efficiently tunes hyperparameters for DRL algorithms. By leveraging the probabilistic nature of Bayesian optimization, BO-Reinforce adaptively adjusts the search space and explores the most promising regions. Experimental results on several benchmark tasks demonstrate that BO-Reinforce significantly outperforms state-of-the-art methods in terms of both optimization efficiency and final performance, while requiring minimal domain knowledge and human intervention.