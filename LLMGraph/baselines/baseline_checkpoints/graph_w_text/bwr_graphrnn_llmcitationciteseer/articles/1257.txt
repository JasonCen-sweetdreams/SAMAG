Traditional knowledge retrieval systems rely on bag-of-words representations, which fail to capture complex relationships between entities in documents. This paper proposes a novel approach, 'EntityGraph', which incorporates entity-aware graph attention mechanisms to learn contextualized document representations. By jointly modeling entity interactions and semantic relationships, EntityGraph significantly improves the retrieval performance on benchmark datasets. We demonstrate the effectiveness of our approach in retrieving relevant documents for entity-centric queries, outperforming state-of-the-art methods by up to 15% in terms of mean average precision.