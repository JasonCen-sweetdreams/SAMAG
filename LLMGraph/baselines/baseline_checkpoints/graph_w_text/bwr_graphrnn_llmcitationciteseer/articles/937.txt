Deep learning models have achieved remarkable success in medical image analysis, but their black-box nature limits their adoption in clinical settings. This paper presents a novel Hierarchical Attention Network (HAN) architecture that provides explainable AI capabilities for medical imaging tasks. HAN adaptively selects relevant regions of interest and highlights critical features, enabling clinicians to understand the decision-making process. We evaluate HAN on a large-scale dataset of MRI scans and demonstrate improved performance, interpretability, and robustness compared to state-of-the-art models.