Augmented reality (AR) is increasingly used in museum exhibitions to enhance visitor engagement. However, current gestural interfaces often fail to consider the diverse needs and abilities of visitors. This paper presents an adaptive gestural interface framework, 'ARtivate', which uses machine learning-based user modeling to personalize the interaction experience. ARtivate incorporates a real-time gesture recognition system, a user profiling module, and a dynamic interface adaptation engine. Our user study with 30 participants demonstrates that ARtivate significantly improves user satisfaction, reduces cognitive load, and enhances overall exhibit exploration.