In multi-agent systems, task allocation is a complex problem that requires efficient coordination among agents to achieve global objectives. This paper proposes a novel approach that leverages deep reinforcement learning to learn coordinated task allocation strategies. We design a decentralized, partially observable Markov decision process framework, where each agent learns to allocate tasks based on local observations and communication with neighboring agents. Our approach is able to adapt to changing task requirements and agent capabilities, outperforming traditional optimization-based methods in simulated experiments.