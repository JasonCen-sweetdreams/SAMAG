This paper presents an HCI-driven approach to designing intelligent gesture recognition systems for elderly users with cognitive impairments. We conducted a user-centered design study with 20 participants, identifying key challenges and opportunities for gesture-based interaction. Our system, 'EasyGesture', utilizes machine learning algorithms to recognize and adapt to individual users' gesture patterns, incorporating feedback mechanisms to enhance user confidence and accuracy. Evaluation results show significant improvements in gesture recognition rates and user satisfaction compared to existing systems, highlighting the potential for EasyGesture to support independent living for elderly individuals with cognitive impairments.