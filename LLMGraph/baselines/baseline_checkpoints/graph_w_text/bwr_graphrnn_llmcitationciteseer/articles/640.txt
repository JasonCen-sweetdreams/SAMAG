Skeleton-based action recognition has gained popularity due to its applications in human-computer interaction and healthcare. However, existing methods struggle to capture complex relationships between body joints. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) architecture, which leverages multi-scale graph attention mechanisms to model joint dependencies at different levels of abstraction. Our experiments on the NTU-RGB+D and Kinetics datasets demonstrate that HGAT achieves state-of-the-art performance, outperforming existing graph-based and CNN-based methods. We further analyze the attention weights to provide insights into the importance of different body joints for action recognition.