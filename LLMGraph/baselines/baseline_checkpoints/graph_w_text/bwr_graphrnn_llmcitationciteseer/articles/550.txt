Virtual reality (VR) systems often suffer from user discomfort and fatigue due to inadequate interface design. This paper presents 'EyeGuide', a novel framework that leverages eye-tracking data to adapt VR interfaces in real-time. Our approach utilizes machine learning models to analyze user gaze patterns, identifying areas of visual attention and adjusting interface elements accordingly. We evaluate EyeGuide through a user study, demonstrating significant reductions in user fatigue and improvements in overall VR experience. The results suggest that eye-tracking-based interface adaptation can become a crucial component of next-generation VR systems.