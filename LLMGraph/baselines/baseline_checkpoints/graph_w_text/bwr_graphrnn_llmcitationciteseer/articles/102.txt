The increasing adoption of AI-driven clinical decision support systems (CDSSs) has raised concerns about their interpretability and trustworthiness. This paper presents a novel Hierarchical Attention Network (HAN) architecture that leverages explainable AI techniques to improve the transparency of CDSSs. Our HAN model integrates attention mechanisms at multiple scales to selectively focus on relevant patient information and provide contextualized explanations for predicted diagnoses. Experimental results on a large-scale electronic health record dataset demonstrate the effectiveness of our approach in enhancing model interpretability while maintaining high diagnostic accuracy.