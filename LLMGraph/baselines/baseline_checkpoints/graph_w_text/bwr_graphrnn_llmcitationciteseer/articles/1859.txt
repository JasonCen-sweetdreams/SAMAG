Knowledge graph embeddings (KGEs) have become a crucial component in various AI applications. However, most existing KGE methods suffer from high computational complexity and limited expressive power. This paper presents a novel approach, Hyperbolic Attention Networks (HAN), which leverages hyperbolic geometry to capture complex relationships in knowledge graphs. HAN employs a hyperbolic attention mechanism that adaptively weights entity and relation representations, enabling efficient and effective KGEs. Experimental results on several benchmark datasets demonstrate that HAN outperforms state-of-the-art methods in terms of link prediction and triple classification tasks.