Urban traffic congestion is a pressing issue, and adaptive traffic signal control can significantly alleviate it. We propose a deep reinforcement learning framework, 'AgentSync', that coordinates heterogeneous agents (traffic signals, autonomous vehicles, and pedestrian crossings) to optimize real-time traffic flow. Our approach leverages graph neural networks to model complex traffic networks and incorporates multi-agent reinforcement learning to adapt to changing traffic conditions. Experimental results on a realistic traffic simulator demonstrate that AgentSync reduces congestion by up to 30% and travel time by up to 25% compared to traditional fixed-time signal control.