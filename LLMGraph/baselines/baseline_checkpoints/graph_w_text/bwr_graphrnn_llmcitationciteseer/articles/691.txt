Neural retrieval models have shown promising results in information retrieval tasks, but often struggle with vocabulary mismatch between queries and documents. This paper proposes a novel approach to query expansion, incorporating knowledge graph embeddings to capture semantic relationships between entities and terms. Our method, called 'KEQE', learns to generate contextualized embeddings for query terms, which are then used to expand the query with related terms. Experimental results on a large-scale IR benchmark dataset show that KEQE significantly improves the retrieval performance of neural models, outperforming traditional query expansion techniques.