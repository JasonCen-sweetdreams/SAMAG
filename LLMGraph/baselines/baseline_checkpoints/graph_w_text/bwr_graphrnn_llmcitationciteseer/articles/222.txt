Virtual reality (VR) technology has the potential to revolutionize various aspects of our lives, but current VR interfaces often fail to accommodate users with disabilities. This paper presents ' GestureFit', a novel adaptive gesture recognition system that enables individuals with motor impairments to interact with VR environments more effectively. We propose a machine learning-based approach that leverages multimodal sensor data and user feedback to dynamically adjust the gesture recognition model, ensuring a more inclusive and personalized VR experience. Our user study with 30 participants demonstrates significant improvements in interaction accuracy and user satisfaction compared to traditional gesture-based interfaces.