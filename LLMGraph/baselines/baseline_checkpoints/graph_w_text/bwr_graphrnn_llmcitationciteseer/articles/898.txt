Real-time object detection is crucial for various applications, including autonomous vehicles, surveillance systems, and augmented reality. However, existing neural architecture search (NAS) methods are computationally expensive and may not generalize well to edge devices. This paper proposes a novel, efficient NAS framework, 'EdgeNAS', which leverages a differentiable search space and a novel, hardware-aware reward function to optimize object detection models for edge devices. Our experiments demonstrate that EdgeNAS can discover models that achieve state-of-the-art performance on COCO and Pascal VOC datasets while requiring only 10% of the computation time and 20% of the energy consumption compared to existing NAS methods.