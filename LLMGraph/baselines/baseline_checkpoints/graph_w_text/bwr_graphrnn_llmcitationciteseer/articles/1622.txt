Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks. However, the lack of transparency in DRL policies hinders trust and adoption in high-stakes applications. This paper proposes a novel hierarchical attention-based approach to providing explanations for DRL policies. Our method, dubbed 'HierExplain', leverages attention mechanisms to identify crucial state features and action components contributing to the policy's decision-making process. We demonstrate the effectiveness of HierExplain in a range of Atari games and a real-world autonomous driving scenario, showcasing its ability to generate intuitive and relevant explanations.