This paper presents a novel approach to coordinating autonomous agents for urban traffic control using deep reinforcement learning. Our framework, 'TrafficCtrl', utilizes a decentralized multi-agent system where each agent learns to optimize traffic signal control in real-time. We introduce a graph neural network-based architecture that integrates traffic flow, road network, and agent interactions to improve traffic efficiency and reduce congestion. Experimental results in a simulated urban environment demonstrate that TrafficCtrl outperforms traditional rule-based systems and state-of-the-art reinforcement learning methods, achieving a 23% reduction in average travel time and a 15% decrease in traffic congestion.