Multimodal information systems have become increasingly prevalent, but their inherent complexity hinders effective retrieval. This paper introduces a novel context-aware query expansion (CAQE) framework that leverages multimodal features to facilitate more accurate and relevant search results. By incorporating user preferences, query context, and semantic relationships between query terms, CAQE generates an optimized set of expansion terms that bridge the semantic gap between the user's information need and the multimodal data. Experimental results on a large-scale multimodal dataset demonstrate a significant improvement in retrieval performance, particularly for multimedia-rich queries.