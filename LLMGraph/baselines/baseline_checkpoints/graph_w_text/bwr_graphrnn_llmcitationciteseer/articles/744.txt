Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can manipulate the input data to mislead the model. This paper proposes a novel Bayesian neural symbolic learning (BNSL) framework to robustify DNNs against such attacks. BNSL integrates symbolic reasoning with Bayesian neural networks to learn a probabilistic representation of the input data. We demonstrate that BNSL can effectively detect and correct adversarial attacks, leading to improved model robustness. Experimental results on the CIFAR-10 and ImageNet datasets show that BNSL outperforms state-of-the-art defense methods in terms of accuracy and robustness.