Deep reinforcement learning (RL) has achieved remarkable success in complex decision-making tasks, but its opacity hinders trust and adoption. We propose an attention-based policy distillation approach, 'ExPD', which enables explainable RL by extracting relevant state features and attention weights from a teacher policy. Our method leverages a novel attention mechanism that focuses on critical state aspects and learns to transfer the teacher's policy to a student network with reduced capacity. Experimental results on Atari games and robotic control tasks demonstrate that ExPD achieves competitive performance while providing interpretable insights into the decision-making process.