This paper presents a novel approach to distributed task allocation for autonomous agents using multi-agent reinforcement learning. Our proposed framework, TARL, enables agents to learn cooperative behaviors and allocate tasks efficiently in dynamic environments. We introduce a decentralized Q-network architecture that incorporates a novel attention mechanism, allowing agents to focus on relevant tasks and communicate effectively. Experimental results on a simulated warehouse scenario demonstrate that TARL outperforms traditional task allocation methods, achieving faster task completion rates and improved overall system efficiency.