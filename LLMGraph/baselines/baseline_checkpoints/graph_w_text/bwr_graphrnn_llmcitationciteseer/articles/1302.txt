This paper presents a decentralized multi-agent reinforcement learning approach for autonomous vehicle platooning. We propose a novel coordination mechanism that enables vehicles to learn cooperative strategies for improving fuel efficiency, reducing traffic congestion, and enhancing safety. Our method, called MARPLE, incorporates a graph neural network to model interactions between vehicles and a hierarchical reinforcement learning framework to optimize platooning decisions. Experimental results using a realistic traffic simulator demonstrate that MARPLE outperforms traditional rule-based platooning methods and achieves significant improvements in fuel efficiency and travel time.