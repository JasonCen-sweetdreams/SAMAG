Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but the lack of transparency and explainability hinders its widespread adoption. This paper proposes a novel approach, 'HAT-DRL', which integrates hierarchical attention mechanisms into DRL agents to provide interpretable explanations for their decision-making processes. Our method leverages the inherent hierarchy of tasks and sub-tasks in DRL to selectively focus on relevant state features, resulting in improved explainability without compromising policy performance. Experimental results on Atari games and robotic control tasks demonstrate the effectiveness of HAT-DRL in generating faithful and actionable explanations.