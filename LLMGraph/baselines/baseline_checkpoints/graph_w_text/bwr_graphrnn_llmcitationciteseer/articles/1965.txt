Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables understanding of agent interactions and decision-making. We propose a novel hierarchical attention network (HAN) framework that incorporates attention mechanisms at both the agent and system levels. Our approach enables the identification of critical agent interactions and provides interpretable explanations for joint policy decisions. Experimental results on a variety of MARL benchmarks demonstrate improved explainability and competitive performance compared to state-of-the-art MARL methods.