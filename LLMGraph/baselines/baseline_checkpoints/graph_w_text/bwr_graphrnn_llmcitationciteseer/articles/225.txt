Distributed resource allocation problems are ubiquitous in modern complex systems, such as smart grids, communication networks, and traffic management. This paper proposes a novel heterogeneous multi-agent reinforcement learning framework, 'HMaRL', which enables agents with different capabilities and objectives to learn cooperative policies for efficient resource allocation. We introduce a decentralized, graph-based actor-critic architecture that leverages local observations and communication to adapt to changing system dynamics. Experimental results on a realistic smart grid simulation demonstrate that HMaRL achieves significant improvements in resource utilization and latency reduction compared to traditional optimization methods.