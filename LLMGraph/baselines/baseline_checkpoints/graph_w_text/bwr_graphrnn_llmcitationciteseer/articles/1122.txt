Neural search engines have gained popularity in recent years, but their retrieval performance can be limited by the quality of the query representation. This paper presents a novel query expansion approach that leverages word embeddings to capture semantic relationships between query terms. We propose a two-stage framework that first generates a set of expansion candidates using a neural language model, and then ranks these candidates based on their proximity to the query representation in the embedding space. Experimental results on several benchmark datasets demonstrate that our approach yields significant improvements in retrieval effectiveness, particularly for short and ambiguous queries.