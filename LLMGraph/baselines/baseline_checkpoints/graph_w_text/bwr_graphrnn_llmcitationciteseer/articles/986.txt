Affective computing has led to the development of virtual assistants that can recognize and respond to users' emotions. However, current systems often lack emotional intelligence, leading to inadequate or even annoying responses. This paper proposes an emotionally intelligent virtual assistant (EIVA) framework that integrates cognitive architectures with multimodal affect recognition. Our approach enables EIVAs to reason about user emotions, empathize, and respond with personalized support. We evaluate our framework through a user study, demonstrating significant improvements in user satisfaction and perceived emotional support. The results have implications for designing more effective and empathetic virtual assistants in various applications.