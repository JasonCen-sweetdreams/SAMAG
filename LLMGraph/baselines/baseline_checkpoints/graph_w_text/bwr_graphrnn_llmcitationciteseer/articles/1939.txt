Explainable recommendation systems have gained significant attention in recent years, as they provide insights into the decision-making process. This paper proposes a novel Hierarchical Attention Graph Neural Network (HAGNN) framework, which integrates graph neural networks with hierarchical attention mechanisms. HAGNN learns to represent users and items as graphs, capturing complex relationships and dependencies. The hierarchical attention mechanism enables the model to focus on relevant features and nodes, providing interpretable explanations for the recommended items. Experimental results on multiple benchmark datasets demonstrate the effectiveness of HAGNN in improving recommendation accuracy and providing meaningful explanations.