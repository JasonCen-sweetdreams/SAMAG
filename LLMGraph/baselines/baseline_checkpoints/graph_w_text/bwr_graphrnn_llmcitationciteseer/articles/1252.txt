In multi-agent systems, decision-making often relies on complex interactions between agents. This paper presents a novel attention mechanism, 'Explainable Attention for Agents' (EAA), which enables explainable decision-making in multi-agent environments. EAA leverages graph neural networks to model agent interactions and incorporate domain knowledge. Our approach achieves state-of-the-art performance on several benchmarks, outperforming existing attention-based methods in terms of both decision quality and interpretability. We demonstrate EAA's effectiveness in a real-world autonomous vehicle scenario, providing insights into the decision-making process.