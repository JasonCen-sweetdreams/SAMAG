Individuals with severe mobility impairments often rely on caregivers or specialized devices for navigation. This paper presents a novel gaze-based intelligent wheelchair navigation system, 'GazeNav', which leverages eye-tracking technology and machine learning algorithms to enable independent mobility. GazeNav uses a convolutional neural network to classify user gaze patterns and predict intended navigation commands. We evaluated GazeNav with 15 participants and achieved an average accuracy of 92.5% in navigating through simulated obstacle courses. Our system demonstrates promising potential for enhancing the autonomy and quality of life of individuals with severe mobility impairments.