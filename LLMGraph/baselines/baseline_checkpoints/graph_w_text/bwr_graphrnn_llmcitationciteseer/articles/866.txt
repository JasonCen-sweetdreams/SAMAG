This paper presents a novel approach to multi-agent task allocation using deep reinforcement learning. Our method, called MARL-TA, leverages a decentralized framework where each agent learns to optimize its task allocation policy based on local observations and rewards. We introduce a hierarchical attention mechanism that enables agents to selectively focus on relevant tasks and teammates, leading to improved scalability and adaptability in dynamic environments. Experimental results on a variety of task allocation benchmarks demonstrate that MARL-TA outperforms traditional optimization-based methods and state-of-the-art machine learning approaches.