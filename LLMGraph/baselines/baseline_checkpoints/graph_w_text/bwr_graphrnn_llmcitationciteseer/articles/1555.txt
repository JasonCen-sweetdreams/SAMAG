This paper presents a novel cooperative multi-agent reinforcement learning (MARL) approach for optimizing route planning in autonomous vehicle (AV) fleets. We propose a decentralized policy gradient method, 'CoopRoute', which enables AVs to learn from shared experiences and adapt to dynamic traffic patterns. By incorporating a graph-based communication framework, CoopRoute facilitates knowledge sharing among agents, leading to improved route efficiency and reduced congestion. Experimental results on a large-scale traffic simulation demonstrate the effectiveness of CoopRoute in minimizing travel time and fuel consumption.