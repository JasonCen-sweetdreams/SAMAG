Decentralized task allocation is a fundamental problem in multi-agent systems, where agents need to coordinate to allocate tasks efficiently. This paper proposes a novel approach using reinforcement learning to learn decentralized task allocation policies. We introduce a Markov decision process (MDP) formulation that captures the decentralized nature of the problem and use deep Q-networks to learn the policy. Our approach is evaluated in a simulated environment and shows significant improvements in terms of task allocation efficiency and adaptability to changing environments compared to traditional decentralized algorithms.