Temporal graph embeddings are crucial for modeling complex relationships in dynamic networks. However, existing methods often suffer from high computational costs and limited scalability. We propose a novel hierarchical attention network (HAT) that leverages both node and graph-level attention mechanisms to efficiently capture temporal dependencies. Experiments on several benchmark datasets demonstrate that HAT achieves state-of-the-art performance in temporal link prediction and node classification tasks while reducing computation time by up to 40% compared to existing methods.