Cloud computing platforms face the challenge of optimizing resource allocation to meet dynamic workload demands. This paper presents a novel deep reinforcement learning (DRL) approach, 'CloudOptimizer', which learns to allocate resources efficiently based on historical workload patterns and real-time monitoring data. Our DRL model incorporates a hierarchical architecture with both global and local decision-making components, enabling it to adapt to changing workload conditions and minimize resource waste. Experimental results on a real-world cloud computing dataset demonstrate that CloudOptimizer achieves significant improvements in resource utilization and reduces energy consumption compared to traditional heuristics.