This paper proposes a decentralized task allocation framework for autonomous agents, utilizing multi-agent Q-networks to learn cooperative policies. We extend the traditional Q-learning framework to accommodate multiple agents, enabling them to learn from their individual experiences and adapt to changing environmental conditions. Our approach is evaluated in a simulated logistics scenario, demonstrating improved task allocation efficiency and adaptability compared to centralized optimization methods. We also provide theoretical guarantees on the convergence of our algorithm, ensuring the emergence of cooperative behavior among agents.