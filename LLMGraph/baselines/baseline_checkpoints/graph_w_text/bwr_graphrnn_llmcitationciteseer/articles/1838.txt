Multi-label classification tasks often suffer from class imbalance, where certain labels have a significantly lower number of instances. This paper proposes a novel hierarchical attention network (HAN) that addresses this issue by learning to focus on relevant labels and instances. Our approach consists of a label-aware attention module that selectively weights labels based on their importance and a instance-aware attention module that adaptively aggregates features from similar instances. Experimental results on several benchmark datasets demonstrate that our HAN model outperforms state-of-the-art methods in terms of macro F1-score and label-wise accuracy, especially in scenarios with severe class imbalance.