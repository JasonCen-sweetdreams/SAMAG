Few-shot learning has gained significant attention in recent years, but existing methods often struggle with scalability and interpretability. We propose Hierarchical Prototypical Networks (HPN), a novel few-shot learning framework that leverages hierarchical clustering to learn prototypical representations. HPN enables efficient inference on large datasets and provides interpretable results by learning a hierarchical structure of prototypes. Our extensive experiments on benchmark datasets demonstrate that HPN achieves state-of-the-art performance while reducing computational cost by up to 75%. We also provide visualizations of the learned prototypes, offering insights into the decision-making process of the model.