Autonomous traffic control systems rely on reinforcement learning (RL) agents to optimize traffic flow. However, the lack of transparency in RL decision-making hinders widespread adoption. We propose 'MARL-Explain', a novel multi-agent RL framework that incorporates explainability techniques to provide insights into agent decision-making. Our approach leverages attention mechanisms and saliency maps to visualize the contribution of each agent to the global reward function. Experimental results on a realistic traffic simulation platform demonstrate improved interpretability and a 15% reduction in travel time compared to state-of-the-art baselines.