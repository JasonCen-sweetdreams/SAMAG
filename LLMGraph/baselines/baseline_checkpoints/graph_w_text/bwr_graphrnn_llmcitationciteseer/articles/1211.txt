This paper proposes a novel meta-learning framework for multi-agent reinforcement learning (MARL) that leverages graph neural networks (GNNs) to model complex agent interactions. Our approach, called Meta-MARL-GNN, uses a meta-learning algorithm to adapt to new tasks and environments by learning a shared policy across multiple agents. We demonstrate the effectiveness of Meta-MARL-GNN in several MARL benchmarks, including traffic control and robot soccer, and show that it outperforms existing MARL methods in terms of learning speed and adaptability.