This paper presents a novel approach to coordinating multi-agent systems for real-time traffic control using reinforcement learning. We propose a decentralized framework, 'TRAFFIC-RL', where each agent learns to adjust traffic signal timings based on local observations and communication with neighboring agents. Our approach leverages a hierarchical architecture to balance global optimality with local responsiveness, achieving improved traffic flow and reduced congestion. Experiments on a large-scale traffic simulation demonstrate the effectiveness of TRAFFIC-RL in adapting to dynamic traffic patterns and outperforming traditional optimization methods.