Autonomous vehicles require robust control systems that can handle uncertain and dynamic environments. This paper proposes a hierarchical reinforcement learning (HRL) framework that integrates uncertainty quantification (UQ) to improve the safety and efficiency of autonomous vehicle control. We introduce a novel UQ module that estimates the uncertainty of the vehicle's state and action spaces, which is then used to adapt the HRL policy. Our approach is evaluated on a realistic simulation platform, demonstrating improved control performance and reduced uncertainty compared to traditional HRL methods.