Explainable AI is crucial in medical diagnosis, where model interpretability can inform treatment decisions. We propose a novel Hierarchical Graph Attention Network (HiGAT) for disease diagnosis, which integrates graph neural networks with attention mechanisms to identify relevant symptoms and their relationships. HiGAT outperforms state-of-the-art models on a benchmark electronic health records dataset, achieving an F1-score of 0.92. We demonstrate the model's explainability through visualizations of attention weights, providing insights into the diagnosis process. Our approach has potential applications in clinical decision support systems, enabling healthcare professionals to make more informed decisions.