Individuals with severe motor impairments face significant challenges in interacting with digital systems. Eye-tracking-based interfaces offer a promising solution, but they often struggle with accuracy and reliability. This paper presents EyeGaze+, a novel interface that leverages machine learning algorithms to improve the performance of eye-tracking systems. Our approach incorporates a personalized calibration process, adaptive gaze estimation, and real-time feedback mechanisms. We evaluate EyeGaze+ with a group of participants with severe motor impairments and demonstrate significant improvements in interface accuracy and user satisfaction.