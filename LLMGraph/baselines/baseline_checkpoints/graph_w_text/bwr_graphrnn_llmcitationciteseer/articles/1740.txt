Deep neural networks are vulnerable to adversarial attacks, which significantly degrade their performance. This paper proposes a novel adversarial training approach that leverages hierarchical latent variables to improve the robustness of image classification models. Our method, dubbed 'HLV-Adv', incorporates a hierarchical Bayesian neural network that learns disentangled and interpretable representations of the input data. We show that HLV-Adv outperforms state-of-the-art adversarial training methods on several benchmark datasets, achieving higher classification accuracy and improved robustness against diverse types of attacks.