Short-text retrieval is a challenging task due to the limited context and semantic information. This paper proposes a novel query expansion approach, NeuralQE, which leverages neural word embeddings to capture nuanced semantic relationships between query terms. Our method adapts the Word2Vec model to learn dense vector representations of words in the query and document collections. We then use a sparse matrix factorization technique to efficiently compute the similarity between the expanded query and documents. Experimental results on several benchmark datasets demonstrate that NeuralQE significantly outperforms traditional query expansion methods, especially for short queries.