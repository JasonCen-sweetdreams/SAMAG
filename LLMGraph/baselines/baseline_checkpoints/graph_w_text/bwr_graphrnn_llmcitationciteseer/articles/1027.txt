Individuals with dementia often struggle with expressive gestures, leading to communication breakdowns. This paper presents a novel approach to adaptive gesture recognition, tailored to the unique needs of older adults with dementia. We propose a multimodal fusion framework that integrates computer vision, machine learning, and cognitive modeling to recognize gestures in real-time. Our system, 'GestureGuide', adapts to the user's abilities and preferences, providing personalized feedback and support. A pilot study with 20 participants demonstrates significant improvements in gesture recognition accuracy and user engagement, highlighting the potential of GestureGuide to enhance communication and quality of life for individuals with dementia.