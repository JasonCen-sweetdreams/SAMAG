This paper presents a novel approach to cooperative task allocation in multi-agent systems, where agents with diverse capabilities must work together to accomplish complex tasks. We propose a deep reinforcement learning framework that enables agents to learn effective task allocation strategies through interactions with their environment and other agents. Our approach, called 'CooperA', leverages graph neural networks to represent agent interactions and a decentralized actor-critic architecture to enable efficient learning. Experimental results demonstrate that CooperA outperforms traditional optimization-based methods and existing learning-based approaches in various task allocation scenarios, showcasing its potential for real-world applications such as search and rescue operations.