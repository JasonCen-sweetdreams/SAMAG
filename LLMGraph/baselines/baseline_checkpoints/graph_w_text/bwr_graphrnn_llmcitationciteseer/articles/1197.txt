Neural retrieval models have shown remarkable performance in information retrieval tasks, but they often suffer from the vocabulary mismatch problem. To address this, we propose a novel query expansion method that leverages contrastive learning to generate high-quality expansion terms. Our approach, dubbed 'ConEx', learns to contrast the query representation with a set of relevant and non-relevant documents, resulting in a more accurate and diverse set of expansion terms. Experimental results on several benchmark datasets demonstrate that ConEx significantly outperforms traditional query expansion methods, leading to improved retrieval performance and robustness.