Meta-learning has emerged as a promising approach to few-shot learning, where a model is trained to adapt to new tasks with limited data. However, existing methods often rely on complex architectures or require extensive hyperparameter tuning. This paper proposes a simple yet effective meta-learning framework, 'AdaTask', which leverages adaptive task embeddings to condition the model's parameters. We introduce a novel task embedding scheme that captures task similarities and dissimilarities, enabling the model to focus on the most informative samples. Experiments on benchmark datasets demonstrate that AdaTask achieves state-of-the-art performance on few-shot image classification tasks, while requiring significantly fewer hyperparameter searches.