Knowledge graph completion is a crucial task in AI, but it becomes increasingly challenging when faced with limited training data. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages hierarchical graph structures to learn effective representations for few-shot knowledge graph completion. HGAT combines graph attention mechanisms with hierarchical clustering to adaptively select relevant nodes and edges, enabling the model to generalize well to unseen entities and relations. Experimental results on benchmark datasets demonstrate that HGAT outperforms state-of-the-art few-shot knowledge graph completion methods, achieving significant improvements in both link prediction and entity disambiguation tasks.