Virtual reality (VR) has the potential to revolutionize human-computer interaction, but high cognitive loads can hinder user experience. This paper explores the concept of embodied cognition in VR, where gestural interfaces can reduce cognitive load by leveraging the brain's motor-sensory integration. We design and evaluate a novel gestural interface, 'CogniGest', which utilizes proprioceptive feedback to facilitate intuitive object manipulation in VR. Our user study shows that CogniGest significantly reduces cognitive load and improves task performance compared to traditional controller-based interfaces. The findings have implications for the design of more immersive and accessible VR experiences.