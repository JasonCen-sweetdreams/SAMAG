State-of-the-art neural ranking models in information retrieval (IR) often rely on complex and computationally expensive architectures. This paper proposes a novel deep neural re-ranking model, 'QRN', which leverages query-document embeddings to efficiently capture semantic relationships between queries and documents. QRN utilizes a dual-encoder architecture that jointly learns query and document representations, and a lightweight re-ranking module that refines the initial ranking list. Experimental results on the TREC Deep Learning Track dataset demonstrate that QRN significantly outperforms traditional ranking methods and achieves comparable performance to more complex neural ranking models, while requiring significantly less computational resources.