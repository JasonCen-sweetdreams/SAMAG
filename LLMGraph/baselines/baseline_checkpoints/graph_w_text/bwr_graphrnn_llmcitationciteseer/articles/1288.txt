Explainable recommendation systems (ERS) are crucial for building trust in AI-driven decision-making. This paper proposes a novel Hierarchical Attention Network (HAN) architecture for ERS, which learns to focus on relevant user and item features to generate interpretable recommendations. Our approach involves a two-stage attention mechanism: (1) item-level attention to identify influential features, and (2) user-level attention to weigh the importance of item features for each user. Experimental results on several benchmark datasets demonstrate that HAN outperforms state-of-the-art ERS models in terms of recommendation accuracy and explanation quality.