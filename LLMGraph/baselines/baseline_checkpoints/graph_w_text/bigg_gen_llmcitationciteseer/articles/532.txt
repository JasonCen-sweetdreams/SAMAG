Cooperative agents in multi-agent systems often struggle with task allocation due to incomplete information and conflicting goals. This paper presents a decentralized task allocation framework that leverages deep reinforcement learning to enable cooperative agents to adapt to dynamic environments. Our approach, called 'CATARINA', utilizes a hierarchical graph neural network to learn a task allocation policy that balances individual agent rewards with global system efficiency. Experimental results on a simulated urban search and rescue scenario demonstrate that CATARINA outperforms traditional optimization-based methods in terms of task completion rate and agent satisfaction.