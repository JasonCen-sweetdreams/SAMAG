Multi-hop question answering (MHQA) requires models to perform complex reasoning over multiple sentences. While existing approaches achieve high accuracy, they often struggle to provide interpretable explanations for their predictions. This paper proposes a novel hierarchical attention network (HAN) that incorporates both word-level and sentence-level attention mechanisms to generate explainable MHQA models. We demonstrate that our HAN-based approach outperforms state-of-the-art models on several MHQA benchmarks while providing transparent and coherent explanations for its answers.