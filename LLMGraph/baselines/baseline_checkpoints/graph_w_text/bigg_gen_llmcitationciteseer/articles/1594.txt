Conversational interfaces have become increasingly prevalent, but their design often neglects the needs of visually impaired users. This paper presents a user-centered approach to designing accessible conversational interfaces, focusing on the development of a novel dialogue management system that leverages natural language processing and machine learning techniques. Our system incorporates a range of accessibility features, including real-time speech output, tactile feedback, and personalized user modeling. A usability study with 20 visually impaired participants demonstrates significant improvements in user satisfaction and task completion rates compared to existing conversational interfaces.