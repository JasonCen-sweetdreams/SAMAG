This paper proposes a decentralized multi-agent reinforcement learning framework for coordinating autonomous vehicles in complex traffic scenarios. Our approach, named 'DMARL-Ctrl', enables vehicles to learn cooperative policies in a decentralized manner, without relying on a central controller or explicit communication. We introduce a novel reward function that incorporates both local and global objectives, and demonstrate its effectiveness in reducing congestion and improving safety in simulated traffic environments. Experimental results show that DMARL-Ctrl outperforms traditional rule-based control methods and centralized optimization approaches in realistic traffic scenarios.