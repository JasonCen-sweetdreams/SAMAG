Individuals with mobility impairments often rely on wheelchairs for daily navigation. This paper presents a novel gaze-based intent recognition system for intelligent wheelchair navigation. We propose a deep learning model that leverages electrooculography (EOG) signals and computer vision techniques to predict the user's intended direction. Our approach integrates a convolutional neural network (CNN) with a long short-term memory (LSTM) network to learn spatiotemporal patterns in EOG data. Experimental results demonstrate that our system achieves an average accuracy of 92.5% in recognizing user intent, outperforming existing methods and enabling more efficient and independent wheelchair navigation.