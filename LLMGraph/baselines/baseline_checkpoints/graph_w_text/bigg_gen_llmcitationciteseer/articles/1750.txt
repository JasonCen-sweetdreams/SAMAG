Effective task allocation is crucial in multi-agent systems, where agents with diverse capabilities and constraints need to collaborate to achieve complex goals. We propose a distributed task allocation framework that leverages reinforcement learning to optimize task assignments in heterogeneous multi-agent systems. Our approach, called HRL-TA, uses a decentralized actor-critic architecture to learn task allocation policies that balance individual agent preferences with system-wide efficiency. Experiments on a real-world disaster response scenario demonstrate that HRL-TA outperforms traditional optimization-based methods in terms of task completion rate and overall system utility.