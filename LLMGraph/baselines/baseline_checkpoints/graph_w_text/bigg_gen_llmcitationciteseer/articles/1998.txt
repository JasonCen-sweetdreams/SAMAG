Cooperative reinforcement learning in multi-agent systems is a challenging problem, as agents must learn to coordinate their actions to achieve a common goal. This paper introduces a novel hierarchical attention network (HAN) architecture that enables agents to selectively focus on relevant teammates and learn effective communication strategies. Our approach improves upon existing methods by incorporating a hierarchical structure that captures both local and global relationships between agents. Experimental results on a range of multi-agent environments demonstrate the effectiveness of HAN in achieving higher rewards and better coordination compared to state-of-the-art baselines.