Neural retrieval models have shown promise in information retrieval tasks, but they often struggle with vocabulary mismatch between the query and relevant documents. This paper proposes a novel query expansion strategy that leverages pseudo-relevance feedback to improve the retrieval performance of neural models. We introduce a neural pseudo-relevance feedback generator that predicts relevant terms based on the query and top-retrieved documents, and demonstrate its effectiveness in expanding the query representation. Experimental results on several benchmark datasets show that our approach significantly outperforms existing query expansion methods, achieving state-of-the-art retrieval performance on several tasks.