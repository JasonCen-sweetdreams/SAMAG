As data warehousing shifts to the cloud, distributed join operations become increasingly critical for query performance. However, optimizing join orders and allocating resources efficiently remain significant challenges. This paper presents a novel query optimization framework, 'DistroJoin', which leverages machine learning and graph-based models to predict optimal join orders and resource allocations. We propose a hybrid approach that combines reinforcement learning with traditional query optimization techniques, resulting in improved query response times and reduced resource utilization. Experimental evaluations on Amazon Redshift and Google BigQuery demonstrate the efficacy of DistroJoin in handling complex distributed join operations.