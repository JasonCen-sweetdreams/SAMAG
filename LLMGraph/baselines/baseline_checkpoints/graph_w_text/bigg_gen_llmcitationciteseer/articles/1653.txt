Virtual reality (VR) has the potential to enhance accessibility and inclusivity, but traditional controllers can be challenging for users with motor impairments. This paper investigates the design and evaluation of gestural interaction techniques for VR, focusing on users with limited mobility. We propose a novel machine learning-based hand-tracking system that recognizes and interprets a range of gestures, allowing users to interact with virtual objects in a more intuitive and accessible manner. Our user study demonstrates improved engagement and task completion rates for participants with motor impairments, highlighting the potential of gestural interaction to increase VR inclusivity.