In virtual reality (VR) environments, accurately inferring user intent is crucial for seamless interaction. This paper introduces EyeGazePredict, a novel deep learning model that leverages gaze patterns to predict user intent in VR. Our model combines convolutional and recurrent neural networks to extract spatial and temporal features from gaze data, achieving an accuracy of 92.5% on a benchmark dataset. We also conduct a user study to demonstrate the model's effectiveness in reducing interaction latency and improving overall user experience. The results have significant implications for the development of intuitive and efficient VR interfaces.