Decentralized task assignment is a fundamental problem in multi-agent systems, where agents need to coordinate to accomplish complex tasks. This paper proposes a novel approach using graph neural networks (GNNs) to learn decentralized task assignment policies. We model the agent interactions as a graph and leverage GNNs to learn a distributed task assignment algorithm that adapts to changing task requirements and agent capabilities. Our approach outperforms traditional decentralized task assignment algorithms in terms of task completion rate and overall system efficiency. We demonstrate the effectiveness of our approach through extensive simulations on various multi-agent systems.