Edge computing has enabled low-latency processing of massive amounts of data, but efficient resource allocation remains a significant challenge. This paper proposes a multi-agent reinforcement learning framework, 'MARA', which enables autonomous decision-making among edge nodes. We design a novel action space that incorporates both resource allocation and task scheduling, and develop a decentralized Q-learning algorithm that adapts to dynamic edge computing environments. Experiments on a realistic edge computing simulator demonstrate that MARA achieves significant improvements in resource utilization, response time, and overall system throughput compared to traditional centralized resource allocation methods.