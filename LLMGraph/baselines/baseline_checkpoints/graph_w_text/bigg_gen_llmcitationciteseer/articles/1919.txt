This paper presents a novel approach to designing voice assistants that adapt to users with dysarthria, a speech disorder that affects articulation, fluency, and intelligibility. We conducted a mixed-methods study with 20 participants, combining speech recognition, eye-tracking, and user experience surveys to investigate the impact of adaptive voice assistants on user interaction. Our findings highlight the importance of multimodal input fusion, personalized error correction, and emotional support in enhancing user engagement and satisfaction. We propose a set of design guidelines for inclusive voice assistants that can be integrated into existing HCI frameworks.