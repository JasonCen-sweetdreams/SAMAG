Coordinating heterogeneous multi-agent systems (MAS) remains a challenging problem in distributed artificial intelligence. This paper proposes a novel deep reinforcement learning (DRL) framework, 'CoMA', which enables heterogeneous agents to learn coordinated policies in complex, dynamic environments. CoMA leverages a graph attention mechanism to model inter-agent relationships and a hierarchical policy architecture to adapt to diverse agent capabilities. Experimental results on a suite of benchmarks demonstrate that CoMA outperforms state-of-the-art MAS algorithms in terms of coordination efficiency and adaptability to changing environmental conditions.