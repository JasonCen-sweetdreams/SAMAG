Virtual reality (VR) systems rely on precise and efficient user input methods. This paper presents a novel gaze-based interaction framework for VR, leveraging deep reinforcement learning (DRL) to predict user intentions from eye-tracking data. Our approach, 'GazeRL', utilizes a hybrid architecture combining convolutional neural networks (CNNs) for feature extraction and a deep Q-network (DQN) for policy optimization. Experimental results demonstrate that GazeRL outperforms traditional gaze-based methods in terms of accuracy and latency, enabling seamless interactions in immersive VR environments.