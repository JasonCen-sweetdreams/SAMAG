Virtual reality (VR) systems rely heavily on natural and intuitive user interfaces. Gesture recognition is a crucial component, but existing systems often struggle with variability in user gestures, leading to reduced accuracy and user frustration. This paper presents a novel adaptive gesture recognition framework, 'AdaptGest', which leverages machine learning and human-computer interaction principles to personalize gesture recognition models to individual users. We conduct a user study to evaluate AdaptGest's performance and demonstrate significant improvements in recognition accuracy and user satisfaction compared to traditional, one-size-fits-all approaches.