Autonomous warehouses are increasingly relying on multi-agent systems to optimize task allocation and execution. This paper proposes a novel hierarchical task planning framework that leverages multi-agent reinforcement learning to coordinate agents in dynamic warehouse environments. Our approach integrates a high-level task planner with a low-level motion planner, enabling agents to learn complex task dependencies and adapt to changing warehouse conditions. Experimental results demonstrate improved task completion rates and reduced agent collisions compared to traditional rule-based approaches.