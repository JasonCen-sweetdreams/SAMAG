Autonomous agents are increasingly being used in complex systems to optimize resource allocation. However, coordinating these agents to achieve global efficiency remains a significant challenge. This paper proposes a novel hierarchical reinforcement learning framework, 'HARL', which enables autonomous agents to learn coordinated policies for efficient resource allocation. HARL consists of a high-level coordinator agent that guides the exploration-exploitation trade-off of lower-level agents, allowing them to adapt to changing system dynamics. Experimental results on a simulated smart grid demonstrate that HARL significantly outperforms traditional decentralized approaches in terms of resource utilization and system stability.