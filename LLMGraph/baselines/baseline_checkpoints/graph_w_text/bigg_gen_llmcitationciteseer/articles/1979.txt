Resource allocation in multi-agent systems is a challenging problem, especially when agents have conflicting objectives. This paper proposes a novel approach that leverages deep reinforcement learning to coordinate agent behavior and optimize resource allocation. We introduce a hierarchical framework that combines a high-level planning module with a low-level execution module, enabling agents to adapt to changing environments and negotiate resources with other agents. Experimental results on a simulated grid resource allocation problem demonstrate that our approach outperforms traditional methods in terms of resource utilization and agent satisfaction.