Virtual reality (VR) systems often rely on manual input devices, which can be cumbersome and disrupt the immersive experience. This paper presents a novel gaze-based interaction approach that leverages machine learning-based eye movement prediction to enable hands-free interaction in VR. Our method uses a convolutional neural network (CNN) to predict the user's gaze direction based on eye movement data, achieving a mean angular error of 2.4 degrees. We integrate this approach with a VR platform and demonstrate its effectiveness in various interactive tasks, including object selection and menu navigation.