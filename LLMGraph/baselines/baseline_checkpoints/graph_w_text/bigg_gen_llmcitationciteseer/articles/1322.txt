Multi-agent decision-making systems require interpretable models that can capture complex relationships between agents and their environments. We propose a novel heterogeneous graph attention network (HGAN) framework that integrates agent-centric and graph-centric representations to facilitate explainable decision-making. Our approach leverages attention mechanisms to selectively focus on relevant agents, objects, and context, enabling the model to provide transparent and interpretable outputs. Experimental results on a real-world autonomous vehicle dataset demonstrate that HGAN outperforms state-of-the-art methods in terms of decision accuracy and explainability.