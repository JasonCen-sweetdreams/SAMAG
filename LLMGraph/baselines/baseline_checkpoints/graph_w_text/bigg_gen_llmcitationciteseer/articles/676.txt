As augmented reality (AR) technology becomes increasingly prevalent, there is a growing need for more natural and intuitive human-computer interaction mechanisms. This paper presents a novel gaze-based interaction framework for AR environments, leveraging computer vision and machine learning techniques to detect and analyze user gaze patterns. Our approach enables users to seamlessly select and manipulate virtual objects in 3D space, eliminating the need for manual input devices. We evaluate our framework through a series of user studies, demonstrating significant improvements in interaction time, accuracy, and overall user experience.