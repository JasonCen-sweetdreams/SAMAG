Neural search engines have shown promising results in ad-hoc retrieval tasks, but often struggle with suboptimal query representations. This paper presents a novel query expansion method, CLQE, which leverages contrastive learning to learn a dense representation of queries and documents. By training a neural network to contrast positive and negative samples, we can generate effective query expansions that improve the retrieval performance of neural search engines. Experimental results on the TREC-8 dataset show that CLQE outperforms state-of-the-art query expansion methods, achieving a 15% increase in mean average precision.