Autonomous vehicles (AVs) rely on multi-modal sensor fusion to perceive their environment. However, integrating and processing this diverse data in real-time remains a significant challenge. This paper proposes a hierarchical reinforcement learning (HRL) framework that leverages a novel, attention-based sensor fusion mechanism to optimize AV control. Our approach combines a high-level, goal-oriented policy with low-level, reactive control modules, enabling efficient exploration and adaptation to complex scenarios. Experimental results on a simulated AV platform demonstrate improved performance and robustness compared to traditional, monolithic RL methods, particularly in the presence of sensor noise and uncertainty.