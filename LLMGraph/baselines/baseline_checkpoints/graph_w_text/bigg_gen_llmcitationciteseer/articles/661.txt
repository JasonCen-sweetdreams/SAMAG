This paper presents a novel approach to coordinating multi-agent systems in dynamic task allocation scenarios. We propose a hierarchical reinforcement learning framework, termed HRL-MA, which enables agents to learn both high-level task assignment policies and low-level action execution strategies. HRL-MA incorporates a layered decomposition of the task space, allowing agents to adapt to changing task requirements and environmental conditions. Experimental results in a simulated smart factory domain demonstrate that HRL-MA outperforms state-of-the-art coordination methods in terms of task completion rates and overall system efficiency.