In multi-agent systems, planning with uncertainty remains a significant challenge. This paper proposes a decentralized approach, 'MA-DRUL', which leverages deep reinforcement learning to learn policies for individual agents that account for uncertain outcomes. We introduce a novel hierarchical architecture that combines a high-level, graph-based planner with low-level, policy-based controllers. Experimental results on a real-world traffic management scenario demonstrate that MA-DRUL outperforms state-of-the-art decentralized planning methods, achieving a 25% reduction in average travel time while handling uncertain traffic patterns.