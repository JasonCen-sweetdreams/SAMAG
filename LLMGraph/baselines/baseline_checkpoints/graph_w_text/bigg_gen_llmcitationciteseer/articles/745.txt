Explainability is crucial in multi-agent systems, where decisions are often made by autonomous entities. We propose a novel hierarchical reasoning framework, HREM, that integrates symbolic reasoning with probabilistic graphical models to provide transparent and justifiable decision-making in multi-agent environments. HREM enables agents to reason about context-specific goals, intentions, and causal relationships, and generates natural language explanations for their decisions. We demonstrate HREM's effectiveness in a simulated smart home scenario, where it outperforms traditional decision-theoretic approaches in terms of explainability and decision quality.