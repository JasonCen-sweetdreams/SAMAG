In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a novel approach that leverages deep reinforcement learning to coordinate task allocation among agents. We propose a decentralized framework, 'CATALYST', which enables agents to learn from their experiences and adapt to dynamic environments. Our approach uses a graph neural network to model agent interactions and a deep Q-network to optimize task assignments. Experimental results on a simulated logistics scenario demonstrate that CATALYST outperforms traditional methods in terms of task completion time and resource utilization.