Explainable recommendation systems have gained significant attention in recent years, but most existing methods rely on hand-crafted features or shallow model interpretations. This paper proposes a novel attention-based framework, 'KG-Attr', that leverages knowledge graph embeddings to provide personalized explanations for recommended items. Our approach incorporates a multi-task learning objective that jointly optimizes recommendation accuracy and explanation quality. Experimental results on two real-world datasets demonstrate that KG-Attr outperforms state-of-the-art explainable recommendation methods while providing intuitive and interpretable explanations.