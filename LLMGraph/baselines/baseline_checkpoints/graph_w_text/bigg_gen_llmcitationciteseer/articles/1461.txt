Question answering (QA) models have achieved remarkable success, but their opacity hinders trust and understanding. This paper proposes a Hierarchical Attention Network (HAN) for explainable QA, which disentangles the reasoning process into attention weights and semantic role identification. Our approach leverages a novel hierarchical attention mechanism that selectively focuses on relevant contextual information and identifies the most informative spans. Experimental results on the SQuAD dataset demonstrate that HAN outperforms state-of-the-art QA models while providing interpretable attention patterns and semantic role-based explanations.