This paper proposes a novel multi-agent reinforcement learning framework for distributed traffic control. Our approach, called 'MARL-Traffic', enables a network of autonomous agents to learn cooperative policies for optimizing traffic flow in real-time. We leverage deep Q-networks with a decentralized actor-critic architecture, allowing agents to adapt to changing traffic patterns and communicate with neighboring agents to minimize congestion. Experimental results on a simulated traffic network demonstrate that MARL-Traffic outperforms traditional traffic signal control methods, reducing travel times by up to 30% and increasing network throughput by 25%