Explainability is crucial in autonomous vehicles to ensure safety and trustworthiness. This paper introduces HAREL, a hierarchical attention-based framework that integrates reinforcement learning with model-based explainability. HAREL incorporates a novel attention mechanism that selectively focuses on relevant sensory inputs, enabling the agent to learn interpretable policies. We evaluate HAREL on a realistic autonomous driving simulation and demonstrate improved explainability, safety, and performance compared to state-of-the-art reinforcement learning methods.