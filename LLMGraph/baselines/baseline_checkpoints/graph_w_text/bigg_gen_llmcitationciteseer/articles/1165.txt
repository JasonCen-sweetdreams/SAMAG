Vision transformers have shown promising results in image classification tasks, but their robustness against adversarial attacks remains a concern, particularly in safety-critical applications like autonomous vehicles. This paper proposes a novel adversarial training framework, 'AdviT', which leverages a surrogate loss function to robustify vision transformers against a wide range of attacks. Our method involves generating adversarial examples using a dynamic perturbation strategy and incorporating them into the training process. Experimental results on the KITTI dataset demonstrate that AdviT significantly improves the robustness of vision transformers against both white-box and black-box attacks, while maintaining state-of-the-art performance on clean images.