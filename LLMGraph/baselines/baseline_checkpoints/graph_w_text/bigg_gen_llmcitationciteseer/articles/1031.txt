Resource allocation in cloud computing is a complex problem that requires efficient optimization. This paper proposes a hierarchical reinforcement learning (HRL) framework to tackle this problem. Our approach uses a high-level policy to allocate resources to different applications, and a low-level policy to optimize the allocation within each application. We introduce a novel reward function that balances resource utilization and application performance. Experimental results on a real-world cloud computing dataset show that our approach outperforms state-of-the-art baselines in terms of resource efficiency and application performance.