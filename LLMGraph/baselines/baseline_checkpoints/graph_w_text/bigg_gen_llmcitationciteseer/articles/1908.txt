Scheduling tasks in cloud computing environments is a complex problem due to resource constraints and dynamic workload demands. This paper proposes a novel deep reinforcement learning (DRL) framework, 'CloudSched', which learns to optimize scheduling decisions based on historical workload patterns and resource availability. We design a customized neural network architecture that incorporates graph attention mechanisms to capture dependency relationships between tasks and resources. Experimental results on a real-world cloud computing dataset show that CloudSched outperforms state-of-the-art scheduling algorithms, achieving significant reductions in average response time and resource utilization.