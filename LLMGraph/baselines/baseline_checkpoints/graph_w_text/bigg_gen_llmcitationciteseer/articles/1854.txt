Deep reinforcement learning (DRL) has achieved significant success in various applications, but it remains vulnerable to adversarial attacks. This paper proposes a novel graph-based anomaly detection approach, 'GADRL', to identify adversarial attacks in DRL agents. GADRL constructs a graph representation of the agent's state-action trajectories and leverages graph neural networks to detect anomalies. We evaluate GADRL on several DRL benchmarks and demonstrate its effectiveness in detecting various types of adversarial attacks, including poisoning and evasion attacks. Our approach outperforms existing detection methods and provides a promising direction for securing DRL systems.