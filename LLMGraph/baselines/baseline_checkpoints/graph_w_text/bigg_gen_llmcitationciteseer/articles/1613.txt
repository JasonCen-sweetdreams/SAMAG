Urban traffic control systems face the challenge of coordinating heterogeneous agents, including autonomous vehicles, traffic signals, and pedestrians. This paper proposes a novel approach that leverages deep reinforcement learning to optimize traffic flow and reduce congestion. We design a multi-agent framework that integrates graph attention networks and Q-learning to learn effective coordination strategies. Experimental results on a simulated urban traffic network demonstrate improved traffic efficiency and reduced travel times compared to traditional control methods. Our approach has potential applications in smart city infrastructure and autonomous transportation systems.