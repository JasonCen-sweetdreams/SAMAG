Few-shot image classification remains a challenging task in computer vision, particularly when dealing with limited training data. This paper proposes a novel deep transfer learning framework, Hierarchical Prototypical Networks (HPNs), which leverages the knowledge acquired from pre-trained models to learn efficient representations for few-shot classification. Our approach introduces a hierarchical prototypical embedding space, where class prototypes are learned at multiple semantic levels, enabling the model to capture both global and local features. Experimental results on benchmark datasets demonstrate that HPNs outperform state-of-the-art methods in few-shot image classification, while requiring fewer parameters and computations.