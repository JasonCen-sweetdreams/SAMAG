Individuals with motor disabilities often rely on assistive systems to communicate and interact with their environment. However, these systems can be improved by incorporating user intention inference. This paper presents a novel approach to inferring user intentions using gaze patterns. We propose a machine learning model that leverages eye-tracking data to predict user goals and adapt the assistive system's behavior accordingly. Our approach is evaluated in a case study with 20 participants, showing significant improvements in task completion time and user satisfaction. The results demonstrate the potential of gaze-based intention inference for enhancing the usability and effectiveness of adaptive assistive systems.