Electromyography (EMG) signals have shown promise in gesture recognition, but existing approaches suffer from limited generalizability and high variability in user data. This paper proposes a novel deep learning framework that integrates EMG signals with computer vision features to enable personalized gesture recognition. Our approach leverages a multitask learning architecture to jointly learn gesture recognition, user identification, and EMG signal denoising. Experimental results on a large-scale dataset demonstrate significant improvements in gesture recognition accuracy and robustness compared to state-of-the-art methods, paving the way for practical applications in human-computer interaction.