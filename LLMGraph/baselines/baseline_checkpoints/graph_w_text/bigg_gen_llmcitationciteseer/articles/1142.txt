Virtual assistants (VAs) are increasingly integrated into daily life, yet users' trust in these systems remains a significant concern. This study investigates the effect of anthropomorphic cues, such as facial expressions and body language, on user trust in VAs. We conducted a mixed-methods study with 120 participants, using a custom-built VA platform with varying levels of anthropomorphism. Results show that subtle anthropomorphic cues can significantly enhance user trust and perceived reliability, particularly among users with lower technology proficiency. However, overt anthropomorphism can lead to decreased trust due to perceived artificiality. Implications for VA design and future research directions are discussed.