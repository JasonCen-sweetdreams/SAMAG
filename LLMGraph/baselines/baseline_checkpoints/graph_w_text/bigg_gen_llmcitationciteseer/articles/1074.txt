Individuals with motor disabilities often face challenges interacting with digital systems. This paper presents 'AdaptaGest', a machine learning-based approach for adaptive gesture recognition that accommodates varying abilities and contexts. AdaptaGest employs a novel transfer learning strategy that leverages domain knowledge from able-bodied users to personalize models for individuals with motor disabilities. Our user study with 20 participants demonstrates significant improvements in gesture recognition accuracy and user satisfaction compared to existing approaches. We also provide insights into the design implications of AdaptaGest for inclusive HCI systems.