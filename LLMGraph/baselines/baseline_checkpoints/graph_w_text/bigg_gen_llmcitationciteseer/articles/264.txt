Deep learning models have achieved state-of-the-art performance in medical image segmentation tasks, but their opacity hinders trust and adoption in clinical practice. This paper proposes a novel hierarchical attention network (HAN) architecture that integrates explainable AI techniques to provide insights into the model's decision-making process. Our approach leverages spatial and channel-wise attention mechanisms to focus on relevant regions and features, respectively, while generating heatmaps that highlight the contribution of each input feature to the segmentation output. Experimental results on the BraTS17 dataset demonstrate that our HAN model achieves comparable performance to state-of-the-art methods while providing interpretable explanations for its predictions.