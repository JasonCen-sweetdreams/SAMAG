Neural retrieval models have gained popularity in ad-hoc search due to their ability to capture complex semantic relationships. However, their performance can be limited by the quality of the input queries. This paper investigates the effectiveness of query expansion techniques on neural retrieval models, focusing on their impact on retrieval accuracy and efficiency. We conduct a comprehensive evaluation of various query expansion methods, including word embeddings, pseudo-relevance feedback, and learning-to-rank, using a range of benchmark datasets. Our results show that carefully selected query expansion strategies can significantly improve the performance of neural retrieval models, but also highlight the importance of query reformulation and term weighting in achieving optimal results.