We present a novel approach to coordinating multi-agent systems for autonomous traffic flow optimization using deep reinforcement learning. Our framework, called MATRL, leverages a decentralized actor-critic architecture to learn cooperative policies for a fleet of autonomous vehicles. MATRL utilizes a graph-based representation of the traffic network to enable efficient communication and coordination among agents. Experimental results on a realistic traffic simulator demonstrate that MATRL outperforms state-of-the-art methods in reducing congestion and increasing traffic flow, while ensuring safety and feasibility constraints. Our approach has the potential to significantly improve the efficiency and safety of autonomous transportation systems.