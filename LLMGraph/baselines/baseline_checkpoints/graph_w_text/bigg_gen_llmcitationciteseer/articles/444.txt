Individuals with dysarthria often face significant challenges when interacting with voice-based systems. This paper presents a novel framework, 'EasyVoice', which leverages machine learning and natural language processing techniques to improve the accessibility of voice-based interfaces for individuals with dysarthria. Our approach involves adapting speech recognition models to accommodate the unique speech patterns of individuals with dysarthria, as well as developing personalized feedback mechanisms to enhance user experience. We evaluate EasyVoice using a user study with 20 participants and demonstrate significant improvements in recognition accuracy and user satisfaction.