In multi-agent systems, efficient task allocation is crucial for achieving optimal performance. This paper presents a hierarchical reinforcement learning framework, 'HRL-TA', which enables agents to adapt to dynamic environments and allocate tasks effectively. HRL-TA consists of a high-level planning module that assigns tasks to agents based on their capabilities and a low-level execution module that refines task allocations using reinforcement learning. We evaluate HRL-TA in a simulated robotic search-and-rescue scenario, demonstrating significant improvements in task completion efficiency and robustness compared to existing methods.