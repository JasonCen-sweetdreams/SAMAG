Virtual reality (VR) has become increasingly popular, but users often experience fatigue and discomfort due to inadequate interface designs. This paper presents an innovative eye-gaze driven adaptive interface, called 'EyeGuide', which leverages machine learning-based gaze tracking to dynamically adjust the VR environment. EyeGuide predicts user intent and preferences, allowing for personalized adjustments to font sizes, color schemes, and navigation. Our user study demonstrates significant improvements in user experience, with reduced eye strain and increased overall satisfaction. The results have implications for designing more accessible and engaging VR interfaces.