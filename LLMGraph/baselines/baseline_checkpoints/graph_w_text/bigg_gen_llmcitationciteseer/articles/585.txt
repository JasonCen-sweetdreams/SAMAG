Autonomous vehicles (AVs) are increasingly being deployed in various scenarios, including search and rescue, environmental monitoring, and urban transportation. Effective task allocation is critical to optimizing the performance of AV teams. This paper proposes a novel multi-agent reinforcement learning (MARL) framework, 'CoopAV', which enables cooperative task allocation among AVs. CoopAV leverages a decentralized policy gradient method to learn communication protocols and task assignments that maximize the team's cumulative reward. Experimental results on a simulated AV fleet demonstrate improved task completion rates and reduced communication overhead compared to traditional, centralized allocation methods.