Estimating uncertainty in deep neural networks is crucial for reliable decision-making in computer vision applications. This paper proposes a novel Bayesian neural network (BNN) framework that leverages efficient Monte Carlo dropout and stochastic variational inference to approximate the posterior distribution over model weights. We introduce a new uncertainty metric, 'Aleatoric Uncertainty Score', which better captures epistemic uncertainty compared to existing methods. Experimental results on image classification and object detection tasks demonstrate that our approach achieves state-of-the-art uncertainty estimation while maintaining competitive predictive performance.