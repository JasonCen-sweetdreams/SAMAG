In information retrieval, document representation is a critical component that affects the performance of search engines. This paper proposes a novel hierarchical document representation framework that leverages attention-based semantic encoding to capture complex contextual relationships between words and documents. Our approach, dubbed HiDRE, learns to represent documents as a weighted combination of semantic concepts, which enables more accurate query-document matching. Experimental results on several benchmark datasets demonstrate that HiDRE outperforms state-of-the-art document representation methods, including BERT-based models, in terms of retrieval accuracy and robustness to noise.