This paper presents a novel multi-agent reinforcement learning framework for coordinating autonomous vehicles in smart cities. Our approach, 'MARL-City', leverages graph neural networks to model the complex interactions between vehicles and the urban environment. We propose a decentralized, hierarchical policy that enables vehicles to adapt to changing traffic conditions and optimize their routes in real-time. Experimental results using a realistic simulator demonstrate that MARL-City outperforms traditional traffic management methods in reducing congestion and improving travel times.