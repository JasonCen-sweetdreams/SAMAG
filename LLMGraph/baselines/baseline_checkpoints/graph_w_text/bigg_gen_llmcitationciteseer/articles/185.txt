In multi-agent systems, deconfliction strategies are crucial to prevent collisions and ensure efficient coordination. This paper presents a novel framework that combines machine learning and graph theory to resolve conflicts in dynamic environments. We propose a decentralized approach where agents learn to predict and adjust their trajectories in real-time, taking into account the changing environment and other agents' intentions. Experimental results in a simulated air traffic control scenario demonstrate that our approach significantly reduces conflicts and improves overall system efficiency compared to traditional rule-based methods.