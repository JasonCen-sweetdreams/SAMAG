Edge computing has emerged as a promising paradigm for reducing latency and improving real-time processing capabilities. However, efficient resource allocation remains a significant challenge in edge computing environments. This paper proposes a novel deep hierarchical reinforcement learning framework, 'EdgeOpt', which learns to allocate resources optimally in edge computing systems. EdgeOpt leverages a hierarchical architecture to represent the complex relationships between edge devices, applications, and resources, and employs a reinforcement learning agent to make adaptive allocation decisions. Experimental results on a real-world edge computing testbed demonstrate that EdgeOpt achieves significant improvements in resource utilization, response time, and energy efficiency compared to traditional optimization techniques.