Explainability is a pressing concern in multi-agent systems, where the complexity of interactions between agents hinders the understanding of decision-making processes. We propose a hierarchical graph attention network (HGAN) that learns to represent agent interactions as a hierarchical graph, capturing both local and global relationships. Our approach enables the identification of influential agents and the visualization of decision-making pathways. Experimental results on a real-world traffic management scenario demonstrate the effectiveness of HGAN in improving explainability and decision quality compared to state-of-the-art methods.