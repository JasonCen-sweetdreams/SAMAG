Deep neural networks are vulnerable to adversarial attacks, which can be crafted to mislead the model's predictions. Existing adversarial training methods primarily focus on defending against known attacks. However, it is essential to develop strategies that can generalize to unknown attacks. This paper proposes a novel adversarial training framework, 'Adversarially Robust Unknown-Attack Training' (ARUAT), which leverages a meta-learning approach to adapt to new, unseen attacks. Our experiments on ImageNet demonstrate that ARUAT significantly improves the robustness of image classification models against a wide range of unknown attacks, outperforming state-of-the-art adversarial training methods.