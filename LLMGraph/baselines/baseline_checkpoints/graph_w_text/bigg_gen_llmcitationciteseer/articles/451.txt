Question answering over knowledge graphs has gained significant attention in recent years. However, existing methods often struggle to capture complex relationships between entities and attributes. This paper proposes a novel graph attention network (GAT) based approach, called KGQA-GAT, for efficient knowledge graph embedding. Our model leverages attention mechanisms to selectively focus on relevant entities and attributes when answering questions. We evaluate KGQA-GAT on several benchmark datasets, demonstrating significant improvements in accuracy and efficiency compared to state-of-the-art methods.