The increasing adoption of autonomous vehicles (AVs) on public roads necessitates efficient coordination mechanisms to ensure safe and efficient traffic flow. This paper proposes a novel multi-agent reinforcement learning framework that leverages graph attention to model complex interactions between AVs and their environment. Our approach, dubbed 'GraphMA', learns to optimize a set of decentralized policies that adapt to changing traffic conditions, incorporating both local and global information. Simulation results demonstrate that GraphMA outperforms state-of-the-art methods in reducing congestion, travel times, and accidents in various urban scenarios.