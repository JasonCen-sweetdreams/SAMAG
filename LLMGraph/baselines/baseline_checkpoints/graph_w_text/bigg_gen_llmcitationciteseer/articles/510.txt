Explainability is crucial in autonomous vehicle control, where trust and transparency are essential. This paper proposes a novel hierarchical attention-based reinforcement learning framework, 'HAT-RL', which learns to focus on relevant features and provide interpretable decisions. HAT-RL integrates a hierarchical attention mechanism into a deep reinforcement learning architecture, enabling the model to selectively attend to relevant sensor inputs and provide explicit explanations for its decisions. Experimental results on a realistic autonomous driving simulator demonstrate that HAT-RL achieves improved performance and provides more interpretable decisions compared to state-of-the-art reinforcement learning methods.