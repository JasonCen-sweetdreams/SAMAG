Individuals with motor impairments face significant challenges in using gesture-based interfaces. This paper proposes a personalized gesture recognition framework that leverages transfer learning to adapt to individual differences in motor abilities. We collect a dataset of gestures from individuals with varying levels of motor impairment and employ a convolutional neural network (CNN) to learn domain-invariant features. Our approach achieves a significant improvement in recognition accuracy compared to traditional machine learning methods, with an average increase of 15.2% in F1-score. We demonstrate the effectiveness of our framework in a case study with individuals with cerebral palsy, highlighting its potential to enhance accessibility in human-computer interaction.