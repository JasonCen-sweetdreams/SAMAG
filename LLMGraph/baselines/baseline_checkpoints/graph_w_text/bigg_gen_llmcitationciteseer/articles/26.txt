Autonomous drone navigation in complex environments requires efficient exploration and adaptation to changing scenarios. We propose Hierarchical Drone Navigation (HDN), a novel hierarchical reinforcement learning framework that leverages a task-agnostic, high-level policy to guide a low-level, reactive controller. HDN achieves significant improvements in navigation efficiency and adaptability compared to state-of-the-art, flat reinforcement learning approaches. We demonstrate the effectiveness of HDN in simulations and real-world experiments, showcasing its potential for rapid deployment in various drone-based applications.