Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its vulnerability to adversarial attacks raises significant concerns. This paper proposes a novel adversarial attack detection framework for DRL systems, leveraging graph convolutional networks (GCNs) to model the complex relationships between states, actions, and rewards. Our approach, dubbed 'GCAD', can accurately detect both query-based and poisoning-based attacks, outperforming existing detection methods. We demonstrate the effectiveness of GCAD on several DRL benchmarks, including Atari games and robotic control tasks.