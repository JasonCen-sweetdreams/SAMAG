Autonomous vehicles rely on reinforcement learning (RL) to optimize control policies, but the lack of transparency in RL decision-making hinders trust and safety. This paper proposes 'XRL', a novel framework that integrates model-based RL with attention-based explainability techniques. XRL generates visual explanations for the control actions taken by the autonomous vehicle, enabling human understanding of the decision-making process. We evaluate XRL on a realistic simulation environment and demonstrate improved interpretability without compromising control performance.