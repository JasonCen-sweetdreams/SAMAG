Conversational interfaces have the potential to provide accessible mental health support, but their effectiveness is hindered by the lack of emotional understanding. This paper presents a novel framework for designing emotion-aware conversational interfaces that can recognize and respond to users' emotional states. We propose a multimodal approach that combines natural language processing, sentiment analysis, and affective computing to create empathetic and personalized interactions. A user study with 100 participants demonstrates that our approach leads to increased user engagement, trust, and self-disclosure, ultimately improving the overall effectiveness of mental health support.