This paper proposes a hierarchical reinforcement learning framework for coordinating multi-agent systems in resource allocation tasks. We introduce a novel agent architecture that combines a high-level planning module with low-level execution modules, enabling agents to adapt to changing environmental conditions and optimize resource allocation. Our approach is evaluated in a simulated smart grid scenario, where it achieves significant improvements in resource utilization and overall system efficiency compared to state-of-the-art decentralized control methods.