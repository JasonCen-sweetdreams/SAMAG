Entity disambiguation is a crucial step in knowledge graph completion, but existing methods struggle to scale with large graphs and diverse entity mentions. We propose a novel approach, 'GraphAttentiveDisambig', which leverages graph attention networks to model complex relationships between entities and their mentions. Our method jointly learns entity representations and attention weights, enabling efficient disambiguation of entities in the presence of noisy or ambiguous mentions. Experimental results on large-scale knowledge graphs demonstrate significant improvements in disambiguation accuracy and scalability over state-of-the-art methods.