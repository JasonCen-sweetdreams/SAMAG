Multi-agent reinforcement learning (MARL) has gained significant attention in recent years, but scaling to complex scenarios remains a challenge. We propose a novel hierarchical attention network (HAN) architecture that efficiently handles varying numbers of agents and state dimensions. HAN incorporates both intra-agent and inter-agent attention mechanisms, enabling agents to selectively focus on relevant information and coordinate their actions. Experimental results on several MARL benchmarks demonstrate that HAN achieves state-of-the-art performance and improves robustness in diverse environments.