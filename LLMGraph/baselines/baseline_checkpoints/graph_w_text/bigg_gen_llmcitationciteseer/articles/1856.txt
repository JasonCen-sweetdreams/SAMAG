Graph neural networks have achieved state-of-the-art performance in node classification tasks, but they often struggle to scale to large graphs. This paper proposes a novel hierarchical graph attention network (HGAT) that leverages a hierarchical graph representation to reduce computational complexity. HGAT uses a pyramid-like architecture to aggregate node features at multiple scales, allowing it to capture both local and global patterns in the graph. We evaluate HGAT on several benchmark datasets and demonstrate its ability to achieve competitive performance with significantly reduced computational resources.