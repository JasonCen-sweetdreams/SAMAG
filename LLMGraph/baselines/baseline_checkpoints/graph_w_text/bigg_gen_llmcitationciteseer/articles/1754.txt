Explainable AI (XAI) is crucial for trustworthy decision-making in high-stakes applications. However, existing knowledge graph embedding techniques struggle to balance expressiveness and efficiency. This paper proposes 'KG-Xplain', a novel framework that leverages graph attention mechanisms and hierarchical knowledge graph representations to learn compact, interpretable embeddings. Experimental results on several benchmark datasets demonstrate that KG-Xplain outperforms state-of-the-art methods in terms of both link prediction accuracy and inference efficiency, while providing transparent insights into AI-driven decision-making processes.