Query expansion (QE) is a crucial component in search engines, aiming to reformulate user queries to improve retrieval performance. Existing QE methods often rely on handcrafted rules or supervised learning, which can be suboptimal. This paper explores the application of reinforcement learning (RL) to QE, where an agent learns to select expansion terms that maximize retrieval effectiveness. We propose a novel RL framework, 'QE-RL', which incorporates a reward function that balances query similarity and diversity. Experimental results on several benchmark datasets demonstrate that QE-RL outperforms state-of-the-art QE methods in terms of retrieval accuracy and robustness to query variations.