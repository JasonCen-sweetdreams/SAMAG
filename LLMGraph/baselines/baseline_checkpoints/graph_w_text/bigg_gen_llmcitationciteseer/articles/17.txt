This paper addresses the problem of cooperative task allocation in heterogeneous multi-agent systems, where agents with different capabilities and limitations need to collaborate to achieve a common goal. We propose a distributed reinforcement learning framework that enables agents to learn cooperative policies for task allocation in a decentralized manner. Our approach leverages a novel combination of actor-critic methods and graph neural networks to model the complex interactions between agents and tasks. Simulation results on a variety of scenarios demonstrate that our approach outperforms traditional centralized planning methods and achieves near-optimal performance in terms of task completion time and resource utilization.