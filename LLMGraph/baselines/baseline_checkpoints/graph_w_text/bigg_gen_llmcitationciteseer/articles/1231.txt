Dialogue systems have made significant progress in generating coherent responses, but their lack of transparency hinders trust and understanding. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that not only improves response generation but also provides interpretable explanations for the model's decisions. Our HAN model captures contextual dependencies at multiple scales, enabling it to highlight relevant input segments and generate attention-based explanations. Experimental results on two benchmark dialogue datasets demonstrate the effectiveness of our approach in producing accurate and interpretable responses.