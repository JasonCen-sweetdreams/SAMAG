This paper presents a novel framework for designing embodied conversational agents (ECAs) with emotional intelligence in healthcare settings. We propose a multimodal affect recognition system that integrates facial expression analysis, speech recognition, and physiological signal processing to enable ECAs to recognize and respond to users' emotions. Our user study shows that the ECA's empathetic responses significantly reduce users' stress levels and improve their overall experience in a simulated healthcare scenario. We discuss the implications of our findings for the development of emotionally intelligent ECAs in healthcare and highlight future research directions.