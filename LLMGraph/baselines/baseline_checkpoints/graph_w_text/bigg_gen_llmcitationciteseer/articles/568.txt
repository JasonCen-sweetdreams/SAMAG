Deep neural networks have been shown to be vulnerable to adversarial attacks, which can significantly degrade their performance. In this paper, we propose a novel defense mechanism that leverages contrastive learning to robustify neural networks against such attacks. Our approach, called CoRe, learns a robust representation by contrasting clean and perturbed samples in the latent space. We demonstrate the effectiveness of CoRe on various benchmark datasets, showing improved robustness against state-of-the-art attacks. Moreover, we analyze the theoretical implications of our approach and provide insights into the underlying mechanisms.