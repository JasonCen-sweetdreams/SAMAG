Main-memory databases have revolutionized real-time analytics by providing low-latency query execution. However, optimizing queries for these systems remains a significant challenge due to the complexity of modern workloads. This paper presents 'MemOpt', a novel query optimization framework that leverages machine learning and advanced indexing techniques to minimize query latency and maximize throughput. We introduce a probabilistic cost model that accurately estimates query execution times and develop a dynamic reordering mechanism to further reduce latency. Experimental results on a real-world dataset demonstrate that MemOpt outperforms state-of-the-art optimizers by up to 3x in query throughput and 2x in latency reduction.