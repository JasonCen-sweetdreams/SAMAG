Reinforcement learning (RL) agents often struggle to generalize across tasks and provide insights into their decision-making processes. This paper introduces Hierarchical Attention Networks (HANs) for Explainable Multi-Task Reinforcement Learning (EMTRL). HANs leverage hierarchical attention mechanisms to selectively focus on relevant task-specific features and provide visual explanations for the agent's actions. We evaluate HANs on a suite of multi-task RL benchmarks and demonstrate improved performance and interpretability compared to state-of-the-art baselines. Our approach has implications for real-world applications where transparency and accountability are crucial, such as autonomous driving and robotics.