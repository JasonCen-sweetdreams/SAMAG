Real-time traffic management is a critical application of autonomous agents, but existing approaches struggle to balance individual agent objectives with system-wide efficiency. This paper introduces HRL-Traffic, a hierarchical reinforcement learning framework that coordinates agents to optimize traffic flow. Our approach decomposes the traffic network into a hierarchy of zones, each managed by an autonomous agent that learns to balance local and global objectives. Experimental results on a large-scale traffic simulator demonstrate that HRL-Traffic reduces congestion by 23% and travel times by 17% compared to state-of-the-art decentralized approaches.