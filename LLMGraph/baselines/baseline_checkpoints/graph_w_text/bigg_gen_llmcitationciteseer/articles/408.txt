Autonomous agents operating in dynamic environments require adaptation to changing conditions to maintain optimality. This paper presents an online reinforcement learning framework, 'DynaAgent', that enables agents to adapt their policies in real-time. DynaAgent combines model-based and model-free reinforcement learning to balance exploration and exploitation, leveraging a novel uncertainty quantification mechanism to adjust the agent's confidence in its policy. Experimental results in a simulated robotic navigation domain demonstrate DynaAgent's ability to adapt to changing environmental conditions, outperforming traditional offline learning approaches.