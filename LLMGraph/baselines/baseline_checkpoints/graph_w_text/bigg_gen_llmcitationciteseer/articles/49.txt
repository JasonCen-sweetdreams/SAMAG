Coordinating multiple agents in dynamic environments is a challenging problem in decentralized AI systems. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that integrates graph attention mechanisms with hierarchical reinforcement learning to facilitate effective multi-agent coordination. HGAT learns to represent complex agent interactions and adapt to changing environmental conditions by recursively applying attention weights to graph-structured state representations. Experimental results in simulated robot soccer and traffic management scenarios demonstrate that HGAT outperforms state-of-the-art baselines in terms of task completion rate and overall system efficiency.