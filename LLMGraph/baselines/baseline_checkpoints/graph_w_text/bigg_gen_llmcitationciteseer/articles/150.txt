Multi-agent reinforcement learning (MARL) has shown great promise in complex real-world applications, but the lack of transparency and explainability in these systems hinders their adoption. This paper proposes a novel hierarchical attention mechanism that enables explainable decision-making in MARL. Our approach, 'HierAttn', applies attention weights to agent interactions, allowing the identification of influential agents and their contributions to the collective reward. We evaluate HierAttn on a range of benchmark environments, demonstrating improved explainability and interpretability without compromising task performance.