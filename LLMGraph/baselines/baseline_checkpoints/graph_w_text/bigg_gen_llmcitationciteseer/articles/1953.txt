Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks, which pose significant security risks in various applications. This paper proposes a novel Bayesian neural architecture search (BNAS) framework to improve the adversarial robustness of DNNs. Our approach involves searching for robust architectures using a probabilistic formulation of the adversarial attack problem. We demonstrate that the resulting architectures exhibit improved robustness against state-of-the-art attacks while maintaining competitive performance on clean data. Experimental results on benchmark datasets show that our method outperforms existing adversarial training methods in terms of both robustness and accuracy.