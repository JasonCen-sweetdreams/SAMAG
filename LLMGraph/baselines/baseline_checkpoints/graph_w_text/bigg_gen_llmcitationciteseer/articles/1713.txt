Distributed database systems face the challenge of optimizing query execution plans to minimize response time and resource utilization. This paper presents a novel approach to query optimization using reinforcement learning, which learns to adapt to changing workloads and system conditions. Our proposed framework, 'RL-Optimizer', employs a deep Q-network to select the optimal execution plan based on a reward function that balances query latency and system resource utilization. Experimental results on a real-world distributed database system show that RL-Optimizer outperforms traditional optimization techniques by up to 30% in terms of average query response time.