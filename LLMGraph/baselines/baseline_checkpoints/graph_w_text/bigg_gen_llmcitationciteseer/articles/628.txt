Vision Transformers (ViTs) have achieved state-of-the-art performance in various computer vision tasks, but their robustness to adversarial attacks remains a concern. This paper proposes a novel knowledge distillation approach, 'ViT-KD', to improve the adversarial robustness of ViTs. By transferring knowledge from a robust teacher model to a student ViT, our method enhances the model's ability to recognize and resist adversarial perturbations. Experiments on ImageNet and CIFAR-10 datasets demonstrate that ViT-KD outperforms existing adversarial training methods, achieving higher accuracy and robustness under various attack scenarios.