This paper presents a novel multimodal interaction framework for embodied conversational agents (ECAs) in healthcare settings. Our framework integrates speech, gesture, and facial recognition to facilitate more natural and inclusive interactions between ECAs and patients with diverse abilities. We evaluate our approach through a user study with 30 participants, demonstrating significant improvements in perceived empathy, trust, and overall user experience. Our findings have implications for the design of ECAs in healthcare, highlighting the importance of multimodal interaction and accessibility in promoting health equity.