Coordinating multi-agent systems is a challenging problem in artificial intelligence, particularly in scenarios where agents have conflicting goals or limited communication. This paper proposes a hierarchical reinforcement learning framework for coordinating multi-agent systems, where a high-level controller learns to issue tasks to agents, and each agent learns to execute tasks using a local reinforcement learning policy. We introduce a novel task allocation mechanism that considers the capabilities and preferences of each agent, and demonstrate its effectiveness in a simulated disaster response scenario. Experimental results show that our approach outperforms existing methods in terms of task completion rate and overall system efficiency.