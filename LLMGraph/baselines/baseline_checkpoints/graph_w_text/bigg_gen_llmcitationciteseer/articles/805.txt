Graph Neural Networks (GNNs) have shown remarkable performance in various graph-based applications. However, they are vulnerable to adversarial attacks that can manipulate the graph structure to mislead the model. This paper proposes a novel detection mechanism, 'GAT-Guard', which leverages graph attention mechanisms to identify adversarial attacks on GNNs. We introduce a trainable attention module that focuses on suspicious nodes and edges, allowing the model to distinguish between genuine and tampered graph data. Experimental results on benchmarks demonstrate that GAT-Guard outperforms existing defense methods in detecting adversarial attacks with high accuracy and efficiency.