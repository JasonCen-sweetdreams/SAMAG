In human-robot collaboration, accurately detecting user intentions is crucial for efficient and safe task execution. We propose a novel gaze-based intention detection framework that leverages deep learning techniques to analyze user gaze patterns. Our approach uses a multimodal fusion of gaze, head pose, and scene context to infer user intentions. We evaluate our method on a dataset of human-robot collaborative tasks and demonstrate significant improvements in intention detection accuracy compared to state-of-the-art methods. Our framework has potential applications in various domains, including manufacturing, healthcare, and assistive robotics.