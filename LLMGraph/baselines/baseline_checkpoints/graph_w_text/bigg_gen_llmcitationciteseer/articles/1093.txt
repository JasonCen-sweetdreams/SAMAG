Explainable AI (XAI) has gained significant attention in healthcare, where model interpretability is crucial for trust and adoption. This paper proposes a novel hierarchical attention-based multi-task learning framework, 'HierXAI', which simultaneously learns diagnostic predictions and explanations for medical images. Our approach leverages a hierarchical attention mechanism to identify relevant regions of interest and generate explanations via visual and textual features. Experimental results on a large-scale medical imaging dataset demonstrate that HierXAI outperforms state-of-the-art models in both diagnosis accuracy and explanation quality, providing actionable insights for clinicians.