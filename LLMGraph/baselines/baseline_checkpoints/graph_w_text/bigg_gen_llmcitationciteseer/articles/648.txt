Distributed graph databases have become increasingly popular for storing and querying large-scale graph-structured data. However, optimizing query performance in these systems remains a challenging problem due to the complexity of graph queries and the need to balance latency and resource utilization. This paper proposes a novel approach to query optimization using reinforcement learning, which learns to select efficient query plans based on runtime feedback. Our approach, called 'GraphRL', integrates a deep reinforcement learning model with a distributed query optimizer to adapt to changing workloads and system conditions. Experimental results on a real-world graph dataset demonstrate that GraphRL achieves significant improvements in query performance and resource efficiency compared to traditional rule-based optimizers.