Virtual reality (VR) systems often rely on standardized gestures that may not be accessible or intuitive for users with diverse abilities. This paper presents an adaptive gesture recognition framework that leverages machine learning and user modeling to personalize VR interactions. Our approach incorporates a probabilistic gesture recognition algorithm that adapts to individual users' motor abilities, learning styles, and preferences. We evaluate our framework through a user study with 30 participants, demonstrating significant improvements in user experience, task completion time, and overall system usability.