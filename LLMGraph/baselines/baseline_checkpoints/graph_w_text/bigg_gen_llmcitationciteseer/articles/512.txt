Time series forecasting models have achieved impressive performance with deep learning techniques, but often lack interpretability. This paper proposes a novel hierarchical attention network (HAN) architecture for time series forecasting, which incorporates both local and global attention mechanisms to capture complex temporal dependencies. Our approach learns to focus on relevant input features and time steps, providing explainable predictions. Experimental results on several benchmark datasets demonstrate the accuracy and interpretability of our HAN model, outperforming state-of-the-art models in both tasks.