Explainability in multi-agent reinforcement learning (MARL) is crucial for real-world applications. This paper introduces Hierarchical Attention Networks (HANs), a novel architecture that integrates attention mechanisms at both the agent and group levels to provide interpretable policies. We demonstrate that HANs outperform state-of-the-art MARL methods in a variety of cooperative and competitive scenarios, while also providing visual explanations of agent decision-making processes. Our results have implications for the development of transparent and trustworthy AI systems in domains such as autonomous driving and robotics.