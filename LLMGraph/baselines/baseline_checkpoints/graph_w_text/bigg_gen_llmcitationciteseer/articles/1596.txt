Explainability is crucial in autonomous systems, where decision-making processes need to be transparent and accountable. This paper introduces HAREL, a novel hierarchical attention-based framework for explainable reinforcement learning (RL) in autonomous systems. HAREL uses a hierarchical attention mechanism to selectively focus on relevant state features, providing interpretable explanations for the RL agent's decisions. We evaluate HAREL on a simulated autonomous driving scenario, demonstrating improved explainability and performance compared to state-of-the-art RL methods. The proposed framework has significant implications for the development of trustworthy autonomous systems.