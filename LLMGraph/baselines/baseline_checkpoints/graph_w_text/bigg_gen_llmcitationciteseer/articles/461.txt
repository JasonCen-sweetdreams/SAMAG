Conversational search systems aim to retrieve relevant answers from a large corpus of documents in response to user queries. This paper presents a novel neural ranking model, 'ConvRank', which leverages pre-trained language models to capture the nuances of conversational queries. We propose a hierarchical attention mechanism that selectively focuses on relevant passages in the document, and a contrastive training objective that encourages the model to differentiate between relevant and irrelevant documents. Experimental results on a popular conversational search benchmark demonstrate that ConvRank outperforms state-of-the-art ranking models in terms of retrieval accuracy and efficiency.