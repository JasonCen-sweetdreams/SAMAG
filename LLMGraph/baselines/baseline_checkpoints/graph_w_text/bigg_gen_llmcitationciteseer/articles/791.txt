In decentralized multi-agent systems, task allocation is a critical problem that requires efficient and adaptive solutions. This paper proposes a novel stochastic optimization framework for task allocation, which leverages the concepts of Markov decision processes and policy gradient methods. Our approach, called 'Dec-TAM', enables agents to learn optimal task assignments in a distributed manner, without relying on centralized coordination or explicit communication. Experimental results on a simulated disaster response scenario demonstrate that Dec-TAM outperforms existing decentralized algorithms in terms of task completion rate and overall system efficiency.