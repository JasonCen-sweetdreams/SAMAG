Autonomous vehicles rely on complex control systems to navigate diverse scenarios safely and efficiently. This paper presents a novel deep hierarchical reinforcement learning (DHRL) framework that decomposes the control task into a set of hierarchical sub-tasks, each addressing a specific aspect of vehicle control. Our approach leverages a multi-level abstraction of the environment, allowing the agent to focus on high-level decision-making while delegating low-level control to specialized sub-policies. Experimental results on a simulated urban driving environment demonstrate significant improvements in fuel efficiency, safety, and adaptability to changing traffic conditions compared to state-of-the-art model-based control methods.