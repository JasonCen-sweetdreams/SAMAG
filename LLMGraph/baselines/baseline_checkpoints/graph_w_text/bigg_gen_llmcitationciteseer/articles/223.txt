Deep neural networks have achieved state-of-the-art performance in various applications, but their computational complexity and memory requirements hinder their deployment on resource-constrained devices. This paper presents HierNAS, a novel hierarchical neural architecture search framework that efficiently explores the vast search space of possible neural architectures. By leveraging a combination of reinforcement learning and gradient-based optimization, HierNAS discovers compact and accurate models that can be executed on edge devices. Our experiments demonstrate that HierNAS achieves a 3.2x speedup in inference time on mobile devices while maintaining comparable accuracy to state-of-the-art models.