Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its vulnerability to adversarial attacks poses a significant threat. In this paper, we propose a novel approach to detect adversarial attacks in DRL using graph attention networks (GATs). Our method, called 'GAT-Defender', leverages the graph structure of the state-action space to identify anomalies in the policy's decision-making process. We evaluate GAT-Defender on several DRL benchmarks and demonstrate its effectiveness in detecting a wide range of attack types, including poisoning, evasion, and trojan attacks. Our results show that GAT-Defender outperforms existing detection methods, achieving an average detection accuracy of 92.5%.