Skeleton-based action recognition is a challenging task in computer vision, where the goal is to classify actions from 3D skeletal data. Existing methods struggle to model complex relationships between joints and capture long-range dependencies. We propose a novel Hierarchical Attention-based Graph Neural Network (HAGNN) framework, which leverages attention mechanisms to selectively focus on relevant joints and hierarchically aggregate features from local to global levels. Experimental results on two benchmark datasets demonstrate that HAGNN outperforms state-of-the-art methods, achieving an accuracy improvement of 3.5% on average.