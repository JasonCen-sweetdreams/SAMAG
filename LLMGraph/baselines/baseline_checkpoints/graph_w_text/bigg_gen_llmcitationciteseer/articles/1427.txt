This paper proposes a novel deep reinforcement learning framework for coordinating multi-agent systems in urban traffic control. We model the traffic network as a decentralized partially observable Markov decision process, where each agent represents an intersection. Our approach, called 'TrafficCoor', leverages graph neural networks to learn a shared policy that optimizes traffic flow and reduces congestion. We evaluate TrafficCoor on a realistic simulation of the Pittsburgh traffic network and demonstrate significant improvements in travel time reduction and traffic signal coordination compared to traditional optimization methods.