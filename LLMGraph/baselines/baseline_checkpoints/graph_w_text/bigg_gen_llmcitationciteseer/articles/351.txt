Individuals with motor impairments face significant challenges when interacting with technology. This paper presents a novel gesture recognition system, 'EaseGR', designed to improve the accessibility of gesture-based interfaces for individuals with motor impairments. We propose a machine learning-based approach that leverages transfer learning and domain adaptation to recognize gestures from a variety of input modalities, including electromyography (EMG), computer vision, and inertial measurement units (IMUs). Our user study with 20 participants demonstrates that EaseGR achieves higher recognition accuracy and improved user experience compared to existing systems, highlighting its potential to enhance digital inclusion.