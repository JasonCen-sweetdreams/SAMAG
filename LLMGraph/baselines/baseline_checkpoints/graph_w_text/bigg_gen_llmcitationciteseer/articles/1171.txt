Autonomous vehicles require efficient and adaptive control systems to navigate complex environments. This paper introduces 'HierRL', a novel deep hierarchical reinforcement learning framework that leverages a two-level hierarchy of policies to control autonomous vehicles. The high-level policy selects a set of primitive actions, while the low-level policy executes these actions using a fine-grained control strategy. We demonstrate the effectiveness of HierRL in various driving scenarios, achieving improved performance and adaptability compared to state-of-the-art reinforcement learning methods.