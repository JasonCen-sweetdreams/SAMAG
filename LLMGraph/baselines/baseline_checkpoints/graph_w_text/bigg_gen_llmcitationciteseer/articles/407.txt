This paper presents a novel multi-agent reinforcement learning (MARL) framework for real-time traffic signal control. Our approach, dubbed 'TrafficSync', leverages graph neural networks to model complex traffic dynamics and learn cooperative policies for multiple intersections. By incorporating a novel attention mechanism, TrafficSync efficiently handles high-dimensional state and action spaces, achieving better performance and scalability compared to existing MARL methods. Experimental results on a realistic traffic simulator demonstrate that TrafficSync reduces average travel time by up to 23% and decreases congestion by 17% compared to traditional traffic signal control strategies.