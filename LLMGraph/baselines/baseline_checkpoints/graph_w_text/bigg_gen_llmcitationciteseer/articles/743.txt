In multi-agent systems, decision-making often involves intricate interactions among agents. To improve transparency and accountability, we propose a novel hierarchical attention network (HAN) that enables explainable decision-making in multi-agent environments. Our approach leverages attention mechanisms to selectively focus on relevant agents and their interactions, generating interpretable explanations for collective decisions. Experimental results on a simulated traffic management scenario demonstrate that HAN outperforms state-of-the-art methods in terms of decision quality and explanation accuracy.