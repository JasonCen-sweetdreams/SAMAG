Deep reinforcement learning (DRL) has achieved impressive results in various applications, but its lack of interpretability hinders its adoption in high-stakes domains. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that integrates attention mechanisms with hierarchical representations to provide explainable DRL. We demonstrate that HAN improves the interpretability of DRL policies by highlighting critical state features and abstract representations that influence decision-making. Experimental results on Atari games and robotic control tasks show that HAN achieves competitive performance while providing actionable insights into the decision-making process.