Autonomous vehicles require efficient task allocation strategies to coordinate their actions in complex urban environments. This paper proposes a multi-agent reinforcement learning framework, 'MARL-TA', which enables distributed task allocation among autonomous vehicles. We introduce a novel reward function that incorporates both local and global task dependencies, allowing agents to adapt to changing environmental conditions. Experimental results using a realistic traffic simulator demonstrate that MARL-TA outperforms traditional centralized allocation methods in terms of task completion efficiency and reduced communication overhead.