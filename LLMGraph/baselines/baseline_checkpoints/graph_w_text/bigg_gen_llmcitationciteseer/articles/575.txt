Medical image classification tasks often suffer from limited annotated data, necessitating few-shot learning approaches. We propose a hierarchical few-shot learning framework, 'HFA', which leverages adaptive attention mechanisms to selectively focus on relevant regions of interest. Our method consists of a meta-learning phase, where a shared attention module is learned across multiple tasks, and a fine-tuning phase, where task-specific attention weights are adapted. We evaluate HFA on three medical image datasets, demonstrating significant improvements in classification accuracy over existing few-shot learning methods, particularly when faced with scarce annotated data.