Virtual reality (VR) systems rely on accurate gesture recognition to provide immersive experiences. This paper presents a novel approach that leverages eye movement analysis to enhance gesture recognition in VR. We propose a machine learning model that incorporates eye-tracking data to infer user intentions and adapt gesture recognition accordingly. Our approach addresses the limitations of traditional computer vision-based methods, which can be affected by occlusions, lighting conditions, and individual differences in hand movements. Experimental results demonstrate significant improvements in gesture recognition accuracy and user satisfaction when using our eye movement-based approach.