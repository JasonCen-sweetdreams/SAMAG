Reinforcement learning has shown impressive results in autonomous vehicles, but the lack of transparency in decision-making processes hinders widespread adoption. We propose a novel hierarchical attention network (HAN) architecture that incorporates explainability into reinforcement learning. Our approach uses a multi-level attention mechanism to highlight relevant sensory inputs and internal state transitions, providing insights into the decision-making process. Experimental results on a simulated driving environment demonstrate that our HAN-based agent achieves comparable performance to state-of-the-art methods while providing interpretable explanations for its actions.