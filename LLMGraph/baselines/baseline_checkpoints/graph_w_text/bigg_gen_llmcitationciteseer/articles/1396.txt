This paper presents a novel approach to coordinating multi-agent systems for dynamic task allocation using reinforcement learning. We propose a decentralized framework, 'MARL-TA', which enables agents to learn cooperative policies for task assignment and scheduling in real-time. Our method leverages a combination of centralized and decentralized critics to improve exploration-exploitation trade-offs and handle partial observability. Experimental results on a simulated manufacturing scenario demonstrate that MARL-TA outperforms traditional optimization methods and achieves near-optimal task allocation with reduced communication overhead.