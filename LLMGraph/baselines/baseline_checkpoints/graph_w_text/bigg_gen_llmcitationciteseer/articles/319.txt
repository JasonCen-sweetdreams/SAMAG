Cloud computing platforms face the challenge of dynamically allocating resources to meet fluctuating workload demands. This paper proposes a hierarchical reinforcement learning (HRL) framework, 'CloudOpt', which learns to optimize resource allocation policies in a decentralized manner. Our approach leverages a hierarchical architecture to balance exploration and exploitation, and incorporates a novel reward function that considers both performance and energy efficiency. Experimental results demonstrate that CloudOpt outperforms state-of-the-art baselines in terms of response time, resource utilization, and energy consumption.