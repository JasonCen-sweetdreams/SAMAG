Explainability is crucial for trustworthy decision-making in autonomous vehicles. This paper presents a novel hierarchical attention-based reinforcement learning (HARL) framework that learns to generate interpretable explanations for its actions. HARL combines a hierarchical attention mechanism with a reinforcement learning policy to identify relevant features and states that influence the decision-making process. We evaluate HARL on a realistic autonomous driving simulator and demonstrate improved explainability and performance compared to state-of-the-art reinforcement learning methods.