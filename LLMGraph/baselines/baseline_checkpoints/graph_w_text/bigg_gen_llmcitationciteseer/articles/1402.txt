Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can significantly compromise their performance. This paper proposes a novel approach, Bayesian Neural Symbolic Learning (BNSL), to robustify DNNs against such attacks. BNSL integrates Bayesian neural networks with symbolic reasoning to learn robust and interpretable representations. We demonstrate that BNSL outperforms state-of-the-art methods in defending against various types of attacks, including projected gradient descent and Carlini and Wagner attacks, on multiple benchmark datasets.