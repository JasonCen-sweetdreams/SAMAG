The increasing adoption of autonomous vehicles (AVs) has created a need for efficient multi-agent coordination. This paper presents a novel decentralized reinforcement learning framework for AV coordination, which leverages graph neural networks to model complex interactions between agents. Our approach, 'MARL-GNN', incorporates a hierarchical reward function that balances individual and global objectives, enabling AVs to navigate complex scenarios while minimizing collisions and congestion. Experimental results demonstrate that MARL-GNN outperforms state-of-the-art methods in various traffic scenarios, achieving improved safety and efficiency.