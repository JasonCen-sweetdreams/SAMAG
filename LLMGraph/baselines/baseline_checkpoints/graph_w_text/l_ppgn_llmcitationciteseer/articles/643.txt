Robot arm control is a challenging problem in robotics, requiring precise and efficient motion planning. This paper presents a novel hierarchical reinforcement learning (HRL) framework, 'HierArm', which leverages a two-level hierarchy to learn complex tasks. The high-level policy learns to select sub-goals, while the low-level policy executes the corresponding motor controls. We demonstrate HierArm's effectiveness in a real-world robot arm platform, achieving a 30% reduction in task completion time compared to state-of-the-art flat reinforcement learning methods.