Deep neural networks are prone to erroneous predictions when encountering out-of-distribution (OOD) inputs. Ensemble methods have shown promise in detecting OOD samples, but often incur significant computational overhead. This paper proposes a novel approach, 'Deep Ensemble Detector' (DED), which leverages the diversity of multiple deep models to detect OOD inputs efficiently. We introduce a lightweight fusion mechanism that adaptively weights the outputs of individual models based on their confidence levels. Experimental results on multiple benchmark datasets demonstrate that DED achieves state-of-the-art OOD detection performance while reducing computational costs by up to 50% compared to existing ensemble methods.