Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but its lack of interpretability hinders its adoption in high-stakes applications. This paper proposes a novel hierarchical attention network (HAN) architecture that integrates attention mechanisms at multiple levels to provide explanations for DRL agents' decision-making processes. Our approach uses a hierarchical policy representation to focus on relevant state features and abstract away irrelevant information. We evaluate HAN on a range of Atari games and demonstrate improved explainability and robustness to perturbations compared to state-of-the-art DRL methods.