Cyber-physical systems (CPS) require efficient task allocation to ensure timely and reliable execution of complex tasks. This paper presents a novel multi-agent reinforcement learning (MARL) framework for distributed task allocation in CPS. Our approach leverages decentralized Q-learning to enable agents to learn optimal task assignment policies in a partially observable environment. We introduce a novel reward function that incorporates both local and global performance metrics, enabling agents to balance individual and system-level objectives. Experimental results on a simulated CPS testbed demonstrate improved task allocation efficiency and reduced system latency compared to traditional centralized optimization methods.