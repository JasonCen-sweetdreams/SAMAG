Explainability is a critical aspect of AI-driven decision-making systems, as they become increasingly pervasive in high-stakes applications. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework that integrates graph neural networks and attention mechanisms to facilitate transparent decision-making. HGAT captures complex relationships between entities and highlights the most influential features contributing to the model's predictions. We evaluate HGAT on a real-world healthcare dataset and demonstrate its ability to provide accurate and interpretable predictions, outperforming state-of-the-art explainable AI baselines.