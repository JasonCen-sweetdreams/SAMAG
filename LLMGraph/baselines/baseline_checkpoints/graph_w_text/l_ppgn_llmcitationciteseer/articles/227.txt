 Commonsense reasoning is a crucial aspect of human-like intelligence, but existing knowledge graph embedding methods struggle to capture nuanced relationships between entities. This paper introduces Hierarchical Attention-based Knowledge Graph Embedding (HATKE), a novel framework that leverages attention mechanisms to selectively focus on relevant subgraphs and contextualize entity representations. We evaluate HATKE on several benchmarks, demonstrating significant improvements in link prediction, entity disambiguation, and question answering tasks. Our approach paves the way for more accurate and interpretable commonsense reasoning in AI systems.