As mixed reality (MR) technology advances, interacting with virtual objects in 3D space becomes increasingly important. This paper presents a novel gaze-based interaction technique, 'GazeShift', which enables users to seamlessly manipulate virtual objects using their gaze direction. We employ a combination of machine learning-based gaze estimation and computer vision techniques to track the user's gaze and infer their intended interaction. Our user study demonstrates that GazeShift outperforms existing interaction methods in terms of speed and accuracy, while also reducing user fatigue and improving overall MR experience.