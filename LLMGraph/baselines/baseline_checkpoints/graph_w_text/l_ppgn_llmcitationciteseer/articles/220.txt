As autonomous agents increasingly interact with humans, there is a growing need for transparent and interpretable decision-making processes. This paper introduces a novel Hierarchical Attention Network (HAN) architecture for multi-agent systems, which learns to selectively focus on relevant agents and their interactions to make explainable decisions. We demonstrate the effectiveness of HAN in a simulated traffic management scenario, where it outperforms existing methods in terms of decision accuracy and interpretability. Our approach has significant implications for the development of trustworthy and human-centric AI systems.