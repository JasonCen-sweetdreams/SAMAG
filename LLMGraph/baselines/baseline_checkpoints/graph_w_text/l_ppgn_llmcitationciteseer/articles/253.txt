Online learning algorithms often struggle with non-stationary environments, where the underlying data distribution changes over time. This paper proposes an adaptive regularization technique, 'AROS', which dynamically adjusts the regularization strength based on the observed data drift. We prove that AROS achieves a tighter regret bound compared to existing methods, and demonstrate its effectiveness in various online learning scenarios, including stock prediction and recommender systems. Our experiments show that AROS outperforms state-of-the-art algorithms in terms of both accuracy and adaptability to changing environments.