Question answering (QA) models often struggle to provide transparent and interpretable reasoning for their predictions, particularly when dealing with multi-hop questions. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) architecture that leverages graph-based reasoning to explicitly model relationships between entities and clauses in the input text. HGAT adaptively attends to relevant context and clause-level information, generating explicit and hierarchical explanations for its predictions. Experimental results on the HotPotQA dataset demonstrate significant improvements in both QA accuracy and explanation quality, outperforming state-of-the-art models.