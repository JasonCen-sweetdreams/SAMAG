Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but the lack of interpretability hinders its adoption in high-stakes applications. This paper proposes a novel model-based state abstraction framework, 'ExplainRL', which enables efficient explainability for DRL agents. By learning a compact, symbolic representation of the environment, ExplainRL reduces the dimensionality of the state space, allowing for more interpretable policies and better understanding of the decision-making process. We demonstrate the effectiveness of ExplainRL on several Atari games, showcasing improved performance and explainability compared to existing methods.