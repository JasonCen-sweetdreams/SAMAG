Autonomous vehicles (AVs) face complex decision-making challenges, particularly in dynamic environments. This paper introduces a hierarchical reinforcement learning (HRL) framework, 'AV-HRL', which decomposes the decision-making process into high-level goal-setting and low-level control optimization. We propose a novel, attention-based abstraction mechanism that enables the high-level policy to focus on relevant contextual information. Experimental results in a simulated urban driving scenario demonstrate that AV-HRL outperforms flat RL approaches in terms of task completion rate and safety metrics.