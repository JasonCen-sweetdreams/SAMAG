Explainable recommendation systems (ERS) have gained significant attention in recent years, as they provide insights into the decision-making process of AI-driven recommender models. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) architecture for ERS, which leverages graph neural networks to model complex user-item interactions. Our approach incorporates multi-level attention mechanisms to capture both local and global dependencies in the graph, enabling the model to generate interpretable explanations for its recommendations. Experimental results on several benchmark datasets demonstrate the effectiveness of HGAT in improving recommendation accuracy and explanation quality.