Ad-hoc search queries often require manual reformulation to achieve relevant results. We propose a novel reinforcement learning-based approach, 'RL-QE', to automate query expansion. Our method leverages a Markov decision process to iteratively refine the query, balancing exploration and exploitation. The reward function incorporates both relevance and fluency metrics, ensuring the generated queries are both effective and readable. Experimental results on the TREC ad-hoc dataset demonstrate that RL-QE outperforms state-of-the-art methods in terms of mean average precision and query quality.