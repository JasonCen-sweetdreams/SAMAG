In this paper, we present a decentralized task allocation framework for multi-agent systems, where agents learn to allocate tasks using reinforcement learning. We propose a novel algorithm, 'DRL-TA', which utilizes a decentralized actor-critic architecture to learn task allocation policies. Our approach enables agents to adapt to dynamic task environments and make efficient allocation decisions without relying on a centralized controller. Experimental results demonstrate that DRL-TA outperforms existing decentralized task allocation methods in terms of task completion time and system efficiency.