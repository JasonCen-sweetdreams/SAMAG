Efficient resource allocation is crucial in distributed systems, where dynamic changes in resource availability and demand require adaptable decision-making. This paper presents a novel multi-agent reinforcement learning (MARL) framework, 'DynaRA', which enables agents to learn cooperative policies for resource allocation in real-time. DynaRA integrates a graph neural network with a decentralized actor-critic architecture, allowing agents to capture complex system dynamics and make coordinated decisions. Experimental results on a simulated cloud computing environment demonstrate that DynaRA outperforms traditional optimization methods in terms of resource utilization and system responsiveness.