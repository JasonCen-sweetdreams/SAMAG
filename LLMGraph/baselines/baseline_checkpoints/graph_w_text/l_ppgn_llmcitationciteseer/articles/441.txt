Graph neural networks (GNNs) have achieved state-of-the-art results in node classification tasks, but often require large amounts of labeled data. This paper proposes a novel hierarchical attention-based GNN (HAT-GNN) that tackles the few-shot node classification problem. Our model leverages a hierarchical attention mechanism to selectively focus on relevant graph structures and node features, enabling effective learning from limited labeled data. We evaluate HAT-GNN on several benchmark datasets and demonstrate significant improvements over existing few-shot learning methods.