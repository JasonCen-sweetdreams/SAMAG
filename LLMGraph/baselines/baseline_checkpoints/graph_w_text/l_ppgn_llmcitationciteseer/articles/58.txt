As virtual reality (VR) technology advances, there is a growing need for natural and intuitive interaction methods. This paper presents a novel gaze-based interaction system for VR, which leverages machine learning to classify eye movement patterns and infer user intent. We conducted a user study to collect and analyze eye-tracking data, and our results show that our approach can accurately recognize user actions such as selection, manipulation, and navigation. We also investigate the effects of gaze-based interaction on user experience and discuss implications for future VR system design.