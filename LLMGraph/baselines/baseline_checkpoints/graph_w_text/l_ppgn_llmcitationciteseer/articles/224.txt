Explainable recommendation systems (ERS) have gained significant attention in recent years. However, most existing ERS methods rely on shallow feature interactions and fail to capture complex relationships between user and item attributes. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) model that integrates multi-modal data (e.g., text, images, and ratings) to provide personalized explanations for recommendations. HGAT leverages graph attention mechanisms to learn hierarchical representations of user and item entities, enabling the model to capture both local and global patterns in the data. Experimental results on two real-world datasets demonstrate that HGAT outperforms state-of-the-art ERS methods in terms of both recommendation accuracy and explanation quality.