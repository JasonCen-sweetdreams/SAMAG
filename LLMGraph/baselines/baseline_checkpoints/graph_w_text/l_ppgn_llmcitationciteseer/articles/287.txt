Classical document retrieval systems rely on term-frequency based representations, which become inefficient when dealing with large-scale text collections. This paper proposes a novel query-adaptive document embedding approach, 'QADE', that leverages the context of the query to dynamically adjust the document representations. QADE utilizes a neural network-based architecture to learn a shared representation space for queries and documents, enabling efficient retrieval through similarity searches. Experimental results on several benchmark datasets demonstrate that QADE outperforms state-of-the-art methods in terms of retrieval accuracy and computational efficiency.