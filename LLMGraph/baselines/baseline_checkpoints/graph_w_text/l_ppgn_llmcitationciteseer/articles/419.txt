Augmented reality (AR) training systems have the potential to revolutionize various industries, but their adoption is hindered by the lack of intuitive user interfaces. This paper presents a gesture-based interface design framework that leverages machine learning and computer vision techniques to recognize and interpret user gestures in AR environments. We conducted a series of user studies to inform the design of our system, which incorporates a novel gesture recognition algorithm and a visual feedback mechanism to enhance user experience. Our evaluation results show that our approach significantly improves user performance and satisfaction in AR-based training tasks.