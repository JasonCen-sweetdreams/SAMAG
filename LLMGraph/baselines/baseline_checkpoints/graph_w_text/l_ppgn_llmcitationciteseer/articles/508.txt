Query expansion is a crucial step in information retrieval, but traditional methods often rely on simplistic assumptions about language and user intent. This paper explores the application of deep neural language models to query expansion, demonstrating improved retrieval performance on challenging datasets. Our approach leverages the contextualized embeddings and language understanding capabilities of transformer-based models to generate more effective expansion terms. We evaluate our method on several standard IR benchmarks, showing significant gains in precision and recall over state-of-the-art techniques.