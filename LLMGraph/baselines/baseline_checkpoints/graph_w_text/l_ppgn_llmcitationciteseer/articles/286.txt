Voice assistants have become ubiquitous in modern life, but their interaction modalities often exclude users with disabilities. This paper presents a multimodal interaction framework for voice assistants that incorporates alternative input methods, such as gesture recognition, eye-tracking, and tactile feedback. We conducted a user study with 20 participants with varying abilities, revealing significant improvements in task completion rates and user satisfaction. Our findings inform the design of more inclusive voice assistants, highlighting the importance of considering diverse user needs in HCI research.