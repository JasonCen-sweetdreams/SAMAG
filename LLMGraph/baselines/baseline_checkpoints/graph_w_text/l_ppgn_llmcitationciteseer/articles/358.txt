In multi-agent systems, efficient exploration is crucial for tasks like surveillance and search-and-rescue. However, as the number of agents increases, the exploration problem becomes increasingly complex. This paper introduces a novel hierarchical graph attention mechanism that enables coordinated exploration among agents. Our approach represents the environment as a graph, where agents learn to focus on the most informative regions and adapt their exploration strategies accordingly. Experimental results in simulated environments demonstrate that our method outperforms existing decentralized exploration approaches, achieving faster coverage and improved knowledge gathering.