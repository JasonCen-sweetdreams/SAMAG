Task-oriented dialogue systems have become increasingly prevalent in various applications, but their lack of transparency and explainability hinders user trust and understanding. This paper introduces HAtED, a hierarchical attention-based framework that generates explanations for its responses in task-oriented conversations. HAtED employs a novel hierarchical attention mechanism to selectively focus on relevant context and intent features, enabling the generation of informative and concise explanations. We evaluate HAtED on two benchmark datasets, demonstrating significant improvements in explanation quality, response accuracy, and user satisfaction compared to state-of-the-art baselines.