State-of-the-art neural ranking models for document retrieval often suffer from high computational costs and limited scalability. This paper proposes a novel hierarchical neural ranking architecture, 'HNRM', which leverages a coarse-to-fine retrieval strategy to reduce the number of documents required for ranking. We employ a combination of dense passage retrieval and hierarchical clustering to prune the document set, followed by a fine-grained ranking module that incorporates semantic and syntactic features. Experimental results on the TREC Deep Learning Track dataset demonstrate that HNRM achieves significant improvements in retrieval efficiency and effectiveness compared to existing neural ranking models.