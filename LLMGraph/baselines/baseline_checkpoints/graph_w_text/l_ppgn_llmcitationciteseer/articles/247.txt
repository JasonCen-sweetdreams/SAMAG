Dense passage retrieval (DPR) has emerged as a powerful paradigm for open-domain question answering. However, the efficiency of DPR systems is hindered by the need to compute dense embeddings for large Passage collections. This paper presents a novel indexing strategy, 'Neural Inverted Index' (NII), that leverages the structure of neural networks to accelerate passage retrieval. NII combines a hierarchical clustering of passages with a learned, sparse indexing scheme, reducing the number of required neural computations by up to 75%. Our experiments on the Natural Questions dataset demonstrate the scalability and effectiveness of NII, achieving a 30% improvement in retrieval efficiency while maintaining state-of-the-art accuracy.