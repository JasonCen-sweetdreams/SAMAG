This paper addresses the problem of multi-agent task allocation in dynamic environments. We propose a novel approach based on deep reinforcement learning, which enables agents to learn effective task assignment strategies through experience. Our method, called 'MATARL', uses a decentralized actor-critic architecture to coordinate agents' actions and adapt to changing task requirements and resource availability. Experimental results in a simulated disaster response scenario demonstrate that MATARL outperforms traditional optimization-based methods in terms of task completion rate and overall system efficiency.