This paper tackles the problem of coordinated exploration in multi-agent systems, where agents must jointly explore a complex environment to maximize cumulative rewards. We propose a novel graph neural network (GNN) architecture, Adaptive Graph Explorer (AGE), which adaptively updates the graph structure to reflect the agents' changing beliefs about the environment. AGE enables agents to share information and coordinate their exploration policies, resulting in improved exploration efficiency and task performance. Experimental results on a range of multi-agent environments demonstrate the effectiveness of AGE in achieving better coordination and exploration compared to baseline methods.