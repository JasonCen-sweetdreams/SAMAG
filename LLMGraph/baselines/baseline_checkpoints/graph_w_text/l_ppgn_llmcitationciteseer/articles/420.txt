Conversational interfaces have become ubiquitous, but their accessibility for visually impaired users remains limited. This paper presents a novel design framework, 'TalkToMe', which integrates audio-based interaction, tactile feedback, and machine learning-driven dialogue management to facilitate inclusive human-computer interaction. We conducted a user study with 20 visually impaired participants, demonstrating significant improvements in task completion rate, user satisfaction, and perceived accessibility compared to commercial virtual assistants. Our findings inform the development of more accessible conversational interfaces and provide insights for future research in this area.