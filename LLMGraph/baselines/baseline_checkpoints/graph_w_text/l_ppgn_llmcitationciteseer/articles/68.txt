Autonomous vehicles require efficient exploration strategies to learn complex behaviors in real-world environments. This paper proposes a novel multi-agent deep reinforcement learning framework, 'MADE', which enables coordinated exploration among agents. MADE leverages attention mechanisms to facilitate communication and cooperation among agents, improving the efficiency of exploration and reducing the likelihood of catastrophic failures. We evaluate MADE on a suite of autonomous driving scenarios, demonstrating improved learning speed and robustness compared to independent exploration strategies.