Cloud computing systems face the challenge of efficiently allocating resources to meet dynamic workload demands. This paper proposes a cooperative multi-agent reinforcement learning framework, 'CMARL', that enables autonomous agents to learn and adapt to changing resource requirements. CMARL employs a decentralized, communication-based approach, where agents share knowledge and negotiate resource allocations to maximize overall system performance. We conduct experiments on a simulated cloud environment and demonstrate that CMARL achieves improved resource utilization, reduced latency, and enhanced system adaptability compared to traditional heuristic-based allocation methods.