Ad-hoc retrieval remains a challenging task in information retrieval (IR) due to the inherent ambiguity of user queries. Query expansion (QE) is a popular technique to resolve this issue, but traditional QE methods rely on manually crafted rules or statistical models. This paper proposes a novel QE approach that leverages deep neural networks to learn semantic query representations. Our model, dubbed 'QE-Net', integrates a transformer-based encoder with a graph-based attention mechanism to capture contextual relationships between query terms. Experimental results on the TREC-8 ad-hoc retrieval dataset demonstrate that QE-Net significantly outperforms state-of-the-art QE methods in terms of mean average precision and recall.