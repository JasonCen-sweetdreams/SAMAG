Neural architecture search (NAS) has revolutionized the design of deep neural networks, but its computational overhead hinders its adoption on resource-constrained devices. This paper presents a novel graph-based pruning approach, 'GraphPrune', which reduces the search space by eliminating redundant graph motifs. We introduce a differentiable graph neural network (GNN) to learn the importance of each motif and prune the architecture accordingly. Experimental results on various benchmark datasets demonstrate that GraphPrune achieves state-of-the-art performance on mobile devices while reducing the search time by an order of magnitude.