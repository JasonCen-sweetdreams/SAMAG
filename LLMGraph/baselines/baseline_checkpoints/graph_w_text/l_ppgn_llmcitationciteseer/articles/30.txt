Graph neural networks (GNNs) have shown promising results in node classification tasks. However, existing methods often suffer from limited expressiveness and lack of interpretability. This paper proposes a novel hierarchical attention-based GNN architecture, 'HAGNN', which leverages multi-scale graph representations and adaptive attention mechanisms to capture complex node relationships. Our approach achieves state-of-the-art performance on several benchmark datasets, including Cora, Citeseer, and Pubmed. We also provide an in-depth analysis of the learned attention patterns, revealing insights into the underlying graph structure and node importance.