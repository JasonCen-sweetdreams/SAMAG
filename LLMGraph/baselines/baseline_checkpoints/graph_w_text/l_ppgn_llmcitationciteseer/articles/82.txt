Knowledge graph embeddings have become a crucial component in various artificial intelligence applications. However, existing methods struggle to effectively model complex relational structures and heterogeneous information. We propose a novel Hierarchical Graph Attention Network (HGAT) framework, which leverages multi-relational attention mechanisms to capture nuanced interactions between entities and relationships. HGAT learns hierarchical representations by recursively applying attention across different relational contexts, enabling the modeling of intricate dependencies and constraints. Experimental results on several benchmark datasets demonstrate the superiority of HGAT in link prediction, entity classification, and question answering tasks, showcasing its potential in real-world knowledge graph applications.