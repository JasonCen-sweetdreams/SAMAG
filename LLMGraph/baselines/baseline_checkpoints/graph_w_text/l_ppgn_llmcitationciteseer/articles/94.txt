Distributed task allocation in smart grids poses significant challenges due to the dynamic and uncertain nature of energy demand and supply. This paper proposes a novel multi-agent reinforcement learning framework, 'MARL-Grid', which enables autonomous agents to learn cooperative task allocation strategies in real-time. We introduce a decentralized Q-network architecture that leverages graph neural networks to model complex dependencies between agents and tasks. Experiments on a simulated smart grid environment demonstrate that MARL-Grid achieves improved task completion rates and reduced energy waste compared to traditional optimization methods.