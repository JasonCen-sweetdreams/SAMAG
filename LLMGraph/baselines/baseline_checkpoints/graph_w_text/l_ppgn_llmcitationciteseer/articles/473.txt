Multimodal retrieval has gained significant attention in recent years, but the problem of query expansion remains a major challenge. This paper proposes a novel deep neural network-based approach for query expansion, which leverages the semantic relationships between text and image modalities. Our proposed model, 'MMQE', uses a multimodal embedding space to learn a compact representation of queries, and then expands the query using a generative adversarial network. Experimental results on several benchmark datasets demonstrate that MMQE significantly outperforms existing state-of-the-art methods, achieving an average improvement of 12.5% in terms of mean average precision.