Deep reinforcement learning (RL) has achieved remarkable success in complex decision-making tasks, but the lack of interpretability hinders its adoption in high-stakes applications. We propose a novel hierarchical attention network (HAN) architecture that incorporates attention mechanisms at multiple levels to provide insights into the decision-making process. Our approach enables the identification of relevant state features and action patterns, improving the transparency of RL policies. Experimental results on Atari games and robotic control tasks demonstrate that HAN-based agents outperform state-of-the-art RL methods while providing meaningful explanations for their actions.