Time series forecasting has numerous applications in finance, healthcare, and climate science. However, most state-of-the-art models lack interpretability, making it challenging to understand the underlying factors driving the predictions. This paper proposes a Hierarchical Attention Network (HAN) for explainable time series forecasting. HAN leverages a novel hierarchical attention mechanism to selectively focus on relevant time steps and features, allowing for visual attribution of the predictions. Experimental results on three benchmark datasets demonstrate that HAN outperforms existing methods in terms of forecasting accuracy and provides meaningful explanations for its predictions.