We propose a hierarchical multi-agent reinforcement learning framework for autonomous traffic signal control, where each agent controls a set of nearby intersections. The framework consists of a high-level planning module that allocates tasks to agents based on traffic conditions, and a low-level execution module that uses deep Q-networks to optimize signal timings. We evaluate our approach on a large-scale simulation of Pittsburgh's traffic network, demonstrating a 23% reduction in average travel time and a 17% decrease in congestion compared to traditional fixed-time signal control. The hierarchical architecture enables efficient exploration and adaptation to changing traffic patterns.