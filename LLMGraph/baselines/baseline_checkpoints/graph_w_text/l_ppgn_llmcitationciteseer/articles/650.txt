Cloud computing platforms face significant challenges in optimizing resource allocation to meet dynamic workload demands. This paper proposes a hierarchical reinforcement learning (HRL) framework, 'CloudOpt', which leverages a two-level policy architecture to efficiently allocate resources. The high-level policy adjusts the resource pool, while the low-level policy allocates resources to individual virtual machines. We demonstrate that CloudOpt outperforms state-of-the-art methods in reducing response times and improving resource utilization on a real-world cloud workload dataset.