Decentralized task allocation is a crucial problem in multi-agent systems, where agents need to allocate tasks efficiently without a central coordinator. This paper proposes a novel approach using reinforcement learning, where agents learn to allocate tasks based on their local observations and interactions with other agents. We introduce a decentralized Q-learning algorithm that enables agents to adapt to changing task demands and agent availability. Experimental results show that our approach outperforms traditional auction-based methods in terms of task completion rate and agent utilization.