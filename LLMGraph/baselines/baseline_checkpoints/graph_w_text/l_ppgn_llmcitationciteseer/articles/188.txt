As machine learning models are increasingly deployed in real-world applications, they become vulnerable to adversarial attacks that can manipulate the model's output. In this paper, we propose a novel approach to detect adversarial attacks in time series data using graph-based anomaly detection. Our method, referred to as 'GAD-TS', constructs a graph from the time series data and leverages graph neural networks to identify anomalous patterns. We evaluate GAD-TS on several benchmark datasets and demonstrate its effectiveness in detecting adversarial attacks with high accuracy and low false positive rates. Our approach outperforms existing methods, especially in scenarios where the attack is subtle and stealthy.