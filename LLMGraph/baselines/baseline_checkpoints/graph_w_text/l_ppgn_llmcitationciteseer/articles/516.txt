Graph Convolutional Networks (GCNs) have achieved state-of-the-art performance in node classification tasks. However, they remain vulnerable to adversarial attacks that manipulate the graph structure or node features. This paper proposes a novel adversarial training framework, 'AdvGCN', which incorporates a perturbation-based adversarial loss function into the GCN training process. We demonstrate that AdvGCN significantly improves the robustness of GCNs against various types of attacks, including node injection, edge rewiring, and feature perturbation. Experimental results on real-world graph datasets show that AdvGCN achieves improved classification accuracy and robustness compared to standard GCN training.