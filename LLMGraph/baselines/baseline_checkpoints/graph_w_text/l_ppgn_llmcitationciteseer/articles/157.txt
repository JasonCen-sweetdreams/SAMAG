Multi-task learning (MTL) has achieved remarkable success in various applications, but interpretability remains a significant challenge. This paper presents a novel hierarchical attention network (HAN) framework, which seamlessly integrates task-specific attention mechanisms and hierarchical representations to facilitate explainable MTL. Our approach enables the model to selectively focus on relevant features and tasks, providing insightful visualizations and quantifiable performance improvements. We conduct extensive experiments on several benchmark datasets, demonstrating the efficacy of HAN in achieving state-of-the-art results while offering interpretable insights into the learned representations.