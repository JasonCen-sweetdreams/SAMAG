In multi-agent systems, trust plays a crucial role in ensuring cooperation and achieving common goals. However, existing trust management approaches often rely on fixed models or assumptions, which can lead to brittleness and vulnerability to manipulation. This paper proposes a novel framework for adaptive trust management, which leverages reinforcement learning and graph-based models to dynamically update trust values based on agent interactions. We demonstrate the effectiveness of our approach in simulated scenarios, showcasing its ability to mitigate manipulation attacks and improve overall system resilience.