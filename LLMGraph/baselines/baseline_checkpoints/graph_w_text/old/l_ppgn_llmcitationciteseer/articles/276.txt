Few-shot learning has made significant progress, but its vulnerability to adversarial attacks remains a major concern. This paper introduces a novel meta-learning framework, 'META-ADV', which robustifies few-shot learners by generating adversarial examples during training. Our approach leverages a meta-learner to adapt the adversarial perturbations to the target task, resulting in improved robustness and generalizability. We evaluate META-ADV on various benchmarks and demonstrate its effectiveness in defending against state-of-the-art attacks, achieving an average improvement of 12.5% in robust accuracy compared to existing few-shot methods.