Individuals with dysarthria, a speech disorder affecting articulation and intelligibility, often face significant barriers when interacting with voice-controlled interfaces. This paper presents a user-centered design approach for developing accessible voice-controlled interfaces tailored to the needs of individuals with dysarthria. We conducted a series of usability studies and interviews to identify key challenges and design requirements. Our proposed interface incorporates adaptive speech recognition, personalized acoustic modeling, and intuitive feedback mechanisms to enhance user experience and accuracy. Results from a pilot study demonstrate improved task completion rates and user satisfaction compared to existing voice-controlled interfaces.