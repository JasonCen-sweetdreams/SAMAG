The vulnerability of AI systems to adversarial examples has sparked concerns about their reliability in real-world applications. This paper presents a novel approach to detecting adversarial examples using Graph Attention Networks (GATs). Our proposed method, GAT-Detector, leverages the power of attention mechanisms to identify the most critical nodes in the input data graph, which are indicative of adversarial perturbations. Experimental results on multiple benchmark datasets demonstrate that GAT-Detector outperforms state-of-the-art detection methods in terms of accuracy and robustness, especially in scenarios with high-dimensional data and varying levels of adversarial attacks.