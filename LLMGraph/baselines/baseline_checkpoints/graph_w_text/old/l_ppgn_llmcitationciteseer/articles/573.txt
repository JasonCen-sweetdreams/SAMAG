Entity disambiguation is a crucial task in information retrieval, as it enables accurate linking of mentions to corresponding entities. However, existing approaches often struggle with multilingual text, where entity mentions may have varying levels of ambiguity. This paper presents a novel neural entity disambiguation framework, 'MLED', which leverages a multitask learning approach to jointly model entity linking and language modeling. Our experiments on a large-scale multilingual dataset demonstrate that MLED outperforms state-of-the-art methods by up to 12% in terms of entity linking accuracy, while also improving language model perplexity.