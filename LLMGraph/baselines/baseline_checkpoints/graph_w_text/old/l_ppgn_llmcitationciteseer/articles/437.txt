Multi-agent reinforcement learning (MARL) has seen significant progress in recent years, but the lack of explainability hinders its adoption in real-world applications. We propose a novel hierarchical attention network (HAN) architecture that facilitates explainable decision-making in MARL. Our approach learns to attend to relevant agents, states, and actions, providing insights into the decision-making process. We evaluate HAN on several benchmark MARL environments and demonstrate improved performance and interpretability compared to state-of-the-art methods.