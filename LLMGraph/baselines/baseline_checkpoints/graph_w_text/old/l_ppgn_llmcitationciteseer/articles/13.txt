Explainable recommendation systems are crucial for building trust in AI-driven decision-making. This paper introduces HGAT, a hierarchical graph attention network that incorporates both item and user embeddings to generate personalized explanations for recommended items. HGAT leverages graph attention mechanisms to model complex relationships between items, users, and their attributes, and employs a hierarchical aggregation strategy to capture both local and global dependencies. Experimental results on the MovieLens and Amazon datasets demonstrate that HGAT outperforms state-of-the-art explainable recommendation models in terms of both recommendation accuracy and explanation quality.