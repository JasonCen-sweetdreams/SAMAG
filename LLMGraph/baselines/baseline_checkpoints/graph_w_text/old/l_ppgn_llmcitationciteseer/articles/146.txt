Multi-agent reinforcement learning (MARL) has emerged as a crucial component in various AI applications, including autonomous systems and smart cities. However, the curse of dimensionality in MARL hinders scalability and efficiency. This paper proposes a novel hierarchical attention network (HAN) framework that leverages the concept of attention mechanisms to selectively focus on relevant agents and their interactions. We demonstrate that HAN-based MARL achieves significant improvements in terms of convergence speed, policy stability, and overall performance compared to state-of-the-art methods. Experimental results on a real-world traffic management scenario showcase the potential of HAN-MARL for large-scale, complex systems.