Knowledge graph embedding (KGE) has emerged as a crucial step in various AI applications, including question answering and recommender systems. However, existing KGE methods struggle to capture complex relationships between entities. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework that leverages multi-scale graph attention to learn more robust and informative embeddings. Our approach hierarchically aggregates attention weights across different graph scales, enabling the model to capture both local and global structural patterns. Experimental results on benchmark datasets demonstrate that HGAT outperforms state-of-the-art KGE methods in terms of link prediction and node classification tasks.