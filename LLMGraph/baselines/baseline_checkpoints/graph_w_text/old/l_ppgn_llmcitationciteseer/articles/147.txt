In multi-agent systems, decision-making often relies on complex interactions between agents. While deep reinforcement learning has shown promise in this domain, its black-box nature hinders interpretability and trustworthiness. We propose a hierarchical attention network (HAN) framework that enables explainable decision-making in multi-agent systems. Our approach leverages attention mechanisms to selectively focus on relevant agents and their interactions, providing a hierarchical representation of the decision-making process. Experimental results on a suite of multi-agent scenarios demonstrate that HAN outperforms state-of-the-art methods while providing insightful visualizations of the decision-making process.