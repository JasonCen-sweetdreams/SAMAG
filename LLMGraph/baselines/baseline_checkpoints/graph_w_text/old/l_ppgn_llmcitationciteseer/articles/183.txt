In decentralized autonomous systems, efficient task allocation is crucial for achieving overall system objectives. We propose a novel multi-agent reinforcement learning framework, 'MARL-TA', which enables agents to learn cooperative task allocation strategies in a decentralized setting. MARL-TA leverages a combination of deep Q-networks and graph attention mechanisms to model agent interactions and task dependencies. We evaluate MARL-TA on a realistic autonomous robotic swarm scenario, demonstrating significant improvements in task completion efficiency and adaptability to dynamic environment changes.