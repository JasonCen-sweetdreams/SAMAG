Online learning from streaming data is crucial in many applications, but existing methods often struggle with adapting to changing data distributions. This paper proposes an efficient online learning algorithm, 'AdaptBatch', which dynamically adjusts the batch size based on the data's variance and concept drift. We theoretically analyze the regret bound of AdaptBatch and demonstrate its effectiveness on several real-world datasets, including sensor readings and financial transactions. Experimental results show that AdaptBatch significantly outperforms state-of-the-art online learning methods in terms of accuracy and computational efficiency.