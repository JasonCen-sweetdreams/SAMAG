Conversational AI systems struggle to adapt to changing user preferences and contexts. This paper presents a novel meta-learning framework, 'AdaDialog', which enables dialogue management systems to learn from limited user interactions and adapt to new scenarios. Our approach leverages model-agnostic meta-learning to train a meta-policy that can be fine-tuned for new users and contexts. We evaluate AdaDialog on a range of conversational tasks and demonstrate significant improvements in response quality and user satisfaction compared to traditional reinforcement learning and supervised learning methods.