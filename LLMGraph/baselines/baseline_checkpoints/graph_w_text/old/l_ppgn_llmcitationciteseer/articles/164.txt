In multi-agent systems, cooperative task allocation is a challenging problem that requires agents to dynamically adapt to changing task requirements and environmental conditions. This paper proposes a novel approach that leverages deep reinforcement learning to learn effective task allocation policies. We introduce a decentralized framework, 'CoopTRA', that uses a hierarchical architecture to combine local and global information for task allocation decisions. Experimental results on a simulated robotics domain demonstrate that CoopTRA outperforms existing methods in terms of task completion efficiency and adaptability to changing task priorities.