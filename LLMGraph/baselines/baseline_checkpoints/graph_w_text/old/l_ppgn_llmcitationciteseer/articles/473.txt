In multi-agent systems, task allocation is a critical problem that requires efficient and adaptive decision-making. This paper proposes a decentralized task allocation framework that leverages graph neural networks (GNNs) to learn a distributed policy. Our approach represents the agent-task graph as a dynamic graph structure, where agents and tasks are nodes, and edges represent feasibility and desirability of task assignments. We train a GNN to predict the optimal task assignments based on the graph structure and agent capabilities. Experimental results on a simulated multi-agent system demonstrate that our approach outperforms traditional decentralized allocation methods in terms of task completion rate and agent utility.