In recent years, decentralized multi-agent systems have gained popularity in various domains, such as autonomous vehicles and smart grids. However, coordinating agent actions in a decentralized setting remains a challenging problem. This paper proposes a novel approach, Hierarchical Graph Neural Networks (HGNN), which leverages graph neural networks to learn decentralized coordination policies. HGNN models the agent interactions as a hierarchical graph structure, enabling agents to learn from local observations and adapt to changing environment dynamics. Experimental results on a traffic simulation benchmark demonstrate that HGNN outperforms existing decentralized coordination methods in terms of global reward and convergence speed.