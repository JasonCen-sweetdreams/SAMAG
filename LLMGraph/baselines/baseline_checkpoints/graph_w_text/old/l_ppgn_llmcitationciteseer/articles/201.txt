Graph neural networks (GNNs) have achieved state-of-the-art performance in node classification tasks. However, existing GNNs often struggle to capture complex hierarchical relationships in graphs. This paper proposes a novel hierarchical attention-based GNN architecture, 'HAGNN', which leverages attention mechanisms to selectively focus on relevant nodes and subgraphs at different levels of abstraction. Experimental results on benchmark datasets demonstrate that HAGNN outperforms existing GNN models in node classification tasks, especially on graphs with complex hierarchical structures.