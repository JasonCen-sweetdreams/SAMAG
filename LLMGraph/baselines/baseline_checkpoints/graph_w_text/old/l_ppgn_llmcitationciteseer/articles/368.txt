This paper presents a decentralized multi-agent reinforcement learning (MARL) approach for coordinated traffic signal control. We propose a novel communication protocol that enables agents to share local observations and learn from each other's experiences. Our method, called Dec-MARL, leverages graph neural networks to model the complex interactions between agents and adapt to dynamic traffic patterns. We evaluate Dec-MARL on a large-scale traffic simulation platform and demonstrate significant improvements in traffic efficiency and reduction of congestion compared to traditional centralized control methods.