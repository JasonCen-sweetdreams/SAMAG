In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a hierarchical task allocation framework that leverages deep reinforcement learning to optimize task assignments. Our approach decomposes the task allocation problem into two layers: a high-level layer that assigns tasks to agent clusters, and a low-level layer that allocates tasks within each cluster. We employ a deep Q-network to learn the optimal task allocation policy, taking into account agent capabilities, task dependencies, and environmental constraints. Experimental results on a simulated disaster response scenario demonstrate that our approach outperforms state-of-the-art methods in terms of task completion efficiency and adaptability to dynamic environments.