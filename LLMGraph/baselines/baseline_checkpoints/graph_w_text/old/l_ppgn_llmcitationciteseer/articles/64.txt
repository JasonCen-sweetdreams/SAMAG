Voice assistants have become ubiquitous, but their interaction modalities often exclude people with disabilities. This paper presents a novel multimodal interaction framework for inclusive voice assistants, incorporating gesture recognition, facial expression analysis, and tactile feedback. We conducted a user study with 30 participants with disabilities, demonstrating significant improvements in task completion rates and user satisfaction. Our approach enables more accessible and empowering interactions for people with disabilities, promoting digital inclusion and social participation.