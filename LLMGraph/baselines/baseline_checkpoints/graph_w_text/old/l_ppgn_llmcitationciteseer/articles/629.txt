This paper proposes a novel approach to traffic signal control using hierarchical reinforcement learning (HRL) in multi-agent systems. We introduce a decentralized framework where each agent, representing a traffic signal, learns to coordinate with its neighbors to optimize traffic flow. The higher-level policy selects the optimal communication graph, while the lower-level policy adjusts the signal timing. Our approach is evaluated in a realistic simulation environment, demonstrating a 23% reduction in average travel time and a 15% decrease in congestion compared to traditional fixed-time control methods.