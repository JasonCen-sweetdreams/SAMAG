Reinforcement learning (RL) has achieved impressive successes in complex decision-making tasks, but the lack of interpretability hinders its adoption in real-world applications. This paper presents a novel hierarchical attention network (HAN) architecture that learns to explain its decision-making process in RL environments. HAN uses a hierarchical structure to represent the state and action spaces, and attention mechanisms to focus on relevant regions of the state space. We evaluate HAN on several Atari games and demonstrate its ability to provide interpretable explanations for its policy decisions, while maintaining competitive performance with state-of-the-art RL algorithms.