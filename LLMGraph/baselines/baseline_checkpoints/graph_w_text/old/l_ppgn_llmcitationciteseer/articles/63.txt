This paper presents a novel decentralized task allocation framework for multi-agent systems, where agents learn to allocate tasks through reinforcement learning. We propose a decentralized Q-learning algorithm that enables agents to adapt to changing task requirements and agent availability. Our approach leverages graph neural networks to represent the agent-task relationships and incorporates a entropy-based exploration strategy to promote diversity in task assignments. Experimental results on a simulated logistics scenario demonstrate that our approach outperforms traditional centralized allocation methods in terms of task completion time and agent utilization.