Autonomous vehicles rely on sophisticated AI systems to make critical decisions in complex scenarios. However, the lack of transparency in these decision-making processes hinders trust and accountability. This paper presents 'XRL', an explainable deep reinforcement learning framework that integrates model-based and model-free techniques to provide interpretable policies for autonomous vehicle control. We introduce a novel attention-based mechanism that highlights the most relevant sensor inputs and internal state variables contributing to the agent's actions. Experimental results on simulated and real-world driving datasets demonstrate the effectiveness of XRL in improving decision-making transparency while maintaining competitive performance.