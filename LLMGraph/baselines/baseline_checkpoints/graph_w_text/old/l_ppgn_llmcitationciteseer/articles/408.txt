Resource allocation in cloud computing is a complex problem that requires efficient and adaptive decision-making. This paper proposes a novel deep reinforcement learning framework, 'AdaRA', which leverages a hierarchical actor-critic architecture to optimize resource allocation in dynamic cloud environments. AdaRA uses a combination of model-free and model-based reinforcement learning to balance exploration and exploitation, and achieves significant improvements in resource utilization and application performance compared to state-of-the-art heuristics. Experimental results on a real-world cloud dataset demonstrate the effectiveness of AdaRA in adapting to changing workload patterns and resource availability.