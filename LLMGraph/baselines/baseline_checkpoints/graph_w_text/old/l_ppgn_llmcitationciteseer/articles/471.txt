Neural architecture search (NAS) has emerged as a promising technique for automating deep learning model design. However, existing methods suffer from high computational costs and limited scalability. This paper proposes a graph-based reinforcement learning approach, 'GRAIL', which leverages graph neural networks to efficiently explore the search space. We introduce a novel reward function that balances model accuracy and complexity, and demonstrate significant improvements in search efficiency and model performance on several benchmark datasets.