In this paper, we propose a decentralized task allocation framework for multi-agent systems, where agents learn to allocate tasks autonomously using reinforcement learning. Our approach, dubbed 'RL-TA', utilizes a decentralized actor-critic architecture, where each agent learns to optimize its local reward function while accounting for the actions of neighboring agents. We evaluate RL-TA on a simulated search-and-rescue scenario, demonstrating improved task allocation efficiency and adaptability compared to traditional centralized approaches. Our results show that RL-TA can effectively scale to large numbers of agents and tasks, making it a promising solution for real-world multi-agent systems.