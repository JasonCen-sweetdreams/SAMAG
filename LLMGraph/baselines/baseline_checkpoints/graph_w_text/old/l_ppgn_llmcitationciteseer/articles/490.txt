Real-time traffic control is a complex problem that requires efficient coordination among multiple agents. We propose a hierarchical reinforcement learning framework, 'HRL-ATS', which enables decentralized decision-making for traffic signal control. Our approach utilizes a two-level hierarchy, where the high-level agent optimizes traffic flow and the low-level agents adjust signal timings based on local observations. We evaluate HRL-ATS on a realistic traffic simulation platform and demonstrate significant reductions in travel time and congestion compared to traditional centralized control methods.