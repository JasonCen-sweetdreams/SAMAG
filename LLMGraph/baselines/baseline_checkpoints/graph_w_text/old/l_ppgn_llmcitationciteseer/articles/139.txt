Multi-label classification is a fundamental problem in machine learning, where each instance can have multiple labels. However, existing methods suffer from scalability issues when dealing with large graphs and numerous labels. We propose a novel Hierarchical Graph Attention Network (HiGAT) that leverages hierarchical label structures and graph attention mechanisms to efficiently capture label correlations. HiGAT achieves state-of-the-art performance on several benchmark datasets, including WikiQA and Amazon-670K, while reducing computational complexity by an order of magnitude compared to existing methods.