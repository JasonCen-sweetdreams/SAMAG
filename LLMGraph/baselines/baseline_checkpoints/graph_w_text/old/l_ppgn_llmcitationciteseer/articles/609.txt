Explainable recommendation systems are crucial for building trust in AI-driven decision-making. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that learns to represent users and items as graph-structured entities. By incorporating attention mechanisms at multiple levels, our approach is able to identify key factors influencing user preferences and provide personalized explanations for recommended items. Experimental results on several benchmark datasets demonstrate the effectiveness of HGAT in improving recommendation accuracy and explainability compared to state-of-the-art methods.