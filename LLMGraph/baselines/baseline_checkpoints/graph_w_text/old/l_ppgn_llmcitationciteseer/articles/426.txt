Explainability is crucial in multi-agent dialogue systems, where agents' decisions and responses need to be transparent and accountable. This paper presents a novel hierarchical attention network (HAN) architecture that generates explanations for agent responses in multi-turn dialogues. Our HAN model consists of two stages: utterance-level attention and dialogue-level attention. We evaluate our approach on a benchmark dialogue dataset and demonstrate improved explanation quality and agent response accuracy compared to state-of-the-art baselines. Our approach has significant implications for real-world applications, such as customer service chatbots and virtual assistants.