In multi-agent systems, task allocation is a crucial problem that involves assigning tasks to agents to maximize overall efficiency. This paper proposes a decentralized task allocation framework that employs hierarchical reinforcement learning to learn effective task assignment policies. Our approach consists of a high-level task allocator that assigns tasks to sub-teams of agents, and a low-level task executor that allocates tasks within each sub-team. We show that our approach outperforms traditional centralized and decentralized methods in terms of task completion time and agent utilization. Experimental results on a simulated robotic warehouse scenario demonstrate the scalability and adaptability of our framework.