Large-scale recommendation systems often rely on graph-based models to capture complex user-item relationships. However, these models suffer from computational and memory bottlenecks, limiting their applicability to real-world scenarios. This paper introduces HiGAT, a hierarchical graph attention network that leverages a novel multi-scale attention mechanism to efficiently process large graphs. We demonstrate HiGAT's effectiveness on multiple benchmark datasets, achieving state-of-the-art performance while reducing computational costs by up to 75%. Furthermore, we provide theoretical analysis and insights into the role of hierarchical attention in graph-based recommendation systems.