Cooperative agent teams have emerged as a powerful paradigm for solving complex tasks in various domains. However, efficient task allocation among agents remains a challenging problem. This paper proposes a decentralized task allocation framework that leverages multi-agent deep reinforcement learning (MADRL). Our approach enables agents to learn cooperative policies that adapt to dynamic task environments and optimize team performance. We evaluate our framework on a simulated disaster response scenario, demonstrating improved task allocation efficiency and team performance compared to traditional centralized approaches.