This paper proposes a decentralized task allocation framework for heterogeneous multi-agent systems, where agents with different capabilities and preferences need to collaborate to achieve complex tasks. We employ deep reinforcement learning to train agents to learn optimal task allocation strategies, taking into account their local preferences and the global system objectives. Our approach uses a multi-agent Q-network to estimate the expected rewards for each agent, and a decentralized actor-critic method to update the task allocation policies. Experimental results on a simulated disaster response scenario demonstrate the effectiveness of our approach in improving task completion rates and reducing communication overhead compared to traditional centralized allocation methods.