Anomaly detection in high-dimensional data is a challenging problem, particularly when explanations for detected anomalies are required. This paper proposes a novel deep hierarchical clustering approach, 'HierEX', which integrates representation learning with interpretable clustering. HierEX uses a stacked denoising autoencoder to learn hierarchical representations, and a modified k-means algorithm to identify clusters and anomalies. We introduce a new explainability metric, 'Cluster Importance', which quantifies the contribution of each feature to the anomaly score. Experiments on multiple benchmark datasets demonstrate that HierEX outperforms state-of-the-art methods in both detection accuracy and explainability.