Deep neural networks have achieved state-of-the-art performance in image classification tasks, but their lack of transparency hinders trust and adoption in high-stakes applications. This paper introduces a novel hierarchical attention network (HAN) architecture that generates interpretable explanations for its classification decisions. By recursively applying attention mechanisms at multiple scales, HAN selectively focuses on salient regions and objects in the image, providing a hierarchical understanding of the classification process. Experimental results on the ImageNet dataset demonstrate that HAN achieves competitive performance to ResNet-50 while providing insightful visual explanations.