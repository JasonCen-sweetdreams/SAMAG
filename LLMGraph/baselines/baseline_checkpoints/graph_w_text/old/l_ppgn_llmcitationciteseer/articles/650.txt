Explainability is crucial in multi-agent reinforcement learning (MARL) to ensure transparency and accountability in decision-making. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable MARL. Our approach employs attention mechanisms to selectively focus on relevant agents and their interactions, providing insights into the decision-making process. We evaluate our method on a suite of multi-agent environments and demonstrate improved interpretability and performance compared to state-of-the-art MARL algorithms. Our approach has implications for real-world applications, such as autonomous vehicles and smart grids, where explainability is essential.