In multi-agent systems, decision-making processes often rely on complex interactions between agents. This paper presents a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in cooperative multi-agent environments. Our HAN model learns to selectively focus on relevant agents, tasks, and contexts, providing interpretable attention weights that justify its decisions. Experimental results on a simulated robot soccer domain demonstrate that our approach outperforms existing state-of-the-art methods in terms of task completion rates and decision-making transparency.