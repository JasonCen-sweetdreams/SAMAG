State-of-the-art neural ranking models have significantly improved the accuracy of document retrieval systems, but their computational cost and memory requirements remain a major bottleneck. This paper proposes a novel hierarchical neural ranking architecture, 'HNRM', which leverages a combination of coarse-grained and fine-grained ranking models to efficiently retrieve relevant documents. We demonstrate that HNRM achieves comparable performance to existing neural ranking models while reducing computational cost by up to 40% and memory usage by up to 30%. Experimental results on the TREC-2004 dataset show that HNRM outperforms traditional ranking models and achieves state-of-the-art results on several benchmark datasets.