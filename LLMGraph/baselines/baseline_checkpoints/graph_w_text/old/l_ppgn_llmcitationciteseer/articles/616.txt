Node classification in large-scale graphs is a fundamental task in many applications, including social network analysis and recommender systems. However, existing graph neural network (GNN) models suffer from high computational costs and limited scalability. This paper proposes a novel hierarchical graph attention network (HGAT) that leverages attention mechanisms to selectively aggregate features from neighboring nodes at multiple scales. We demonstrate that HGAT achieves state-of-the-art performance on several benchmark datasets while reducing computational overhead by up to 70%. Furthermore, we provide theoretical analysis of the model's scalability and convergence properties.