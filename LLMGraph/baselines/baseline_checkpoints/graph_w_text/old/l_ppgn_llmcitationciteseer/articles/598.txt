Skeleton-based action recognition has gained popularity in recent years, but existing methods struggle to effectively capture spatial and temporal dependencies in skeleton data. This paper proposes a novel hierarchical attention-based graph neural network (HAGNN) that leverages both node-level and graph-level attention mechanisms to selectively focus on informative joints and frames. Extensive experiments on the NTU-RGB+D and PKU-MMD datasets demonstrate that HAGNN outperforms state-of-the-art methods in terms of recognition accuracy and robustness to noisy data.