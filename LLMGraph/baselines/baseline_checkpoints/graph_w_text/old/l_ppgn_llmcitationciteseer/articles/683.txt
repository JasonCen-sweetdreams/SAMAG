This paper addresses the problem of distributed resource allocation in complex systems, where multiple agents with conflicting objectives interact and adapt to their environment. We propose a decentralized multi-agent reinforcement learning framework, 'DMA-RL', which enables agents to learn cooperative strategies without relying on centralized control or explicit communication. Our approach leverages graph neural networks to model agent interactions and incorporates a novel reward function that encourages fair resource allocation. Experimental results on a simulated smart grid scenario demonstrate that DMA-RL outperforms traditional optimization methods and achieves better system-wide efficiency.