In this paper, we propose a novel distributed task allocation framework for heterogeneous multi-agent systems, where agents have diverse capabilities and tasks require varying levels of resources. We leverage reinforcement learning to enable agents to learn optimal task allocation strategies in a decentralized manner. Our approach, called HRL-TA, combines hierarchical reinforcement learning with graph neural networks to capture complex task dependencies and agent interactions. Experimental results on a simulated robotic swarm demonstrate that HRL-TA outperforms state-of-the-art methods in terms of task completion rate and resource utilization, while adapting to dynamic changes in the environment.