Autonomous vehicles require efficient navigation strategies to ensure safety and efficiency in complex urban environments. This paper proposes a multi-agent cooperative learning framework, 'MACNAV', which enables autonomous vehicles to learn from each other's experiences and adapt to dynamic scenarios. By integrating reinforcement learning with graph-based communication protocols, MACNAV achieves improved navigation performance and reduced collisions compared to individual vehicle learning. We evaluate our approach on a realistic simulation environment and demonstrate its scalability to large fleets of autonomous vehicles.