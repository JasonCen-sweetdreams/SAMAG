This paper presents a novel explainable multi-agent reinforcement learning (MARL) approach for autonomous vehicle coordination in complex urban scenarios. Our method, called EXPLAIN-MARL, integrates a graph neural network-based communication module with a hierarchical reinforcement learning framework, enabling agents to learn cooperative policies while generating interpretable explanations for their actions. We evaluate EXPLAIN-MARL on a realistic simulation platform, demonstrating improved coordination efficiency and safety compared to state-of-the-art MARL methods. The generated explanations also provide valuable insights into the decision-making process of autonomous vehicles.