Coordinating multi-agent systems is a challenging problem in various domains, including robotics, autonomous vehicles, and smart grids. We propose a novel approach that combines deep reinforcement learning with graph attention to learn effective coordination strategies. Our method, called Graph-Attention Multi-Agent Q-Network (GAMAQN), uses a graph neural network to model agent interactions and a deep Q-network to learn coordination policies. We evaluate GAMAQN on several benchmarks and demonstrate its ability to outperform state-of-the-art methods in terms of coordination efficiency and adaptability to changing environments.