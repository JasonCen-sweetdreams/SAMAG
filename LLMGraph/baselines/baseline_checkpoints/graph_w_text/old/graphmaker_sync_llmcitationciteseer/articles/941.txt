Deep reinforcement learning (DRL) has achieved remarkable success in various applications, including game playing and robotics. However, DRL models are vulnerable to adversarial attacks that can manipulate the environment or state observations to compromise the decision-making process. This paper proposes a novel graph-based anomaly detection method,GRADED, to identify adversarial attacks in DRL. GRADED constructs a graph representing the agent's interactions with the environment and detects anomalies using graph-based metrics. Experimental results on the Atari games and robotic manipulation tasks demonstrate that GRADED achieves high detection accuracy and outperforms existing methods in detecting both white-box and black-box attacks.