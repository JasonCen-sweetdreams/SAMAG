Open-domain question answering (ODQA) requires retrieving relevant passages from a large corpus to answer a given question. Existing methods rely on traditional information retrieval (IR) techniques, which are limited by their inability to capture semantic relationships between passages. We propose a neural passage retrieval (NPR) model that leverages pre-trained language models to encode passages and questions, and learns to rank passages based on their relevance to the question. Our experiments on the Natural Questions dataset demonstrate that NPR outperforms state-of-the-art IR methods, achieving a 10% improvement in recall@10 and a 5% improvement in answer accuracy.