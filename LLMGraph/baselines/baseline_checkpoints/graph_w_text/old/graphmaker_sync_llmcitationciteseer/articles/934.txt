Neural ranking models have achieved state-of-the-art performance in ad-hoc retrieval tasks, but their effectiveness is heavily dependent on the quality of the input queries. Query expansion techniques have been widely used to improve retrieval performance, but their impact on neural ranking models remains understudied. This paper investigates the effect of query expansion on neural ranking models, examining the trade-offs between retrieval effectiveness and computational efficiency. Our experiments on several benchmark datasets demonstrate that query expansion can significantly improve the performance of neural ranking models, but may also introduce additional computational overhead. We propose a novel query expansion framework that adaptively selects expansion terms based on the neural model's uncertainty, achieving a better balance between effectiveness and efficiency.