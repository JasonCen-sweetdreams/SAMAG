Time-series forecasting models often lack transparency, making it challenging to understand the underlying factors driving predictions. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates both local and global attention mechanisms to selectively focus on relevant input features and time-steps. Our approach enables the model to generate interpretable attention weights, providing insights into the most influential factors contributing to forecasted values. Experimental results on several benchmark datasets demonstrate the effectiveness of HAN in improving forecasting performance while offering enhanced explainability.