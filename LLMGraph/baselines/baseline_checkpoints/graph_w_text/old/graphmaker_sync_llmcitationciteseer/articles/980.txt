E-commerce search systems require effective ranking models to retrieve relevant products from large catalogs. This paper proposes a novel neural ranking framework, 'MMR-NRM', which integrates visual and textual product features for multi-modal retrieval. Our approach leverages a dual-encoder architecture with a shared knowledge graph to capture complex relationships between products. Experimental results on a large-scale e-commerce dataset demonstrate that MMR-NRM outperforms state-of-the-art ranking models in terms of precision, recall, and user satisfaction metrics.