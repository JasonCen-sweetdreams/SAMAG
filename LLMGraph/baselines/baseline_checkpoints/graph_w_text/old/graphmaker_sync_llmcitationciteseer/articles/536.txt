In this paper, we address the problem of decentralized task allocation in multi-agent systems, where agents with limited communication range need to coordinate to achieve a common goal. We propose a novel approach that leverages graph neural networks (GNNs) to learn a distributed task allocation policy. Our method, called DAGNET, uses a decentralized GNN architecture to learn agent representations and allocate tasks based on the agents' capabilities and the task requirements. We evaluate DAGNET in a simulated search and rescue scenario and show that it outperforms traditional decentralized allocation methods in terms of task completion rate and communication overhead.