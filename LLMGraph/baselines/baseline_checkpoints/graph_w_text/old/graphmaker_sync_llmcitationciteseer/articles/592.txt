Dialogue state tracking (DST) is a crucial component of task-oriented dialogue systems, requiring accurate identification of user goals and preferences. This paper proposes a novel hierarchical graph attention network (HGAT) for DST, which leverages multi-modal inputs from speech, text, and visual cues. Our model employs a hierarchical graph structure to capture complex relationships between dialogue turns, and attention mechanisms to selectively focus on relevant modalities. Experimental results on the MultiWOZ dataset demonstrate that HGAT outperforms state-of-the-art DST models, achieving a 12.1% absolute improvement in joint goal accuracy.