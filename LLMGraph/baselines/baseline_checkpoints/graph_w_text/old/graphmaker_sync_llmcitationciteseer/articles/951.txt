Distributed database systems have become increasingly popular for handling large-scale data storage and querying. However, optimizing query execution plans in these systems remains a challenging problem. This paper explores the application of reinforcement learning to query optimization in distributed databases. We propose a novel framework, 'RL-Optimizer', which learns to select efficient query plans based on feedback from the database system. Our approach incorporates a reward function that balances query latency, resource utilization, and data freshness. Experimental results on a real-world dataset demonstrate that RL-Optimizer outperforms traditional rule-based and cost-based optimizers, achieving an average query latency reduction of 23.5%.