We propose a novel hierarchical attention network (HAN) architecture for multi-agent reinforcement learning (MARL) in complex, dynamic environments. Our approach enables agents to selectively focus on relevant teammates, opponents, or environmental features, leading to improved coordination and decision-making. We evaluate HAN on a range of MARL benchmarks, demonstrating significant performance gains over state-of-the-art methods in cooperative and competitive settings. Furthermore, we provide theoretical guarantees on the convergence of HAN-based MARL algorithms.