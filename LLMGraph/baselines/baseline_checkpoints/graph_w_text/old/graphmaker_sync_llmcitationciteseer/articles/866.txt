Question answering (QA) models often struggle to provide interpretable explanations for their predictions, especially when dealing with multi-hop questions that require reasoning over long-range dependencies. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that integrates both local and global attention mechanisms to selectively emphasize relevant contextual information. We demonstrate that HGAT outperforms state-of-the-art QA models on several benchmark datasets, including HotPotQA and WikiHop, while providing more transparent and explainable predictions.