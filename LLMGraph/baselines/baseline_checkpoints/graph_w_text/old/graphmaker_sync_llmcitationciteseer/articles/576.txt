Graph neural networks (GNNs) have shown promising results in node classification tasks, but their computational complexity hinders their scalability to large graphs. This paper proposes a novel hierarchical attention-based GNN framework, 'HierAttn', which leverages a hierarchical graph representation to selectively attend to relevant nodes and reduce the computational overhead. We introduce a node importance scoring function that adaptively adjusts the attention weights based on node centrality and feature similarity. Experimental results on several real-world graph datasets demonstrate that HierAttn outperforms state-of-the-art GNN models in terms of both accuracy and efficiency.