Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables understanding of agent decision-making. Existing methods focus on feature importance or attention visualization, neglecting the complex interactions between agents. We propose HiGAT, a hierarchical graph attention network that models agent relationships and joint policy learning. HiGAT incorporates graph attention mechanisms to identify influential agents and their interactions, thereby providing interpretable explanations for joint policy decisions. Experimental results on the Multi-Agent Particle Environment demonstrate improved explainability and coordination in MARL settings.