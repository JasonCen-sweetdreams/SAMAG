Voice assistants have become ubiquitous in modern life, but their efficacy is often limited by cultural and linguistic biases. This paper presents a mixed-methods study examining the effects of cultural and linguistic biases on voice assistant interaction. We conducted user studies with 120 participants from diverse cultural backgrounds, analyzing their interactions with popular voice assistants. Our results reveal significant differences in interaction patterns, error rates, and user satisfaction across cultural groups. We propose a framework for inclusive voice assistant design, incorporating culturally sensitive language processing and personalized feedback mechanisms. Our approach aims to reduce biases and improve the overall user experience for diverse populations.