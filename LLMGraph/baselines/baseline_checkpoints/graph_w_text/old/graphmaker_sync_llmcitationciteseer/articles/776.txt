Task allocation is a fundamental problem in multi-agent systems, where heterogeneous agents with varying capabilities and constraints need to be assigned tasks to optimize system performance. This paper proposes a novel deep reinforcement learning framework, 'MARL-TA', that learns to allocate tasks in a scalable and decentralized manner. Our approach leverages graph neural networks to model agent interactions and a hierarchical reinforcement learning architecture to handle task dependencies. Experimental results on a simulated logistics domain demonstrate that MARL-TA outperforms traditional optimization-based methods in terms of task completion time and system efficiency, while adapting to changing agent capabilities and task requirements.