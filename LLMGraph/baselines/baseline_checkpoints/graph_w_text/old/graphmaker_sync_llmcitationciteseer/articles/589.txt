This paper presents a decentralized multi-agent reinforcement learning (MARL) framework for adaptive traffic signal control. We consider a network of intersections, each controlled by an autonomous agent, which learns to optimize traffic flow by interacting with neighboring agents. Our approach leverages a Graph Attention Network (GAT) to model agent-agent interactions and learn a shared policy. We evaluate our method on a realistic simulation environment and demonstrate significant reductions in travel time and congestion compared to traditional fixed-time signal control strategies.