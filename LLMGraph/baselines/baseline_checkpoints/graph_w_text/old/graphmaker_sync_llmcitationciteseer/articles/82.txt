Autonomous agents are increasingly being used in complex systems, but coordinating their actions to achieve optimal task-oriented performance remains a significant challenge. This paper proposes a novel approach to multi-agent coordination using deep reinforcement learning (DRL). We introduce a hierarchical DRL framework that enables agents to learn cooperative policies while adapting to dynamic task requirements. Our method, called Coop-DRL, leverages graph neural networks to model agent interactions and incorporates a novel task-oriented reward function. Experimental results on a simulated logistics scenario demonstrate that Coop-DRL outperforms traditional multi-agent planning methods, achieving up to 25% improvement in task completion efficiency.