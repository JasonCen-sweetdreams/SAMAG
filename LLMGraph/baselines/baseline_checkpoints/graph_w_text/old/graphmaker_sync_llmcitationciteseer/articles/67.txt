Anomaly detection in time-series data is crucial for various applications, such as predictive maintenance and fraud detection. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable anomaly detection. Our approach leverages self-attention mechanisms to model complex temporal dependencies and hierarchically aggregates features to identify anomalies. We also introduce an interpretable attention-based explanation technique, which provides insights into the anomaly detection process. Experimental results on real-world datasets demonstrate that HAN outperforms state-of-the-art methods in terms of detection accuracy and provides meaningful explanations for detected anomalies.