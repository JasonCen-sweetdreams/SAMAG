Multimodal sentiment analysis (MSA) models have gained popularity, but their lack of interpretability hinders trustworthiness. This paper proposes a novel hybrid attention mechanism, 'HybridAtt', which integrates self-attention and graph attention to capture complex relationships between modalities. HybridAtt enables explainable MSA by generating attention weights that highlight relevant input features contributing to sentiment predictions. Experimental results on three benchmark datasets demonstrate that HybridAtt outperforms state-of-the-art MSA models while providing meaningful insights into the decision-making process.