Deep neural networks are vulnerable to adversarial attacks, which can compromise their reliability in critical applications. This paper proposes a novel Bayesian neural architecture search (B NAS) framework to improve the adversarial robustness of neural networks. Our approach leverages a probabilistic formulation to jointly optimize the network architecture and weights, resulting in models that are more resilient to perturbations. We demonstrate the effectiveness of our approach on several benchmark datasets, achieving state-of-the-art robustness against both white-box and black-box attacks.