As multi-agent systems become increasingly prevalent, understanding the decision-making processes of autonomous agents is crucial. This paper introduces a novel Hierarchical Attention Network (HAN) architecture for explainable multi-agent reinforcement learning. HAN combines attention mechanisms at both the agent and system levels to provide insights into agent interactions and policy decisions. We evaluate HAN on a range of cooperative and competitive multi-agent scenarios, demonstrating improved explainability and policy performance compared to state-of-the-art methods.