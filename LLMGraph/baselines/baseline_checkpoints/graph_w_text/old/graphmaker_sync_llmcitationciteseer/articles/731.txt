Ad-hoc retrieval systems often rely on query expansion to improve retrieval effectiveness. However, traditional methods based on term co-occurrence or pseudo-relevance feedback can be computationally expensive and ineffective for rare or ambiguous queries. This paper proposes a novel neural approach, 'NeuroXPand', which leverages pre-trained language models to learn semantic embeddings of queries and documents. We demonstrate that NeuroXPand can effectively capture query intent and expand queries with relevant terms, leading to significant improvements in retrieval performance on several benchmark datasets.