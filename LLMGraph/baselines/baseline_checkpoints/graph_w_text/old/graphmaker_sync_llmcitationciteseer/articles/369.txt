Efficient resource allocation is a critical problem in multi-agent systems. This paper proposes a novel approach that leverages deep reinforcement learning to coordinate agent actions and optimize resource allocation. Our method, 'MARL-RA', uses a decentralized actor-critic framework to learn policies for each agent, while a centralized critic updates the global state value function. We evaluate MARL-RA on a simulated smart grid environment and demonstrate improved resource allocation efficiency and reduced communication overhead compared to traditional approaches. The results have implications for applications in smart cities, IoT, and autonomous systems.