This paper presents a novel hierarchical attention network (HAN) architecture for explainable multi-agent reinforcement learning. Our approach leverages attention mechanisms to selectively focus on relevant agents and their interactions, facilitating more efficient and interpretable decision-making. We evaluate our HAN model on a range of cooperative and competitive multi-agent environments, demonstrating improved performance and enhanced explainability compared to state-of-the-art baselines. Our results highlight the potential of HANs for real-world applications, such as autonomous vehicles and smart grids, where transparency and accountability are critical.