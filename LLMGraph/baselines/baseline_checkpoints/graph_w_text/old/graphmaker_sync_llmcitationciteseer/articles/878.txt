Autonomous vehicles require efficient control strategies that can adapt to complex scenarios. This paper presents a novel deep hierarchical reinforcement learning framework, 'DeepCtrl', which integrates a high-level decision-making module with a low-level control policy. Our approach leverages a hierarchical graph neural network to model the vehicle's environment and a proximal policy optimization algorithm to learn the control policy. Experimental results on a realistic simulation platform demonstrate that DeepCtrl outperforms state-of-the-art methods in terms of safety, efficiency, and adaptability in diverse urban driving scenarios.