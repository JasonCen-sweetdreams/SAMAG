Cooperative learning in multi-agent systems is crucial for achieving complex tasks, but it often lacks transparency and interpretability. We propose a novel hierarchical attention network (HAT) framework, which enables explainable cooperation by learning attention weights across agents and tasks. Our approach combines graph attention networks with hierarchical reinforcement learning, allowing agents to selectively focus on relevant information and coordinate their actions. Experimental results on a scenario-based multi-agent environment show that HAT outperforms state-of-the-art methods in terms of cooperation efficiency and explainability.