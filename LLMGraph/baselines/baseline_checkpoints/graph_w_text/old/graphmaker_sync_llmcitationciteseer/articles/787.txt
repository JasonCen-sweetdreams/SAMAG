In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper proposes a novel approach that leverages reinforcement learning to dynamically allocate tasks to agents based on their capabilities, availability, and environmental constraints. We introduce a decentralized, model-free algorithm that enables agents to learn from their experiences and adapt to changing task requirements and system dynamics. Experimental results on a simulated robotic search and rescue scenario demonstrate that our approach outperforms traditional, hand-designed allocation strategies in terms of task completion time and system efficiency.