Individuals with motor impairments often struggle with precise cursor control, hindering their ability to interact with computers. This paper presents a novel gaze-based cursor control system leveraging deep reinforcement learning. Our approach, dubbed 'GazeRL', utilizes a convolutional neural network to extract features from eye-tracking data and a reinforcement learning agent to infer user intent. We demonstrate improved pointing accuracy and reduced latency compared to traditional gaze-based systems in a user study involving participants with and without motor impairments. GazeRL has the potential to enhance the accessibility of graphical user interfaces for individuals with diverse abilities.