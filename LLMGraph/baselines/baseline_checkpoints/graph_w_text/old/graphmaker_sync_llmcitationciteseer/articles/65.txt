Distributed database systems (DDBS) pose significant challenges for query optimization. Traditional cost-based optimization approaches often fail to adapt to dynamic workloads and system variations. This paper proposes a novel adaptive query optimization framework, 'AQORL', that leverages reinforcement learning (RL) to optimize query plans in DDBS. AQORL uses a deep Q-network to learn the optimal query plan from a large state-action space, and incorporates a novel exploration strategy to adapt to changing system conditions. Experimental results on a real-world DDBS benchmark demonstrate that AQORL outperforms state-of-the-art optimization techniques by up to 30% in query execution time.