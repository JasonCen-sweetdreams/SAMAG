Few-shot image classification has gained significant attention in recent years. However, most existing approaches focus on single-task learning, neglecting the potential benefits of multi-task learning. This paper proposes a novel hierarchical attention-based multi-task learning framework, 'HAMTL', which jointly learns multiple related tasks with limited data. Our approach leverages a task-agnostic feature extractor and task-specific attention modules to adapt to new tasks with only a few examples. Experiments on benchmark datasets demonstrate the effectiveness of HAMTL in improving few-shot image classification performance and reducing task-specific overfitting.