In multi-agent systems, cooperative decision-making often relies on opaque AI models that hinder interpretability and trust. This paper presents HANC, a hierarchical attention network that facilitates explainable cooperation among agents. HANC integrates local attention mechanisms, which focus on relevant state features, with a global attention layer, which selectively weighs agent contributions. We demonstrate HANC's effectiveness in a simulated urban search and rescue scenario, where it outperforms baseline methods in terms of task completion rate and interpretability metrics. Our approach enables transparent and efficient cooperation, paving the way for real-world multi-agent systems.