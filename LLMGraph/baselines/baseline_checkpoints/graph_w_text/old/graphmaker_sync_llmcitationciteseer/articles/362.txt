This paper presents a novel approach to coordinating autonomous vehicles (AVs) in complex traffic scenarios using multi-agent reinforcement learning (MARL) with graph attention. We model the interactions between AVs and the environment as a graph, leveraging attention mechanisms to focus on the most influential agents and edges. Our method, 'GAT-MARL', learns to optimize traffic flow and reduce congestion by adaptively adjusting the behaviors of individual AVs. Experimental results on a simulated traffic network demonstrate that GAT-MARL outperforms state-of-the-art MARL methods in terms of average speed, travel time, and safety metrics.