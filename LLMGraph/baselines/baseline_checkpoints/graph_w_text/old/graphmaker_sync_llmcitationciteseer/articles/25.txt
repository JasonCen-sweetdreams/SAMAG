This paper presents a novel hierarchical reinforcement learning framework for autonomous drone navigation in complex, dynamic environments. Our approach leverages graph attention mechanisms to model the relationships between different objects and obstacles in the scene, enabling the drone to learn a hierarchical policy that balances short-term reactive control with long-term goal-directed planning. Experimental results demonstrate significant improvements in navigation efficiency and safety compared to state-of-the-art reinforcement learning methods, particularly in scenarios with multiple moving obstacles.