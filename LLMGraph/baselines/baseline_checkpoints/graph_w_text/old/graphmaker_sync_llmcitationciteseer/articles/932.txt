Cloud computing platforms face the challenge of efficiently allocating resources to meet dynamic workload demands. This paper proposes a deep reinforcement learning (DRL) framework, 'CloudAllocator', which learns to optimize resource allocation policies for virtual machines. Our approach leverages a novel combination of deep Q-networks and graph neural networks to learn representations of workload patterns and resource availability. Experimental results on a large-scale cloud simulation platform demonstrate that CloudAllocator outperforms state-of-the-art resource allocation algorithms in terms of responsiveness, efficiency, and adaptability.