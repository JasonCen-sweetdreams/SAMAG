In multi-agent systems, trust management is crucial to ensure cooperation and prevent malicious behavior. This paper presents a novel approach to adaptive trust management using reinforcement learning. Our method, called TRUST-RL, leverages Q-learning to learn the optimal trust policies for each agent based on their interactions and behaviors. We evaluate TRUST-RL in a simulated environment and show that it outperforms traditional trust management methods in terms of convergence speed and robustness to false information. The results demonstrate the potential of reinforcement learning for building more resilient and trustworthy multi-agent systems.