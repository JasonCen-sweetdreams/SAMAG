Deep reinforcement learning (DRL) has achieved impressive results in complex tasks, but its lack of interpretability hinders its adoption in high-stakes applications. We propose a novel Hierarchical Attention Network (HAN) that integrates attention mechanisms into DRL to provide explainable decision-making. HAN learns to focus on relevant state features and action components, enabling the identification of key factors influencing policy decisions. Our experiments on Atari games and a real-world autonomous driving scenario demonstrate that HAN improves policy transparency and performance, while reducing the risk of catastrophic failures.