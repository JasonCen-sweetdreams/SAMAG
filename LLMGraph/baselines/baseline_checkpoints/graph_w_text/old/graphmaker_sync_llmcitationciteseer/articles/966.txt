Multi-agent cooperation is a crucial aspect of many real-world applications, such as robotics, smart cities, and autonomous vehicles. However, existing approaches often rely on black-box models that lack interpretability, hindering trust and reliability. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that enables transparent and explainable multi-agent cooperation. HGAT combines graph attention mechanisms with hierarchical clustering to capture complex agent interactions and provide fine-grained explanations for cooperative decision-making. Experimental results on a simulated search-and-rescue scenario demonstrate the effectiveness of HGAT in improving cooperation efficiency and providing interpretable insights into agent behavior.