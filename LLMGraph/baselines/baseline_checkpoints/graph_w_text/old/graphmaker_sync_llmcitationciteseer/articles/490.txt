Explainability is crucial in multi-agent reinforcement learning (MARL) to understand agent decision-making and improve collaboration. This paper presents HAN-MARL, a hierarchical attention network that learns to selectively focus on relevant agents, states, and actions to produce explainable policies. We demonstrate the effectiveness of HAN-MARL in several MARL benchmarks, showcasing improved explainability, interpretability, and performance compared to state-of-the-art methods. Furthermore, we introduce a novel metric, Explainability Gain, to quantify the added value of explainability in MARL.