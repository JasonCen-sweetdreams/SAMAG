Explainability is crucial in multi-agent systems, where autonomous agents make decisions that impact human lives. This paper introduces HAN-MAD, a novel hierarchical attention network that provides interpretable decision-making models for multi-agent systems. HAN-MAD employs a two-level attention mechanism, where the first level attends to relevant agents and the second level attends to crucial features of those agents. We evaluate HAN-MAD on a real-world autonomous vehicle dataset and demonstrate improved explainability and decision-making performance compared to existing approaches. Our work has significant implications for trustable and transparent AI systems in complex, dynamic environments.