In complex task allocation problems, multiple agents with varying capabilities must cooperate to achieve a common goal. This paper presents a novel multi-agent reinforcement learning framework, 'CoopTask', which enables agents to learn cooperative strategies for task allocation. We introduce a decentralized, graph-based approach that incorporates both local and global reward functions, allowing agents to adapt to dynamic task requirements and environmental changes. Experimental results on a simulated logistics scenario demonstrate that CoopTask significantly outperforms traditional, non-cooperative allocation methods in terms of task completion time and resource utilization.