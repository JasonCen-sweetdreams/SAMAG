Open-domain question answering (ODQA) relies on effective passage retrieval to identify relevant documents. We propose a novel hierarchical dense retrieval (HDR) approach that leverages a dual-encoder architecture to efficiently retrieve passages. The first encoder generates a coarse-grained document representation, while the second encoder refines the representation using a hierarchical attention mechanism. Experiments on the Natural Questions and TriviaQA datasets demonstrate that HDR outperforms state-of-the-art dense retrieval methods, achieving a 10% increase in top-20 passage retrieval accuracy while reducing computational cost by 30%.