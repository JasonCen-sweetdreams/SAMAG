Graph Neural Networks (GNNs) have achieved remarkable success in various applications, but their vulnerability to adversarial attacks remains a significant concern. This paper proposes a novel approach to enhance the adversarial robustness of GNNs via meta-learning. We design a meta-learner that generates adaptive perturbations to simulate diverse attack scenarios, and a robustness module that learns to defend against these perturbations. Our experiments on several benchmark datasets demonstrate that the proposed method significantly improves the robustness of GNNs against various types of attacks, while maintaining their performance on clean data.