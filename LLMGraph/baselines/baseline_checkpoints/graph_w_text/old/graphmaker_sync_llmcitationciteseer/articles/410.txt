Query expansion (QE) is a critical component of ad-hoc retrieval systems, but traditional methods often rely on manual feature engineering and heuristics. This paper proposes a novel reinforcement learning (RL) framework for QE, which learns to select optimal expansion terms by maximizing a reward function that incorporates relevance and diversity metrics. Our approach, dubbed 'RL-QE', uses a deep Q-network to learn a policy that adapts to varying query characteristics and document collections. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art QE methods in terms of retrieval effectiveness and efficiency.