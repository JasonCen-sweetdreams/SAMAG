Time-series forecasting models often lack interpretability, making it challenging to understand their predictions. This paper proposes a hierarchical attention network (HAN) architecture that incorporates both local and global attention mechanisms to prioritize relevant features and time steps. Our approach enables model interpretability by providing attention weights that highlight the most influential factors contributing to the forecast. Experimental results on multiple benchmark datasets demonstrate that HAN outperforms state-of-the-art models in terms of forecasting accuracy and provides meaningful insights into the underlying dynamics.