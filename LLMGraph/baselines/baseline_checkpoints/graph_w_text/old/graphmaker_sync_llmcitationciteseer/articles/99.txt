Effective anomaly detection in time-series data is crucial for various applications, including healthcare and finance. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable anomaly detection. Our approach leverages self-attention mechanisms to capture long-range dependencies and hierarchical representations to identify anomalies at multiple scales. We introduce a novel explainability module that provides feature importance scores, enabling the identification of root causes for anomalies. Experimental results on real-world datasets demonstrate the superior performance of HAN over state-of-the-art methods, with improved interpretability and robustness to noisy data.