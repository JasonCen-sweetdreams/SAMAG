Autonomous vehicles rely on reinforcement learning (RL) to make critical decisions, but the lack of transparency in RL models hinders trust and accountability. This paper presents 'XRL', an explainable RL framework that integrates attention mechanisms and model-based reasoning to provide insights into decision-making processes. We evaluate XRL on a simulated autonomous driving environment, demonstrating improved transparency and interpretability while maintaining competitive performance. Our approach enables human-AI collaboration, facilitating safer and more reliable autonomous systems.