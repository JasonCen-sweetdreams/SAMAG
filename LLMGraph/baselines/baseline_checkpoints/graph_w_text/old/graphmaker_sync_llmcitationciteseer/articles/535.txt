Explainability is a crucial aspect of multi-agent reinforcement learning (MARL) in real-world applications. This paper introduces Hierarchical Attention Networks (HANs) to improve the transparency and interpretability of MARL policies. Our proposed HAN architecture consists of two stages: an intra-agent attention module that captures task-specific features and an inter-agent attention module that models the interactions between agents. We demonstrate the effectiveness of HANs in a variety of MARL benchmarks, showcasing improved performance and enhanced explainability through visualizations of attention weights.