The rise of big data and distributed computing has led to a significant increase in the complexity of query optimization for relational databases. Traditional optimization techniques often rely on heuristics and manual tuning, which can be time-consuming and suboptimal. This paper proposes a novel approach that leverages reinforcement learning to optimize query plans for distributed relational databases. Our method, dubbed 'RL-QO', uses a deep Q-network to learn an optimal policy for query optimization, taking into account factors such as data distribution, network latency, and available resources. Experimental results on a real-world dataset demonstrate that RL-QO outperforms state-of-the-art optimization techniques by up to 30% in terms of query execution time.