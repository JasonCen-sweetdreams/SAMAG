Explainability is crucial in AI-driven recommendation systems, where users expect transparency into the decision-making process. This paper proposes a novel heterogeneous graph attention network (HGAT) architecture that leverages both user-item interactions and item features to generate personalized recommendations. Our approach incorporates a hierarchical attention mechanism that captures complex relationships between users, items, and features, enabling the model to provide interpretable explanations for its recommendations. Experimental results on multiple benchmark datasets demonstrate the effectiveness of HGAT in improving recommendation accuracy and explainability.