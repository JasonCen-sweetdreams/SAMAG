As multi-agent systems become increasingly prevalent, the need for transparent and interpretable decision-making processes grows. This paper presents a novel hierarchical attention network (HAN) architecture, designed to facilitate explainable decision-making in multi-agent settings. Our approach leverages attention mechanisms to weight the relative importance of individual agent features, enabling the identification of influential agents and features. We evaluate our method using a simulated traffic control scenario, demonstrating improved explainability and decision quality compared to traditional reinforcement learning approaches.