In multi-agent reinforcement learning, understanding the decision-making process of individual agents is crucial for effective cooperation and coordination. This paper introduces HAN-MARL, a novel hierarchical attention network architecture that learns to extract relevant features from agent interactions and environment observations. Our approach enables explainable decision-making by generating attention weights that indicate the relative importance of different agents and features. Experiments on a variety of cooperative and competitive scenarios demonstrate that HAN-MARL outperforms state-of-the-art MARL methods in terms of both performance and interpretability.