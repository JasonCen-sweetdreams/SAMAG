Multi-agent reinforcement learning has seen significant progress in recent years, but existing methods often struggle to model complex relationships between agents. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that learns to represent agents as nodes in a graph and applies attention mechanisms to selectively focus on relevant interactions. We demonstrate the effectiveness of HGAT in a variety of multi-agent environments, including traffic control and robotic soccer, and show that it outperforms state-of-the-art methods in terms of both performance and interpretability.