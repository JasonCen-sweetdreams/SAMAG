Neural information retrieval (IR) models have achieved state-of-the-art performance in ad-hoc retrieval tasks. However, their computational cost remains a significant bottleneck, especially when processing long documents. This paper proposes a novel approach to exploit document structure for efficient passage retrieval in neural IR models. We develop a hierarchical document encoder that captures both local and global contextual information, enabling the model to identify relevant passages more effectively. Our experimental results on several benchmark datasets demonstrate significant improvements in retrieval efficiency while maintaining comparable performance to existing neural IR models.