Conversational search systems aim to facilitate natural language interactions between users and search engines. However, accurately interpreting user queries remains a significant challenge. This paper proposes a novel neural query expansion approach, 'ConverseQE', which leverages contextualized language models to generate semantically relevant expansion terms. Our method incorporates a dual-encoder architecture that jointly learns query and document representations, enabling more effective query expansion and retrieval. Experimental results on a large conversational search dataset demonstrate significant improvements in retrieval performance and user satisfaction compared to traditional query expansion techniques.