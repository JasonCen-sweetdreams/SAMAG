Virtual reality (VR) has revolutionized human-computer interaction, but the lack of naturalistic gestures hinders user immersion. This paper explores the application of embodied cognition principles to gesture-based interaction in VR. We designed a novel gesture recognition system, 'Embodify', which leverages machine learning and computer vision to detect and interpret user gestures. Our user study reveals that Embodify significantly enhances user experience, improves task completion time, and reduces cognitive load. We discuss the implications of our findings for designing more intuitive and engaging VR interfaces.