Multi-agent reinforcement learning (MARL) has shown promise in various applications, but its interpretability remains a significant challenge. This paper introduces Hierarchical Attention Networks (HANs) to enable explainable decision-making in MARL. HANs leverage hierarchical graph attention to capture complex agent-agent and agent-environment interactions. We propose a novel attention-based credit assignment mechanism that identifies the most influential agents and interactions contributing to the team's reward. Experimental results on several MARL benchmarks demonstrate that HANs improve both the performance and interpretability of the learned policies.