Time series forecasting models often struggle to provide interpretable insights into their predictions. This paper proposes a novel hierarchical attention network (HAN) architecture that addresses this challenge. Our HAN model employs a hierarchical structure to capture both short- and long-term dependencies in time series data, while attention mechanisms facilitate the identification of relevant input features. We demonstrate the effectiveness of our approach on several benchmark datasets, achieving state-of-the-art forecasting performance while providing transparent and explainable results.