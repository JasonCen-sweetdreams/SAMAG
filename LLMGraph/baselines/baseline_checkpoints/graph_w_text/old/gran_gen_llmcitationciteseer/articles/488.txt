Distributed database systems (DDS) have become increasingly popular for handling large-scale data storage and processing. However, query optimization in DDS remains a challenging problem due to the complexity of data distribution and network latency. This paper proposes a novel approach to query optimization using reinforcement learning (RL). We design a RL framework that learns to optimize query plans based on a reward function that considers both execution time and resource utilization. Experimental results on a real-world dataset demonstrate that our approach outperforms traditional query optimization techniques by up to 30% in terms of execution time and 25% in terms of resource utilization.