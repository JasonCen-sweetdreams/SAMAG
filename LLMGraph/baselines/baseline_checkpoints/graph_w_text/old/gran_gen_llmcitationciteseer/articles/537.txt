Distributed graph databases have become increasingly popular for storing and querying large-scale graph data. However, optimizing queries in these systems remains a challenging task due to the complexity of graph structures and the need to balance query performance with data distribution and network latency. This paper proposes a novel query optimization approach that leverages reinforcement learning to learn efficient query plans. Our approach, called GraphRL, uses a deep Q-network to learn a policy for selecting optimal query plans based on graph topology, data distribution, and system workload. Experimental results on a real-world graph dataset demonstrate that GraphRL outperforms state-of-the-art query optimization techniques by up to 30% in terms of query latency and 25% in terms of resource utilization.