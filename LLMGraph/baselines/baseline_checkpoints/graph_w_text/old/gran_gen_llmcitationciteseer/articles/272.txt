In heterogeneous multi-agent systems, decentralized task allocation is a challenging problem due to the varying capabilities and constraints of individual agents. This paper proposes a novel deep reinforcement learning framework, 'HETERO', that enables agents to learn optimal task allocation policies in a decentralized manner. HETERO utilizes a graph neural network to model agent interactions and a hierarchical reinforcement learning architecture to handle tasks with varying complexities. Experimental results on a simulated search-and-rescue scenario demonstrate that HETERO outperforms traditional decentralized task allocation algorithms in terms of task completion efficiency and adaptability to changing environmental conditions.