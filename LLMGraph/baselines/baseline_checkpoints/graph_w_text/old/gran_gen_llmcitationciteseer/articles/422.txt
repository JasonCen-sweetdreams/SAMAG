Distributed database systems (DDS) are increasingly used to manage large-scale data. However, optimizing query performance in DDS remains a significant challenge. This paper proposes a novel approach that leverages machine learning (ML) to predict and optimize query execution plans. We develop a neural network-based model that learns from query patterns and system performance metrics to identify the most efficient execution plan. Our experiments on a real-world DDS demonstrate that the proposed approach reduces query latency by up to 30% compared to traditional optimization techniques.