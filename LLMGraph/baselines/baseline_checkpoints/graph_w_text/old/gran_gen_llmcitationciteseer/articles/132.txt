Deep neural ranking models have achieved state-of-the-art performance in ad-hoc retrieval, but their effectiveness is often hindered by the vocabulary mismatch problem. This paper proposes a novel query expansion approach that leverages the semantic representation capabilities of pre-trained language models. Our method, dubbed 'NeuralEX', uses a masked language model to generate context-aware expansion terms, which are then incorporated into the original query. Experimental results on several benchmark datasets demonstrate that NeuralEX significantly improves the retrieval performance of neural ranking models, outperforming traditional query expansion techniques and achieving competitive results with more computationally expensive methods.