This paper proposes a novel approach to scalable multi-agent task allocation using hierarchical reinforcement learning. Our method, HierMAL, integrates a high-level task allocator with low-level agent controllers, enabling efficient allocation of tasks to agents in complex, dynamic environments. We demonstrate the effectiveness of HierMAL through simulations of a disaster response scenario, showcasing significant improvements in task completion rates and agent utilization compared to existing decentralized allocation methods.