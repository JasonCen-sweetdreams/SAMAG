Knowledge graph embedding (KGE) has become a crucial component in explainable AI systems, enabling the interpretation of AI-driven decisions. However, existing KGE methods often suffer from high computational complexity and inadequate modeling of complex relationships. This paper proposes a novel hierarchical attention-based KGE framework, 'HAT-KGE', which leverages graph attention mechanisms to capture multi-level relational patterns. We demonstrate the effectiveness of HAT-KGE on benchmark datasets, achieving state-of-the-art performance in link prediction and entity disambiguation tasks while providing transparent and interpretable representations.