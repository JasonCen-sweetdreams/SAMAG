This paper introduces Hierarchical Attention Networks (HANs) for explainable multi-agent reinforcement learning. HANs learn to selectively focus on relevant agents and their interactions, enabling the identification of influential agents and behaviors that contribute to the team's overall performance. We evaluate HANs on a range of multi-agent environments, demonstrating improved performance and interpretability compared to existing methods. Furthermore, we provide a theoretical analysis of HANs, showing that they can be understood as a form of hierarchical graph attention, and that they satisfy certain desirable properties for explainability.