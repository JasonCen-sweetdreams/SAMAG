Graph neural networks (GNNs) have shown great promise in various applications, but their vulnerability to adversarial attacks remains a major concern. This paper proposes a novel curriculum learning approach to generate targeted attacks on GNNs. Our method, 'Graft', iteratively perturbs the graph structure and node features, adapting to the model's robustness at each iteration. We demonstrate the effectiveness of Graft on several benchmark datasets, achieving state-of-the-art attack success rates while requiring minimal knowledge of the target model. We also explore the transferability of our attacks across different GNN architectures, highlighting the need for robustness-aware model design.