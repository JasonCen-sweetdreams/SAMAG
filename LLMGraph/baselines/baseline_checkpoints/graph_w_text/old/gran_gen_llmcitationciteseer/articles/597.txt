We propose a decentralized multi-agent reinforcement learning framework for autonomous traffic control, where each agent learns to optimize traffic signal control in a distributed manner. Our approach leverages graph neural networks to model the complex interactions between traffic signals and incorporates a novel asynchronous update mechanism to handle delayed and incomplete information. Experimental results on a real-world traffic dataset demonstrate that our approach outperforms traditional centralized methods in terms of reducing congestion and travel time.