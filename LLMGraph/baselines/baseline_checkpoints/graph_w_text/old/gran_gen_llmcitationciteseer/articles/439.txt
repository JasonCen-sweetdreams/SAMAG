Optimizing traffic signal control in real-time is a complex problem that requires coordinating multiple agents to minimize congestion and reduce travel times. We propose a novel multi-agent reinforcement learning framework, 'MARL-TSC', that leverages decentralized learning to adapt to changing traffic patterns. Our approach utilizes a hierarchical architecture, where local agents learn to optimize signal timings for individual intersections, while a central controller coordinates agent actions to optimize global traffic flow. Simulation results on a realistic traffic network demonstrate that MARL-TSC outperforms traditional traffic signal control methods, reducing average travel times by up to 23%.