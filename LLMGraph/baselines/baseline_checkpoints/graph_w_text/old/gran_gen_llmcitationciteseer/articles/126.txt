Deep reinforcement learning (DRL) has achieved impressive results in robotics, but the lack of transparency in decision-making hinders trust and utilization. This paper proposes a novel model-agnostic explainability framework, 'RL-Explain', which generates saliency maps and feature importance scores for DRL policies. Our approach leverages a combination of gradient-based attribution methods and causal graph analysis to identify key factors influencing the agent's behavior. Experimental results on a robotic arm manipulation task demonstrate that RL-Explain improves understanding of DRL decision-making without compromising performance.