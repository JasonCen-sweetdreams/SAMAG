Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but the lack of transparency and interpretability hinders its adoption in high-stakes applications. This paper presents a novel hierarchical attention network (HAN) architecture for explainable DRL. Our model incorporates attention modules at both the state and action levels, enabling the identification of critical state features and action components that contribute to the decision-making process. We evaluate our approach on several Atari games and demonstrate improved performance and interpretability compared to state-of-the-art DRL methods.