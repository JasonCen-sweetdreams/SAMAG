Motion planning for autonomous vehicles is a complex problem that requires efficient exploration of a high-dimensional action space. This paper presents a hierarchical reinforcement learning approach, 'HRL-MP', which decomposes the motion planning problem into a series of sub-tasks, each solved by a specialized deep Q-network. We introduce a novel curriculum learning strategy that adapts the difficulty of sub-tasks to the agent's learning progress, leading to faster convergence and improved planning performance. Experimental results on a simulated urban driving environment demonstrate the effectiveness of HRL-MP in navigating complex scenarios while avoiding collisions and respecting traffic rules.