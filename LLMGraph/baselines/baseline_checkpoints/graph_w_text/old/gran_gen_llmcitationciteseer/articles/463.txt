Deep neural ranking models have revolutionized the field of information retrieval, but their reliance on sparse query representations can lead to suboptimal retrieval performance. This paper proposes a novel query expansion framework, 'NeuroXPand', which leverages the semantic capabilities of pre-trained language models to generate context-aware expansion terms. We introduce a reinforcement learning-based approach to optimize the expansion process, allowing the model to adapt to diverse query types and document collections. Experimental results on several benchmark datasets demonstrate significant improvements in retrieval effectiveness and efficiency compared to state-of-the-art query expansion techniques.