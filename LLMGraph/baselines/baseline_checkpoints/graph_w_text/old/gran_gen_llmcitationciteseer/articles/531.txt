In multi-agent systems, understanding the decision-making process is crucial for trust and accountability. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable decision making in cooperative multi-agent environments. Our HAN model learns to selectively focus on relevant agents and their interactions, generating attention weights that provide insights into the decision-making process. We evaluate our approach on a variety of cooperative game scenarios, demonstrating improved performance and explainability compared to traditional reinforcement learning methods.