The increasing adoption of AI-powered diagnosis systems in healthcare has raised concerns about their interpretability and trustworthiness. This paper presents a novel hierarchical attention network (HAN) architecture for explainable AI-driven medical diagnosis. Our HAN model leverages multi-scale feature representations and attention mechanisms to identify salient regions in medical images and highlight relevant clinical features. Experimental results on a large dataset of chest X-rays demonstrate that our approach improves diagnosis accuracy by 12% compared to state-of-the-art models while providing visually interpretable explanations for the predicted diagnoses.