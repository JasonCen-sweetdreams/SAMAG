Multi-label classification tasks often involve imbalanced datasets, where some labels have a significantly larger number of instances than others. This paper proposes a novel hierarchical attention network (HAN) architecture that adaptively focuses on relevant labels and instances to improve classification performance. Our approach leverages a label-aware attention mechanism to weight the importance of different labels and a instance-aware attention mechanism to select informative instances. Experimental results on several benchmark datasets demonstrate that our HAN model outperforms state-of-the-art methods in terms of macro-averaged F1-score and label-wise accuracy.