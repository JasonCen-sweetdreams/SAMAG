Question answering (QA) over knowledge graphs (KGs) has garnered significant attention in recent years. However, most existing approaches suffer from high computational costs and poor performance on complex queries. This paper proposes a novel KG embedding method, 'HAtt-KGE', which leverages hierarchical attention mechanisms to selectively focus on relevant entities and relations. Our experiments on several benchmark datasets demonstrate that HAtt-KGE achieves state-of-the-art performance on QA tasks while reducing training time by an order of magnitude compared to existing methods.