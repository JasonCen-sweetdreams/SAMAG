Conversational AI systems are increasingly prevalent in various applications, from virtual assistants to customer service chatbots. However, the lack of transparency and accountability in these systems can lead to distrust among users. This study explores the effect of anthropomorphic design elements on user trust in conversational AI systems. We conducted a mixed-methods experiment involving 120 participants, which revealed that the presence of humanoid features, such as faces and gestures, can increase perceived trustworthiness but also lead to higher expectations of human-like intelligence. Our findings have implications for the design of conversational AI systems that aim to balance transparency, accountability, and user trust.