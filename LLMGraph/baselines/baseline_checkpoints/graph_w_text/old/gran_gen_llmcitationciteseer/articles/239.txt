Autonomous robots operating in complex environments require efficient task planning to achieve mission objectives. This paper presents a novel hierarchical task network planning framework that leverages deep reinforcement learning (DRL) to adapt to changing task requirements. Our approach, called HTN-DRL, integrates a high-level task network planner with a DRL-based subtask executor, enabling robots to dynamically adjust their behavior in response to unexpected events. Experimental results on a simulated robotic warehouse scenario demonstrate that HTN-DRL outperforms traditional planning methods in terms of task completion rate and adaptability to sudden changes.