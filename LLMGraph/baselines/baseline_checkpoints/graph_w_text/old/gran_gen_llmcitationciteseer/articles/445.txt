In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel reinforcement learning approach, 'DTRL', to allocate tasks in a distributed manner. DTRL utilizes a decentralized, asynchronous framework, where each agent learns to select tasks based on local observations and communication with neighboring agents. We demonstrate the effectiveness of DTRL in various environments, including search and rescue scenarios and packet routing in communication networks. Experimental results show that DTRL outperforms traditional, centralized allocation methods in terms of task completion rate and adaptability to dynamic environments.