Time-series forecasting is a crucial task in many applications, but traditional methods often lack transparency and interpretability. We propose a novel hierarchical attention network (HAN) architecture that learns to selectively focus on relevant temporal segments and features to improve forecasting accuracy. Our approach incorporates a self-attention mechanism to capture long-range dependencies and a feature attention module to identify important variables. We evaluate our model on several real-world datasets, demonstrating improved performance and providing visual explanations for the forecasting decisions.