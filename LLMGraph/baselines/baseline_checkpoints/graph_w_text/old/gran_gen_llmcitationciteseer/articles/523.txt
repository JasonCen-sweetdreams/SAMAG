Explainability is crucial in multi-agent reinforcement learning (MARL) as it enhances transparency and trust in decision-making. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that integrates attention mechanisms at both local and global levels to facilitate interpretable MARL policies. Our approach enables the identification of influential agents and their contributions to joint actions. Experimental results on a variety of MARL benchmarks demonstrate that HAN outperforms state-of-the-art methods in terms of both performance and explainability.