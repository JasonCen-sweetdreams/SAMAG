Explainable AI is crucial for real-world adoption of multi-agent reinforcement learning (MARL) systems. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates attention mechanisms at both the agent and team levels. Our approach enables learned attention weights to provide insights into agent decision-making and team coordination. We evaluate HAN on a range of MARL benchmarks, demonstrating improved performance and interpretability compared to state-of-the-art methods. Our results highlight the potential of HAN for explainable MARL in real-world applications such as autonomous driving and smart grids.