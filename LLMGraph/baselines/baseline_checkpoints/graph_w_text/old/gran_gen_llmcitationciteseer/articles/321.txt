Neural information retrieval (IR) models have demonstrated impressive performance in various search tasks. However, they often rely on elaborate query representation and sophisticated training procedures. This paper explores the potential of pseudo-relevance feedback (PRF) for query expansion in neural IR models. We propose a novel PRF-based approach that leverages the interaction between the query and the top-retrieved documents to generate more informative query representations. Experimental results on several benchmark datasets show that our approach significantly improves the retrieval performance of neural IR models, particularly in scenarios with limited training data.