Explainable AI is crucial in healthcare, where model interpretability can facilitate trust in diagnosis. This paper presents a novel Hierarchical Graph Attention Network (HGAT) framework for disease diagnosis, which leverages graph neural networks to capture complex relationships between symptoms, medical concepts, and patient data. We introduce a hierarchical attention mechanism that recursively aggregates node features, enabling the identification of key contributing factors to the predicted diagnosis. Experimental results on a large-scale electronic health record dataset demonstrate that HGAT outperforms state-of-the-art models in terms of both accuracy and explainability, providing actionable insights for clinicians.