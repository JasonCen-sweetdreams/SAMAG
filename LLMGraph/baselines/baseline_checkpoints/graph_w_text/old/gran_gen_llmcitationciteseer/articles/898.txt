Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables understanding of complex decision-making processes. However, existing methods often rely on simplistic attention mechanisms that fail to capture hierarchical relationships between agents. This paper introduces HAN-MARL, a novel hierarchical attention network that learns to focus on relevant agents, entities, and contexts in a hierarchical manner. Our approach improves explainability by providing interpretable attention weights and achieves state-of-the-art performance in several MARL benchmarks. We demonstrate the effectiveness of HAN-MARL in a real-world robotics scenario, showcasing its potential for real-world applications.