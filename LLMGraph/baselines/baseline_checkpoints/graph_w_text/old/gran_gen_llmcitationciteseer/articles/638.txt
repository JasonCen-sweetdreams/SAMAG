Time series forecasting is a crucial task in various domains, but traditional methods often lack interpretability. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable time series forecasting. HAN integrates local and global attention mechanisms to capture complex temporal dependencies and identify influential factors. We evaluate HAN on three real-world datasets and demonstrate its superiority over state-of-the-art methods in terms of forecasting accuracy and feature importance interpretability. Furthermore, we provide visualizations and case studies to illustrate the model's explainability.