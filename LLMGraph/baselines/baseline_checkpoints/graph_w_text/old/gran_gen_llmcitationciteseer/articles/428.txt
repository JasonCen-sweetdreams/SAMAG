Virtual reality (VR) has revolutionized immersive experiences, but users often struggle with navigation using traditional controllers. This paper presents EyeTracker, a novel gaze-based interface that enables hands-free navigation in VR. We develop a machine learning model that accurately predicts user intentions from eye movements, allowing users to navigate through virtual environments with unprecedented ease and precision. Our user study demonstrates significant improvements in navigation speed and accuracy, as well as reduced user fatigue and cognitive load, compared to traditional controller-based methods.