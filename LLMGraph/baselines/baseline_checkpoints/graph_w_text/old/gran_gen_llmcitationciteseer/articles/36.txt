Decision-making in multi-agent systems often relies on complex interactions, making it challenging to interpret the decisions made. This paper proposes a hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent systems. Our approach learns to attend to relevant agent interactions and perceptions, generating saliency maps that highlight the key factors influencing the decision. We evaluate our method on a real-world autonomous driving scenario, demonstrating improved decision-making performance and interpretability compared to existing attention-based methods.