Traditional document representation techniques in Information Retrieval (IR) often fail to capture the hierarchical structure of documents, leading to suboptimal retrieval performance. This paper proposes a novel Hierarchical Attention-based Neural Network (HAN) architecture for learning document representations. Our approach leverages attention mechanisms to selectively focus on salient sentences and words within a document, enabling the model to capture both local and global contextual information. Experimental results on several benchmark datasets demonstrate that our HAN-based model outperforms state-of-the-art methods in terms of retrieval accuracy and efficiency.