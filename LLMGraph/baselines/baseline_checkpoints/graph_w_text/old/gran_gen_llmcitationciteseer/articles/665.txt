Explainability is a crucial aspect of multi-agent decision-making, where agents need to justify their actions to humans. This paper introduces HAN-MAD, a hierarchical attention network that generates interpretable explanations for agent decisions. Our approach leverages a novel graph attention mechanism to model agent interactions and a hierarchical explanation framework to provide both local and global insights into agent decision-making processes. Experimental results on a real-world autonomous vehicle dataset demonstrate the effectiveness of HAN-MAD in improving explanation quality and facilitating human-agent collaboration.