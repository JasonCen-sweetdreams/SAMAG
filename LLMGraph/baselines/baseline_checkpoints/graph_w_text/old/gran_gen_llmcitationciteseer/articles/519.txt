Virtual reality (VR) systems have become increasingly popular, but gesture recognition remains a significant bottleneck. This paper presents an adaptive gesture recognition system that leverages machine learning and sensor fusion to improve accuracy and user experience. Our system integrates data from various sensors, including hand tracking, inertial measurement units, and electromyography. We propose a novel transfer learning approach that adapts to individual user preferences and habits, enabling personalized gesture recognition. Experimental results demonstrate significant improvements in recognition accuracy and user satisfaction compared to state-of-the-art systems.