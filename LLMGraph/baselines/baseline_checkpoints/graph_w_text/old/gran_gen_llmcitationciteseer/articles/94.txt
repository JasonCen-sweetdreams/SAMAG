Distributed relational databases have become increasingly popular for large-scale data storage and querying. However, optimizing queries in these systems remains a challenging problem. This paper proposes a novel machine learning-based approach to query optimization, which leverages graph neural networks to model the query execution plan space. We develop a reinforcement learning framework that learns to optimize queries by interacting with the database and minimizing execution time. Experimental results on a real-world dataset demonstrate that our approach outperforms traditional query optimization techniques by up to 30% in terms of execution time.