Visual question answering (VQA) models often struggle to provide interpretable explanations for their answers. This paper proposes a novel hierarchical attention mechanism that enables explainable VQA by modeling the relationships between visual regions, question tokens, and answer choices. Our approach, 'HARE', incorporates a hierarchical graph neural network to capture complex contextual dependencies and a soft attention mechanism to selectively focus on relevant visual regions. Experimental results on the VQA-X benchmark demonstrate that HARE achieves state-of-the-art performance while providing visual explanations that align with human intuition.