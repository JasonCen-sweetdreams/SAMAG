Distributed graph databases have become increasingly popular for storing and querying large-scale graph data. However, query optimization in these systems remains a challenging task due to the complex interplay between data distribution, network topology, and query patterns. This paper proposes a novel approach to query optimization using reinforcement learning, where the query optimizer learns to adapt to changing system conditions and query workloads. We design a reward function that balances query latency and resource utilization, and demonstrate significant performance improvements over traditional rule-based optimizers in a real-world graph database setup.