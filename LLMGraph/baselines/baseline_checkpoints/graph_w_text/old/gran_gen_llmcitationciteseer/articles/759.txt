Cooperative task allocation in multi-agent systems is a challenging problem that requires efficient coordination and decision-making. This paper presents a decentralized multi-agent reinforcement learning framework, 'MARL-CTA', that enables agents to learn cooperative behaviors and allocate tasks in a distributed manner. We propose a novel communication protocol that allows agents to share local observations and learned policies, while maintaining privacy and robustness to agent failures. Experimental results on a simulated disaster response scenario demonstrate that MARL-CTA outperforms traditional centralized approaches in terms of task completion rate and overall system efficiency.