Explainability is crucial in multi-agent reinforcement learning (MARL) to ensure trust and accountability in complex decision-making systems. This paper introduces Hierarchical Attention Networks (HANs), a novel architecture that integrates attention mechanisms at both local and global levels to provide interpretable policies. HANs enable agents to selectively focus on relevant teammates, opponents, and environmental features, thereby improving cooperation and competition in MARL scenarios. We evaluate HANs on several MARL benchmarks, demonstrating significant improvements in explainability and policy performance compared to state-of-the-art methods.