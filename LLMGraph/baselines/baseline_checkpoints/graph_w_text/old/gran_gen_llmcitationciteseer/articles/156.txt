This paper proposes a decentralized multi-agent reinforcement learning framework for autonomous traffic signal control. We model each traffic signal as an autonomous agent that interacts with its neighboring agents to optimize traffic flow. Our approach, called MARL-TSC, uses a novel reward function that incorporates real-time traffic metrics, such as queue length and delay, to learn adaptive signal control policies. Simulation results on a realistic traffic network demonstrate that MARL-TSC outperforms traditional fixed-time and adaptive signal control methods, reducing average delay by 23.4% and increasing network throughput by 15.6%.