Explainable recommendation systems (ERS) are crucial for building trust in AI-driven decision-making. We propose Hierarchical Graph Attention Networks (HiGAT), a novel framework that leverages graph neural networks and attention mechanisms to provide personalized explanations for recommendation outcomes. HiGAT models user-item interactions as a hierarchical graph, where attention weights are learned to highlight influential nodes and edges. We demonstrate HiGAT's effectiveness on three real-world datasets, showcasing improved recommendation accuracy and transparent explanations that enhance user understanding.