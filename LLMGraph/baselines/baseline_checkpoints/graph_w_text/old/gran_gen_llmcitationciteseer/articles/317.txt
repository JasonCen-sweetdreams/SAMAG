This paper proposes a decentralized multi-agent deep reinforcement learning (MADRL) framework for coordinating autonomous vehicles in complex urban scenarios. Our approach, dubbed 'Vehicle Coalition', utilizes a novel graph neural network architecture to learn effective communication strategies among agents, enabling them to cooperatively optimize traffic flow and reduce congestion. We evaluate Vehicle Coalition on a realistic simulation platform, demonstrating significant improvements in travel time, fuel efficiency, and safety compared to traditional rule-based approaches.