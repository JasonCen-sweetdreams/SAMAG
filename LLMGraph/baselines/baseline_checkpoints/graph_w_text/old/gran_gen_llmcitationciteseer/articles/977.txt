Explainability is a crucial aspect of multi-agent reinforcement learning (MARL) systems, as they are increasingly being deployed in real-world applications. This paper presents a novel hierarchical attention network (HAN) architecture that enables explainable MARL. Our approach integrates attention mechanisms at both the intra-agent and inter-agent levels, allowing for interpretable policy decisions. We evaluate our method on several cooperative MARL benchmarks and demonstrate improved performance and explainability compared to state-of-the-art methods. The proposed HAN framework has significant implications for real-world applications such as autonomous vehicles and smart grids.