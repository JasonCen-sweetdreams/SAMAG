Coordinating the actions of multiple agents in complex environments is a challenging problem in reinforcement learning. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that learns to represent agent interactions and coordination strategies. Our approach leverages a hierarchical graph structure to model agent relationships at multiple scales, and incorporates attention mechanisms to focus on relevant interactions. We evaluate HGAT on a range of multi-agent environments, demonstrating improved performance and scalability compared to existing methods.