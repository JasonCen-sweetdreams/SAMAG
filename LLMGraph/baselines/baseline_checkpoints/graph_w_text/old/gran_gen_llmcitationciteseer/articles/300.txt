Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks. However, the lack of transparency in DRL models hinders their adoption in high-stakes applications. This paper proposes a novel hierarchical attention mechanism, 'HiAttn', to provide efficient explainability in DRL. HiAttn selectively focuses on salient regions of the input state and action spaces, generating interpretable explanations for the agent's decisions. We evaluate HiAttn on a range of Atari games and a real-world autonomous driving scenario, demonstrating improved explanation quality and reduced computational overhead compared to existing methods.