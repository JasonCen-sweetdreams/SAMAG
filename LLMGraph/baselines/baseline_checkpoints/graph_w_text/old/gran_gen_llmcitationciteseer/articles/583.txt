In dynamic environments, task allocation among agents is a challenging problem. This paper proposes a novel multi-agent reinforcement learning framework, 'DynaMAL', which enables agents to learn distributed task allocation strategies. DynaMAL integrates graph neural networks with deep Q-networks to model complex environment dynamics and agent interactions. We evaluate DynaMAL on a variety of scenarios, including a simulated warehouse management system, and demonstrate improved task allocation efficiency and adaptability compared to traditional optimization-based approaches.