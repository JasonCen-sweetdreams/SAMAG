Explainability is a crucial aspect of multi-agent reinforcement learning (MARL) systems, as they are increasingly applied to real-world scenarios. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in MARL. Our approach integrates attention mechanisms at both the agent and team levels, allowing for the identification of relevant features and agents contributing to joint actions. Experimental results on a range of cooperative and competitive MARL benchmarks demonstrate the effectiveness of HAN in improving task performance and providing interpretable insights into agent decision-making processes.