Explainability is crucial in multi-agent systems, where decision-making processes involve complex interactions and dependencies. This paper presents a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent scenarios. Our approach leverages attention mechanisms to model agent interactions and aggregate local decision-making processes. We evaluate our method on a real-world autonomous vehicle dataset and demonstrate improved explainability and decision quality compared to state-of-the-art baselines. The proposed HAN framework has significant implications for designing trustworthy and transparent multi-agent systems.