Knowledge graph embedding (KGE) is a crucial task in AI, but existing methods struggle with scalability and expressive power. We propose a novel hierarchical graph attention framework, HGA-KGE, which leverages a hierarchical structure to model complex relationships between entities. HGA-KGE adaptively assigns attention weights to different aspects of the graph, enabling more accurate and efficient representation of entities. Experimental results on benchmark datasets demonstrate that HGA-KGE outperforms state-of-the-art methods in terms of link prediction and entity classification while reducing computational cost.