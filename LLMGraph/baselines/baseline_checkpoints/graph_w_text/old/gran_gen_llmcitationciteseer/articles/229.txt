Intelligent traffic management is crucial for mitigating urban congestion. This paper presents a novel multi-agent reinforcement learning (MARL) framework for adaptive traffic signal control. We model traffic intersections as a decentralized partially observable Markov decision process (Dec-POMDP) and propose a hierarchical learning architecture that combines graph attention networks with deep Q-networks. Our approach enables agents to learn cooperative policies that adapt to dynamic traffic conditions, reducing congestion and travel times. Experimental results on a realistic traffic simulator demonstrate the effectiveness of our approach compared to traditional optimization methods and single-agent RL baselines.