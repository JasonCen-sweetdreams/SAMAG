Distributed relational databases have become increasingly popular for large-scale data management. However, query optimization remains a significant challenge due to the complexity of data distribution and network latency. This paper proposes a novel approach, 'RL-QO', that leverages reinforcement learning to optimize query execution plans in distributed databases. We design a reward function that balances query latency and resource utilization, and employ a deep Q-network to learn optimal query plans. Experimental results on a real-world dataset demonstrate that RL-QO outperforms traditional query optimizers by up to 30% in terms of query latency and 25% in terms of resource usage.