Task allocation is a critical problem in distributed systems, where efficient allocation can significantly impact system performance. This paper proposes a hierarchical reinforcement learning (HRL) framework, 'HierTask', that learns to allocate tasks in a distributed system. HierTask consists of a high-level task allocator and low-level resource managers, which jointly optimize task allocation and resource utilization. We introduce a novel hierarchical exploration strategy that balances exploration-exploitation trade-offs across multiple levels of abstraction. Our experiments on a simulated distributed system show that HierTask outperforms state-of-the-art task allocation methods in terms of system throughput, resource utilization, and adaptability to changing workloads.