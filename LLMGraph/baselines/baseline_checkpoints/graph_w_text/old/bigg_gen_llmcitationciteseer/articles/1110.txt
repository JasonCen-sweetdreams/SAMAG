This paper presents a decentralized multi-agent reinforcement learning framework for real-time urban traffic signal control. We model each traffic signal as an autonomous agent, which learns to optimize its signal timing policy based on local observations and communication with neighboring agents. Our approach leverages graph attention networks to handle the complex spatial and temporal dependencies between agents. Experimental results on a large-scale simulation of Pittsburgh's traffic network demonstrate that our method reduces average travel time by 23% and increases network throughput by 17% compared to traditional centralized control methods.