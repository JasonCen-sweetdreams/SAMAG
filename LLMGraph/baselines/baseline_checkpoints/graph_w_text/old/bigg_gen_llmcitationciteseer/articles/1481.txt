Multi-agent systems are increasingly used in various applications, including autonomous vehicles, smart grids, and robotic teams. Task scheduling is a critical problem in such systems, as it directly affects the overall performance and efficiency. This paper proposes a novel deep reinforcement learning (DRL) approach to task scheduling, which leverages the strengths of both model-free and model-based RL methods. Our approach, called 'DRL-Sched', uses a deep neural network to learn the scheduling policy and a model-based component to optimize the policy. We evaluate DRL-Sched on a simulated multi-agent system and demonstrate its effectiveness in reducing task completion time and improving system throughput compared to traditional scheduling algorithms.