Virtual reality (VR) systems have become increasingly popular, but existing interaction methods are often cumbersome and limited. This paper explores the potential of gaze-based interaction in VR, focusing on the analysis of eye movement patterns. We collected eye-tracking data from 30 participants performing various tasks in a VR environment and developed a machine learning model to predict user intent from gaze behavior. Our results show that the proposed approach achieves high accuracy (>90%) in intent recognition, enabling seamless interaction with virtual objects. The findings have implications for the design of more intuitive and immersive VR experiences.