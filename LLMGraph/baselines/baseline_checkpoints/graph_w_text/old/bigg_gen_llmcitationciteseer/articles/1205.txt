Explainable AI (XAI) has gained significant attention in healthcare, where model interpretability is crucial for trust and decision-making. However, existing XAI methods often incur significant computational overhead, limiting their adoption in real-world applications. This paper proposes a novel hierarchical attention network (HAN) for efficient XAI in healthcare. Our approach leverages a multi-scale attention mechanism to identify relevant features and their contributions to the model's predictions. We evaluate our HAN on several medical imaging datasets and demonstrate significant improvements in both model interpretability and computational efficiency compared to state-of-the-art XAI methods.