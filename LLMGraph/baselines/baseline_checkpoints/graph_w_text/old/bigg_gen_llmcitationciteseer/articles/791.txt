Wheelchair users often struggle with navigation due to limited motor abilities. This paper presents a novel gaze-based intention recognition system, 'GazeNav', which enables intelligent wheelchair navigation. Our approach leverages a deep neural network to predict user intentions from gaze patterns, detected using a wearable eye-tracking device. Experimental results with 15 participants show that GazeNav achieves an accuracy of 92.5% in recognizing user intentions, significantly outperforming traditional joystick-based interfaces. We discuss the implications of our work for improving the quality of life for individuals with mobility impairments.