Time-series forecasting models often lack transparency, making it challenging to understand their predictions. This paper proposes a hierarchical attention network (HAN) architecture that incorporates attention mechanisms at multiple scales to provide interpretable forecasts. Our approach leverages factorized attention to selectively focus on relevant time-series segments and features, enabling the model to adapt to complex patterns and trends. Experimental results on several benchmark datasets demonstrate that HAN outperforms state-of-the-art models while offering improved explainability through attention visualization.