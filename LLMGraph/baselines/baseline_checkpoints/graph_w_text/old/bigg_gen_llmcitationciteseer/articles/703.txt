Multi-agent reinforcement learning (MARL) has shown promise in various applications, but the lack of explainability hinders its adoption in real-world scenarios. This paper introduces a novel hierarchical attention network (HAN) architecture that enables explainable MARL. Our approach combines a graph attention mechanism to model agent interactions with a hierarchical decomposition of the state space, allowing for interpretable policy representations. We demonstrate the effectiveness of HAN in a variety of MARL benchmarks, showcasing improved performance and enhanced explainability compared to existing methods.