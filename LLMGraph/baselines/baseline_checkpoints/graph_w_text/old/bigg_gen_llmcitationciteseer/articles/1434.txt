This paper presents a novel approach to task allocation in multi-agent systems using deep reinforcement learning. We propose a decentralized framework, 'DRL-TA', where each agent learns to allocate tasks based on its local observations and interactions with neighboring agents. Our method employs a graph neural network to model the agent interactions and a deep Q-network to learn the optimal task allocation policy. We evaluate DRL-TA in a simulated warehouse environment and demonstrate its effectiveness in improving task completion efficiency and reducing communication overhead compared to traditional centralized approaches.