Object detection is a fundamental task in computer vision, but existing approaches often rely on manual architecture design and require significant computational resources. This paper proposes a novel neural architecture search (NAS) framework that leverages attention mechanisms to efficiently search for optimal object detection architectures. Our approach, dubbed 'AttentionNAS', utilizes a hierarchical attention module to adaptively weight the importance of different neural building blocks during the search process. Experimental results on the COCO dataset demonstrate that AttentionNAS achieves state-of-the-art object detection performance while reducing search time by 3.5x compared to existing NAS methods.