In this paper, we tackle the problem of decentralized task allocation in heterogeneous multi-agent systems, where agents have varying capabilities and tasks require different skills. We propose a novel approach based on multi-agent reinforcement learning, which enables agents to learn to allocate tasks effectively without explicit communication. Our method, called HRL-TA, uses a hierarchical reinforcement learning framework to learn both task allocation policies and skill-based agent models. We evaluate HRL-TA in a simulated warehouse scenario, demonstrating significant improvements in task completion efficiency and adaptability to agent failures compared to traditional optimization-based approaches.