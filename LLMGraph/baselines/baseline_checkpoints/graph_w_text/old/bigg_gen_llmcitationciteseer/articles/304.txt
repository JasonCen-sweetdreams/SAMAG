Graph convolutional networks (GCNs) have shown remarkable success in graph-structured data analysis. However, their robustness to adversarial attacks remains a significant concern. This paper introduces Bayesian neural symbolic learning (BNSL) to enhance the adversarial robustness of GCNs. We propose a novel framework, 'Robust-GCN', which integrates BNSL with GCNs to learn robust graph representations. Our approach leverages the symbolic reasoning capabilities of BNSL to detect and correct adversarial perturbations on graphs. Experimental results on benchmark datasets demonstrate that Robust-GCN outperforms state-of-the-art defense methods in terms of both accuracy and robustness under various attack scenarios.