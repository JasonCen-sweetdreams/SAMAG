In multi-agent systems, task allocation is a challenging problem that requires efficient and adaptive decision-making. This paper proposes a decentralized task allocation framework that leverages deep reinforcement learning (DRL) to optimize task assignments in dynamic environments. Our approach, called 'DTRL', uses a distributed DRL architecture to enable agents to learn from their local interactions and adapt to changing task requirements. We evaluate DTRL in a simulated disaster response scenario and demonstrate improved task completion rates and reduced communication overhead compared to traditional centralized allocation methods.