In multi-agent systems, decision-making often relies on complex interactions between agents. To improve transparency and trust, we propose a novel hierarchical attention network (HAN) architecture that learns to selectively focus on relevant agent interactions and generate interpretable explanations for collective decisions. Our HAN model combines graph attention mechanisms with a hierarchical encoder-decoder framework, enabling it to capture both local and global dependencies between agents. We evaluate our approach on a realistic multi-agent scenario, demonstrating significant improvements in decision-making performance and explainability compared to state-of-the-art baselines.