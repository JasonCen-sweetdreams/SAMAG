Task allocation is a crucial problem in multi-agent systems, where agents need to coordinate to accomplish complex tasks. This paper proposes a novel deep reinforcement learning framework, 'Coop-TARL', which enables agents to learn cooperative task allocation strategies. We model the task allocation problem as a decentralized partially observable Markov decision process and employ a graph neural network to represent agent interactions. Experimental results on a variety of task allocation scenarios demonstrate that Coop-TARL outperforms existing methods in terms of task completion rate, agent utilization, and adaptability to changing environments.