Hand pose estimation is a crucial step in gesture recognition systems, but existing methods often struggle with variability in hand shapes, orientations, and occlusions. This paper presents a novel approach, 'HandPoseNet', which leverages deep learning to estimate 3D hand poses from RGB images. We propose a multi-task learning framework that jointly optimizes hand pose estimation, finger detection, and gesture recognition. Experimental results on a large-scale gesture dataset demonstrate that HandPoseNet outperforms state-of-the-art methods in terms of accuracy, robustness, and real-time performance, paving the way for more sophisticated human-computer interaction applications.