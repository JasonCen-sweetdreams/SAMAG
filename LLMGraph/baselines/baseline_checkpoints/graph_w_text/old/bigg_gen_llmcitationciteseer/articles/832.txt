Real-world traffic control systems face the challenge of dynamic and unpredictable environments, necessitating the development of adaptive and scalable solutions. This paper proposes a novel multi-agent reinforcement learning (MARL) framework, 'TrafficMA', which leverages decentralized deep Q-networks (DDQN) to optimize traffic signal control. We introduce a hierarchical communication mechanism that enables agents to share local knowledge and adapt to changing traffic patterns. Experimental results using real-world traffic datasets demonstrate that TrafficMA outperforms traditional fixed-time and adaptive signal control methods in reducing congestion and travel times.