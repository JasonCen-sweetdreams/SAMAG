Cooperative agents in complex environments often require efficient task allocation mechanisms to achieve shared goals. This paper proposes a decentralized task allocation framework using multi-agent deep reinforcement learning (MARL). Our approach, called 'CoopTA', leverages graph neural networks to model agent interactions and learn cooperative policies. We evaluate CoopTA in a simulation environment with varying numbers of agents and tasks, demonstrating improved task allocation efficiency and adaptability compared to traditional centralized allocation methods. The results have implications for real-world applications such as search and rescue, environmental monitoring, and resource allocation.