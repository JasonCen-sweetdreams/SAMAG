Recent advancements in deep reinforcement learning (DRL) have led to widespread adoption in real-world applications. However, DRL models are vulnerable to adversarial attacks, which can have catastrophic consequences. This paper proposes a novel approach to detect adversarial attacks in DRL using explainable AI (XAI) techniques. We develop a framework that leverages saliency maps to identify suspicious patterns in the input data, and demonstrate its effectiveness in detecting attacks on a range of DRL benchmarks. Our approach not only improves the robustness of DRL models but also provides insights into the attack mechanisms, enabling more effective defense strategies.