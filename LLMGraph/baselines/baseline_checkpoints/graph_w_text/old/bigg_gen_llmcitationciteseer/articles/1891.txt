Cloud computing has become a ubiquitous paradigm for on-demand resource provisioning, but efficient resource allocation remains a significant challenge. This paper proposes a novel deep reinforcement learning (DRL) framework, 'CloudAllocator', which leverages a hierarchical actor-critic architecture to optimize resource allocation in cloud data centers. Our approach integrates a graph neural network to model complex dependencies between virtual machines and physical resources, thereby improving allocation efficiency and reducing energy consumption. Experimental results on a real-world cloud dataset demonstrate that CloudAllocator outperforms traditional rule-based allocation methods and achieves significant cost savings.