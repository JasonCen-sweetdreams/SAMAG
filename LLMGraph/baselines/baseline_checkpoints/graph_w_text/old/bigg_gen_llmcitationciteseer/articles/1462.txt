Autonomous vehicles rely on complex reinforcement learning (RL) models to make decisions in uncertain environments. However, the lack of transparency in these models hinders trust and accountability. We propose XRL, an explainable RL framework that generates visual and textual explanations for autonomous vehicle decision-making. XRL integrates a novel attention-based mechanism that highlights salient input features and a model-agnostic explanation methodology that provides insights into the decision-making process. Experimental results on a simulated driving dataset demonstrate that XRL improves model interpretability without compromising performance.