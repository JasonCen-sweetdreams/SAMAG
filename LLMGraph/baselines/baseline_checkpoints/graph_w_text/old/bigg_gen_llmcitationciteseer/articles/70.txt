This paper presents a novel approach to inferring emotional states from gaze patterns using deep learning. Our proposed model, 'EmoGaze', leverages a convolutional neural network (CNN) to analyze eye-tracking data and predict emotional states such as happiness, sadness, and frustration. We collected a large dataset of gaze patterns from users interacting with a virtual assistant and demonstrate that EmoGaze outperforms state-of-the-art methods in emotional state inference. The results have implications for enhancing human-computer interaction through affective computing and personalized user experiences.