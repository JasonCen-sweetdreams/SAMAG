This paper proposes a decentralized multi-agent reinforcement learning (MARL) framework for coordinating autonomous vehicles in complex urban scenarios. Our approach, called 'Coordinated MotionPlanning' (CMP), leverages graph neural networks to model vehicle interactions and learns effective communication strategies between agents. We evaluate CMP on a realistic simulation platform and demonstrate significant improvements in traffic flow, reduced congestion, and increased safety compared to traditional rule-based control methods. The proposed framework has the potential to revolutionize the field of autonomous transportation by enabling scalable, real-time coordination of autonomous vehicles.