In multi-agent systems, efficient task allocation is crucial for achieving global objectives. However, existing approaches often rely on centralized controllers or simplistic heuristics, which may fail in large-scale, dynamic environments. This paper proposes a decentralized task allocation framework, TAGNN, that leverages graph neural networks (GNNs) to learn task assignment policies. Each agent maintains a local GNN that predicts task suitability based on its own capabilities and interactions with neighboring agents. Experimental results on a simulated disaster response scenario demonstrate that TAGNN outperforms state-of-the-art methods in terms of task completion rate and adaptation to changing environments.