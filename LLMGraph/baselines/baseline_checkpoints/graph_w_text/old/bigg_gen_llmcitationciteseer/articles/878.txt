Cooperative task allocation is a challenging problem in multi-agent systems, where agents must coordinate to achieve a common goal. We propose a decentralized multi-agent reinforcement learning framework, 'MA-RL-CTA', that enables agents to learn cooperative policies without explicit communication. We introduce a novel reward function that incorporates both individual and team-based objectives, and a decentralized critic-actor architecture that facilitates policy learning. Experimental results on a simulated robotic search and rescue scenario demonstrate that MA-RL-CTA outperforms existing methods in terms of task completion time and success rate.