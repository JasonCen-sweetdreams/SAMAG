Voice assistants have become ubiquitous in modern life, but people with dysarthria, a speech disorder characterized by impaired articulation, face significant barriers in interacting with these systems. This paper presents a novel approach to designing inclusive voice assistants that accommodate the unique needs of individuals with dysarthria. We propose a multi-modal input framework that integrates speech, gesture, and gaze inputs to enable more accurate and efficient communication. A user study with 20 participants with dysarthria demonstrates that our approach improves task completion rates by 35% and reduces user frustration by 40% compared to commercial voice assistants.