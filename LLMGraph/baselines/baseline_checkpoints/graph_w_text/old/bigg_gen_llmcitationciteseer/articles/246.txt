Explainable recommendation systems (ERS) have gained significant attention in recent years due to the increasing need for transparency in AI-driven decision-making. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that incorporates both user and item embeddings to provide personalized explanations for recommended items. Our approach leverages multi-hop graph attention mechanisms to capture complex relationships between users, items, and their attributes, resulting in improved recommendation accuracy and explanation quality. Experimental results on two real-world datasets demonstrate the effectiveness of HGAT in providing interpretable and diverse recommendations.