Decentralized task allocation in multi-agent systems is a challenging problem, as agents must coordinate to achieve global objectives without a central authority. This paper proposes a novel decentralized task allocation algorithm, 'RL-TA', which leverages reinforcement learning to learn coordination strategies. RL-TA uses a decentralized actor-critic framework, where each agent learns to allocate tasks based on local observations and rewards. We evaluate RL-TA in a simulated logistics scenario, demonstrating improved task completion rates and reduced communication overhead compared to existing decentralized allocation methods.