Cloud computing platforms face the challenge of efficiently allocating resources to meet dynamic workload demands. This paper presents a deep reinforcement learning (DRL) approach to optimize resource allocation in cloud data centers. We design a novel DRL algorithm, 'CloudOptimizer', which leverages a hybrid state representation combining queueing theory and resource utilization metrics. Our experiments on a real-world cloud workload dataset demonstrate that CloudOptimizer achieves significant reductions in resource waste and response times compared to traditional heuristics, while adapting to changing workload patterns.