Time series forecasting models often lack interpretability, making it challenging to understand their predictions. This paper proposes a novel Hierarchical Attention Network (HAN) architecture for explainable time series forecasting. HAN incorporates both local and global attention mechanisms to selectively focus on relevant input features and time steps. We evaluate HAN on several benchmark datasets and demonstrate its superiority over state-of-the-art models in terms of accuracy and interpretability. Furthermore, we provide visualizations of the attention weights to illustrate the model's decision-making process.