Deep neural networks have been shown to be vulnerable to adversarial attacks, which can result in misclassification of inputs with imperceptible perturbations. This paper proposes a novel approach to improve the robustness of neural networks against such attacks by adaptively encoding input data. Our method, called 'Adaptive Encoding for Robustness' (AER), learns to encode inputs in a way that reduces the susceptibility of the network to adversarial attacks. We demonstrate the effectiveness of AER on several benchmark datasets, achieving state-of-the-art results in terms of robustness against a range of attack types.