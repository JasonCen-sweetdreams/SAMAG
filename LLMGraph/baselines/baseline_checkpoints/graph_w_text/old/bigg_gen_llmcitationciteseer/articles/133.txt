Multi-agent reinforcement learning (MARL) has shown significant promise in various domains, but the lack of transparency in decision-making processes hinders its adoption. We propose a hierarchical attention network (HAN) framework that learns to disentangle and explain the contributions of individual agents in cooperative MARL settings. Our method leverages attention mechanisms to selectively focus on relevant agents and their interactions, enabling the identification of key decision-making factors. Experimental results on a range of MARL benchmarks demonstrate the effectiveness of HAN in improving cooperation and transparency, while reducing the complexity of learned policies.