This paper presents a novel approach to coordinated task allocation in multi-agent systems using deep reinforcement learning. We propose a decentralized framework, 'CATS', where agents learn to allocate tasks based on their individual capabilities, availability, and task requirements. Our method utilizes a hierarchical architecture, combining a high-level coordination mechanism with low-level task allocation policies. Experimental results on a simulated warehouse scenario demonstrate that CATS outperforms traditional optimization-based approaches in terms of task completion time, agent utilization, and adaptability to changing environment conditions.