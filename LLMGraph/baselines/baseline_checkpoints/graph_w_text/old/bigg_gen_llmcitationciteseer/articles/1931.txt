Query expansion (QE) is a crucial component in ad-hoc retrieval, aiming to improve the retrieval effectiveness by reformulating the original query. However, the optimal QE strategy is often dataset-dependent and requires careful tuning. This paper proposes a novel reinforcement learning (RL) framework, 'RL-QE', which learns to select the most effective QE technique and parameters for a given dataset. We model the QE process as a Markov decision process and employ a deep Q-network to learn the optimal policy. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms state-of-the-art QE methods in terms of retrieval effectiveness and efficiency.