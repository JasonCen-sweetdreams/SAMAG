Voice assistants have become ubiquitous, but their usability is often limited for users with disabilities. This paper presents an adaptive dialogue management system that tailors the interaction to individual users' needs. Our approach combines machine learning-based user modeling with a knowledge graph of assistive technologies. We conducted a user study with 30 participants with diverse disabilities, demonstrating significant improvements in task completion rates and user satisfaction. The proposed system can be integrated into existing voice assistants, enhancing their accessibility and promoting inclusive design.