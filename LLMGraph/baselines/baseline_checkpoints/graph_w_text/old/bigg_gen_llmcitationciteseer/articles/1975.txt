Deep neural networks have achieved state-of-the-art performance in emotion recognition tasks, but their opacity hinders trust and understanding. This paper proposes a novel guided attention mechanism, 'EmoAtt', that provides interpretability and explainability in neural network-based emotion recognition models. EmoAtt exploits the correlation between facial action units and emotional states to focus attention on relevant facial regions, leading to improved recognition accuracy and model transparency. We evaluate EmoAtt on the FER2013 dataset and demonstrate its effectiveness in recognizing emotions from facial expressions, while providing visual explanations for the recognition process.