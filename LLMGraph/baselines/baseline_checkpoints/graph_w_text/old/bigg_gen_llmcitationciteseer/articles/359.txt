Explainable recommendation systems are crucial for building trust with users. We propose a novel hierarchical attentional graph neural network (HAGNN) that learns to identify influential users and items in a graph-structured recommendation dataset. HAGNN incorporates multi-hop attention mechanisms to capture complex relationships between users and items, and outputs interpretable explanations for top-N recommended items. Experimental results on three real-world datasets demonstrate that HAGNN outperforms state-of-the-art models in terms of recommendation accuracy and explanation quality, while providing insights into user behavior and item relationships.