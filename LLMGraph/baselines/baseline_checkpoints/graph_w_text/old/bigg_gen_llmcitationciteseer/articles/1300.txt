In multi-agent systems, decision-making often relies on complex interactions between agents. While deep learning models have shown promise in this domain, their lack of transparency hinders trust and understanding. We propose a novel hierarchical attention network (HAN) architecture that not only improves decision-making performance but also provides explainable insights into agent interactions. Our HAN model incorporates attention mechanisms at multiple levels, enabling the identification of influential agents and their contributions to the decision-making process. Experimental results on a real-world robotic soccer dataset demonstrate the effectiveness of our approach, achieving a 15% improvement in decision accuracy while providing interpretable explanations.