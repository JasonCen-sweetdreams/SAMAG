Deep learning models are vulnerable to adversarial attacks, which can manipulate the model's predictions. Existing detection methods are typically based on handcrafted features or shallow learning models. This paper proposes a novel approach using Graph Convolutional Networks (GCNs) to detect adversarial attacks. We model the input data as a graph and leverage GCNs to capture complex patterns and relationships between features. Our approach outperforms state-of-the-art methods on several benchmark datasets, achieving an F1-score of 0.95 on the CIFAR-10 dataset. Furthermore, we demonstrate the effectiveness of our method in detecting attacks on real-world medical images.