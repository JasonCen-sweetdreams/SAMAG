This paper presents a novel decentralized task allocation framework for multi-agent systems, leveraging reinforcement learning to optimize task assignments. Our approach, dubbed 'RL-TA', enables agents to learn from their interactions and adapt to dynamic environment changes. We propose a decentralized Q-learning algorithm, which allows agents to update their policies independently while sharing limited information. Experimental results on a simulated robotic scenario demonstrate that RL-TA outperforms traditional auction-based methods in terms of task completion efficiency and robustness to agent failures.