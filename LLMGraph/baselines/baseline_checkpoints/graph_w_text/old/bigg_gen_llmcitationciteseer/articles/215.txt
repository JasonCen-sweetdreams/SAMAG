Individuals with motor impairments face significant challenges when interacting with computing systems. This paper presents EyeGazeType, a novel text entry system that leverages gaze-based gesture recognition to improve typing accuracy and efficiency. Our approach utilizes a convolutional neural network (CNN) to classify gaze patterns and recognize gestures, which are then mapped to corresponding keyboard inputs. We evaluate EyeGazeType with 20 participants with motor impairments and demonstrate a significant reduction in error rate (35.4%) and increase in typing speed (23.1%) compared to traditional gaze-based typing systems.