In multi-agent systems, task allocation is a challenging problem due to the complexity of interacting agents and dynamic environments. This paper presents a novel approach to cooperative task allocation using deep reinforcement learning. We propose a decentralized framework, 'Coop-TA', where agents learn to allocate tasks by interacting with each other and the environment. Our approach utilizes a hierarchical deep Q-network to model the agents' decision-making process and incorporates a novel reward function that encourages cooperation and fairness. Experimental results on a simulated disaster response scenario demonstrate that Coop-TA outperforms traditional methods in terms of task completion rate and overall system efficiency.