This paper presents a novel framework for designing adaptive gesture-based interfaces that cater to individuals with motor disabilities. We propose a machine learning-based approach that utilizes real-time gesture recognition, electromyography (EMG) signals, and user feedback to dynamically adjust interface parameters. Our system, called GestureAdapt, is designed to improve interface accessibility and usability for individuals with varying levels of motor impairment. We conducted a user study with 20 participants, demonstrating significant improvements in interaction accuracy and user satisfaction compared to traditional gesture-based interfaces.