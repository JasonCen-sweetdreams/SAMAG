Time-series anomaly detection is a crucial task in many fields, but existing methods often lack transparency and interpretability. This paper proposes a novel Hierarchical Attention Network (HAN) architecture for explainable time-series anomaly detection. Our approach leverages self-attention mechanisms to capture complex temporal dependencies and identify anomalous patterns. We also introduce a hierarchical structure to model the relationships between different time-series segments, enabling more accurate and interpretable anomaly detection. Experimental results on real-world datasets demonstrate the effectiveness of HAN in detecting anomalies and providing insights into the underlying patterns.