 Contrastive representation learning has shown promising results in computer vision tasks, but its computational cost and memory requirements can be prohibitive for large-scale datasets. This paper presents a novel hierarchical contrastive learning framework, 'HiCLR', which leverages a multi-resolution feature pyramid to efficiently learn visual representations. By adapting the contrastive loss to each pyramid level, HiCLR reduces the number of negative samples required, resulting in significant speedups and improved performance on downstream tasks like image classification and object detection. Experiments on ImageNet and COCO benchmarks demonstrate the efficacy of HiCLR in learning robust and transferable representations.