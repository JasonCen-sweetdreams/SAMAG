In multi-agent systems, understanding decision-making processes is crucial for trust and accountability. We propose a novel Hierarchical Attention Network (HAN) architecture that enables explainable decision-making in cooperative and competitive agent scenarios. Our HAN model learns to focus on relevant agent interactions and contextual features, generating attention weights that indicate the importance of each agent's contributions. We evaluate our approach on two benchmarks, demonstrating improved decision-making performance and providing transparent explanations for agent decisions.