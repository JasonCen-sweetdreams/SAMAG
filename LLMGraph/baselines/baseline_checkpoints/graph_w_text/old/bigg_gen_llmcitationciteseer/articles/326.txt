Time series forecasting models often lack interpretability, hindering their adoption in high-stakes applications. This paper proposes a novel hierarchical attention network (HAN) architecture that generates explanations for its predictions. Our HAN model employs a hierarchical encoder to capture long-term dependencies and a attention-based decoder to generate feature importance scores. We evaluate our approach on several benchmarks and demonstrate its ability to accurately forecast time series data while providing meaningful explanations. The proposed method achieves state-of-the-art results on the M4 competition dataset and outperforms existing explainable models.