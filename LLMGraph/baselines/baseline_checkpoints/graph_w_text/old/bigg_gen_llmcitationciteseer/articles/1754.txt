Anomaly detection in time series data is crucial in various domains, including finance, healthcare, and IoT. However, existing methods often rely on labeled data, which can be scarce and expensive to obtain. This paper presents a self-supervised approach for time series anomaly detection, leveraging contrastive learning to learn robust representations. Our proposed method, 'TS-Rep', uses a novel time-series specific augmentation strategy to generate positive and negative samples, enabling the model to learn discriminative features. Experimental results on several benchmark datasets demonstrate that TS-Rep outperforms state-of-the-art supervised and unsupervised methods, achieving an average F1-score improvement of 12.5%.