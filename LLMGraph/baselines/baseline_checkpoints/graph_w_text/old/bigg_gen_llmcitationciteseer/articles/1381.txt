Route planning for autonomous vehicles (AVs) requires efficient decision-making in complex, dynamic environments. This paper proposes a hierarchical reinforcement learning (HRL) framework, 'HierRoute', which leverages a novel combination of deep Q-networks and graph-based planning to optimize AV route planning. We introduce a hierarchical state representation that captures both local and global navigation contexts, enabling more efficient exploration and exploitation of the action space. Experimental results on a realistic simulation platform demonstrate that HierRoute outperforms existing flat RL approaches in terms of planning efficiency, safety, and adaptability to changing traffic conditions.