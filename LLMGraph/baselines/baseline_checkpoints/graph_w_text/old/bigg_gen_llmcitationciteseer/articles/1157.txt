Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but its performance heavily relies on careful hyperparameter tuning. This process is often time-consuming and computationally expensive. In this paper, we propose a novel Bayesian optimization approach, called 'BO-DRL', that leverages a probabilistic surrogate model to efficiently search for optimal hyperparameters. We demonstrate the effectiveness of BO-DRL on several DRL benchmarks, showing significant improvements in terms of tuning time and model performance compared to state-of-the-art methods.