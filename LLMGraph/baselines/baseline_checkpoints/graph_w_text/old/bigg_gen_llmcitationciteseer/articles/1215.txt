As multi-agent systems become increasingly complex, explaining the decision-making processes of autonomous agents is crucial for trust and accountability. This paper introduces a novel Hierarchical Attention Network (HAN) architecture for explainable multi-agent reinforcement learning. Our approach learns attention weights that highlight relevant agent interactions and action sequences, providing insights into cooperative and competitive behaviors. Experimental results on a simulated robotic soccer domain demonstrate improved explainability and policy performance compared to state-of-the-art reinforcement learning baselines.