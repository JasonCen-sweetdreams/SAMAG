In multi-agent systems, decision-making often relies on complex interactions between agents. While attention mechanisms have shown promise in modeling these interactions, they lack interpretability and transparency. This paper proposes a hierarchical attention network (HAN) framework that enables explainable decision-making in multi-agent settings. HAN integrates attention weights with graph neural networks to capture agent relationships and contextual information. We demonstrate the effectiveness of HAN in a traffic management scenario, where it outperforms state-of-the-art methods in terms of decision accuracy and interpretability. Our approach has implications for real-world multi-agent systems, where transparency and accountability are crucial.