Virtual reality (VR) technology has enabled the development of gesture recognition systems (GRS) that can accurately classify user gestures. However, the impact of embodiment on GRS performance remains understudied. This paper presents an empirical study exploring how different levels of embodiment (i.e., agency, body ownership, and sensory feedback) influence user experience and gesture recognition accuracy in VR-based GRS. Our results show that increasing embodiment improves gesture recognition accuracy by 15% and user satisfaction by 25%. We discuss the implications of these findings for the design of future VR-based GRS and their potential applications in human-computer interaction.