Few-shot node classification in graph-structured data is a challenging problem, especially when dealing with limited labeled instances. This paper proposes a novel hierarchical graph attention network (HGAT) architecture that leverages both local and global graph structure to learn transferable representations. HGAT utilizes a hierarchical attention mechanism to selectively focus on relevant nodes and edges, enabling effective knowledge transfer across tasks. Experimental results on several benchmark datasets demonstrate that HGAT outperforms state-of-the-art few-shot learning methods, achieving significant improvements in node classification accuracy.