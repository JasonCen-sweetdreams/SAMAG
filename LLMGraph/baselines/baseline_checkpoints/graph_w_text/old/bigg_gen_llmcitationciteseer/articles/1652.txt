Multi-agent reinforcement learning (MARL) has progressed significantly in recent years, but a major challenge remains in understanding the decision-making processes of individual agents. We propose a novel hierarchical attention network (HAN) architecture that enables explainable MARL. HAN incorporates a hierarchical graph attention mechanism to model complex agent interactions and a sparse attention module to identify influential agents. We evaluate our approach on a variety of MARL benchmarks, demonstrating improved performance and interpretability compared to state-of-the-art methods. Our results have significant implications for real-world applications, such as autonomous vehicles and smart grids.