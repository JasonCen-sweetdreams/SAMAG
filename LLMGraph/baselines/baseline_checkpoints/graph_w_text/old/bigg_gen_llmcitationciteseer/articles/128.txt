This paper presents a decentralized multi-agent reinforcement learning (MARL) approach for autonomous traffic signal control. We propose a novel communication protocol that enables agents to share local observations and coordinate their actions to minimize congestion and reduce travel times. Our approach leverages graph attention networks to model complex traffic dynamics and incorporates domain knowledge to ensure safety and fairness. Evaluations on a realistic traffic simulation platform demonstrate that our MARL framework outperforms traditional centralized and decentralized methods, showcasing its potential for real-world deployment.