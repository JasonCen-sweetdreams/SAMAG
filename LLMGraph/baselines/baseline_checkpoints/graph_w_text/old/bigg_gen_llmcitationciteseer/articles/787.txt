In multi-agent systems, task allocation is a challenging problem that requires efficient coordination among agents. This paper presents a hierarchical reinforcement learning (HRL) framework that learns to allocate tasks adaptively based on the dynamic environment and agent capabilities. Our approach, called HRL-TA, consists of a high-level task allocator that assigns tasks to agents and a low-level controller that executes the tasks. We demonstrate the effectiveness of HRL-TA in a simulated drone surveillance scenario, where it outperforms traditional manual allocation and other reinforcement learning baselines in terms of task completion rate and agent utilization.