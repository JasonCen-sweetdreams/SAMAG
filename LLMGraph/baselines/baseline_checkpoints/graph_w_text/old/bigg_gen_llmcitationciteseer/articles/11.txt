Decentralized task allocation in multi-agent systems is a challenging problem due to the inherent complexity of coordinating agents with limited communication and partial observability. This paper proposes a novel approach, 'Deep-TA', which leverages deep reinforcement learning to enable agents to learn decentralized task allocation policies. We utilize a decentralized actor-critic framework, where each agent learns to optimize its local policy based on its own observations and rewards. Experimental results on a variety of benchmark scenarios demonstrate that Deep-TA outperforms state-of-the-art decentralized allocation methods in terms of task completion rate and agent efficiency.