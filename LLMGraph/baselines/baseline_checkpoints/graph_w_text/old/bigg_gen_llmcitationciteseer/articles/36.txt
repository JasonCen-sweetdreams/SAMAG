As multi-agent systems become increasingly prevalent, the need for explainable decision-making processes grows. This paper proposes Hierarchical Attention Networks (HANs) for multi-agent reinforcement learning, enabling agents to selectively focus on relevant teammates and environment features when making decisions. We introduce a novel hierarchical attention mechanism that leverages both spatial and temporal dependencies, leading to improved coordination and cooperation among agents. Experimental results on several multi-agent environments demonstrate the effectiveness of HANs in enhancing both agent performance and interpretability.