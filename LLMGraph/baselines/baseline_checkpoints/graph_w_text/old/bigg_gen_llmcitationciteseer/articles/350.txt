This paper investigates the role of embodied cognition in virtual reality (VR)-based gesture recognition systems. We designed an experiment where participants performed a series of gestures in a VR environment while their brain activity was recorded using EEG. Our results show that the incorporation of embodied cognition principles, such as motor simulation and sensory feedback, significantly improves gesture recognition accuracy. We propose a novel framework, 'EmboGesture', which leverages these findings to develop more intuitive and effective VR-based interfaces. Our approach has implications for a wide range of applications, including gaming, education, and rehabilitation.