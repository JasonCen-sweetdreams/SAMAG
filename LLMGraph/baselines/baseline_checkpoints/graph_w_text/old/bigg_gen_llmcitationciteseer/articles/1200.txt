Explainability is a crucial aspect of real-world multi-agent systems, where autonomous agents make decisions that impact human lives. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable multi-agent reinforcement learning. Our approach learns to identify relevant agents, states, and actions that contribute to the decision-making process, thereby providing interpretable policies. We evaluate our method on a range of cooperative and competitive multi-agent environments, demonstrating improved explainability and performance compared to state-of-the-art baselines.