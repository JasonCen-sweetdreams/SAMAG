In multi-agent systems, task allocation is a complex problem that requires efficient coordination among agents. This paper proposes a decentralized approach that leverages reinforcement learning to allocate tasks in a dynamic environment. Our framework, 'DMA-TA', uses a decentralized Q-learning algorithm that enables agents to learn from their experiences and adapt to changing task requirements. We evaluate DMA-TA on a simulated robotics scenario and demonstrate significant improvements in task completion time and overall system efficiency compared to traditional centralized allocation methods.