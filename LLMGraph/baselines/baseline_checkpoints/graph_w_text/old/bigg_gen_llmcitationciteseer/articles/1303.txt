As multi-agent systems become increasingly prevalent in real-world applications, there is a growing need for explainable AI that can provide insights into agent decision-making. This paper proposes a novel hierarchical attention network (HAN) architecture for multi-agent reinforcement learning, which enables agents to selectively focus on relevant information from their peers and the environment. We demonstrate the effectiveness of our approach in a range of cooperative and competitive scenarios, and show that the attention weights provide a clear understanding of agent coordination and communication strategies.