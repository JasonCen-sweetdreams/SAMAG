Multi-agent systems are increasingly deployed in real-world scenarios, necessitating explainable decision-making processes. This paper presents a novel hierarchical attention network (HAN) architecture that enables agents to selectively focus on relevant information from other agents and the environment. Our approach integrates attention mechanisms at both local and global levels, allowing agents to generate interpretable explanations for their decisions. We evaluate HAN on a complex multi-agent robotics task and demonstrate improved performance and explainability compared to existing deep reinforcement learning methods.