Deep reinforcement learning (DRL) has achieved remarkable success in various applications, but it remains vulnerable to adversarial attacks. Existing detection methods often rely on statistical analysis or hand-crafted features, which can be evaded by sophisticated attacks. This paper proposes a novel graph-based anomaly detection approach, 'Grape', to identify adversarial attacks on DRL agents. By modeling the agent's state transition graph, Grape detects anomalies in the graph structure and node features, achieving high detection accuracy even against unknown attacks. Experiments on popular DRL benchmarks demonstrate Grape's effectiveness in detecting attacks and improving the robustness of DRL agents.