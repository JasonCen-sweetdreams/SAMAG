Time series forecasting has numerous applications in finance, healthcare, and climate science. However, the lack of interpretability in deep learning models hinders their adoption in high-stakes domains. This paper proposes a novel attention-based neural architecture search (NAS) framework for explainable time series forecasting. Our approach leverages attention mechanisms to identify relevant input features and generate feature importance scores, enabling model interpretability. Experimental results on three benchmark datasets demonstrate that our NAS framework outperforms state-of-the-art models in terms of forecasting accuracy while providing meaningful feature attributions.