Ad-hoc retrieval remains a challenging task in information retrieval, particularly when dealing with ambiguous or under-specified queries. This paper proposes a novel query expansion approach that leverages reinforcement learning to optimize the selection of expansion terms. Our method, called RL-QE, learns to predict the relevance of candidate terms based on their contextualized embeddings and rewards the agent for selecting terms that improve retrieval performance. Experimental results on several benchmark datasets demonstrate that RL-QE outperforms traditional query expansion methods, such as Rocchio and relevance models, in terms of mean average precision and normalized discounted cumulative gain.