Deep reinforcement learning (RL) has achieved impressive results in complex tasks, but its opacity hinders trust and understanding. This paper presents a novel explainability framework, 'DeepRL-Explainer', which leverages model-based RL and attention mechanisms to provide feature-importance explanations for policies. We introduce a sparse attention module that selectively highlights relevant state features, enabling more accurate and efficient explanations. Experimental results on Atari games and robotic manipulation tasks demonstrate the effectiveness of DeepRL-Explainer in improving transparency and facilitating policy improvement.