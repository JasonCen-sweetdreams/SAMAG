As collaborative systems become increasingly prevalent, the need for effective visualizations to support multi-user interactions grows. This paper presents a novel approach to adaptive visualization design, focusing on multi-touch gestures. We introduce a machine learning-based framework that infers users' intent and adapts visualization parameters accordingly, enhancing the collaborative experience. Our user study demonstrates significant improvements in task completion time and user satisfaction compared to traditional visualization methods. The proposed approach has implications for a range of applications, from co-located collaboration to remote teamwork.