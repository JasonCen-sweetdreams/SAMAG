Autonomous vehicles rely on reinforcement learning (RL) to adapt to complex scenarios, but existing methods suffer from slow learning and limited scalability. This paper introduces 'Hierarchical Q-Networks' (HQN), a novel RL framework that leverages a hierarchical structure to decompose the control problem into manageable sub-tasks. By recursively applying HQN to a set of carefully designed sub-policies, we demonstrate significant improvements in training efficiency and control performance. Experiments on a realistic simulation platform show that HQN outperforms state-of-the-art RL methods in navigating complex urban scenarios.