Graph neural networks (GNNs) have achieved state-of-the-art performance in various node classification tasks. However, most existing methods focus on single-label classification, whereas many real-world applications involve multi-label scenarios. This paper proposes a novel hierarchical graph attention network (HGAT) architecture, which leverages attention mechanisms at multiple scales to capture complex relationships between nodes and their labels. Our experiments on several benchmark datasets demonstrate that HGAT outperforms existing GNN-based methods in multi-label node classification tasks, achieving significant improvements in both macro-F1 and micro-F1 scores.