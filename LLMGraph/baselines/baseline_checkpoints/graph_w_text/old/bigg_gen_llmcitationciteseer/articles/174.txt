Multi-agent reinforcement learning (MARL) has achieved remarkable success in complex real-world domains, but the lack of interpretability hinders its adoption in high-stakes applications. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates explanations into MARL. HAN leverages attention mechanisms to identify influential agents and their interactions, generating human-readable explanations for the learned policies. We evaluate HAN on three cooperative MARL benchmarks, demonstrating improved explainability and comparable performance to state-of-the-art MARL methods.