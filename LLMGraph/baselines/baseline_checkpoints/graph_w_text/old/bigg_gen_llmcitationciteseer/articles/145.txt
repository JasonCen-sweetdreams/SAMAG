Multi-agent systems often require efficient task allocation to achieve collective goals. This paper presents a decentralized task allocation framework using graph neural networks (GNNs) to model complex agent interactions. Our approach, called GraphAgent, learns to allocate tasks by iteratively updating agent embeddings and task assignments based on local communication. We evaluate GraphAgent on several benchmark problems and demonstrate its scalability and adaptability to dynamic environments, outperforming traditional centralized and heuristic-based methods. Theoretical analysis and experiments show that GraphAgent achieves near-optimal task allocation while maintaining agent autonomy and flexibility.