As robots increasingly interact with humans, it is essential to develop vision systems that can provide interpretable explanations for their decisions. This paper presents a novel Hierarchical Attention Network (HAN) architecture, which integrates visual attention mechanisms with hierarchical feature extraction to enable explainable robot vision. Our approach achieves state-of-the-art performance on the EPIC-KITCHENS dataset while providing visual explanations for action recognition tasks. We demonstrate the effectiveness of HAN in real-world robotics applications, including human-robot collaboration and object manipulation.