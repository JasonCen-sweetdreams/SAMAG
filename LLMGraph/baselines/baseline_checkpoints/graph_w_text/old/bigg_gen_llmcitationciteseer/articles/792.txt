Explainability is crucial in multi-agent reinforcement learning (MARL) as it enables understanding of complex decision-making processes. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that integrates attention mechanisms at both agent and system levels. HAN enables the identification of influential agents and their interactions, facilitating explainability in MARL. We evaluate HAN on a variety of cooperative and competitive MARL scenarios, demonstrating improved performance and interpretability compared to state-of-the-art MARL algorithms. Furthermore, we provide visualizations of attention weights, offering insights into the decision-making process of individual agents and the overall system.