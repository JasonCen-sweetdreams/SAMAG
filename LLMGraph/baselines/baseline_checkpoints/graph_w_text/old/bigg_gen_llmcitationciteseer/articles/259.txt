Autonomous vehicles require efficient motion planning algorithms to navigate complex scenarios. This paper presents a novel deep hierarchical reinforcement learning framework, 'DeepHier', which integrates high-level trajectory planning with low-level control policy optimization. Our approach leverages a hierarchical actor-critic architecture to balance exploration-exploitation trade-offs and incorporates domain knowledge through semantic graph-based state representation. Experimental results on simulated urban driving scenarios demonstrate that DeepHier outperforms state-of-the-art methods in terms of safety, smoothness, and computational efficiency.