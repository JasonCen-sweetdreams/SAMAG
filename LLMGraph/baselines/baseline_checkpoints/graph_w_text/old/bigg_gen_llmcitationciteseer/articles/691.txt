Autonomous robotics relies heavily on reinforcement learning (RL) to learn complex tasks from scratch. However, the sample efficiency of RL algorithms remains a significant bottleneck. This paper proposes a novel hierarchical task decomposition framework, 'HTD-RL', which leverages a hierarchical Bayesian model to decompose complex tasks into simpler sub-tasks. We demonstrate that HTD-RL achieves significant improvements in sample efficiency and task success rates compared to state-of-the-art RL algorithms on a range of autonomous robotics tasks, including robotic grasping and manipulation.