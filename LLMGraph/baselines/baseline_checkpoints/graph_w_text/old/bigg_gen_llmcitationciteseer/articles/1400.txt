This paper presents a decentralized multi-agent reinforcement learning framework for adaptive traffic signal control. We propose a novel architecture where each agent, representing a traffic signal, learns to optimize its control policy based on local observations and communication with neighboring agents. Our approach leverages graph neural networks to model the traffic network and enable efficient information exchange among agents. Experimental results on a real-world traffic dataset demonstrate that our approach outperforms traditional centralized methods in reducing congestion and improving traffic flow.