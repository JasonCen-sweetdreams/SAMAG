Despite their impressive performance, deep neural networks (DNNs) remain vulnerable to carefully crafted adversarial attacks. This paper presents a novel approach to enhancing the robustness of DNNs against such attacks, leveraging hierarchical attention mechanisms (HAMs). By selectively focusing on critical input features and suppressing irrelevant ones, HAMs enable DNNs to better distinguish between benign and adversarial inputs. Our experiments demonstrate that HAM-equipped DNNs exhibit significant improvements in robustness against state-of-the-art attacks, while maintaining competitive performance on clean data.