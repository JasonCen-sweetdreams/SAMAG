In multi-agent reinforcement learning, explaining the decision-making process of agents is crucial for trust and accountability. We propose a novel Hierarchical Attention Network (HAN) architecture that integrates attention mechanisms at both the agent and team levels. Our approach enables the extraction of interpretable features and attention weights, providing insights into agent interactions and joint decision-making. Experimental results on a cooperative navigation task demonstrate that HAN improves both team performance and explainability compared to state-of-the-art methods.