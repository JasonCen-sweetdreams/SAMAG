Multi-agent reinforcement learning (MARL) has shown great promise in complex decision-making tasks, but the lack of interpretability hinders its adoption in real-world applications. We propose a novel hierarchical attention network (HAN) that learns to identify and prioritize relevant agents and their interactions in MARL scenarios. Our approach leverages a attention-based graph neural network to model agent relationships and a hierarchical policy to optimize joint actions. We demonstrate the effectiveness of HAN in a variety of MARL benchmarks, including traffic management and robot swarm control, and provide insights into the decision-making process through visualized attention weights.