This paper presents a novel voice-based interface framework, 'EasyVox', designed to improve accessibility in smart home environments. EasyVox integrates natural language processing (NLP) and machine learning (ML) techniques to enable users with disabilities to control and interact with smart devices more easily. We conducted a user-centered design study to identify key accessibility requirements and developed a set of voice-based commands and feedback mechanisms to support intuitive interaction. Evaluation results show that EasyVox significantly improves task completion rates and user satisfaction for users with visual and motor impairments.