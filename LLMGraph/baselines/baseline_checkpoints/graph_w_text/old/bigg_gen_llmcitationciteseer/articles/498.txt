Cooperative task allocation is a crucial problem in many real-world applications, such as search and rescue, smart grids, and autonomous vehicles. This paper proposes a novel multi-agent reinforcement learning framework that enables agents to learn cooperative policies for task allocation in dynamic environments. We introduce a decentralized Q-network architecture that incorporates a communication mechanism, allowing agents to share information about the environment and their actions. We evaluate our approach in a simulated search and rescue scenario and demonstrate improved task allocation efficiency and adaptability compared to traditional decentralized approaches.