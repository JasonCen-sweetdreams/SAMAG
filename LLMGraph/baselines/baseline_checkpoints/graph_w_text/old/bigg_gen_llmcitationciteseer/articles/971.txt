In multi-agent systems, task allocation is a crucial problem that requires efficient and adaptive decision-making. This paper proposes a decentralized task allocation framework using reinforcement learning, where agents learn to allocate tasks based on their capabilities and environmental feedback. We introduce a novel algorithm, 'MATRL', that leverages a combination of actor-critic methods and graph neural networks to learn effective task allocation policies. Experimental results on a simulated robotic warehouse environment demonstrate that MATRL outperforms traditional centralized approaches in terms of task completion time and agent utilization.