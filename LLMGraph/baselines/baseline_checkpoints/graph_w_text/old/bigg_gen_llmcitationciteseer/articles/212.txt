As augmented reality (AR) technology becomes increasingly prevalent in industrial settings, there is a growing need for intuitive and efficient interfaces. This paper presents a novel gaze-based intelligent interface, 'GazeAR', which leverages machine learning and computer vision techniques to enable hands-free interaction with virtual objects in AR environments. We propose a hierarchical attention model that integrates gaze tracking, object recognition, and task inference to predict user intentions and provide context-aware assistance. Experimental results demonstrate that GazeAR outperforms traditional manual interfaces in terms of task completion time and user satisfaction.