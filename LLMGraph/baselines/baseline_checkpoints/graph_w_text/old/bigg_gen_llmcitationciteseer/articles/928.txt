Cooperative object transportation tasks in multi-agent systems require efficient communication and coordination strategies. This paper proposes a novel deep hierarchical reinforcement learning framework, 'CoopHRL', which combines a high-level task allocator with low-level motion controllers. We introduce a hierarchical attention mechanism that enables agents to selectively focus on relevant teammates and objects, leading to improved cooperative behavior and reduced communication overhead. Experiments in a simulated warehouse environment demonstrate that CoopHRL outperforms state-of-the-art methods in terms of task completion time and success rate.