This paper introduces a novel hierarchical attention mechanism for explainable multi-agent reinforcement learning. Our approach, called HAT-MARL, extends traditional attention-based models by incorporating a hierarchical structure to capture both local and global dependencies between agents. We demonstrate that HAT-MARL improves the interpretability and performance of MARL policies in complex environments, such as traffic control and robotic swarm coordination. Experimental results show that HAT-MARL outperforms state-of-the-art MARL methods in terms of both task performance and explanation quality.