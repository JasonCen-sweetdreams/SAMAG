As time-series forecasting models become increasingly deployed in critical applications, their vulnerability to adversarial attacks poses a significant threat. This paper investigates the robustness of state-of-the-art models against carefully crafted perturbations in the input data. We propose a novel attack strategy, 'TS-Fool', which exploits the temporal dependencies in time-series data to induce errors in forecasting. Our experiments on real-world datasets demonstrate the effectiveness of TS-Fool and highlight the need for interpretability techniques to identify vulnerable components in these models. We further propose a regularization-based defense mechanism that improves the robustness of forecasting models against adversarial attacks.