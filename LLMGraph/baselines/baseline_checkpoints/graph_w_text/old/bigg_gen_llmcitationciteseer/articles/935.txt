Query optimization is a crucial step in graph database systems, particularly in distributed settings where data is scattered across multiple nodes. Traditional optimization techniques often rely on heuristics or exhaustive search, leading to suboptimal performance. This paper proposes a novel approach that leverages reinforcement learning to optimize query plans for distributed graph databases. Our method, called GraphOpt, learns to navigate the vast space of possible query plans using a reward function that balances execution time, memory usage, and result quality. Experimental results on a real-world graph dataset demonstrate that GraphOpt outperforms state-of-the-art optimization techniques by up to 3x in terms of query execution speed and 2x in terms of memory usage.