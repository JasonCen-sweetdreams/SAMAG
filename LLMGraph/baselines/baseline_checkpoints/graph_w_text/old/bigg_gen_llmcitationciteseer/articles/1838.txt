Time series forecasting models are widely used in various domains, but their lack of transparency hinders trust and adoption. This paper proposes a novel Hierarchical Attention Neural Network (HATNet) architecture that incorporates explainability into time series forecasting. HATNet utilizes a hierarchical attention mechanism to selectively focus on relevant temporal dependencies and features, providing insights into the forecasting process. Experimental results on four benchmark datasets demonstrate that HATNet outperforms state-of-the-art models in terms of forecasting accuracy and provides meaningful interpretability.