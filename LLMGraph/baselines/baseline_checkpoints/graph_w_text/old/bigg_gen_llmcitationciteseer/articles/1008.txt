Accurate intention recognition is crucial for developing intuitive human-computer interaction (HCI) systems. This paper presents a novel gaze-based approach that leverages machine learning to recognize users' intentions from their gaze patterns. We propose a hierarchical classification framework that combines convolutional neural networks (CNNs) and long short-term memory (LSTM) networks to model the spatial and temporal aspects of gaze data. Our evaluation on a large-scale gaze dataset demonstrates that our approach outperforms state-of-the-art intention recognition methods by 12.5% in terms of accuracy, paving the way for more natural and efficient HCI systems.