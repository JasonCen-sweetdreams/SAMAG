Voice assistants have become ubiquitous, but their usability for users with disabilities remains limited. This paper presents a user-centered design approach to create more inclusive conversational interfaces. We conducted a mixed-methods study involving 30 participants with disabilities, exploring their experiences and preferences when interacting with voice assistants. Our findings highlight the need for personalized vocabulary, adaptive speech recognition, and multimodal feedback. We propose a set of design guidelines and a novel interaction framework, 'InConverse', which incorporates these features to improve the accessibility and usability of voice assistants. Our evaluation shows that InConverse significantly enhances user satisfaction and task completion rates for users with disabilities.