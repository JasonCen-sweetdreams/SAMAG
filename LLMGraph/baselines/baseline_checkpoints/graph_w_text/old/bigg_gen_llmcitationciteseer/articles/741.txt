The increasing penetration of renewable energy sources in smart grids necessitates the development of autonomous and adaptive control strategies. In this paper, we propose a multi-agent system (MAS) framework that leverages deep reinforcement learning (DRL) to coordinate the actions of distributed energy resources and loads. Our approach uses a decentralized actor-critic architecture to learn optimal policies for each agent, while a hierarchical framework enables efficient communication and coordination among agents. Experimental results on a simulated smart grid testbed demonstrate the effectiveness of our approach in reducing energy losses, voltage fluctuations, and peak demand.