Optimizing query performance is crucial in distributed relational databases, where complex queries can lead to significant latency and resource consumption. This paper proposes a novel approach to query optimization using reinforcement learning (RL). We formulate the query optimization problem as a Markov Decision Process and develop an RL-based framework that learns to select optimal query plans based on the database's runtime statistics. Our experimental results on a real-world dataset demonstrate that our approach outperforms traditional rule-based and cost-based optimizers, achieving up to 30% improvement in query performance.