Query optimization is a critical component of distributed database systems, as it directly impacts system performance and scalability. This paper proposes a novel approach to query optimization using machine learning techniques. We develop a cost-based query optimizer that leverages a deep neural network to accurately predict query execution times. Experimental results on a large-scale distributed database system demonstrate that our approach outperforms traditional rule-based optimizers by up to 30% in terms of query execution time, while also reducing optimization overhead by 25%. We further explore the applicability of our approach to various distributed database architectures and query workloads.