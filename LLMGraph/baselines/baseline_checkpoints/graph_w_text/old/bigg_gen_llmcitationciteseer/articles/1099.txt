Autonomous vehicles rely heavily on reinforcement learning (RL) to make decisions in complex scenarios. However, the lack of transparency in RL models hinders their widespread adoption. This paper proposes a novel explainable RL framework, 'XRL', which integrates attention mechanisms and model-agnostic explanations to provide insights into the decision-making process. We evaluate XRL on a realistic autonomous driving simulator and demonstrate improved interpretability without compromising task performance. Our approach has significant implications for the development of trustworthy autonomous systems.