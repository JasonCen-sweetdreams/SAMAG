Query expansion is a crucial component in ad-hoc retrieval, aiming to overcome the vocabulary mismatch between users' queries and relevant documents. However, existing methods often rely on heuristics or manual tuning, leading to suboptimal performance. This paper proposes a novel reinforcement learning framework, RLQE, to learn query expansion strategies that adapt to diverse query types and document collections. We formulate query expansion as a Markov decision process, where the agent learns to select expansion terms based on rewards derived from retrieval performance. Experimental results on several TREC datasets demonstrate that RLQE outperforms state-of-the-art methods, achieving significant improvements in mean average precision and normalized discounted cumulative gain.