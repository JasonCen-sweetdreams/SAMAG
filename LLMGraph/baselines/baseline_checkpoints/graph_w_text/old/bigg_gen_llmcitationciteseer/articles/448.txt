In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a novel distributed task allocation framework that leverages deep reinforcement learning to optimize task assignments for heterogeneous agents. We propose a decentralized, communication-efficient approach that enables agents to learn from their local observations and adapt to changing system conditions. Experimental results on a simulated disaster response scenario demonstrate the effectiveness of our approach in improving task completion rates and reducing overall system latency.