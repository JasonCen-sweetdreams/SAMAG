Decentralized task allocation is a fundamental problem in autonomous agent systems, where agents need to coordinate to accomplish complex tasks. This paper proposes a novel approach using graph neural networks (GNNs) to learn decentralized task allocation policies. Our method, called AgentGNN, represents the agent-task graph as a dynamic graph signal and learns to predict task assignments that maximize system utility. We evaluate AgentGNN on a range of simulated environments and show that it outperforms existing decentralized task allocation algorithms in terms of task completion rate and system efficiency.