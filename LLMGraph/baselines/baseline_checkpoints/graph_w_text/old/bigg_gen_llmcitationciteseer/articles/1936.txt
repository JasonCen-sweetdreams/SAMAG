Ad-hoc retrieval systems struggle to effectively capture user intent, leading to subpar retrieval performance. This paper proposes a novel query expansion approach, 'DRL-QE', which leverages deep reinforcement learning to adaptively select expansion terms. By formulating query expansion as a Markov decision process, our method learns to optimize the trade-off between query drift and relevance improvement. Experimental results on the TREC-8 ad-hoc retrieval dataset demonstrate that DRL-QE outperforms state-of-the-art expansion techniques, achieving significant improvements in mean average precision and recall.