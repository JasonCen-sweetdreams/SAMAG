Despite advances in neural ranking models, capturing context-dependent relevance in document retrieval remains a challenging task. We propose a novel Hierarchical Attention Network (HAN) architecture that incorporates both local and global context to improve ranking accuracy. Our approach leverages a multi-level attention mechanism to selectively focus on relevant passages, sentences, and keywords, thereby better capturing contextual relationships between queries and documents. Experimental results on several benchmark datasets demonstrate significant improvements in retrieval performance, particularly for long-tail queries and noisy documents.