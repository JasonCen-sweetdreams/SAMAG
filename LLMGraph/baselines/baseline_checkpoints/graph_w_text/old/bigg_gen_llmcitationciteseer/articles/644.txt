 Passage retrieval is a crucial step in various information retrieval tasks, such as open-domain question answering and text classification. However, existing methods often rely on computationally expensive dense retrieval models or suffer from suboptimal document encoding. This paper introduces QDDE, a novel query-driven document embedding framework that jointly learns query and document representations in a shared semantic space. QDDE leverages a lightweight, query-conditioned transformer architecture to generate compact document embeddings, enabling efficient passage retrieval. Experimental results on several benchmark datasets demonstrate QDDE's effectiveness in improving retrieval accuracy while reducing computational costs.