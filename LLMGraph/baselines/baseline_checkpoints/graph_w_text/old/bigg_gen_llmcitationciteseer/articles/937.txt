Multi-task learning (MTL) has shown promising results in various applications, but scaling MTL to large datasets and complex graph-structured data remains a significant challenge. We propose a novel hierarchical graph neural network (HGNN) framework that integrates task-specific graph attention mechanisms with a hierarchical clustering approach. Our method, called HierMTL, adaptively partitions the graph into subgraphs based on task relationships and learns a hierarchical representation that captures both local and global dependencies. Experimental results on several benchmark datasets demonstrate that HierMTL achieves state-of-the-art performance on multiple tasks while reducing computational overhead.