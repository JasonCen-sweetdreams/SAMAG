Autonomous vehicles require efficient decision-making strategies to navigate complex scenarios. This paper presents a novel deep hierarchical reinforcement learning (DHRL) framework, which integrates high-level task planning with low-level motion control. Our approach leverages a hierarchical policy architecture, comprising a task encoder, a option selector, and a motion controller. We evaluate the DHRL framework on a simulated autonomous driving environment, demonstrating improved decision-making capabilities and adaptability to changing scenarios compared to flat policy-based approaches.