Explainability is crucial in multi-agent reinforcement learning (MARL) to understand agent decision-making. This paper proposes a novel hierarchical attention network (HAN) architecture that integrates attention mechanisms at both the agent and team levels. Our HAN approach enables the interpretability of agent policies and their interactions, improving the transparency of MARL systems. We evaluate our approach on a variety of MARL benchmarks, demonstrating improved performance and explainability compared to state-of-the-art methods.