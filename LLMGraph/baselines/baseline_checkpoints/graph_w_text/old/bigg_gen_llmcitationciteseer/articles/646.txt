Multi-agent reinforcement learning (MARL) has shown promise in various applications, but its lack of interpretability hinders its adoption in real-world scenarios. This paper introduces Hierarchical Attention Networks (HANs) to improve the explainability of MARL. HANs utilize attention mechanisms at both the agent and team levels to selectively focus on relevant information and facilitate knowledge sharing among agents. We demonstrate the effectiveness of HANs in a variety of cooperative and competitive MARL environments, showcasing improved performance and interpretability compared to state-of-the-art baselines.