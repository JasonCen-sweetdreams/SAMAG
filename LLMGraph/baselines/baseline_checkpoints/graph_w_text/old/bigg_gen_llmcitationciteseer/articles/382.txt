Graph Neural Networks (GNNs) have achieved state-of-the-art performance on various graph-based tasks. However, their vulnerability to adversarial attacks remains largely unexplored. This paper proposes a novel attack framework, 'GraphFool', which crafts structured perturbations to manipulate the graph structure and features. We demonstrate that GraphFool can significantly degrade the performance of popular GNN models on benchmark datasets. Furthermore, we develop a robust GNN architecture that incorporates adversarial training and graph refinement techniques to improve its resilience against such attacks.