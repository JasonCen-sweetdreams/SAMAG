This paper presents a novel multi-agent reinforcement learning framework for real-time traffic control. We propose a decentralized approach, where multiple agents, each responsible for a traffic signal, learn to optimize traffic flow in a coordinated manner. Our algorithm, 'Traffic Harmony', employs a hierarchical architecture with a centralized critic and distributed actors, allowing for efficient exploration and exploitation of the action space. Experiments on a large-scale traffic simulator demonstrate significant reductions in travel time and congestion compared to traditional, rule-based traffic control methods.