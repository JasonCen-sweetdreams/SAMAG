Conversational AI systems often struggle to balance exploration and exploitation in dialogue management, leading to inefficient and suboptimal conversations. We propose a hierarchical reinforcement learning framework, 'DiaHier', which leverages a novel graph-based state representation and a two-level action space to tackle this challenge. DiaHier enables the agent to reason about both short-term and long-term goals, resulting in more coherent and goal-oriented dialogues. Our experiments on a large-scale conversational dataset demonstrate significant improvements in dialogue efficiency and user satisfaction.