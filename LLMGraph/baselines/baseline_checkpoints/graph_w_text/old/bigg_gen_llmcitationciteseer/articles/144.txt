Voice assistants have become ubiquitous, but their language processing capabilities often perpetuate cultural stereotypes and biases. This paper presents a mixed-methods study investigating the impact of language bias and cultural insensitivity on user experience. We developed a culturally sensitive voice assistant framework, 'EchoPlex', which incorporates linguistic and cultural knowledge graphs to mitigate bias. Our user study with 100 participants from diverse linguistic and cultural backgrounds shows that EchoPlex reduces culturally insensitive responses by 75% and improves overall user satisfaction by 30%. We discuss the implications of our findings for designing more inclusive voice assistants.