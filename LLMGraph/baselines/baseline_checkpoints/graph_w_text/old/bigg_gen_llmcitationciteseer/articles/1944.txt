Short-text document collections, such as social media posts and product reviews, pose significant challenges for traditional information retrieval systems. This paper proposes a novel neural query expansion approach, 'NQE-ST', which leverages the semantic relationships between words in the query and document collections. We use a pre-trained language model to generate contextualized embeddings and then adapt a graph attention network to model the relationships between query terms and document keywords. Experimental results on several benchmark datasets demonstrate that NQE-ST consistently outperforms state-of-the-art query expansion techniques, achieving significant improvements in retrieval effectiveness and efficiency.