Distributed relational databases are increasingly used in modern data-intensive applications, where query optimization is crucial for performance. Existing approaches rely on heuristics or manual tuning, which can lead to suboptimal query plans. This paper proposes a novel query optimization framework, 'RL-QOP', that leverages reinforcement learning to efficiently explore the vast space of possible query plans. We design a custom reward function that balances execution time and resource utilization, and demonstrate RL-QOP's ability to adapt to diverse workload patterns. Experimental results on a real-world distributed database show that RL-QOP outperforms state-of-the-art query optimizers by up to 30% in terms of query execution time.