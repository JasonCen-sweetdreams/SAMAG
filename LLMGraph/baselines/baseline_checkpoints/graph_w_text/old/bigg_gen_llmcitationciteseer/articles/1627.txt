Explainability is crucial for real-world adoption of multi-agent reinforcement learning (MARL) in complex domains. This paper presents Hierarchical Attention Networks (HANs), a novel architecture that incorporates hierarchical attention mechanisms to selectively focus on relevant agents, states, and actions. HANs enable interpretable policy and value functions, thereby providing insights into the decision-making process. We evaluate HANs on a suite of MARL benchmarks, demonstrating improved performance and explainability compared to state-of-the-art methods. Our approach has potential applications in autonomous systems, smart cities, and human-robot collaboration.