Explainability is crucial in multi-agent systems, where decision-making involves complex interactions and dependencies. We propose a novel Hierarchical Attention Network (HAN) architecture that learns to identify and highlight key factors influencing agent decisions. Our approach integrates attention mechanisms at multiple levels, enabling the model to capture both local and global relationships between agents and their environment. Experimental results on a simulated traffic control scenario demonstrate the effectiveness of HAN in improving transparency and accountability in multi-agent decision-making.