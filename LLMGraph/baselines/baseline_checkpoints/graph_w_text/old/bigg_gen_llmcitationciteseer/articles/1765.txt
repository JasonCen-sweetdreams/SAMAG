Cloud computing has become a ubiquitous platform for deploying large-scale applications, but efficient resource allocation remains a significant challenge. This paper proposes a deep hierarchical reinforcement learning (DHRL) framework that learns to optimize resource allocation in cloud computing environments. Our DHRL approach leverages a hierarchical structure to model complex resource dependencies and incorporates deep reinforcement learning to learn optimal allocation policies. Experimental results on a real-world cloud computing dataset demonstrate that our DHRL approach outperforms existing resource allocation methods in terms of resource utilization, response time, and cost efficiency.