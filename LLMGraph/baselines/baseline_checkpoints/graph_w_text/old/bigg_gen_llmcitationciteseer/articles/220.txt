 Passage retrieval is a crucial component of various natural language processing applications, including question answering and text summarization. This paper proposes a novel document representation approach, Hierarchical Attention-based Passage Encoder (HAPE), which leverages hierarchical attention mechanisms to capture both local and global contextual information within a document. Our experiments on several benchmark datasets demonstrate that HAPE significantly outperforms state-of-the-art passage retrieval models, achieving an average gain of 12.5% in terms of recall@10. We also provide a thorough analysis of the attention patterns learned by HAPE, which sheds light on the importance of hierarchical context in document representation.