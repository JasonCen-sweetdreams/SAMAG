As multi-agent systems become increasingly prevalent, the need for transparent and interpretable decision-making processes grows. This paper proposes a novel hierarchical attention mechanism for multi-agent reinforcement learning, enabling agents to selectively focus on relevant observations and actions. Our approach, 'HAT-MARL', improves both the performance and explainability of learned policies, allowing for better understanding of agent interactions and decision-making. Experimental results on a range of benchmark environments demonstrate the effectiveness of HAT-MARL in achieving superior performance and interpretability compared to state-of-the-art methods.