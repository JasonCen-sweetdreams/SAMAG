Virtual assistants are increasingly prevalent in various domains, but they often struggle to proactively assist users due to the lack of explicit input. This paper proposes a novel gaze-based intention recognition framework, 'GazePro', which leverages machine learning and computer vision techniques to infer user intentions from gaze patterns. We develop a multimodal dataset comprising eye-tracking, facial expression, and user behavior data, and demonstrate that GazePro outperforms state-of-the-art intention recognition models by 12.5% in accuracy. Our results have significant implications for developing more proactive and user-centered virtual assistants.