In multi-agent reinforcement learning, the lack of transparency in decision-making processes hinders trust and cooperation among agents. We propose Hierarchical Attention Networks (HAN) to address this challenge. HAN introduces a novel attention mechanism that selectively focuses on relevant agents, states, and actions, generating interpretable explanations for agent decisions. Our experiments on a variety of multi-agent environments demonstrate that HAN improves cooperation and overall system performance while providing meaningful insights into agent behavior. We also show that HAN outperforms existing methods in terms of explainability, achieving state-of-the-art results in several benchmark tasks.