Voice assistants have become ubiquitous, but they often struggle to understand users with disabilities or non-native accents. This paper presents 'AdaVox', a novel dialogue system that adaptively adjusts its language processing and response generation based on user preferences and abilities. We employ a machine learning framework that integrates user feedback, speech recognition, and natural language processing to improve the accessibility and inclusivity of voice assistants. Our user study involving 150 participants with diverse abilities demonstrates significant improvements in user satisfaction and task completion rates compared to existing voice assistants.