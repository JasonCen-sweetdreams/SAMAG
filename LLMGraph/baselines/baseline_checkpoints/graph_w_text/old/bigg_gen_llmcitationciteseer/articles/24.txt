Multi-agent systems often rely on complex decision-making processes that are difficult to interpret. This paper presents a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent settings. Our HAN model consists of two attention layers: an intra-agent attention layer that captures individual agent-level features and an inter-agent attention layer that models agent interactions. We evaluate our approach on a real-world autonomous vehicle dataset and demonstrate improved explainability and decision-making performance compared to state-of-the-art methods.