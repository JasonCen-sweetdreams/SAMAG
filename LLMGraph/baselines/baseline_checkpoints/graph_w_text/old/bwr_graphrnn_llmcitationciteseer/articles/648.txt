Cooperative task allocation is a challenging problem in multi-agent systems, particularly in dynamic environments where tasks and agent capabilities change over time. This paper presents a novel multi-agent reinforcement learning framework, 'CoopRTL', which enables agents to learn cooperative policies for task allocation. We introduce a hierarchical graph-based representation of tasks and agents, which allows for efficient exploration and exploitation of the joint action space. Experimental results in a simulated robotic search and rescue scenario demonstrate that CoopRTL outperforms existing decentralized task allocation methods in terms of task completion rate and overall system efficiency.