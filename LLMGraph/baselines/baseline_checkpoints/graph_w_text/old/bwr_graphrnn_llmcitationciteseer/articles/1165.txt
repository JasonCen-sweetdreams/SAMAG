Time-series forecasting models often lack transparency, making it challenging to understand the underlying patterns driving predictions. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that incorporates both local and global attention mechanisms to capture complex dependencies in time-series data. Our approach enables feature importance attribution, allowing users to identify influential factors contributing to forecasted values. Experimental results on several benchmark datasets demonstrate that HAN outperforms state-of-the-art models in terms of accuracy and interpretability, offering a promising solution for explainable time-series forecasting.