In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel context-aware task allocation framework, 'CATAR', which leverages reinforcement learning to adapt to dynamic environmental changes. CATAR integrates a deep Q-network with a graph neural network to learn task dependencies and agent capabilities, enabling effective task assignment and reallocation. Experimental results on a simulated disaster response scenario demonstrate that CATAR outperforms existing methods in terms of task completion rate and overall system efficiency.