Explainable recommendation systems (ERS) aim to provide transparency into the decision-making process of AI-driven recommenders. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) architecture, which integrates graph attention mechanisms with hierarchical representations to model complex user-item relationships. By incorporating attention weights as a proxy for feature importance, HGAT enables interpretable recommendations. Experimental results on two large-scale datasets demonstrate that HGAT outperforms state-of-the-art ERS methods in terms of both recommendation accuracy and explainability.