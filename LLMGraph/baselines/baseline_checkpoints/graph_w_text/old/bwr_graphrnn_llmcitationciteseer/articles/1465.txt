Resource allocation in cloud computing is a complex problem that requires balancing competing objectives, such as latency, throughput, and cost. This paper proposes a hierarchical reinforcement learning (HRL) framework, 'CloudOpt', which decomposes the resource allocation problem into a hierarchy of sub-problems, each solved by a specialized deep Q-network. We introduce a novel state representation that captures the spatial and temporal dependencies of cloud workloads, enabling the HRL agent to make informed decisions about resource provisioning. Experimental results on a simulated cloud environment show that CloudOpt outperforms state-of-the-art resource allocation algorithms in terms of average response time and resource utilization.