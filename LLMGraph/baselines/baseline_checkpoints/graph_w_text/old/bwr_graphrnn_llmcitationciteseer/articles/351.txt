In multi-agent systems, decision-making involves complex interactions and dependencies among agents. Existing approaches often rely on opaque neural networks, making it challenging to understand and interpret agent behaviors. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent environments. HAN integrates attention mechanisms at both local and global levels, allowing agents to selectively focus on relevant features and interactions. We evaluate our approach on a real-world autonomous driving scenario, demonstrating improved decision-making accuracy and interpretability compared to state-of-the-art methods.