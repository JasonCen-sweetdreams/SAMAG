Deep reinforcement learning (DRL) has shown remarkable success in autonomous systems, but the lack of transparency and explainability hinders their adoption in safety-critical applications. This paper proposes a novel model-agnostic explainability framework, 'DRL-X', which leverages attention mechanisms and feature importance to provide insights into DRL decision-making. We evaluate DRL-X on a variety of autonomous driving scenarios and demonstrate its effectiveness in identifying critical state features, improving policy interpretability, and enhancing model trustworthiness. Our framework has significant implications for the development of reliable and transparent autonomous systems.