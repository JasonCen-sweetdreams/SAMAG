Multi-label classification is a challenging problem in machine learning, where an instance can be associated with multiple labels. This paper proposes a novel hierarchical attention network (HAN) architecture for efficient multi-label classification. HAN employs a label-aware attention mechanism to selectively focus on relevant labels and features, reducing the dimensionality of the input space. Experimental results on several benchmark datasets demonstrate that HAN outperforms state-of-the-art methods in terms of label-wise F1-score and computational efficiency, making it suitable for large-scale applications.