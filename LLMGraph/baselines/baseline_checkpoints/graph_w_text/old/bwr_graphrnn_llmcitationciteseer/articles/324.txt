In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper proposes a decentralized task allocation framework that leverages graph neural networks (GNNs) to model agent interactions and task dependencies. Our approach, dubbed 'GNN-TA', enables agents to learn a distributed allocation policy that minimizes communication overhead and adapts to dynamic environment changes. We evaluate GNN-TA on various benchmark scenarios, demonstrating improved task completion rates and reduced communication costs compared to traditional centralized and distributed allocation methods.