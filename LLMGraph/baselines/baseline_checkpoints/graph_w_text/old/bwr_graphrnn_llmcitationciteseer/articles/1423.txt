Explainability is crucial in multi-agent reinforcement learning (MARL) to ensure accountability and trust in AI systems. This paper introduces Hierarchical Attention Networks (HANs) to enable explainable decision-making in MARL. HANs leverage hierarchical graph attention mechanisms to model complex agent-agent and agent-environment interactions. We propose a novel attention-based credit assignment algorithm to attribute rewards to individual agents, facilitating explainability. Experimental results on the StarCraft II MARL benchmark demonstrate that HANs achieve state-of-the-art performance while providing interpretable insights into agent behavior and decision-making processes.