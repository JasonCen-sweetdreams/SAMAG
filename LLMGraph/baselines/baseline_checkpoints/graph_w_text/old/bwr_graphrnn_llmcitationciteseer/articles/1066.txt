This paper proposes a novel hierarchical attention framework for explainable multi-agent reinforcement learning. Our approach, dubbed 'HAT-MARL', integrates attention mechanisms at both the local and global levels to facilitate cooperation and communication among agents. We demonstrate that HAT-MARL improves the interpretability and transparency of MARL policies, enabling humans to understand and intervene in complex decision-making processes. Experimental results on a suite of benchmark environments show that HAT-MARL outperforms state-of-the-art MARL methods in terms of both performance and explainability.