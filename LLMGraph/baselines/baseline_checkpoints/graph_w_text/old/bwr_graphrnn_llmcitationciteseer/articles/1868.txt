Explainable recommendation systems are crucial for building trust in AI-driven decision-making. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) model, which learns to focus on relevant graph structures and node features to generate interpretable recommendations. By incorporating multi-hop attention mechanisms and hierarchical graph pooling, HGAT outperforms state-of-the-art models on several benchmark datasets. We demonstrate the effectiveness of HGAT in explaining recommendation results through visualizations and quantitative metrics, opening up new avenues for explainable AI research.