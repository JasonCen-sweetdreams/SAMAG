Explainable recommendation systems (ERS) are crucial for building trust in AI-driven decision-making processes. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) architecture that learns to generate personalized explanations for recommended items. HGAT combines multi-hop graph attention with hierarchical aggregation to capture complex relationships between users, items, and their attributes. Our experiments on two real-world datasets demonstrate that HGAT outperforms state-of-the-art ERS methods in terms of recommendation accuracy and explanation quality, while providing insights into the decision-making process.