This paper presents a novel framework for designing accessible multimodal interfaces for individuals with visual impairments. We conducted a comprehensive user study to identify the most effective combinations of auditory, tactile, and gestural cues for conveying information in various tasks. Our results show that a hybrid approach, leveraging both speech output and haptic feedback, significantly improves user performance and satisfaction in navigation and object recognition tasks. We also propose a set of guidelines for designers to create more inclusive and accessible multimodal interfaces, which are validated through a usability evaluation with visually impaired participants.