As robots increasingly interact with humans in various settings, effective human-robot collaboration (HRC) relies on efficient multimodal fusion. This paper presents a novel design framework for interactive visualizations that facilitates HRC by integrating visual, auditory, and haptic cues. We propose a taxonomy of multimodal fusion strategies and develop a set of visualization guidelines for effective information exchange between humans and robots. Our user study demonstrates that the proposed framework improves collaboration outcomes, reduces communication errors, and enhances user experience in HRC scenarios.