Decentralized task allocation is a fundamental problem in multi-agent systems, where agents with varying capabilities must coordinate to accomplish complex tasks. This paper proposes a novel approach using graph neural networks (GNNs) to learn decentralized task allocation policies for heterogeneous agents. We model the agent interactions as a graph and leverage GNNs to learn a distributed policy that adapts to the dynamic environment and agent capabilities. Experimental results on a simulated search-and-rescue scenario demonstrate improved task completion rates and reduced communication overhead compared to existing decentralized methods.