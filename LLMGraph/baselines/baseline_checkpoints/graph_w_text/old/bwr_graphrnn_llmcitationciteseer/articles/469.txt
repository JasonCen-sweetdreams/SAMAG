As augmented reality (AR) technology advances, effective user interaction methods become crucial. This study explores the potential of gaze-based interaction in AR, focusing on user experience and performance. We designed and evaluated a gaze-based system using a novel machine learning model that predicts user intentions from eye movement patterns. Our user study with 30 participants shows that the gaze-based approach outperforms traditional hand-held controllers in terms of task completion time and user satisfaction. We also identify factors influencing user performance, including gaze accuracy and visual attention. The results inform the design of more intuitive and efficient AR interaction systems.