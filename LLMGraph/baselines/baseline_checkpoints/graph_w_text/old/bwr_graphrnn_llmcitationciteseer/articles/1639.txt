Node representation learning is a fundamental task in graph-based machine learning, but existing methods often struggle to capture complex relationships between nodes. This paper introduces Hierarchical Graph Attention Networks (HGAT), a novel architecture that leverages hierarchical graph structures to learn node representations. HGAT employs a multi-level attention mechanism to aggregate features from neighboring nodes, incorporating both local and global context. We evaluate HGAT on several benchmark datasets, demonstrating its ability to outperform state-of-the-art methods in node classification and graph-based clustering tasks.