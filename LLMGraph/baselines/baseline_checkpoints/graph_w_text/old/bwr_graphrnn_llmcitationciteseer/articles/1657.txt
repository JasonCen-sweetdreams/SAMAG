Multimodal sentiment analysis has gained significant attention in recent years, but the task's complexity necessitates efficient model design. This paper proposes a novel neural architecture search (NAS) framework, 'MMNAS', tailored to multimodal sentiment analysis. MMNAS leverages a differentiable search space and a sentiment-aware reward function to optimize the architecture for better performance and reduced computational cost. Experimental results on the CMU-MOSI dataset demonstrate that MMNAS discovers architectures that outperform handcrafted models while reducing the search time by an order of magnitude.