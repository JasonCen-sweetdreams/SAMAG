Node classification is a fundamental task in graph-structured data, but existing methods often struggle with scalability. We propose a novel hierarchical graph attention network (HGAT) that leverages a multi-level attention mechanism to selectively focus on relevant graph structures. HGAT can handle large graphs by recursively applying attention at each level, allowing it to adapt to varying graph densities. We evaluate HGAT on several real-world datasets, demonstrating its ability to achieve state-of-the-art performance while reducing computation time by up to 75% compared to existing methods.