Sentiment analysis in social media has become increasingly important for businesses and organizations. However, the complexity of handling multimodal data (e.g., text, images, videos) and the scarcity of labeled data hinder the development of accurate models. This paper explores the effectiveness of deep transfer learning for multimodal sentiment analysis. We propose a novel architecture that leverages pre-trained convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to extract features from images and text, respectively. Experimental results on a large-scale social media dataset demonstrate that our approach outperforms state-of-the-art methods, achieving an F1-score of 92.5% on a challenging multimodal sentiment analysis task.