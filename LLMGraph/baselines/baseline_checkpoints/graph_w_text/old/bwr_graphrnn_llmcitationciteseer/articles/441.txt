Query expansion is a crucial step in ad-hoc retrieval, but existing methods often rely on hand-crafted rules or unsupervised learning. This paper proposes a novel deep reinforcement learning approach, 'RL-Expander', which learns to expand queries by optimizing a reward function that balances relevance and diversity. We employ a hierarchical policy network that integrates semantic and syntactic features of query terms and documents. Experimental results on the TREC Ad-hoc Retrieval dataset demonstrate that RL-Expander outperforms state-of-the-art methods in terms of NDCG@10 and MAP, while reducing the number of irrelevant documents retrieved.