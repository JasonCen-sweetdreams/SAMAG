In industrial settings, human-robot collaboration is crucial for efficient task completion. This paper presents a novel multimodal embodied conversational agent (ECA) that leverages computer vision, natural language processing, and machine learning to facilitate seamless human-robot interaction. Our ECA, 'RoboGuide', uses gaze, gesture, and speech to understand human intent and provide context-aware guidance. We conduct a user study in a real-world industrial setting, demonstrating that RoboGuide significantly improves task completion time and user satisfaction compared to traditional interface-based interaction methods.