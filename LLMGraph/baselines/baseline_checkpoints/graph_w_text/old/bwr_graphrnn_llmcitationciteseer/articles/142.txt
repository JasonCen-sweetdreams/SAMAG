Ad-hoc retrieval systems often struggle to accurately capture the nuances of user queries, leading to suboptimal results. This paper proposes a novel approach to query expansion using graph-based semantic embeddings. We leverage a heterogeneous graph that integrates word co-occurrence, semantic role labeling, and entity relationships to learn dense vector representations of query terms. These embeddings are then utilized to expand the original query, incorporating context-aware semantic relatedness. Experimental results on the TREC dataset demonstrate significant improvements in retrieval performance, outperforming state-of-the-art methods by up to 15% in terms of mean average precision.