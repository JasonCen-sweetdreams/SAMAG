In multi-agent systems, task allocation is a crucial problem that requires efficient coordination among agents to achieve global objectives. This paper proposes a decentralized task allocation framework using deep reinforcement learning, where each agent learns to make decisions based on local observations and communication with neighboring agents. Our approach utilizes a hierarchical architecture, combining graph neural networks for agent representation and deep Q-networks for task allocation. Experimental results on various benchmark scenarios demonstrate the effectiveness of our method in terms of task completion rate, communication overhead, and scalability.