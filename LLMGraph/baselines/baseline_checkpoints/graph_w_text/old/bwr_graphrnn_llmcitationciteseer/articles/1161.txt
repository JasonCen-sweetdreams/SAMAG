The scalability of information retrieval systems is crucial for handling massive document collections. This paper proposes a novel hierarchical document embedding approach, HiDE, which enables efficient retrieval in large-scale systems. HiDE leverages a hierarchical clustering algorithm to group semantically similar documents and represents each cluster as a dense vector. We demonstrate that HiDE achieves significant improvements in retrieval efficiency while maintaining comparable accuracy to state-of-the-art dense retrieval models. Experimental results on the TREC 2020 benchmark show that HiDE reduces the retrieval latency by up to 50% compared to existing methods.