Coordinating heterogeneous multi-agent systems is a challenging problem in many real-world applications, such as smart cities and autonomous vehicles. This paper presents a novel approach that leverages deep graph reinforcement learning to learn effective coordination strategies for agents with different capabilities and goals. We propose a graph neural network-based framework that integrates attention mechanisms and reinforcement learning to learn a shared coordination policy. Experimental results on a simulated urban traffic scenario demonstrate that our approach outperforms traditional decentralized control methods and achieves better system-wide performance.