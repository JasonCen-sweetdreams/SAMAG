Virtual reality (VR) has the potential to revolutionize accessibility, but existing VR interfaces often exclude users with visual impairments. This paper presents a novel framework for designing inclusive VR interfaces that cater to users with varying levels of visual impairment. We conducted a user study with 20 participants to identify key challenges and opportunities in VR interaction. Our findings inform the development of 'EchoSense', a VR interface that leverages audio and haptic feedback to facilitate navigation and object manipulation. Results show that EchoSense enables users with visual impairments to complete tasks with significantly higher accuracy and satisfaction compared to traditional VR interfaces.