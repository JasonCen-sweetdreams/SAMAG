Distributed database systems have become increasingly popular in modern data-intensive applications. However, query optimization remains a challenging problem due to the complexity of distributed query plans. This paper proposes a novel approach to query optimization using machine learning. We develop a deep reinforcement learning framework that learns to optimize query plans based on runtime statistics and database characteristics. Our experimental results on a real-world dataset show that the proposed approach outperforms traditional query optimizers by up to 30% in terms of query execution time.