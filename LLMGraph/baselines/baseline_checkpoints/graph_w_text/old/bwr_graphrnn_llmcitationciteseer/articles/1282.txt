Virtual reality (VR) systems often rely on cumbersome controllers or gestures, limiting the sense of immersion. We propose a gaze-based interaction framework, 'GazeVR', which leverages deep learning to track users' eye movements and infer their intentions. Our approach utilizes a convolutional neural network (CNN) to classify gaze patterns and a recurrent neural network (RNN) to predict user actions. We conduct a user study with 20 participants, demonstrating that GazeVR achieves high accuracy and user satisfaction in various VR tasks, including object selection and manipulation.