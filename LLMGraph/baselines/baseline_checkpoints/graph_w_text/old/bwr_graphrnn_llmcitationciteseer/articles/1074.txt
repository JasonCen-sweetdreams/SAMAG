Graph neural networks (GNNs) have achieved state-of-the-art performance on various node classification tasks. However, they often require large amounts of labeled data, which can be costly to obtain. This paper proposes a hierarchical graph attention network (HGAT) that tackles few-shot node classification by learning attention weights at multiple graph scales. Our approach leverages meta-learning to adapt to new classes and few labeled samples. Experimental results on several benchmark datasets demonstrate that HGAT outperforms existing few-shot learning methods and achieves competitive performance with fully supervised GNNs.