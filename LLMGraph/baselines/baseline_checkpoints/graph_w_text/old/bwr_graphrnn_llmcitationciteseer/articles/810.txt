gesture recognition systems have shown promise in enhancing human-computer interaction for individuals with disabilities. However, existing approaches often rely on generic models that fail to account for the unique characteristics of individuals with disabilities. This paper presents a novel approach to personalized hand gesture recognition, leveraging a combination of machine learning and computer vision techniques. We collect a dataset of hand gestures from individuals with varying abilities and develop a framework for creating customized models that adapt to individual differences. Our results demonstrate significant improvements in recognition accuracy and user satisfaction, highlighting the potential for personalized gesture recognition to promote greater accessibility in HCI.