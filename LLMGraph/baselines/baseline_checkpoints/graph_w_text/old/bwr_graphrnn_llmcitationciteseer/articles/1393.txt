Coordinating heterogeneous multi-agent systems (MAS) in complex environments is a challenging problem. We propose a decentralized reinforcement learning (DRL) framework that enables agents to learn coordinated policies without relying on a centralized controller. Our approach utilizes a novel graph-attention mechanism to facilitate communication and cooperation among agents, leading to improved overall system performance. We evaluate our method in a simulated supply chain management scenario, demonstrating significant gains in efficiency and adaptability compared to traditional centralized control strategies.