Virtual reality (VR) technology has the potential to revolutionize various aspects of our lives, but existing interaction methods can be inaccessible or uncomfortable for people with disabilities. This paper presents a novel gaze-based interaction system for VR, designed to be more inclusive and intuitive. We leverage machine learning algorithms to accurately detect and track user gaze, enabling seamless interaction with virtual objects. Our user study with participants from diverse abilities demonstrates significant improvements in usability and user experience. We also discuss the implications of our system for promoting accessibility in VR applications.