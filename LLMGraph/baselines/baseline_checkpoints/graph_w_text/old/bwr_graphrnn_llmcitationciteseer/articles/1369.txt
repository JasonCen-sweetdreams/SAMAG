Time-series anomaly detection is crucial in various domains, but traditional methods often lack interpretability. We propose a novel hierarchical attention network (HAN) architecture that detects anomalies while providing explanations for its decisions. HAN leverages self-attention mechanisms to capture complex temporal dependencies and identify salient features contributing to anomalies. Our experiments on real-world datasets demonstrate that HAN outperforms state-of-the-art methods in terms of detection accuracy and F1-score, while also providing insightful visualizations of anomaly explanations.