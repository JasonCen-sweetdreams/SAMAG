Explainability is crucial in multi-agent reinforcement learning (MARL) to understand agent interactions and decision-making. We propose a novel hierarchical attention network (HAT) that learns to focus on relevant agents and their interactions to improve explainability. HAT consists of two attention mechanisms: agent-level attention to identify influential agents and a hierarchical attention mechanism to capture complex agent interactions. Experimental results on a range of MARL benchmarks demonstrate that HAT outperforms state-of-the-art methods in terms of both performance and explainability, providing insights into agent decision-making.