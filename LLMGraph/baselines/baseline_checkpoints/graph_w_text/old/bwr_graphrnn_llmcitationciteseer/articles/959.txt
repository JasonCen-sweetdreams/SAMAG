Individuals with motor disabilities face significant barriers when interacting with gesture-based interfaces. This paper presents 'AdaptiGesture', a novel framework that adaptively adjusts gesture recognition thresholds and models based on an individual's abilities. We conducted a user study with 20 participants with varying motor disabilities and found that AdaptiGesture outperforms existing gesture recognition systems, achieving a 35% reduction in false negatives and a 25% increase in recognition accuracy. Our approach has implications for the design of more inclusive and accessible human-computer interfaces.