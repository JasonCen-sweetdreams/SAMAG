Graph neural networks (GNNs) have shown promising results in various applications, but their performance heavily relies on careful hyperparameter tuning. In this paper, we propose a novel Bayesian optimization framework, 'GNN-BO', tailored to the specific characteristics of GNNs. By incorporating graph structure information into the acquisition function, GNN-BO efficiently explores the hyperparameter space and converges to optimal solutions faster than existing methods. Experiments on several benchmark datasets demonstrate that GNN-BO achieves state-of-the-art performance in node classification and graph regression tasks, while reducing the computational cost by up to 70%.