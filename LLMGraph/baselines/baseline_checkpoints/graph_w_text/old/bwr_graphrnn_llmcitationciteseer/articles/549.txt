Conversational systems have become increasingly popular, but generating accurate and timely responses to user queries remains a significant challenge. This paper explores the application of deep reinforcement learning to real-time question answering in conversational systems. We propose a novel architecture, 'ConverseQA', which leverages a hierarchical reinforcement learning framework to optimize response generation. Our approach incorporates a reward function that balances response accuracy, fluency, and latency. Experimental results on a large-scale conversational dataset demonstrate that ConverseQA outperforms state-of-the-art methods in terms of response quality and response time.