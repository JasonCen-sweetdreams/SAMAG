As smart home devices become increasingly prevalent, there is a growing need for intuitive and hands-free interaction methods. This paper explores the design and evaluation of mid-air gesture recognition systems for smart home devices. We propose a novel machine learning-based approach that leverages computer vision and skeletal tracking data to recognize a range of gestures. Our user study with 30 participants demonstrates that our system achieves an average accuracy of 92.5% and outperforms existing gesture recognition systems in terms of user experience and performance. We discuss the implications of our findings for the development of invisible interfaces and provide recommendations for designers and developers.