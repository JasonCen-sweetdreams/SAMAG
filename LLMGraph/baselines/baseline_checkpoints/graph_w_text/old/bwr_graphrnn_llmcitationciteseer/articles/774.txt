Accurate time series forecasting is crucial in various domains, including finance, healthcare, and climate science. However, existing methods often rely on labeled data, which can be scarce or expensive to obtain. This paper introduces a novel self-supervised approach, 'TS-CoDim', that leverages contrastive learning to learn effective representations for time series forecasting. By minimizing the distance between positive pairs of time series segments in a lower-dimensional space, TS-CoDim captures inherent patterns and trends, enabling accurate forecasting without requiring labeled data. Experimental results on popular benchmarks demonstrate that TS-CoDim outperforms state-of-the-art self-supervised and semi-supervised methods, while being more computationally efficient.