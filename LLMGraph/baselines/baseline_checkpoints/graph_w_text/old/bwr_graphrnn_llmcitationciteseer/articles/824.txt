Coordinating heterogeneous multi-agent systems is a challenging problem in artificial intelligence, particularly when agents have different goals, capabilities, and communication protocols. This paper proposes a novel framework, 'HeteroRL', which leverages reinforcement learning to coordinate agents in such systems. HeteroRL learns to generate task assignments, communication protocols, and coordination strategies that maximize the overall system performance. We evaluate HeteroRL in a simulated disaster response scenario, demonstrating improved response times and resource allocation compared to traditional, hand-crafted coordination approaches.