This paper addresses the problem of task allocation in heterogeneous multi-agent systems, where agents with diverse capabilities and constraints need to perform complex tasks in a decentralized manner. We propose a novel deep reinforcement learning approach, 'Dec-HRL', which learns to allocate tasks based on agent capabilities, task requirements, and environmental constraints. Dec-HRL utilizes a hierarchical representation of tasks and agents, enabling efficient exploration of the vast action space. Experimental results on a simulated search-and-rescue scenario demonstrate that Dec-HRL outperforms traditional optimization-based approaches in terms of task completion time and agent utilization.