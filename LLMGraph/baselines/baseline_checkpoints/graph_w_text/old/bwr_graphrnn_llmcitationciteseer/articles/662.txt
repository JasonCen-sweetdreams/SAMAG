Dialogue generation models often struggle to provide transparent and interpretable responses. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates explainability mechanisms into the dialogue generation process. Our HAN model employs a multi-level attention framework that selectively focuses on relevant input context, knowledge graph entities, and dialogue history to generate coherent and informative responses. We evaluate our approach on the DSTC9 dataset and demonstrate significant improvements in both response quality and explainability compared to state-of-the-art baselines.