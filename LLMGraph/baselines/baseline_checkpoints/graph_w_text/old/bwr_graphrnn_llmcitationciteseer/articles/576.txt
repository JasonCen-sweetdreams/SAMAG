Ad-hoc retrieval remains a challenging task in information retrieval, particularly when dealing with complex query structures and lengthy documents. This paper proposes a novel hierarchical document representation model, 'HiAtt', which leverages neural attention mechanisms to selectively focus on relevant document segments. Our approach combines a coarse-grained sentence-level encoder with a fine-grained word-level attention module, enabling the model to capture both local and global contextual relationships. Experimental results on the TREC Robust04 dataset demonstrate that HiAtt significantly outperforms state-of-the-art retrieval models, achieving a 15% increase in mean average precision.