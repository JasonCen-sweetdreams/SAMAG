Time series forecasting is a crucial task in many real-world applications, but the lack of interpretability in modern deep learning models hinders their adoption. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that incorporates attention mechanisms at multiple scales to provide explainable time series forecasting. Our approach learns to focus on relevant input features and time steps, enabling visualization of the model's decision-making process. We evaluate HAN on several benchmark datasets and demonstrate its superiority over state-of-the-art methods in terms of forecasting accuracy and interpretability.