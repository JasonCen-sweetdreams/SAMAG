Multi-agent systems face challenges in dynamic environments where task allocation and coordination are crucial. This paper presents a decentralized task allocation framework using multi-agent reinforcement learning (MARL) that adapts to changing environmental conditions. Our approach, 'AdaptMA', utilizes a graph neural network to model agent interactions and a novel reward function that balances individual and collective performance. We evaluate AdaptMA on a simulated disaster response scenario, demonstrating improved task completion rates and reduced communication overhead compared to traditional centralized approaches.