This paper presents a novel approach to designing gesture recognition systems that adapt to individuals with motor impairments. We developed a machine learning-based framework that leverages a wearable inertial measurement unit (IMU) and a computer vision system to recognize gestures. Our approach uses a transfer learning strategy to fine-tune a pre-trained model on a small dataset of gestures performed by individuals with motor impairments. We evaluated our system with 15 participants and achieved an average recognition accuracy of 92.5%, outperforming state-of-the-art systems. Our findings suggest that adaptive gesture recognition systems can significantly improve the accessibility of human-computer interfaces for people with motor impairments.