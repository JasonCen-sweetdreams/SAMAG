Recent advances in neural query embeddings have shown promising results in ad-hoc retrieval tasks. However, most approaches rely on a single neural model, which may not generalize well to diverse query types and domains. This paper proposes a ranking ensemble framework, 'NERVE', that combines multiple neural query embeddings to improve the robustness and accuracy of retrieval models. We introduce a novel query-aware weighting scheme that adaptively assigns importance to individual models based on their confidence and relevance to the query. Experimental results on several benchmark datasets demonstrate that NERVE outperforms state-of-the-art single-model approaches, achieving significant improvements in mean average precision and normalized discounted cumulative gain.