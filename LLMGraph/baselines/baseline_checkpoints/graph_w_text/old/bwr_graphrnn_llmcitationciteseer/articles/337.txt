In multi-agent systems, understanding the decision-making process of individual agents is crucial for trust and reliability. This paper proposes a novel hierarchical attention network (HAN) framework for explainable decision making in multi-agent environments. Our HAN architecture consists of two stages: (1) intra-agent attention, which captures feature importance within each agent's state, and (2) inter-agent attention, which models the interactions and relationships between agents. We demonstrate the effectiveness of our approach on a real-world autonomous vehicle scenario, showcasing improved performance and interpretability compared to traditional reinforcement learning methods.