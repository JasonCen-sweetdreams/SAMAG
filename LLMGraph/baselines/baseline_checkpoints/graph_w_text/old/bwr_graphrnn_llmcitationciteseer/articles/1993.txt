This paper presents a novel approach to coordinating multi-agent systems for urban traffic management using deep reinforcement learning. We propose a decentralized framework, where each agent learns to adapt to the dynamic environment and cooperate with neighboring agents to minimize congestion and reduce travel times. Our approach integrates graph neural networks with deep Q-networks to learn cooperative policies that balance individual agent objectives with system-level optimality. Experimental results on a realistic traffic simulator demonstrate the effectiveness of our approach in reducing traffic congestion and improving overall network efficiency.