Recent advances in deep learning have led to the development of powerful image classification models, but their vulnerability to adversarial attacks remains a significant concern. This paper proposes a novel adversarial training framework that focuses on image-agnostic attacks, which are independent of the input image. We introduce a new set of attack algorithms that generate perturbations in the frequency domain, and demonstrate their effectiveness against state-of-the-art models. Our experiments show that models trained using our framework exhibit improved robustness against a range of image-agnostic attacks, while maintaining competitive performance on clean images.