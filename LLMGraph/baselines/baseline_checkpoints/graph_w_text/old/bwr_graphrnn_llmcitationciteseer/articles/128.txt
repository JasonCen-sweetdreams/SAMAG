Explainability is a crucial aspect of multi-agent decision-making, particularly in real-world applications like autonomous vehicles and smart homes. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in cooperative multi-agent systems. Our HAN model learns to attend to relevant agents and their local observations, generating attention weights that provide insights into the decision-making process. We evaluate our approach on a synthetic traffic simulation environment and demonstrate improved explainability and decision quality compared to existing methods.