Dense passage indexing has emerged as a promising approach for efficient open-domain question answering. However, existing methods rely on dense retrieval models that are computationally expensive and memory-intensive. This paper proposes a novel deep retrieval framework, 'DRIFT', which leverages a hierarchical neural architecture to effectively prune irrelevant passages and reduce the search space. We introduce a sparse attention mechanism that adaptively focuses on relevant contextual information, resulting in significant improvements in both retrieval efficiency and accuracy. Experimental results on the Natural Questions benchmark demonstrate that DRIFT outperforms state-of-the-art methods while requiring fewer computational resources.