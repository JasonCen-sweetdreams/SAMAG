Explainability is crucial in multi-agent systems where agents learn to cooperate or compete. This paper introduces a novel hierarchical attention network (HAN) architecture for explainable multi-agent reinforcement learning. HAN learns to focus on relevant agents, states, and actions, generating interpretable attention weights that reveal the decision-making process. We evaluate HAN on a suite of cooperative and competitive tasks, showing improved performance and interpretability compared to existing methods. Additionally, we propose a novel metric, Attention-based Explainability Score (AES), to quantify the explainability of multi-agent systems.