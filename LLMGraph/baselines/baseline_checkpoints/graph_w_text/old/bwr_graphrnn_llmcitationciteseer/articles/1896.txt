In multi-agent systems, task allocation is a crucial problem that requires efficient and robust decision-making. This paper proposes a novel approach, 'UA-RS', which integrates uncertainty-aware reward shaping into a decentralized task allocation framework. We model agent uncertainty using Bayesian neural networks and incorporate it into the reward function to encourage risk-averse behavior. Experimental results on a simulated disaster response scenario demonstrate that UA-RS outperforms state-of-the-art methods in terms of task completion rates and adaptability to changing environmental conditions.