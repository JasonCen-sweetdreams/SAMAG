Explainable recommendation systems have gained significant attention in recent years, as users increasingly demand transparency in AI-driven decision-making. This paper proposes a novel hierarchical graph attention network (HGAN) architecture, which incorporates both user-item interactions and contextual features to generate personalized recommendations. Our approach leverages a dual-attention mechanism to capture complex relationships between entities and attributes, enabling the model to provide interpretable explanations for its suggestions. Experimental results on several benchmark datasets demonstrate the effectiveness of HGAN in improving recommendation accuracy and explainability.