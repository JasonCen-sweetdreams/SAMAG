Multi-agent reinforcement learning (MARL) has seen significant advances in recent years, but the lack of interpretability and explainability hinders its adoption in real-world applications. This paper proposes a novel hierarchical attention network (HAN) architecture for MARL, which enables agents to selectively focus on relevant information from their observations and teammates' actions. We demonstrate that HAN improves both the learning efficiency and final performance of MARL algorithms in complex environments, while providing insights into the decision-making process through attention visualization. Experimental results on a decentralized robot navigation task show the effectiveness of our approach.