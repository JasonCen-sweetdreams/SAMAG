In multi-agent systems, coalition formation is a crucial problem that involves forming groups of agents to achieve common goals. This paper proposes a novel approach to adaptive coalition formation using deep reinforcement learning. We design a neural network-based architecture that learns to form coalitions by maximizing a reward function based on the agents' individual and collective goals. Our approach adapts to changing environments and agent behaviors, and we demonstrate its effectiveness in a simulated robotics domain. Experimental results show that our method outperforms traditional coalition formation algorithms in terms of goal achievement and adaptability.