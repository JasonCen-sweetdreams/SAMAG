Time-series anomaly detection is crucial in various domains, including finance, healthcare, and IoT. However, existing approaches often lack interpretability, making it challenging to identify the root cause of anomalies. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that leverages self-attention mechanisms to learn hierarchical representations of time-series data. Our approach enables explainable anomaly detection by identifying the most relevant segments and features contributing to the anomalies. Experimental results on real-world datasets demonstrate the effectiveness of HAN in detecting anomalies while providing insightful explanations.