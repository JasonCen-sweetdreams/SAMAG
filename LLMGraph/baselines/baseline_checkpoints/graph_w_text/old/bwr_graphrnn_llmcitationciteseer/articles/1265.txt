Deep reinforcement learning has achieved remarkable success in multi-agent environments, but its lack of interpretability hinders its adoption in real-world applications. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent reinforcement learning. Our approach incorporates attention mechanisms at both the agent and team levels, allowing for transparent identification of influential agents and their contributions to team rewards. Experiments on a series of cooperative and competitive game scenarios demonstrate the effectiveness of HAN in improving team performance while providing actionable insights into agent interactions.