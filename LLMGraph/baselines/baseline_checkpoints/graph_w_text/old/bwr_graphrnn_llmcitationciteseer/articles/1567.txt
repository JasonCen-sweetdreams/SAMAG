Cloud computing platforms face the challenge of optimizing resource allocation to meet dynamic workload demands while minimizing energy consumption and costs. This paper proposes a novel hierarchical reinforcement learning (HRL) framework, 'CloudOpt', which integrates a high-level resource manager with low-level controllers for fine-grained allocation. Our approach leverages deep Q-networks to learn optimal resource allocation policies, and we introduce a novel reward function that balances performance, energy efficiency, and cost. Experimental results on a realistic cloud simulation platform demonstrate that CloudOpt outperforms existing heuristics and model-based optimization methods, achieving up to 25% energy savings and 30% cost reduction.