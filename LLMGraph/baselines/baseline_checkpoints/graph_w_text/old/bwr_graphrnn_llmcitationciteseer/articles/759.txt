This paper proposes a novel decentralized task allocation framework for autonomous agents using graph neural networks (GNNs). We model the agent network as a graph, where each node represents an agent and edges signify communication links. Our approach, dubbed 'GNN-TA', leverages GNNs to learn a distributed task allocation policy that minimizes latency and maximizes overall system utility. Experimental results on a simulated robotic swarm demonstrate that GNN-TA outperforms traditional decentralized methods, achieving a 25% reduction in task completion time and a 30% increase in system throughput.