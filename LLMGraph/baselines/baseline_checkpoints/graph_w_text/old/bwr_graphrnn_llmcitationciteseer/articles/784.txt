Multi-agent systems often require efficient task allocation to achieve collective goals. However, existing methods struggle to adapt to dynamic environments and diverse agent capabilities. We propose a novel approach, 'DeepTask', which leverages deep reinforcement learning to learn adaptive task allocation policies. DeepTask uses a decentralized, communication-efficient architecture that incorporates agent-specific Q-networks and a centralized critic network. Experimental results on a simulated robotic search-and-rescue scenario demonstrate that DeepTask outperforms state-of-the-art methods in terms of task completion time and overall system efficiency.