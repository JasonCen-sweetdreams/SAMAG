Distributed database systems (DDS) have become ubiquitous in modern data centers, but optimizing query performance remains a significant challenge. This paper explores the application of reinforcement learning (RL) to optimize query execution plans in DDS. We propose an RL-based framework that learns to predict optimal query plans based on workload characteristics and system performance metrics. Our experimental evaluation on a real-world DDS benchmark demonstrates that our approach outperforms traditional query optimization techniques by up to 30% in terms of query latency and resource utilization.