In multi-agent reinforcement learning, understanding the decision-making process of individual agents is crucial for effective teamwork and coordination. This paper introduces HAN-MARL, a hierarchical attention network that provides explainable policy learning for multi-agent systems. By incorporating attention mechanisms at both the agent and team levels, HAN-MARL learns to focus on relevant information and relationships between agents, resulting in improved coordination and overall team performance. We evaluate HAN-MARL on a variety of multi-agent environments and demonstrate its ability to provide interpretable insights into agent decision-making.