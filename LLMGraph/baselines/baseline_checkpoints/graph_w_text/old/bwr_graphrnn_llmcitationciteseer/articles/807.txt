This paper presents a novel approach to distributed agent coordination using hierarchical graph neural networks (HGNNs). We propose a decentralized framework where agents learn to represent their local interactions as graph structures, which are then aggregated to form a hierarchical representation of the global system. This enables agents to make coordinated decisions while adapting to dynamic changes in their local environment. We evaluate our approach on a simulated robot swarm task and demonstrate improved coordination and adaptability compared to traditional decentralized control methods.