Conversational search systems rely on reformulating user queries to retrieve relevant documents efficiently. However, existing approaches often rely on simplistic keyword extraction or manual rules, leading to suboptimal performance. This paper proposes a novel deep learning framework, 'ConverseQR', which leverages a hierarchical attention mechanism to model query-document interactions. ConverseQR learns to identify salient query terms, recognize contextual dependencies, and generate refined queries that better capture user intent. Experimental results on the TREC Conversational Assistance Track dataset demonstrate significant improvements in retrieval effectiveness and efficiency compared to state-of-the-art baselines.