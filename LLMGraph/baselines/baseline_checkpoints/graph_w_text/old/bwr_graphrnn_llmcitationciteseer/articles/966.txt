Ad-hoc retrieval systems often struggle to effectively expand user queries, leading to suboptimal retrieval performance. This paper proposes a novel reinforcement learning-based approach, 'RL-QE', which learns to select optimal expansion terms by maximizing a reward function that balances query semantics and document relevance. RL-QE outperforms state-of-the-art query expansion methods on several benchmark datasets, achieving significant improvements in mean average precision and normalized discounted cumulative gain. Our analysis reveals that RL-QE adapts well to diverse query types and document collections, making it a promising solution for real-world information retrieval systems.