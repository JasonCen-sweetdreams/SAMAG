Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks. However, the lack of transparency and interpretability in DRL models hinders their adoption in real-world applications. This paper proposes a novel approach, called 'Explainable Model-based RL' (EMRL), which integrates model-based representation learning with feature importance-based explainability techniques. EMRL enables the generation of actionable explanations for DRL agents' decisions, improving trust and decision-making efficiency. Our experiments on Atari games and robotic control tasks demonstrate the effectiveness of EMRL in balancing explainability and performance.