This paper introduces 'GestoCare', a novel framework for designing adaptive gesture-based interfaces tailored to individuals with motor disabilities. GestoCare leverages machine learning-based gesture recognition and probabilistic modeling to dynamically adjust interface parameters, such as gesture tolerance and feedback mechanisms, based on user performance and fatigue levels. We evaluate GestoCare through a user study with 20 participants, demonstrating significant improvements in interaction accuracy and user satisfaction compared to traditional one-size-fits-all approaches. Our findings have implications for the development of more inclusive and accessible human-computer interaction systems.