Traditional information retrieval systems rely on bag-of-words representations, which fail to capture nuanced semantic relationships between documents and queries. This paper presents a novel hierarchical neural ranking model, HierRank, that leverages transformer-based architectures to encode documents and queries hierarchically. HierRank learns to aggregate semantic features from multiple levels of abstraction, improving retrieval performance on long-tail queries. Experimental results on the TREC-2004 dataset demonstrate a 15% increase in mean average precision compared to state-of-the-art neural ranking models.