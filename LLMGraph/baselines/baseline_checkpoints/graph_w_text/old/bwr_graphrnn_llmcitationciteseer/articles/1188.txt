In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a novel decentralized approach using graph neural networks (GNNs) to allocate tasks to agents in a distributed manner. Our method, called DecTAG, exploits the structural properties of the agent interaction graph to learn a task allocation policy that adapts to changing environmental conditions. We evaluate DecTAG on a range of benchmark scenarios, demonstrating improved task completion rates and reduced communication overhead compared to traditional centralized and decentralized approaches. The proposed framework has potential applications in autonomous robotics, smart cities, and disaster response.