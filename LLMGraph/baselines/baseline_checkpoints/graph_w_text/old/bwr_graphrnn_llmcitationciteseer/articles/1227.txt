Deep neural networks are prone to overconfident predictions on out-of-distribution (OOD) inputs, which can lead to unexpected failures in real-world applications. This paper presents a novel hierarchical self-supervised learning framework, 'HierODD', that leverages the clustering structure of the input data to detect OOD samples. By learning a hierarchical representation of the input space, HierODD can identify anomalies at multiple scales, achieving state-of-the-art detection performance on several benchmark datasets. We also show that HierODD can be seamlessly integrated with existing models, providing a robust and efficient solution for OOD detection in various domains.