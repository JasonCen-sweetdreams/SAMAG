Recent advances in deep reinforcement learning have led to the development of complex multi-agent systems. However, the lack of transparency in these systems hinders their adoption in real-world scenarios. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent reinforcement learning. Our approach learns to attend to relevant agents, states, and actions, providing insights into the decision-making process. We evaluate HAN on a range of cooperative and competitive environments, demonstrating improved performance and interpretability compared to state-of-the-art methods.