Commonsense question answering (CQA) has emerged as a challenging task in natural language processing, requiring models to reason about implicit relationships between entities and events. We propose a novel hierarchical attention-based framework, 'HARE', which leverages symbolic reasoning to provide interpretable explanations for its predictions. HARE exploits the graph structure of knowledge graphs to recursively attend to relevant entities and relationships, enabling the model to capture complex contextual dependencies. Our experiments on the CommonsenseQA dataset demonstrate significant improvements in accuracy and explainability over state-of-the-art models.