Deep reinforcement learning (DRL) has achieved remarkable success in robotics, but the lack of transparency and interpretability hinders its widespread adoption. This paper presents a novel explainability framework, dubbed 'RL-X', which leverages attention mechanisms and model-agnostic saliency maps to provide insights into DRL decision-making processes. We demonstrate the effectiveness of RL-X on two robotic tasks, namely, robotic arm manipulation and autonomous driving, and show that our approach improves model trustworthiness without compromising performance.