In multi-agent systems, task allocation is a challenging problem that requires efficient and adaptive decision-making. This paper proposes a decentralized task allocation framework that leverages deep reinforcement learning to enable agents to learn from their interactions and adapt to changing environmental conditions. We introduce a novel neural network architecture that combines graph convolutional layers with multi-agent Q-networks to learn effective task allocation policies. Experimental results on a simulated disaster response scenario demonstrate that our approach outperforms traditional centralized and decentralized methods in terms of task completion time and agent utility.