Neural search has revolutionized information retrieval by leveraging deep learning models to capture semantic query-document relationships. However, the effectiveness of neural search hinges on the quality of query representations. This paper proposes a novel query expansion method, ConEx, which employs contrastive learning to refine query embeddings. ConEx learns to identify informative terms in the query context and generates expanded queries that better capture user intent. Our experiments on the TREC DL benchmark demonstrate that ConEx significantly improves the retrieval performance of state-of-the-art neural search models, achieving a 15% increase in mean average precision.