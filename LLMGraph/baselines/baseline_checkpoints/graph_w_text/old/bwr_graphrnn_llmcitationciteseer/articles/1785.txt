Graph neural networks (GNNs) have achieved state-of-the-art performance in various node classification tasks. However, existing GNN architectures often overlook the hierarchical structure inherent in many real-world graphs. This paper proposes a novel hierarchical attention-based GNN (HAGNN) framework that captures both local and global dependencies in graph-structured data. By incorporating a hierarchical attention mechanism, HAGNN learns to selectively focus on relevant nodes and subgraphs, leading to improved performance and interpretability. Experimental results on several benchmark datasets demonstrate the effectiveness of HAGNN in node classification tasks, outperforming existing state-of-the-art models.