Traditional document representation methods in Information Retrieval (IR) rely on bag-of-words or shallow neural networks, which fail to capture complex semantic relationships between entities and context. We propose a novel Hierarchical Graph Attention Network (HGAT) that models documents as graphs, where entities, sentences, and paragraphs are nodes with attention-based interactions. HGAT learns to weigh importance of entities, sentences, and paragraphs, leading to a more comprehensive and efficient document representation. Our experiments on several benchmark datasets demonstrate significant improvements in retrieval performance, especially for long documents and rare entities.