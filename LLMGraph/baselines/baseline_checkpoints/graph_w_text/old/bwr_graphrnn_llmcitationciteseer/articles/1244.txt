 Gesture-based authentication has gained popularity for wearable devices, but existing methods often rely on able-bodied users' motor skills, excluding users with disabilities. This paper presents 'AdaptaSign', a novel gesture-recognition system that adaptively adjusts to individual users' motor abilities. Our approach leverages machine learning to identify subtle patterns in gesture data, enabling authentication for users with varying levels of dexterity. A user study with 30 participants, including those with motor impairments, demonstrates AdaptaSign's effectiveness in balancing security and accessibility.