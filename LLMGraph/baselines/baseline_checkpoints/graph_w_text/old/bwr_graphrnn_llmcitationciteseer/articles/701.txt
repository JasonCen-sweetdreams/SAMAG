Despite advances in neural ranking models, search engines still rely on traditional query expansion techniques to improve retrieval efficiency. This paper proposes a novel neural query expansion approach, 'NQE', that leverages a transformer-based architecture to learn context-aware term embeddings. By incorporating NQE into a production-ready search engine, we demonstrate significant improvements in retrieval efficiency (up to 30%) while maintaining state-of-the-art ranking performance. Our experiments on a large-scale web corpus highlight the benefits of NQE in handling noisy and ambiguous queries.