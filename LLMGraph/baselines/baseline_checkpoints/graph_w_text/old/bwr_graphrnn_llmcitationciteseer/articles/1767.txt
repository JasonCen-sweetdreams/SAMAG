In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a decentralized task allocation framework, 'RL-Allocator', which leverages reinforcement learning to assign tasks to agents based on their capabilities and environmental dynamics. We model the allocation problem as a Markov decision process and apply a distributed Q-learning algorithm, enabling agents to adapt to changing task requirements and agent availability. Experimental results on a simulated disaster response scenario demonstrate that RL-Allocator outperforms traditional centralized allocation methods in terms of task completion time and agent utilization.