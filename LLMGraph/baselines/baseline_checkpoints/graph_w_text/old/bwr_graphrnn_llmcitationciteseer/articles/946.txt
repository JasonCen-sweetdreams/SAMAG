Individuals with motor impairments often face challenges when interacting with gesture recognition systems. This paper presents a novel adaptive framework, ' GestureAdapt', which leverages machine learning and computer vision techniques to personalize gesture recognition models for users with motor impairments. We introduce a hierarchical representation of gestures, allowing the system to adapt to varying levels of impairment. Our evaluation with 20 participants shows that GestureAdapt outperforms state-of-the-art methods in terms of gesture recognition accuracy and user satisfaction, providing a more inclusive and accessible interaction experience for individuals with motor impairments.