Virtual assistants have become ubiquitous in modern computing, but interacting with them can be cumbersome. This paper presents a novel gaze-based interaction system that leverages deep learning-based eye movement analysis to enable hands-free control. We propose a convolutional neural network (CNN) architecture that learns to classify eye movements into distinct commands, achieving an accuracy of 95.6% on our collected dataset. Our system, 'GazeVA', is evaluated in a user study, demonstrating improved interaction efficiency and user satisfaction compared to traditional voice-based input methods.