Few-shot image classification remains a challenging problem in computer vision. This paper presents a novel approach that leverages meta-learning to facilitate efficient transfer learning for few-shot image classification tasks. Our proposed method, 'MetaTL', learns a meta-model that can adapt to new tasks with only a few examples. We introduce a task-agnostic embedding space that enables knowledge transfer from base classes to novel classes. Experiments on benchmark datasets demonstrate that MetaTL outperforms state-of-the-art methods in terms of accuracy and requires significantly fewer parameters and computations.