In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper presents a decentralized task allocation framework, 'DRL-TA', which leverages deep reinforcement learning to optimize task assignments. We formulate the problem as a Markov decision process and propose a novel, actor-critic architecture that incorporates communication costs and task dependencies. Experimental results on a simulated robotic search and rescue scenario demonstrate that DRL-TA outperforms traditional, centralized allocation methods in terms of task completion rate and overall system efficiency.