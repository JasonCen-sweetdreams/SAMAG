This paper presents a novel approach to coordinating multi-agent systems using distributed reinforcement learning with graph attention. We introduce a decentralized framework, 'GraphMA', which enables agents to learn coordinated policies in complex, dynamic environments. GraphMA incorporates a graph attention mechanism to selectively focus on relevant agents and their interactions, thereby improving learning efficiency and scalability. Experimental results on a variety of multi-agent tasks demonstrate the effectiveness of GraphMA in achieving superior coordination and adaptability compared to existing methods.