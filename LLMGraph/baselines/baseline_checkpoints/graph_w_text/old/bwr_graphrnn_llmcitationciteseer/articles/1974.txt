Conversational AI systems often struggle to provide transparent and interpretable decision-making processes, hindering trust and adoption. This paper introduces HAN-Dial, a hierarchical attention network architecture for dialogue management that generates explanations for its responses. HAN-Dial employs a novel attention mechanism that learns to focus on relevant context, intents, and dialogue history, allowing for more accurate and informative responses. We evaluate HAN-Dial on a benchmark dialogue dataset, demonstrating improved response quality and explanation plausibility compared to state-of-the-art models. Our approach has significant implications for developing more trustworthy and human-centered conversational AI systems.