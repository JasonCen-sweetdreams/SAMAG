Graph Neural Networks (GNNs) have achieved state-of-the-art performance in various graph-based applications. However, recent studies have shown that GNNs are vulnerable to adversarial attacks, which can significantly degrade their performance. This paper presents a comprehensive survey of recent advances in adversarial attacks on GNNs, including poisoning, evasion, and graph-based attacks. We also introduce a benchmark framework, 'GNN-Bench', to evaluate the robustness of GNNs against various attack strategies. Our experiments on several popular GNN models and datasets demonstrate the effectiveness of our benchmark and highlight the need for developing robust GNN architectures.