Existing neural document embedding models are computationally expensive and often fail to capture the hierarchical structure of documents. This paper proposes a novel approach, Hierarchical Document Embeddings (HDE), which learns a hierarchical representation of documents by modeling the relationships between sentences, paragraphs, and documents. We demonstrate that HDE outperforms state-of-the-art models on several benchmark datasets, achieving significant improvements in document retrieval accuracy and efficiency. Furthermore, we show that HDE can be seamlessly integrated with traditional information retrieval systems, making it a promising solution for large-scale document retrieval applications.