In multi-agent systems, decision-making often relies on opaque AI models that lack transparency and interpretability. This paper introduces a novel hierarchical attention network (HAN) framework that enables explainable decision-making in multi-agent settings. Our approach integrates agent-level attention mechanisms with a hierarchical graph neural network to model complex dependencies between agents. We demonstrate the effectiveness of HAN in a realistic robotic soccer scenario, showing improved decision-making accuracy and interpretability compared to state-of-the-art methods.