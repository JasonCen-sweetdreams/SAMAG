Virtual reality (VR) has transformed human-computer interaction, but existing gestural interfaces often neglect the embodied cognition aspects of human behavior. This paper presents a comprehensive study on redesigning gesture-based interaction in VR to better align with human motor skills and cognitive processes. We developed a novel, embodied cognition-inspired framework for gesture recognition and conducted a user study with 30 participants. Our results show a significant reduction in gesture recognition errors and improved user experience compared to traditional machine learning-based approaches.