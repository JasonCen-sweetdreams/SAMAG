Recent advancements in multi-agent reinforcement learning have led to significant improvements in complex task solving. However, the lack of transparency in these systems hinders their adoption in real-world applications. This paper proposes a novel hierarchical attention network (HAN) architecture for explainable multi-agent reinforcement learning. Our approach leverages attention mechanisms to selectively focus on relevant agents and their interactions, thereby providing insights into the decision-making process. Experimental results on a cooperative navigation task demonstrate that HAN outperforms state-of-the-art methods while generating interpretable explanations for agent behavior.