In multi-agent systems, task allocation is a crucial problem that involves assigning tasks to agents with varying capabilities and preferences. This paper proposes a decentralized task allocation framework that leverages reinforcement learning to adapt to heterogeneous agent populations. Our approach, called HRL-TA, uses a novel combination of graph neural networks and multi-agent Q-learning to optimize task assignments in real-time. We evaluate HRL-TA on a simulated disaster response scenario and demonstrate significant improvements in task completion efficiency and agent satisfaction compared to traditional centralized optimization methods.