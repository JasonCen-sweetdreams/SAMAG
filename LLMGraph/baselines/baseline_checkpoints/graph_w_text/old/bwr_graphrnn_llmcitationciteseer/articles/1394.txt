In multi-agent systems, decision-making often relies on learned policies that lack transparency and interpretability. This paper introduces HATNeT, a novel hierarchical attention network architecture that enables explainable decision-making in cooperative and competitive multi-agent settings. By iteratively refining attention weights across agents and tasks, HATNeT improves both team performance and interpretability. We evaluate HATNeT on a variety of multi-agent benchmark domains, demonstrating superior performance and insights into agent interactions and decision-making processes.