Autonomous vehicles require efficient and adaptive control systems to navigate complex environments. This paper presents a hierarchical reinforcement learning (HRL) framework that integrates real-time object detection to improve vehicle control. Our approach leverages a high-level policy to select from a set of pre-defined maneuvers, while a low-level controller executes the selected action. We employ a deep Q-network to learn the high-level policy and a convolutional neural network for object detection. Experimental results demonstrate improved control performance and reduced collision rates in simulated urban scenarios, showcasing the potential of HRL for autonomous vehicle control.