In multi-agent reinforcement learning, explainability is crucial for understanding agent interactions and decision-making processes. This paper proposes a novel hierarchical attention network (HAN) architecture that learns to selectively focus on relevant agents, states, and actions when making decisions. Our HAN framework consists of two stages: intra-agent attention for feature extraction and inter-agent attention for communication. We evaluate our approach on a suite of cooperative and competitive multi-agent environments, demonstrating improved explainability and performance compared to state-of-the-art baselines.