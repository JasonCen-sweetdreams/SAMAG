Distributed database systems (DDS) have become increasingly popular for handling large-scale data storage and querying. However, query optimization in DDS remains a challenging problem. This paper proposes a novel approach to query optimization by leveraging machine learning (ML) techniques for index selection. We develop a framework that learns from query patterns and database statistics to predict the most effective index configuration for a given query. Experimental results on a real-world dataset demonstrate that our approach outperforms traditional index selection methods by up to 30% in terms of query execution time, while also reducing storage overhead.