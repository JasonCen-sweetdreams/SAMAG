 Ranking models have become a crucial component in modern information retrieval systems. This paper proposes a novel deep neural ranking model that incorporates query expansion techniques to improve the retrieval efficiency. Our approach, dubbed 'QNRM', uses a transformer-based architecture to model the semantic relationships between queries and documents. We introduce a new query expansion method based on word embeddings and demonstrate its effectiveness in enhancing the ranking performance. Experimental results on several benchmark datasets show that QNRM outperforms state-of-the-art ranking models in terms of both relevance and efficiency metrics.