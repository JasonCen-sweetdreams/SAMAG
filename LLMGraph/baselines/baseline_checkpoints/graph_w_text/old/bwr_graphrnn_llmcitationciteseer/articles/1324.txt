This paper introduces HAT-MARL, a novel hierarchical attention network for explainable multi-agent reinforcement learning. HAT-MARL leverages attention mechanisms to selectively focus on relevant agents and their interactions, improving the learning efficiency and interpretability of multi-agent systems. We demonstrate the effectiveness of HAT-MARL on a range of cooperative and competitive tasks, showcasing its ability to learn scalable and transferable policies. Furthermore, we provide visualizations and analyses of the attention weights, offering insights into the decision-making processes of the agents and facilitating explainability in complex multi-agent scenarios.