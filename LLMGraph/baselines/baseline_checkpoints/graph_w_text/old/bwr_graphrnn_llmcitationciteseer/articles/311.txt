We propose a novel multi-agent reinforcement learning framework for real-time traffic control, dubbed 'MARL-RTC'. By leveraging decentralized actor-critic methods and graph neural networks, MARL-RTC enables the coordination of multiple agents to optimize traffic flow in complex road networks. Our approach addresses the scalability limitations of existing methods by introducing a hierarchical clustering mechanism that adaptively groups agents based on their spatial proximity and traffic patterns. Experimental results on a large-scale traffic simulation demonstrate that MARL-RTC outperforms state-of-the-art methods in reducing congestion and travel times, while maintaining a low computational overhead.