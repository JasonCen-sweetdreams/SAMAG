Knowledge graph embedding (KGE) has become a crucial component in AI-driven question answering systems. However, existing KGE methods struggle to capture complex relational patterns and scale to large graphs. This paper proposes a novel approach, HyperKGE, which leverages hyperbolic geometry to learn embeddings that better preserve hierarchical and relational structures. Our experiments on several benchmark datasets demonstrate that HyperKGE outperforms state-of-the-art methods in terms of link prediction and question answering accuracy, while requiring fewer model parameters and computational resources.