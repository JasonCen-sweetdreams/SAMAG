Online learning for contextual bandits has numerous applications in personalized recommendation systems and online advertising. We propose a novel algorithm, 'NeuralUCB', which leverages neural networks to model complex relationships between contexts and rewards. Our approach combines the strengths of both model-based and model-free methods, achieving a provably efficient regret bound of O(T^2/3) in the online learning setting. Empirical evaluation on synthetic and real-world datasets demonstrates the competitiveness of NeuralUCB against state-of-the-art baselines.