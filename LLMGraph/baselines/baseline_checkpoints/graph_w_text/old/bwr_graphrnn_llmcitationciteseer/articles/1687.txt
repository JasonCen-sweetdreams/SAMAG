This paper addresses the task allocation problem in large-scale multi-agent systems, where agents with diverse capabilities must be assigned to tasks to optimize overall system performance. We propose a hierarchical reinforcement learning framework, 'HRL-TA', which leverages both global and local rewards to learn effective task allocation policies. HRL-TA employs a novel hierarchical decomposition of the task allocation problem, allowing it to scale to hundreds of agents and tasks. Experimental results demonstrate that HRL-TA outperforms state-of-the-art methods in terms of system utility, adaptability, and robustness to agent failures.