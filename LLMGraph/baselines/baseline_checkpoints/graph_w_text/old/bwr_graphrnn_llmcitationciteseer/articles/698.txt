In multi-agent systems, decision-making often relies on complex, black-box models that lack transparency and accountability. This paper proposes a novel hierarchical attention network (HAN) architecture that enables explainable decision-making in multi-agent settings. Our HAN model incorporates attention mechanisms at both the agent and system levels, allowing for interpretable representations of agent interactions and decision-making processes. We evaluate our approach on a real-world traffic management scenario, demonstrating improved decision-making performance and enhanced explainability compared to traditional deep reinforcement learning methods.