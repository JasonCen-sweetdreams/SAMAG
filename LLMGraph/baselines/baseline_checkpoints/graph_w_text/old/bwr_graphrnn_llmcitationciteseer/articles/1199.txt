Explainability is crucial in multi-agent reinforcement learning (MARL) to understand the decision-making process of agents. This paper proposes a novel hierarchical attention network (HAN) architecture that provides interpretable explanations for agent interactions. Our HAN model consists of two attention layers: an intra-agent attention layer that focuses on relevant state features and an inter-agent attention layer that captures relationships between agents. We evaluate our approach on a cooperative navigation task and show that it outperforms state-of-the-art MARL methods in terms of both task performance and explanation quality.