In multi-agent systems, decision-making often involves complex interactions between agents with varying goals and preferences. This paper proposes a novel hierarchical attention network (HAN) architecture to learn explainable decision-making policies in such settings. Our HAN model comprises two stages: an attention-based agent encoder that captures agent-specific features, and a graph neural network-based policy decoder that generates joint actions. We evaluate our approach on a real-world autonomous driving dataset, demonstrating improved decision-making performance and interpretability compared to existing methods.