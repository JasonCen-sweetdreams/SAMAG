Graph neural networks have achieved state-of-the-art performance in node classification tasks, but their scalability is limited by the complexity of graph attention mechanisms. This paper proposes a novel hierarchical graph attention network (HiGAT) that adaptively selects relevant nodes at multiple scales, reducing computational cost and improving performance. We also introduce a new graph coarsening technique that preserves local structure and node features. Experiments on large-scale graph datasets demonstrate HiGAT's ability to achieve competitive accuracy with significant speedups over existing methods.