This paper presents a novel approach to distributed task allocation in multi-agent systems, where agents with different capabilities and constraints need to coordinate to achieve a common goal. We propose a deep reinforcement learning framework that enables heterogeneous agents to learn cooperative policies for task allocation. Our approach leverages a hierarchical architecture, where a high-level coordinator agent learns to allocate tasks to lower-level executor agents based on their capabilities and availability. Experimental results on a simulated disaster response scenario demonstrate that our approach outperforms traditional optimization-based methods in terms of task completion rate and overall system efficiency.