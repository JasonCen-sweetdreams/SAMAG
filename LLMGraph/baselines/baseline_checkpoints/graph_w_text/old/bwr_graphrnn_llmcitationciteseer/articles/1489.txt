Multi-agent systems often struggle to provide transparent decision-making processes, hindering trust and accountability. This paper introduces HAN-XD, a hierarchical attention network that generates interpretable explanations for joint decisions in multi-agent environments. HAN-XD combines graph attention mechanisms with hierarchical reasoning to identify key agents, actions, and contextual factors influencing collective outcomes. Experimental results on a variety of multi-agent scenarios demonstrate that HAN-XD outperforms existing explainability methods in terms of accuracy and usefulness, while also providing insights into agent interactions and decision-making dynamics.