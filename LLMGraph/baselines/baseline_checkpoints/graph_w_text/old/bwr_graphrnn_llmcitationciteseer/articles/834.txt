Coordinating multiple agents in complex scenarios is a challenging problem in multi-agent systems. This paper introduces a decentralized graph neural network (DGNN) approach to learn effective coordination strategies. Our method leverages local observations and communication with neighboring agents to learn a distributed representation of the graph structure. We demonstrate the effectiveness of our approach in several benchmarks, including traffic management and resource allocation tasks, and show that it outperforms traditional centralized and rule-based methods. The proposed DGNN architecture is highly scalable and can be applied to various real-world multi-agent systems.