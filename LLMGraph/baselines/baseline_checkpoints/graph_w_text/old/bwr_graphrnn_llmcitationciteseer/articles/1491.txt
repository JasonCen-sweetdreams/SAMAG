This paper presents a novel approach to coordinating autonomous agents for urban traffic management using hierarchical reinforcement learning. We propose a two-level architecture, where a high-level planner generates traffic signal control policies and a low-level controller executes these policies using reinforcement learning. Our approach incorporates real-time traffic data and agent interactions to optimize traffic flow and reduce congestion. Experimental results in a simulated urban environment demonstrate significant improvements in traffic throughput and reduced travel times compared to traditional signal control methods.