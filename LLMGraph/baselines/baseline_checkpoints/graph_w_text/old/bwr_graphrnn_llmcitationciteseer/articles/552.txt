Designing effective and interpretable multi-agent reinforcement learning (MARL) systems remains a significant challenge. This paper presents HAN-MARL, a novel hierarchical attention network architecture that enables explainable decision-making in cooperative MARL settings. By recursively applying attention mechanisms at both the agent and team levels, our approach identifies relevant information flows and prioritizes actions that maximize global rewards. Experimental results on a variety of MARL benchmarks demonstrate improved performance and interpretability of HAN-MARL compared to state-of-the-art methods.