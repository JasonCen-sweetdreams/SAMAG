Cloud computing resources are often underutilized due to inefficient allocation strategies. This paper proposes a hierarchical deep reinforcement learning (HDRL) framework to optimize resource allocation in real-time. Our approach combines a high-level policy network with a set of low-level actor-critic networks to allocate resources at multiple granularities. We evaluate our framework on a simulated cloud environment and demonstrate significant improvements in resource utilization, response times, and energy efficiency compared to state-of-the-art baselines.