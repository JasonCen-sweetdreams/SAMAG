Query optimization is a crucial task in graph databases, particularly in distributed settings where data is scattered across multiple nodes. Existing approaches rely on heuristics or exhaustive search, leading to suboptimal performance and limited scalability. This paper proposes a novel query optimization framework, 'GraphRL', which leverages reinforcement learning to efficiently explore the vast space of possible query plans. We introduce a graph-structured agent that learns to navigate the plan space, leveraging graph neural networks to encode query semantics and node properties. Experimental results on real-world graph datasets demonstrate that GraphRL outperforms state-of-the-art optimizers, achieving up to 3x speedup and 2x better plan quality.