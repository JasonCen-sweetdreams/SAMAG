Cloud computing platforms face the challenge of optimizing resource allocation to meet dynamic workload demands. This paper presents a hierarchical reinforcement learning (HRL) framework, 'CloudOpt', which learns to allocate resources efficiently by modeling the hierarchical structure of cloud infrastructure. Our approach combines a high-level policy for resource allocation with low-level controllers for task scheduling, achieving improved resource utilization and reduced energy consumption. Experiments on a real-world cloud dataset demonstrate that CloudOpt outperforms state-of-the-art baselines in terms of resource efficiency and scalability.