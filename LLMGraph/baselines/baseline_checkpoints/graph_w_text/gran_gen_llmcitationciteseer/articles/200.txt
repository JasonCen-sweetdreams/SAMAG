Object detection systems have become ubiquitous in various applications, including surveillance, autonomous vehicles, and healthcare. However, these systems are vulnerable to adversarial attacks that can compromise their performance. This paper proposes an Explainable AI (XAI) framework to detect adversarial attacks on real-time object detection systems. Our approach leverages a novel attention-based mechanism that identifies suspicious patterns in the input data, which are then analyzed using SHAP values to explain the model's predictions. Experimental results on popular object detection benchmarks demonstrate the effectiveness of our approach in detecting adversarial attacks, even in the presence of noise and occlusion.