Sentiment analysis tasks often involve processing heterogeneous data from multiple sources, such as text, images, and audio. This paper presents a novel hierarchical graph attention network (HGAN) architecture that effectively integrates and leverages the strengths of multi-modal data. HGAN employs a hierarchical graph structure to model complex relationships between modalities, and attention mechanisms to selectively weight features from each modality. Experimental results on a benchmark dataset demonstrate that HGAN outperforms state-of-the-art methods in sentiment analysis tasks, particularly in scenarios with noisy or missing data.