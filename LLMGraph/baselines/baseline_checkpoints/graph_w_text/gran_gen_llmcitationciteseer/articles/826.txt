Document classification is a fundamental task in natural language processing, but it remains challenging due to the high dimensionality of document representations. This paper proposes a novel hierarchical attention network (HAN) architecture that selectively focuses on relevant sentences and words when classification. We introduce a two-stage attention mechanism that first identifies informative sentences and then extracts key phrases within those sentences. Our experiments on several benchmark datasets demonstrate that HAN outperforms state-of-the-art models in terms of accuracy and computational efficiency, making it suitable for real-world applications.