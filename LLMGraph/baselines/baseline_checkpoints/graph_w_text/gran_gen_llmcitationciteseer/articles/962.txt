Cloud-native database systems face significant performance challenges due to the shift towards distributed, scale-out architectures. Traditional indexing techniques often fall short in these environments, leading to suboptimal query performance. This paper proposes a novel approach that leverages learned index structures to optimize query execution in cloud-native databases. By integrating machine learning models into the indexing layer, we demonstrate significant improvements in query latency and throughput. Our experiments on a real-world cloud database benchmark show that learned index structures can reduce query execution time by up to 3.5x compared to traditional indexing techniques.