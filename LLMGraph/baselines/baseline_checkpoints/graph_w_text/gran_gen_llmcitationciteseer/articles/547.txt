Cloud computing platforms face the challenge of efficiently allocating resources to meet dynamic workload demands. This paper presents a novel approach to resource allocation using deep reinforcement learning (DRL). We propose a multi-agent DRL framework that leverages graph neural networks to model complex relationships between cloud resources and workloads. Our approach learns to adaptively allocate resources based on real-time workload patterns, achieving improved resource utilization and reduced latency compared to traditional rule-based methods. Experimental results on a large-scale cloud simulator demonstrate the effectiveness of our approach in reducing costs and improving quality of service.