Knowledge graph embeddings (KGEs) have shown promising results in various NLP tasks, but often struggle with entity disambiguation due to the complexity of real-world graphs. This paper proposes an attention-based graph neural network (GNN) approach to disambiguate entities in KGEs. Our model, AttentiveKG, learns to focus on relevant neighboring entities and relations when computing entity representations, thereby improving disambiguation accuracy. Experimental results on several benchmark datasets demonstrate the effectiveness of AttentiveKG in reducing entity ambiguity and enhancing overall KGE performance.