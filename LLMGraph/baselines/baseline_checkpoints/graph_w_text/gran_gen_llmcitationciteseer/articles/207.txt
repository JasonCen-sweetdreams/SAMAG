Graph neural networks (GNNs) have shown remarkable success in node classification tasks, but often struggle with scalability and capturing complex graph structures. We propose a novel hierarchical attention-based GNN framework, 'HAGNet', which leverages a hierarchical clustering approach to decompose large graphs into smaller subgraphs. Our model employs attention mechanisms to selectively focus on relevant subgraphs and nodes, enabling more efficient learning and improved classification performance. Experimental results on benchmark datasets demonstrate the effectiveness of HAGNet in node classification tasks, particularly in scenarios with large and complex graphs.