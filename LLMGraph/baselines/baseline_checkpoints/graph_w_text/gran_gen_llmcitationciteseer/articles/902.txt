Virtual reality (VR) has revolutionized the way we interact with digital environments. However, traditional interfaces often rely on manual input, which can be cumbersome and detract from the immersive experience. This paper presents EyeMovementPatterns, a novel gaze-based interface that leverages machine learning to infer user intent from eye movement patterns. Our approach combines convolutional neural networks with transfer learning to recognize gaze patterns, enabling users to navigate and interact with virtual objects using only their gaze. We conducted a user study to evaluate the usability and effectiveness of EyeMovementPatterns, demonstrating significant improvements in user experience and interaction efficiency.