Eye-tracking has been increasingly used in human-computer interaction (HCI) to improve user experience. However, existing eye-tracking systems often suffer from low accuracy and high latency. This paper proposes EyeGaze, a machine learning-based approach that leverages convolutional neural networks (CNNs) and transfer learning to enhance eye-tracking accuracy. Our approach uses a multi-modal fusion of eye movement and facial features to improve gaze estimation. Experimental results demonstrate that EyeGaze outperforms state-of-the-art eye-tracking systems, achieving an average accuracy of 95.2% and latency of 50ms. We envision EyeGaze to have significant implications for HCI applications, including virtual reality, gaming, and assistive technologies.