Resource allocation in cloud computing is a complex, dynamic problem that requires efficient decision-making. This paper proposes a novel deep hierarchical reinforcement learning (DHRL) framework, 'CloudOpt', which learns to optimize resource allocation in cloud environments. CloudOpt incorporates a hierarchical architecture that decomposes the problem into sub-tasks, allowing the agent to focus on specific resource allocation decisions. Experimental results on a real-world cloud dataset demonstrate that CloudOpt achieves significant improvements in resource utilization and reduces energy consumption compared to state-of-the-art baselines.