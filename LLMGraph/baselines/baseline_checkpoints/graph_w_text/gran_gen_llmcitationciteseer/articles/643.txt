Urban traffic congestion is a major challenge for modern cities, and multi-agent systems have shown promise in optimizing traffic flow. This paper presents a novel hierarchical reinforcement learning (HRL) framework for coordinating autonomous agents in urban traffic control. Our approach combines a high-level planner that sets traffic signal timings with low-level controllers that adjust signal phases based on real-time traffic data. Experimental results using a realistic traffic simulator demonstrate that our HRL framework outperforms traditional fixed-time signal control and model-based optimization methods in terms of reducing congestion and travel times.