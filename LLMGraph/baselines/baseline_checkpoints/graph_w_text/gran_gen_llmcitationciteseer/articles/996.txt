Few-shot image classification remains a challenging problem in machine learning, particularly when faced with limited labeled data. This paper proposes a hierarchical meta-learning approach, 'HierMeta', that leverages self-supervised pre-training to improve adaptability to new classes. We introduce a novel hierarchical attention mechanism that selectively focuses on relevant task-specific features, while also utilizing contrastive self-supervised learning to enhance feature representations. Experimental results on benchmark datasets show that HierMeta outperforms state-of-the-art few-shot classification methods, achieving significant improvements in accuracy and robustness.