Deep learning models are increasingly vulnerable to adversarial attacks, which can have catastrophic consequences in safety-critical applications. This paper proposes a novel approach to improve the robustness of deep learning models by leveraging Bayesian neural network ensembles. Our method, called 'BayesRobust', combines the outputs of multiple Bayesian neural networks to generate an ensemble prediction that is more resistant to adversarial perturbations. We demonstrate the effectiveness of BayesRobust on several benchmark datasets, showing improved robustness to state-of-the-art attacks while maintaining competitive performance on clean data.