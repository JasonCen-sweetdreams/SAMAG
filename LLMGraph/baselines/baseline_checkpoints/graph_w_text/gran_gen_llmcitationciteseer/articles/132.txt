Gaze-based interaction has emerged as a promising modality for human-computer interaction, but accurate gaze estimation remains a significant challenge. This paper presents EyeGaze+, a novel framework that leverages machine learning to correct gaze errors in real-time. Our approach combines a convolutional neural network (CNN) with a Kalman filter to refine gaze estimates, achieving a mean absolute error reduction of 35% compared to state-of-the-art methods. We evaluate EyeGaze+ in a user study, demonstrating improved performance in gaze-based typing and selection tasks. The proposed framework has implications for enhancing accessibility and usability in various HCI applications.