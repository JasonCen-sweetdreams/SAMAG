The proliferation of IoT devices has created a need for efficient task allocation mechanisms in decentralized networks. This paper presents a novel multi-agent reinforcement learning framework, 'MARL-IoT', which enables autonomous task allocation in IoT networks. MARL-IoT utilizes a decentralized actor-critic architecture, where each agent learns to allocate tasks based on its local observations and communicates with neighboring agents to achieve global optimality. We evaluate MARL-IoT on a simulated IoT network and demonstrate improved task allocation efficiency and adaptability compared to traditional centralized approaches.