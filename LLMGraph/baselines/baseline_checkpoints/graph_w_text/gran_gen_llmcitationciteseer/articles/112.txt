Autonomous vehicles (AVs) promise to revolutionize urban transportation, but coordinating their actions in complex scenarios remains a significant challenge. This paper introduces a decentralized multi-agent reinforcement learning (MARL) framework, 'AV-CORD', which enables AVs to learn cooperative policies in real-time. We propose a novel, graph-based communication mechanism that facilitates information exchange between agents while respecting privacy and bandwidth constraints. Experimental results using a realistic simulation platform demonstrate that AV-CORD outperforms traditional, centralized approaches in terms of traffic efficiency, safety, and scalability.