Gesture-based interfaces have become increasingly prevalent in modern computing, but individuals with motor impairments often face significant barriers to accessing these systems. This paper presents a novel framework for designing inclusive gesture-based interfaces that accommodate the needs of users with motor impairments. We conducted a comprehensive study involving 30 participants with varying motor abilities, and identified key design principles for reducing error rates and improving user experience. Our proposed framework incorporates a machine learning-based gesture recognition system that adaptively adjusts to individual users' abilities, and has been evaluated in a real-world scenario with promising results.