Neural retrieval models have achieved state-of-the-art performance in various information retrieval tasks. However, they often suffer from the vocabulary mismatch problem, where the query and document vocabularies do not align. We propose a novel query expansion approach that leverages reinforcement learning to adaptively select expansion terms. Our method, called RLERank, learns to optimize the ranking metrics by interacting with a simulated environment. Experimental results on several benchmark datasets demonstrate that RLERank outperforms traditional query expansion techniques and improves the overall retrieval performance of neural models.