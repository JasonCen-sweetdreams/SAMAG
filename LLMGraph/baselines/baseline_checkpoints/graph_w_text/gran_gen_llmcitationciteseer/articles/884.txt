Individuals with motor impairments often face significant barriers when interacting with gesture-based systems. This paper presents a novel framework for designing accessible gesture-based interfaces that accommodate a wide range of motor abilities. We introduce a machine learning-based approach to recognize and adapt to individual users' gesture patterns, enabling more accurate and efficient interaction. Our user study with 20 participants reveals that our approach significantly improves task completion rates and user satisfaction compared to traditional gesture recognition systems.