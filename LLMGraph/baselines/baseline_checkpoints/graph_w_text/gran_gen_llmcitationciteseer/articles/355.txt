Task allocation is a critical problem in multi-agent systems, where agents with diverse capabilities must collaborate to accomplish complex tasks. This paper proposes a novel deep reinforcement learning approach, 'TASKER', which learns to allocate tasks efficiently by modeling agent interactions and task dependencies. Our approach leverages graph neural networks to represent agent relationships and task graphs, and uses a hierarchical reinforcement learning framework to optimize task allocation. Experimental results on a variety of task allocation benchmarks demonstrate that TASKER outperforms existing approaches in terms of task completion time and agent utilization.