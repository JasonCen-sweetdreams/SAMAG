Multimodal retrieval has become increasingly important in various applications, such as image and video search. However, the efficiency and effectiveness of retrieval models are often hindered by the complexity of user queries and the scale of the datasets. This paper proposes a novel hierarchical query expansion approach, which leverages both semantic and visual features to expand user queries. Our method employs a graph-based clustering algorithm to group semantically similar queries and then uses a deep learning-based model to learn visual representations of the expanded queries. Experimental results on several large-scale datasets show that our approach significantly improves the retrieval performance and reduces the computational cost compared to state-of-the-art methods.