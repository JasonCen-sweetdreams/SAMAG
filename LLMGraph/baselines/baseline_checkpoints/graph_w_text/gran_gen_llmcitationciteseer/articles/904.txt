Distributed query processing systems face the challenging problem of optimizing join order enumeration to minimize query execution time. Existing solutions rely on heuristics or exhaustive search, which can lead to suboptimal plans. This paper proposes 'RLJoin', a novel approach that leverages reinforcement learning to optimize join order enumeration. RLJoin formulates the problem as a Markov decision process and employs a deep Q-network to learn an optimal policy from a dataset of query executions. Experiments on the TPC-DS benchmark demonstrate that RLJoin outperforms state-of-the-art methods by up to 30% in terms of query execution time, while adapting to diverse data distributions and query patterns.