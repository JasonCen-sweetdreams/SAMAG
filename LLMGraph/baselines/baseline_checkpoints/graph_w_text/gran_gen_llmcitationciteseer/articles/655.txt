Voice assistants have become ubiquitous in modern life, but their interfaces can perpetuate cognitive biases and exacerbate social inequalities. This paper presents a novel, multimodal framework for designing inclusive voice assistants that mitigate biases in speech recognition, natural language understanding, and response generation. We introduce a contextualized embedding approach that incorporates user demographics, language proficiency, and cultural background to adapt the assistant's behavior and language. A user study with 120 participants demonstrates significant reductions in biased responses and improved user satisfaction, particularly among underrepresented groups.