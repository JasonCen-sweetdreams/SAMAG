Relevance feedback is a crucial component in information retrieval systems, as it enables users to provide explicit judgments about the relevance of retrieved documents. However, in many real-world scenarios, the feedback is sparse and noisy, which can significantly degrade the performance of ranking models. In this paper, we propose a novel deep neural ranking model, 'NoiseRobustRank', that incorporates a denoising autoencoder to learns robust representations of user feedback. We also introduce a new loss function, 'SparseRankLoss', that adaptively weights the importance of each feedback instance based on its confidence score. Experimental results on several benchmark datasets demonstrate that NoiseRobustRank outperforms state-of-the-art ranking models in terms of both effectiveness and robustness.