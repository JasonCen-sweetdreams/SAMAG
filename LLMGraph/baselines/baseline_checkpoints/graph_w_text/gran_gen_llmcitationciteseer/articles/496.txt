This paper presents a novel approach to deep reinforcement learning (DRL) for robotics, leveraging AdaBoost to improve exploration and exploitation in complex, high-dimensional state spaces. Our method, dubbed 'AdaRL', adaptively combines the strengths of multiple DRL agents, each with distinct exploration strategies, to achieve better overall performance and robustness. Experimental results on a robotic arm manipulation task demonstrate that AdaRL outperforms state-of-the-art DRL methods, achieving higher success rates and faster learning convergence.