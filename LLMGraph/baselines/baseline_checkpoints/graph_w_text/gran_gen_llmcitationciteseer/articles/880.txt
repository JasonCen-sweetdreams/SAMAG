This paper presents a novel approach to gesture recognition that adapts to the unique abilities and needs of individuals with motor disabilities. We propose a machine learning-based framework that leverages a small set of calibration gestures to personalize the recognition model for each user. Our approach integrates computer vision and machine learning techniques to identify the most informative features of gestures, even in the presence of motor variability and noise. Evaluation results with 20 participants with motor disabilities demonstrate significant improvements in gesture recognition accuracy and user satisfaction compared to existing, one-size-fits-all approaches.