Robots operating in complex environments require interpretable decision-making models to ensure safety and efficiency. This paper proposes a novel hierarchical graph attention network (HGAT) architecture for robot learning, which integrates attention mechanisms and graph neural networks to learn hierarchical representations of robot states and environments. By leveraging attention weights, our approach provides explainable policies for robot navigation and manipulation tasks. Experimental results on a robotic grasping benchmark demonstrate improved performance and interpretability compared to state-of-the-art reinforcement learning methods.