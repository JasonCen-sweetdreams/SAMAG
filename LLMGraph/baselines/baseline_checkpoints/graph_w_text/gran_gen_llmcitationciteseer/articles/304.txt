Node classification in graphs is a fundamental task in many applications, but existing methods often suffer from high computational complexity and poor scalability. This paper presents a novel Hierarchical Graph Attention Network (HGAT) architecture that leverages graph attention mechanisms to selectively focus on relevant nodes and subgraphs. By hierarchically applying attention at multiple scales, HGAT reduces the number of parameters and computations required, achieving state-of-the-art performance on several benchmark datasets while being orders of magnitude faster than existing methods.