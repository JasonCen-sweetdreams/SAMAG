Skeleton-based action recognition has garnered significant attention in recent years due to its applications in healthcare, surveillance, and human-computer interaction. This paper proposes a novel Hierarchical Attention Graph Convolutional Network (HAGCN) architecture that leverages the hierarchical structure of skeleton data to improve action recognition performance. Our approach incorporates attention mechanisms at multiple scales to capture informative joint interactions and contextual relationships. Experimental results on the NTU-RGB+D and PKU-MMD datasets demonstrate that HAGCN outperforms state-of-the-art methods, achieving an average accuracy of 95.2% and 92.5%, respectively.