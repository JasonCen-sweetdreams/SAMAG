Deep neural networks are vulnerable to adversarial attacks, which can mislead them into making incorrect predictions. This paper proposes a novel defense mechanism, Hierarchical Attention-based Adversarial Robustness (HAAR), which leverages attention mechanisms to identify and suppress adversarial perturbations. HAAR uses a hierarchical structure to adaptively focus on relevant features and regions of the input data, thereby improving the robustness of the network against diverse attack types. Our extensive experiments on ImageNet and CIFAR-10 datasets demonstrate that HAAR outperforms state-of-the-art defense methods in terms of both accuracy and robustness.