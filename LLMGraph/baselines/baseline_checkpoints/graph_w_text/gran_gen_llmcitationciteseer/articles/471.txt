Explainable recommendation systems (ERS) aim to provide transparent and trustworthy suggestions to users. This paper introduces a novel hybrid approach, 'HAGN', which combines graph neural networks (GNNs) with attentional mechanisms to model complex user-item relationships. HAGN leverages graph structure to capture latent patterns and attention to emphasize relevant features, generating interpretable explanations for top-N recommendations. Experimental results on benchmark datasets demonstrate the effectiveness of HAGN in improving recommendation accuracy and explanation quality compared to state-of-the-art ERS methods.