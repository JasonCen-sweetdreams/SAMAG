Ad-hoc search systems struggle to effectively capture user intent, leading to suboptimal retrieval performance. This paper proposes a novel neural query expansion approach, 'NeuQE', that leverages the semantic capabilities of transformer-based retrieval models. By fine-tuning a pre-trained neural retriever on a large-scale dataset, we generate high-quality query expansions that capture nuanced relationships between terms. Our experiments on the TREC ad-hoc benchmark demonstrate significant improvements in retrieval effectiveness, outperforming state-of-the-art expansion methods. NeuQE's efficiency and scalability make it a promising solution for real-world search applications.