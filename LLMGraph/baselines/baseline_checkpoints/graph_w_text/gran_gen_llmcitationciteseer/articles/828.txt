Individuals with speech disorders, such as apraxia or dysarthria, often face challenges when interacting with voice-based interfaces. This paper presents a novel framework for designing inclusive voice-based interfaces that can accommodate diverse speech patterns. We propose a hybrid approach combining machine learning-based speech recognition with rule-based language processing to improve recognition accuracy for individuals with speech disorders. Our user study with 20 participants shows that our approach achieves a 35% reduction in error rate compared to commercial speech recognition systems, leading to improved user experience and accessibility.