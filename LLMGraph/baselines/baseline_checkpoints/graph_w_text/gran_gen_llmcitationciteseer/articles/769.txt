Augmented reality (AR) technology has the potential to revolutionize the way people interact with digital information. However, users with motor impairments, such as those with spinal cord injuries or Parkinson's disease, face significant challenges in interacting with AR interfaces. This paper presents a novel gaze-based interaction system, 'GazeAR', which leverages eye-tracking technology to enable users to select and manipulate virtual objects in AR environments. We evaluate GazeAR with a user study involving 15 participants with motor impairments and demonstrate improved interaction accuracy and efficiency compared to traditional gaze-based systems.