Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks, but its lack of transparency hinders its adoption in high-stakes applications. We introduce Hierarchical Attention Networks (HANs), a novel architecture that incorporates attention mechanisms at multiple levels to provide explanations for DRL policies. HANs disentangle the decision-making process into interpretable components, enabling the identification of relevant state features and action influences. Our experiments on Atari games and a real-world robotics task demonstrate that HANs achieve comparable performance to state-of-the-art DRL methods while providing insightful visualizations and feature importance scores.