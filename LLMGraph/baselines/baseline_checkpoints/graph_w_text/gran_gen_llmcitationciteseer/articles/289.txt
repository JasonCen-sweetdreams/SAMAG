This paper proposes a decentralized multi-agent reinforcement learning approach to coordinate autonomous vehicles in urban traffic networks. We formulate the problem as a Markov game, where each agent learns to optimize its actions based on local observations and communication with neighboring agents. Our method, dubbed 'MARL-Traffic', incorporates a novel attention mechanism to prioritize critical intersections and adapt to changing traffic conditions. Simulation results demonstrate a significant reduction in travel time and increased traffic flow compared to traditional traffic signal control methods.