Explainable recommendation systems have gained significant attention in recent years, yet most existing approaches rely on complex and opaque neural networks. This paper proposes a novel graph attention network (GAT) architecture, 'ExplainGAT', which leverages attention mechanisms to provide transparent and interpretable recommendations. We demonstrate that ExplainGAT outperforms state-of-the-art models on benchmark datasets while providing visual explanations for recommended items. Furthermore, we introduce a novel evaluation metric, 'Explainability Score', to quantify the interpretability of recommendation models.