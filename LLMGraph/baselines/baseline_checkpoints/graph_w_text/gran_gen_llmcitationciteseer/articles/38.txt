Document clustering is a fundamental task in Information Retrieval (IR) that enables efficient organization and retrieval of large document collections. This paper proposes a novel hierarchical document clustering approach, 'DeepSemClus', which leverages deep semantic representations learned from pre-trained language models. Our method first extracts dense, contextualized embeddings for each document using a fine-tuned BERT model. Then, we employ a hierarchical agglomerative clustering algorithm to group documents based on their semantic similarity. Experiments on several benchmark datasets demonstrate that DeepSemClus outperforms state-of-the-art clustering methods, achieving higher purity and F1-scores. We also show that our approach is robust to varying cluster densities and noise levels.