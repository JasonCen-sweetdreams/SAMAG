We propose a novel hierarchical graph attention network (HGAT) architecture for multi-agent reinforcement learning. HGAT leverages graph attention mechanisms to model complex interactions between agents and their environment. Our approach enables agents to learn hierarchical representations of their observations, facilitating more effective exploration and exploitation in cooperative and competitive scenarios. Experimental results on several benchmarks demonstrate that HGAT outperforms state-of-the-art methods in terms of learning efficiency and task performance.