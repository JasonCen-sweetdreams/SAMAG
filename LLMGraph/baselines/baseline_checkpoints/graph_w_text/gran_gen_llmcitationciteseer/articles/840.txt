In virtual reality (VR) environments, understanding user intent is crucial for providing personalized experiences. This paper presents EyeGazeExplorer, a deep learning framework that leverages eye movement data to infer user intent. Our approach combines convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to analyze gaze patterns and predict user goals. We evaluate EyeGazeExplorer on a large-scale VR dataset and demonstrate its effectiveness in improving user experience and reducing interaction latency. Our framework has implications for various HCI applications, including virtual shopping, gaming, and education.