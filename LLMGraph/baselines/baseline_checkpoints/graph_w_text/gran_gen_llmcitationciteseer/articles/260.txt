Ad-hoc search systems rely on effective query expansion techniques to improve retrieval performance. This paper proposes a novel approach that leverages neural language models to generate high-quality expansion terms. Our method, dubbed NeuroQE, utilizes a masked language modeling objective to learn a dense representation of the query context. We demonstrate that NeuroQE outperforms traditional query expansion methods, such as Rocchio and KL-divergence, on several benchmark datasets. Furthermore, we show that NeuroQE can be seamlessly integrated into existing search architectures, resulting in significant improvements in mean average precision and normalized discounted cumulative gain.