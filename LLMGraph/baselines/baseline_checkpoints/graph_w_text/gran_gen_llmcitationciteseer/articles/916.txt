Autonomous vehicles require efficient control strategies to navigate complex scenarios. This paper presents a hierarchical reinforcement learning (HRL) framework for autonomous vehicle control, which decomposes the control problem into a hierarchy of tasks. Our approach leverages a high-level planner to select tasks, while a low-level controller executes the selected tasks using deep reinforcement learning. We evaluate our framework on a simulated urban driving environment and demonstrate improved efficiency and adaptability compared to flat reinforcement learning baselines. The proposed HRL framework has potential applications in real-world autonomous vehicle systems.