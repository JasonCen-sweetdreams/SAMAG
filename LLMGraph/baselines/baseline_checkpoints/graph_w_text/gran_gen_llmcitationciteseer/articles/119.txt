Multi-task learning (MTL) has shown promise in computer vision, but existing methods often suffer from increased computational complexity and decreased performance. This paper proposes a novel hierarchical attention network (HAN) architecture that efficiently learns shared representations across multiple tasks. Our approach leverages task-specific attention weights to selectively focus on relevant features, reducing the impact of negative transfer. We demonstrate improved performance and reduced computation time on several benchmark datasets, including Cityscapes and COCO, and provide insights into the learned attention patterns.