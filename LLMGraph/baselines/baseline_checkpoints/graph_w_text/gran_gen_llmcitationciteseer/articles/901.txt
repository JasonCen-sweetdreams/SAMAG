Ad-hoc retrieval is a fundamental task in information retrieval, where the goal is to retrieve relevant documents for a given query. One effective approach to improve retrieval performance is query expansion, which involves adding relevant terms to the original query. In this paper, we propose a neural query expansion framework that leverages pre-trained language models to learn dense embeddings for queries and documents. We introduce a novel attention-based mechanism to selectively expand the query, incorporating both local and global context. Experimental results on several benchmark datasets demonstrate the effectiveness of our approach, outperforming state-of-the-art query expansion techniques in terms of retrieval accuracy and efficiency.