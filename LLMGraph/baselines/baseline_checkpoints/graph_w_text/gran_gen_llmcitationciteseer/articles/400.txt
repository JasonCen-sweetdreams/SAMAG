As augmented reality (AR) technology becomes increasingly prevalent, the need for more natural and intuitive interaction methods grows. This paper explores the potential of gaze-based interaction with virtual agents in AR environments. We propose a novel gaze-tracking algorithm that leverages machine learning-based eye movement classification and demonstrate its application in a virtual shopping assistant scenario. Our user study shows that gaze-based interaction can reduce task completion time and improve user satisfaction compared to traditional controller-based input methods.