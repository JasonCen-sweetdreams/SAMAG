Explainable AI is crucial in multi-agent dialogue systems, where agents must understand and respond to user queries. This paper proposes a novel hierarchical attention network (HAN) architecture that generates interpretable responses while maintaining high task accuracy. Our approach incorporates a multi-level attention mechanism, which selectively focuses on relevant dialogue context, agent knowledge, and user preferences. We evaluate our HAN model on a large-scale dialogue dataset and demonstrate significant improvements in response quality and interpretability compared to state-of-the-art baselines.