Virtual reality (VR) has seen significant advancements in recent years, but user interaction remains a major bottleneck. This paper explores the use of gaze-based interaction as a novel modality for VR. We designed and implemented a gaze-driven interface for manipulating virtual objects and conducted a user study to evaluate its effectiveness. Our results show that gaze-based interaction can improve user experience and performance in VR tasks, particularly for users with motor impairments. We also identify key challenges and opportunities for future research in this area, including the need for more accurate and robust gaze-tracking algorithms.