Deep neural networks (DNNs) are vulnerable to adversarial attacks, which can be attributed to their limited robustness to input perturbations. This paper proposes a novel defense strategy based on hierarchical mutual information (HMI) to improve the robustness of DNNs. Our approach leverages the HMI metric to quantify the information flow between different layers of the network, allowing us to identify and regularize the most vulnerable components. Experimental results on several benchmark datasets demonstrate that our method significantly enhances the robustness of DNNs against various types of adversarial attacks, while maintaining their accuracy on clean data.