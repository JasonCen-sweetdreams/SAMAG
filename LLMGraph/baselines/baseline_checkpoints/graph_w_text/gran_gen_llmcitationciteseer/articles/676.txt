Deep learning models have achieved state-of-the-art performance in medical image classification tasks, but their lack of transparency hinders trust and adoption in clinical practice. This paper proposes a novel hierarchical attention network (HAN) architecture that provides explainable and interpretable results. We design a multi-level attention mechanism that selectively focuses on relevant regions and features, generating attention maps that highlight diagnostic cues. Our experiments on a large dataset of chest X-rays demonstrate that HAN outperforms existing models while providing insights into the decision-making process, facilitating improved diagnosis and treatment.