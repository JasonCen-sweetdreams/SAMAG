This paper introduces a decentralized multi-agent reinforcement learning framework for adaptive traffic signal control. Our approach utilizes a novel agent architecture that integrates both local and global state information to optimize traffic signal timing. We evaluate our method on a realistic simulation platform, demonstrating significant reductions in average travel time and congestion levels compared to traditional fixed-timing and decentralized reinforcement learning baselines. Furthermore, we provide theoretical analysis on the convergence properties of our algorithm in decentralized settings.