Open-domain question answering (ODQA) requires retrieving relevant documents and accurately identifying the answer span. This paper proposes a novel neural re-ranking approach that incorporates document expansion, leveraging both local and global contextual information. Our method, called 'DocExpan', expands each document by generating synthetic paragraphs that capture latent semantic relationships. The re-ranker then leverages these expanded documents to better distinguish between relevant and irrelevant passages. Experimental results on the Natural Questions dataset demonstrate that DocExpan significantly outperforms state-of-the-art models in both retrieval and answer accuracy.