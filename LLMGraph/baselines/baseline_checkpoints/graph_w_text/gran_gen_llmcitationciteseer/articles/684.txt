Virtual reality (VR) systems often rely on gesture recognition to enable immersive interactions. However, the lack of tactile feedback can lead to reduced accuracy and user frustration. This paper explores the design of visuospatial tactile feedback to enhance gesture recognition in VR. We propose a novel framework that integrates vibrotactile cues with visual and auditory feedback to improve gesture recognition. Our user study shows that the proposed framework increases gesture recognition accuracy by 23% compared to traditional visual-based recognition methods. Furthermore, participants reported a significant reduction in cognitive load and improved overall VR experience.