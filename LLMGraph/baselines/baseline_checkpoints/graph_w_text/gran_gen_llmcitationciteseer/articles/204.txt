Search engines rely on query reformulation to improve the relevance of search results. However, existing methods often rely on hand-crafted rules or supervised learning, which may not generalize well to diverse user queries. This paper proposes a novel approach, QRLR, which leverages reinforcement learning to learn an optimal query reformulation policy. Our method uses a deep Q-network to learn from user interactions and adapts to changing user behavior. Experimental results on a large-scale search engine dataset show that QRLR significantly outperforms state-of-the-art methods in terms of ranking improvement and user satisfaction.