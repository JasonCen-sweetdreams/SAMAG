Knowledge graph embedding (KGE) has shown promise in various applications, but existing methods often neglect the hierarchical structure inherent in many knowledge graphs. We propose a novel KGE approach, 'HAT-KGE', which leverages hierarchical attention networks to capture complex relationships between entities and their attributes. Our experiments on benchmark datasets demonstrate that HAT-KGE outperforms state-of-the-art methods in link prediction and entity classification tasks, while reducing computational complexity. We further show that HAT-KGE can be easily integrated with popular AI frameworks for real-world applications.