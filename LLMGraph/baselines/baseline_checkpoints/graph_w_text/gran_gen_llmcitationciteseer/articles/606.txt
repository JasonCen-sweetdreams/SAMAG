This paper addresses the challenging problem of cooperative task allocation in multi-agent systems, where agents must work together to accomplish complex tasks. We propose a novel distributed reinforcement learning framework, 'CoRAL', that enables agents to learn cooperative policies in a decentralized manner. CoRAL combines Q-learning with a consensus-based protocol to ensure that agents converge to a common optimal policy. We evaluate CoRAL in a simulated environment and demonstrate its effectiveness in improving task completion rates and reducing communication overhead compared to existing approaches.