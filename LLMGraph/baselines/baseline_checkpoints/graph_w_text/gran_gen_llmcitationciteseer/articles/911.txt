In complex multi-agent systems, interpretable decision-making is crucial for safety, trust, and accountability. This paper presents HAT-MAD, a novel hierarchical attention network architecture that enables explainable decision-making in multi-agent scenarios. HAT-MAD learns to focus on relevant agents, their relationships, and context-dependent features, generating attention weights that provide insights into the decision-making process. We evaluate HAT-MAD on a variety of multi-agent tasks, demonstrating improved performance and interpretability compared to state-of-the-art baselines.