This paper addresses the problem of distributed task allocation for autonomous agents in dynamic environments. We propose a hierarchical reinforcement learning framework that enables agents to learn task allocation policies in a decentralized manner. The framework consists of a high-level planner that assigns tasks to agents and a low-level executor that adapts to changes in the environment. We evaluate our approach using a simulated search-and-rescue scenario and demonstrate significant improvements in task completion rates and agent utilization compared to traditional methods. Our results have implications for the deployment of autonomous agents in real-world applications.