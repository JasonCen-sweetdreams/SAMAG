In multi-robot systems, task allocation and coordination are critical challenges, particularly in dynamic environments. This paper presents a novel adaptive agent coordination framework, 'DynaAgent', which leverages a decentralized Markov decision process (MDP) to optimize task allocation and resource utilization. DynaAgent utilizes a probabilistic graph model to represent agent capabilities and task dependencies, enabling efficient and flexible coordination. Experimental results on a simulated warehouse scenario demonstrate significant improvements in task completion time and resource utilization compared to existing centralized and decentralized approaches.