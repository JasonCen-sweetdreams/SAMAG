This paper proposes a novel approach to coordinated task allocation for heterogeneous agent teams using deep reinforcement learning. We formulate the task allocation problem as a decentralized, partially observable Markov decision process and develop a hierarchical reinforcement learning framework that leverages both global and local observations. Our approach enables efficient and adaptive task allocation in real-time, even in the presence of uncertain and dynamic task requirements. Experimental results demonstrate significant improvements in team performance and scalability compared to traditional, centralized optimization methods.