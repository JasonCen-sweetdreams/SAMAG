Individuals with severe motor impairments face significant barriers to interacting with digital systems. This paper presents a novel gaze-based HCI system, 'EyeLink', which combines eye-tracking technology with machine learning-based gaze estimation to enable accurate and efficient communication. We evaluate EyeLink with a user study involving 20 participants with severe motor impairments, demonstrating a significant reduction in interaction time and error rate compared to existing gaze-based systems. Our approach has the potential to improve the quality of life for individuals with motor impairments, enabling them to engage more effectively with digital technologies.