In decentralized multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a novel approach that leverages graph convolutional networks (GCNs) to learn task allocation policies. We formulate task allocation as a graph-based optimization problem, where agents are nodes, and tasks are edges. Our GCN-based algorithm, 'AgentGCN', learns to allocate tasks by capturing complex relationships between agents and tasks. Experimental results on a variety of task allocation scenarios demonstrate that AgentGCN outperforms state-of-the-art methods, achieving improved task completion rates and reduced communication overhead.