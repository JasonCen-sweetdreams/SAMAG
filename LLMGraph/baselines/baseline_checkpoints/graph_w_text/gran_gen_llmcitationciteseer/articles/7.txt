Ad-hoc retrieval systems rely heavily on effective query expansion techniques to improve retrieval performance. In this paper, we propose a novel neural query graph embedding approach, dubbed 'NQGE', which learns to represent queries as dense vectors in a high-dimensional space. By leveraging graph convolutional networks and self-attention mechanisms, NQGE captures complex relationships between query terms and their contextual dependencies. Experimental results on several benchmark datasets demonstrate that NQGE outperforms state-of-the-art query expansion methods, achieving significant improvements in mean average precision and normalized discounted cumulative gain.