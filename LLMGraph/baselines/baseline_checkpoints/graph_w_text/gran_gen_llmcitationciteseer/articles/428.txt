As AI systems increasingly influence decision-making, the need for explainable AI (XAI) has become paramount. This paper proposes a novel Hierarchical Attention Network (HAN) architecture for sentiment analysis, which provides interpretable insights into the decision-making process. Our approach leverages both word-level and sentence-level attention to identify key phrases and sentences contributing to the sentiment classification. We evaluate our model on benchmark datasets and demonstrate improved accuracy and explainability compared to state-of-the-art XAI methods. The proposed HAN framework has far-reaching implications for trustworthy AI applications in customer service, marketing, and healthcare.