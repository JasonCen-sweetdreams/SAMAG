This paper addresses the problem of task allocation in multi-agent systems, where agents with varying capabilities and availability need to be assigned to tasks with different priorities and deadlines. We propose a decentralized approach using reinforcement learning, where each agent learns to make allocation decisions based on local observations and communication with neighboring agents. Our algorithm, called MARL-TA, uses a distributed Q-network to learn the optimal allocation policy, which is shown to outperform traditional centralized and heuristic-based methods in simulations with varying task and agent dynamics.