Query expansion (QE) is a crucial technique for improving the effectiveness of ad-hoc retrieval systems. However, traditional QE methods often rely on manual feature engineering and suffer from lexical mismatch issues. This paper proposes a novel neural QE approach, 'NeuroQE', which leverages pre-trained language models to learn dense embeddings for query terms and documents. We introduce a hierarchical attention mechanism that adaptively selects and weights relevant expansion terms based on their semantic relationships with the original query. Experimental results on several benchmark datasets demonstrate that NeuroQE outperforms state-of-the-art QE methods in terms of retrieval accuracy and efficiency.