Autonomous traffic management systems require coordinating multiple heterogeneous agents to optimize traffic flow and reduce congestion. In this paper, we propose a decentralized reinforcement learning framework, 'HATR', that enables agents to learn from their local observations and make coordinated decisions without relying on a centralized controller. HATR uses a novel, graph-based state representation that captures the complex relationships between agents and their environment. We evaluate HATR on a realistic traffic simulation platform and demonstrate significant improvements in traffic throughput and reduced congestion compared to traditional, centralized control methods.