Explainable AI (XAI) is crucial in medical imaging to build trust in AI-driven diagnosis. However, existing XAI methods often incur significant computational overhead. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that efficiently generates interpretable explanations for medical image analysis tasks. HAN leverages a hierarchical attention mechanism to selectively focus on relevant regions and features, reducing the computational cost of explanation generation. We evaluate HAN on a large-scale medical imaging dataset and demonstrate its effectiveness in improving model interpretability while maintaining state-of-the-art performance.