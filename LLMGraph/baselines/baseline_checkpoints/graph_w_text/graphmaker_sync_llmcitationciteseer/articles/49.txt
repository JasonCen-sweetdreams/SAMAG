Autonomous driving has seen significant progress in recent years, but real-world deployment remains challenging due to the complexity and variability of real-world scenarios. This paper introduces a novel graph-based state representation for reinforcement learning in autonomous driving, which captures the structural relationships between various road elements and agents. Our approach, 'GraphDrive', leverages graph neural networks to learn a compact and expressive state representation, improving the sample efficiency and scalability of reinforcement learning algorithms. Experimental results on a large-scale autonomous driving dataset demonstrate that GraphDrive outperforms existing methods in terms of driving safety and efficiency.