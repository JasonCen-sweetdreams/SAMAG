Real-time autonomous driving requires rapid decision-making and adaptability to dynamic environments. This paper introduces a novel hierarchical reinforcement learning framework, 'HRL-AD', which leverages a combination of high-level planning and low-level control to improve navigation efficiency and safety. Our approach decomposes the driving task into a hierarchical structure, where a high-level policy optimizes long-term goals, and a low-level policy executes short-term actions. We demonstrate the effectiveness of HRL-AD in various real-world driving scenarios, achieving significant improvements in task completion rate and reduced latency compared to flat reinforcement learning methods.