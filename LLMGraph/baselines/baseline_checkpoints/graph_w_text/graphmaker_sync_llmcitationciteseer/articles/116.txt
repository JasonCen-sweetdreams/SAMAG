Deep neural networks have achieved state-of-the-art performance in various computer vision tasks, but their lack of transparency and interpretability hinders their adoption in high-stakes applications. This paper proposes a novel hierarchical adversarial learning framework, 'HALO', which generates explainable visual features by leveraging the adversarial relationship between a generator network and a discriminator network. Our approach encourages the generator to produce saliency maps that highlight the most informative regions in an image, leading to improved model interpretability and robustness. We demonstrate the effectiveness of HALO on several benchmark datasets, including ImageNet and COCO.