In multi-agent systems, task allocation is a critical problem that requires efficient and adaptive decision-making. This paper proposes a decentralized task allocation framework that leverages reinforcement learning to optimize agent utility and minimize communication overhead. Our approach, called 'RL-TA', uses a distributed Q-network to learn task allocation policies for each agent, taking into account local observations and partial knowledge of the environment. We evaluate RL-TA in a simulated search-and-rescue scenario and demonstrate significant improvements in task completion time and agent satisfaction compared to traditional auction-based methods.