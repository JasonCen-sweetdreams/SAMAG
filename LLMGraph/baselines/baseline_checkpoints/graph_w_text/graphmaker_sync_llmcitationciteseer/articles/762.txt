In multi-agent systems, cooperative behavior often relies on complex interactions and relationships between agents. However, existing approaches to multi-agent cooperation lack interpretability, making it difficult to understand the decision-making process. This paper proposes a novel hierarchical graph attention network (HGAN) architecture that enables explainable multi-agent cooperation. HGAN integrates graph attention mechanisms to capture agent relationships at multiple scales, allowing for transparent and interpretable cooperation policies. We evaluate HGAN on a range of cooperative tasks, demonstrating improved performance and interpretability compared to state-of-the-art baselines.