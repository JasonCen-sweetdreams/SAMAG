Human-AI collaboration has become increasingly important in various domains, but understanding AI decision-making processes remains a significant challenge. This paper proposes a novel Hierarchical Graph Attention Network (HGAT) framework that enables explainable human-AI collaboration. HGAT captures complex relationships between human and AI agents by learning hierarchical graph representations. We introduce a novel attention mechanism that adaptively weighs the importance of human and AI inputs, facilitating transparent and interpretable decision-making. Experimental results on a real-world healthcare dataset demonstrate that HGAT improves collaboration outcomes while providing insightful explanations for AI-driven decisions.