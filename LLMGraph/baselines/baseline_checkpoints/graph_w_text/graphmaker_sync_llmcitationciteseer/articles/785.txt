As augmented reality (AR) technology becomes increasingly prevalent, there is a growing need for intuitive and natural interaction mechanisms. This paper presents a novel gesture-based interface for AR environments that leverages machine learning-driven gesture recognition. We conducted a user study to evaluate the effectiveness of our approach, which incorporates a combination of hand tracking, skeletal modeling, and gesture classification. The results show significant improvements in user performance and satisfaction compared to traditional controller-based interfaces. We also discuss the implications of our findings for the design of future AR systems.