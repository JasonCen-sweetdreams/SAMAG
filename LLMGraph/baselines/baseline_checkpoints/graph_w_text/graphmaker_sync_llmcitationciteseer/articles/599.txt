Transfer learning has become a de facto standard for deploying deep neural networks in various applications. However, recent studies have shown that these models are vulnerable to adversarial attacks, which can compromise their performance and reliability. This paper proposes a novel adversarial training framework for transfer learning, dubbed 'AdvTune', which leverages the concept of meta-learning to adapt to different attack scenarios. Experimental results on multiple benchmark datasets demonstrate that AdvTune significantly improves the robustness of pre-trained models against various types of adversarial attacks, without sacrificing their original performance.