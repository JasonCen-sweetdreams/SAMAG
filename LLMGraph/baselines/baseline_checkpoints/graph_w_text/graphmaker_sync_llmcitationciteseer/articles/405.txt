This paper presents a decentralized multi-agent reinforcement learning framework for efficient resource allocation in smart grids. We model the problem as a Markov game, where each agent represents a microgrid and learns to optimize its local resource allocation policy while interacting with neighboring agents. We propose a novel algorithm, 'MARL-DR', which combines deep Q-networks with a graph attention mechanism to capture the complex interactions between agents. Experimental results on a simulated smart grid environment demonstrate that MARL-DR outperforms traditional centralized optimization methods and achieves significant reductions in energy losses and costs.