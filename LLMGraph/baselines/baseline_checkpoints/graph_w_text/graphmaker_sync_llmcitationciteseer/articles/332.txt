In multi-agent systems, task allocation is a complex problem that requires efficient and adaptive decision-making. This paper proposes a decentralized reinforcement learning framework for hierarchical task allocation, where agents learn to allocate tasks based on their capabilities and the system's overall objectives. Our approach uses a graph neural network to model agent interactions and a decentralized Q-learning algorithm to optimize task allocation. Experimental results on a simulated robotic search and rescue scenario demonstrate that our approach outperforms traditional centralized methods in terms of task completion rate and system adaptability.