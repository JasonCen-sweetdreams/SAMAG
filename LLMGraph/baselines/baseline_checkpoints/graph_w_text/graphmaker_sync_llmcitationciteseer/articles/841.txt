Neural ranking models have become increasingly popular in information retrieval due to their ability to capture complex semantic relationships between queries and documents. However, their computational overhead can lead to significant latency and resource consumption. This paper proposes a novel query optimization framework, 'NeuroOpt', which leverages pruning and quantization techniques to reduce the computational cost of neural ranking models. We evaluate NeuroOpt on several benchmark datasets and demonstrate significant speedups while maintaining retrieval effectiveness.