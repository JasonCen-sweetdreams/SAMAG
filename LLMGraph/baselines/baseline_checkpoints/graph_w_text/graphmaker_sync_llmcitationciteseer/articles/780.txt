Explainability is crucial for real-world adoption of reinforcement learning (RL) agents. Existing methods often focus on post-hoc explanation or rely on simplified, linear models. We propose a novel hierarchical attention framework, HAT, which integrates explainability into the RL process. HAT uses a hierarchical policy network with attention mechanisms to selectively focus on relevant state features, providing insights into the decision-making process. Our experiments on Atari games and a real-world robotics task demonstrate that HAT achieves competitive performance while providing meaningful explanations of the agent's policy.