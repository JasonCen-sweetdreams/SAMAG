Time-series anomaly detection is a crucial task in various domains, but the lack of interpretability in existing methods hinders their adoption. This paper proposes a novel Hierarchical Attention Network (HAN) architecture that detects anomalies while providing explainable insights into the decision-making process. Our approach leverages self-attention to model temporal dependencies and hierarchical attention to capture local and global patterns. We evaluate HAN on three real-world datasets and demonstrate its superiority over state-of-the-art methods in terms of detection accuracy and interpretability.