Explainable recommendation systems have gained significant attention in recent years. This paper introduces a novel Bayesian graph attention network (BGAT) that leverages both graph structures and attention mechanisms to provide interpretable recommendations. BGAT models user behavior as a probabilistic graph, where attention weights are learned to identify influential items and users. We propose a Bayesian inference approach to capture uncertainty in attention weights, enabling the model to provide personalized explanations for recommended items. Experimental results on several real-world datasets demonstrate the effectiveness of BGAT in improving recommendation performance and providing meaningful explanations.