Sentiment analysis is a crucial task in natural language processing, but existing approaches often rely on manually designed models that are computationally expensive and limited to specific modalities. This paper presents a novel deep neural architecture search framework, 'MultiModalNAS', which automatically discovers efficient and effective architectures for multi-modal sentiment analysis. Our method leverages a hierarchical search space and a novel multi-objective reward function to optimize both accuracy and inference time. Experimental results on a benchmark dataset demonstrate that MultiModalNAS achieves state-of-the-art performance on sentiment analysis tasks while reducing inference time by up to 3.5x compared to existing approaches.