Knowledge graph embedding (KGE) aims to represent entities and relations in a low-dimensional vector space. However, existing methods struggle to capture complex relationships between entities. We propose HierGA, a novel hierarchical graph attention network that learnspatterns at multiple scales. Our approach leverages both entity and relation attention mechanisms to capture multi-relational dependencies. Experimental results on benchmark datasets show that HierGA outperforms state-of-the-art KGE methods, achieving significant improvements in link prediction and triple classification tasks.