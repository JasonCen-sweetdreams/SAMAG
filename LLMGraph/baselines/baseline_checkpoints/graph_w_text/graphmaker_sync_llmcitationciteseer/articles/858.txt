This paper presents a decentralized task allocation framework for swarm robotics using multi-agent reinforcement learning. Our approach, called 'MARLA', enables a team of robots to learn to allocate tasks autonomously in dynamic environments. MARLA combines a decentralized actor-critic architecture with a novel, graph-based communication protocol to facilitate efficient information exchange among robots. We evaluate MARLA on a variety of swarm robotics tasks, including object manipulation and environmental monitoring, and demonstrate significant improvements in task completion time and robot utilization compared to traditional, centralized allocation methods.