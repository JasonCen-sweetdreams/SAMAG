Emotion recognition has become increasingly important in human-computer interaction (HCI). This paper presents EmoSpark, a novel affective state recognition system that leverages electrodermal activity (EDA) and machine learning techniques. We collect EDA signals from 30 participants while they experience various emotional stimuli, and develop a deep neural network that achieves 87.2% accuracy in classifying four emotions: happiness, sadness, fear, and anger. We demonstrate EmoSpark's applicability in HCI scenarios, such as emotion-aware gaming and mental health monitoring, and discuss its implications for designing more empathetic and personalized interfaces.