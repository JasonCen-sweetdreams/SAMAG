Virtual reality (VR) has revolutionized immersive experiences, but its high computational demands often lead to decreased performance and visual quality. This paper presents a novel eye-tracking based adaptive foveated rendering (EFR) technique that optimizes VR rendering by allocating processing resources to the user's gaze direction. We propose a machine learning model that predicts the user's gaze pattern and dynamically adjusts the rendering resolution, resulting in significant performance improvements and reduced computational overhead. Our user study shows that the proposed EFR technique enhances the overall VR user experience, with participants reporting improved visual quality and reduced fatigue.