Voice assistants have become ubiquitous, but their conversational interfaces often exclude users with disabilities. This paper presents a user-centered design approach to create more inclusive voice assistants. We conducted a mixed-methods study with 30 participants with visual, hearing, motor, or cognitive disabilities to identify challenges and opportunities in conversational interactions. Our findings inform the development of adaptive conversational strategies, such as personalized feedback, explicit error handling, and multimodal input support. We evaluate these strategies through a prototype voice assistant and demonstrate significant improvements in user experience and task completion rates.