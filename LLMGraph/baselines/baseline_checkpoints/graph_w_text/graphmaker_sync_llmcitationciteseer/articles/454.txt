This paper presents a novel approach to gesture recognition systems that adapt to the abilities and needs of older adults with cognitive impairments. Our system, called 'Easy Gesture', uses a machine learning-based framework to recognize and interpret gestures from a range of input devices, including cameras, sensors, and wearable devices. We conducted a user study with 20 older adults with cognitive impairments and found that Easy Gesture significantly improved gesture recognition accuracy and reduced user frustration compared to existing systems. Our results have implications for the design of accessible and inclusive human-computer interfaces for older adults.