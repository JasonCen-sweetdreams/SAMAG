This paper explores the design of adaptive haptic feedback systems for multimodal virtual reality (VR) experiences. We propose a novel framework, 'HapSense', which integrates machine learning-based user modeling, haptic rendering, and real-time physiological signal processing. Our approach enables personalized and context-aware haptic feedback that enhances user immersion and engagement in VR applications. A user study involving 30 participants demonstrates significant improvements in presence, spatial awareness, and overall user experience when using HapSense compared to traditional haptic feedback methods.