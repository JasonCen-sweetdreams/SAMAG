We propose a novel framework for distributed task allocation in multi-agent systems, leveraging reinforcement learning with graph attention mechanisms. Our approach, dubbed 'DAGMA', enables agents to learn cooperative strategies for task assignment and execution, while adapting to dynamic network topologies and task dependencies. Experimental results on a range of benchmark scenarios demonstrate that DAGMA outperforms state-of-the-art methods in terms of task completion efficiency, communication overhead, and robustness to agent failures.