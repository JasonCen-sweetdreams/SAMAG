This paper proposes a decentralized task allocation framework for heterogeneous multi-agent systems, where agents with diverse capabilities and constraints need to collaborate to accomplish complex tasks. We develop a novel deep reinforcement learning approach that enables agents to learn cooperative strategies and adapt to changing environmental conditions. Our method, called 'HRL-TA', combines a hierarchical reinforcement learning architecture with a graph neural network to model agent interactions and task dependencies. Experimental results on a simulated robotic search and rescue scenario demonstrate significant improvements in task completion efficiency and robustness compared to traditional optimization-based approaches.