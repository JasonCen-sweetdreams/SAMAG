Cooperative task allocation in dynamic environments is a challenging problem that requires agents to adapt to changing circumstances while coordinating with each other. This paper proposes a decentralized multi-agent reinforcement learning framework, 'DMARL-CTA', which enables agents to learn cooperative policies in a distributed manner. We introduce a novel communication protocol that facilitates information exchange between agents, and a modular neural network architecture that allows agents to update their policies independently. Experimental results on a simulated search-and-rescue scenario demonstrate that DMARL-CTA outperforms existing centralized and decentralized approaches in terms of task completion rate and adaptability to changing environments.