In multi-agent systems, efficient task allocation is crucial for achieving collective goals. This paper proposes a hierarchical reinforcement learning framework for autonomous task allocation, where agents learn to allocate tasks based on their capabilities and environmental constraints. We introduce a novel decomposition method that separates the task allocation problem into two levels: high-level planning and low-level execution. Experimental results on a simulated disaster response scenario show that our approach outperforms traditional centralized allocation methods in terms of task completion rate and agent utilization.