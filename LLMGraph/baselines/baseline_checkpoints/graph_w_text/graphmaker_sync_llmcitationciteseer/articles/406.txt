Distributed databases have become increasingly popular in modern data-intensive applications, but optimizing queries across multiple nodes remains a challenging problem. This paper proposes a novel approach to query optimization using reinforcement learning (RL). We design an RL agent that learns to navigate the vast space of possible query plans and identifies near-optimal solutions. Our approach leverages a domain-specific reward function that balances query latency, resource utilization, and data freshness. Experimental results on a real-world distributed database system demonstrate that our RL-based optimizer outperforms traditional rule-based approaches by up to 30% in terms of query execution time.