Deep reinforcement learning (DRL) has achieved remarkable success in various domains, but the lack of transparency in learned policies hinders trust and understanding. This paper proposes a novel hierarchical attention mechanism, 'HAX', which generates explanations for DRL policies. HAX recursively decomposes the policy into attention weights, highlighting the most relevant states, actions, and features contributing to the decision-making process. We demonstrate the effectiveness of HAX on several Atari games and a real-world robotics task, showcasing its ability to provide insightful explanations, improve policy interpretation, and facilitate policy improvement through human-in-the-loop feedback.