Graph neural networks (GNNs) have shown great potential in node classification tasks. However, in many real-world scenarios, labeled data is scarce and expensive to obtain. This paper proposes a Hierarchical Graph Attention Network (HGAT) that leverages both local and global graph structures to improve node classification performance with limited labels. HGAT employs a hierarchical attention mechanism that adaptively selects relevant nodes and layers to aggregate features. Our experiments on four benchmark datasets demonstrate that HGAT outperforms state-of-the-art GNNs and attention-based models in low-label settings, with significant improvements in accuracy and F1-score.