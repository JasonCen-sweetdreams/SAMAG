Virtual reality (VR) technology has the potential to revolutionize accessibility, but current gesture recognition systems often struggle with users who have motor impairments. This paper presents 'AdaptaGest', a machine learning-based framework that adapts to individual users' abilities and preferences in real-time. Our approach leverages a novel combination of computer vision, machine learning, and HCI principles to recognize gestures from a diverse range of users, including those with disabilities. Results from a user study show that AdaptaGest significantly improves gesture recognition accuracy and user experience for participants with motor impairments, enabling more inclusive and accessible VR interactions.