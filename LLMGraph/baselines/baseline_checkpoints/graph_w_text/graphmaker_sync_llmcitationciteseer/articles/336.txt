In dynamic environments, autonomous agents must adapt to changing task requirements and allocate resources efficiently. We propose a hierarchical reinforcement learning framework, 'HRL-ATA', that enables agents to coordinate and allocate tasks in real-time. HRL-ATA combines a high-level planning module with a low-level execution module, allowing agents to balance exploration and exploitation in complex task spaces. Our experiments demonstrate that HRL-ATA outperforms state-of-the-art methods in dynamic task allocation scenarios, such as disaster response and autonomous warehouse management.