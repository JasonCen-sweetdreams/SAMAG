Traditional learning-to-rank approaches in information retrieval (IR) suffer from high computational costs and limited scalability. This paper proposes a novel hierarchical neural ranking model, 'HierRank', which integrates a coarse-grained document filtering stage with a fine-grained ranking stage. We employ a hierarchical attention mechanism to selectively focus on relevant document regions and reduce the dimensionality of the input space. Experimental results on the TREC Deep Learning Track dataset demonstrate that HierRank achieves state-of-the-art retrieval performance while reducing computational costs by up to 60% compared to existing neural ranking models.