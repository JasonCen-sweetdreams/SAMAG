Graph neural networks (GNNs) have achieved state-of-the-art performance in node classification tasks, but their scalability is limited by the computation and memory requirements of attention mechanisms. This paper proposes a novel hierarchical graph attention network (HGAN) that leverages a hierarchical representation of the graph to reduce the attention complexity. HGAN incorporates a node clustering step to group similar nodes, followed by a hierarchical attention mechanism that learns to focus on relevant clusters and nodes. Experimental results on large-scale graph datasets demonstrate that HGAN achieves comparable accuracy to state-of-the-art GNNs while reducing the computational cost by up to 75%.