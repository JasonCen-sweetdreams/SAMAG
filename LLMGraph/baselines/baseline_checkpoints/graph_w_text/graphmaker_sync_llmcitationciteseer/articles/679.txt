This paper introduces a novel hierarchical attention-based knowledge graph embedding (HAKGE) method for multi-label classification tasks. Our approach leverages the structural information in knowledge graphs to learn entity and relation embeddings, which are then integrated with a hierarchical attention mechanism to capture complex semantic dependencies between entities. Experimental results on real-world datasets demonstrate that HAKGE outperforms state-of-the-art methods in multi-label classification, particularly in scenarios with limited training data. Our approach has potential applications in natural language processing, question answering, and recommender systems.