The increasing adoption of autonomous vehicles on public roads necessitates the development of efficient coordination mechanisms to ensure safe and efficient traffic flow. This paper proposes a novel multi-agent reinforcement learning framework, 'AV-Coor', which enables autonomous vehicles to learn cooperative behaviors in complex traffic scenarios. AV-Coor utilizes a decentralized, graph-structured neural network to model the interactions among vehicles and the environment, and demonstrates improved traffic throughput and reduced congestion compared to traditional rule-based approaches in simulated experiments.