Open-domain question answering (ODQA) models rely on passage retrieval to gather relevant information for answering user queries. However, the retrieval stage often suffers from vocabulary mismatch and semantic ambiguity, leading to suboptimal performance. This paper proposes a deep query expansion (DQE) framework that leverages a combination of semantic and syntactic analysis to generate high-quality, context-aware query expansions. Our experiments on the Natural Questions dataset demonstrate that DQE improves passage retrieval accuracy by 12.3% and boosts overall ODQA performance by 7.5% compared to state-of-the-art baselines.