Ad-hoc search systems struggle to efficiently retrieve relevant documents from large corpora, particularly when dealing with short queries. This paper introduces HierDoc, a novel document representation technique that leverages hierarchical embeddings to capture both local and global semantic relationships. By encoding documents as hierarchical compositions of sentence and paragraph embeddings, HierDoc enables more effective pruning of irrelevant documents and reduces the number of required similarity computations. Experiments on several benchmark datasets demonstrate that HierDoc outperforms state-of-the-art retrieval methods in terms of mean average precision and query throughput.