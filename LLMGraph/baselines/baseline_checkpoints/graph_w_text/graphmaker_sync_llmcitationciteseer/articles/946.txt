Few-shot learning has garnered significant attention in recent years, but most existing approaches rely on transductive settings or require extensive retraining for new tasks. This paper presents a novel hierarchical graph attention network (HGAT) that enables inductive few-shot learning. HGAT leverages task-agnostic graph representations and attention mechanisms to adapt to novel tasks with limited labeled data. Our experiments on benchmark datasets demonstrate that HGAT outperforms state-of-the-art methods in both few-shot and zero-shot settings, while requiring minimal additional training data.