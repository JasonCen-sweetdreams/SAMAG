Multi-agent systems (MAS) often face challenges in coordinating actions to achieve common goals, particularly in resource-constrained environments. This paper presents a decentralized reinforcement learning (DRL) framework for coordinating MAS in resource allocation tasks. Our approach, called 'DRL-MA', enables agents to learn cooperative policies through localized interactions and asynchronous updates. We evaluate DRL-MA in a simulated grid-world environment and demonstrate its ability to adapt to changing resource availability and agent behaviors, outperforming traditional centralized and heuristic-based approaches.