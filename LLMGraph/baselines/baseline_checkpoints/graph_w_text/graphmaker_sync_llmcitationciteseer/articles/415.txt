This paper addresses the problem of decentralized task allocation in multi-agent systems, where agents with limited communication ranges need to collectively accomplish tasks in a dynamic environment. We propose a novel approach that leverages graph neural networks (GNNs) to learn a distributed task allocation policy. Our method, called GNN-TA, uses a decentralized GNN architecture to learn a latent representation of the agent-task graph, enabling agents to make allocation decisions based on local information. Experimental results on a variety of task allocation scenarios demonstrate that GNN-TA outperforms existing decentralized methods in terms of task completion rate and communication efficiency.