This paper proposes a novel hierarchical task decomposition framework for multi-agent planning in dynamic environments. Our approach, called HTD-MA, leverages a two-layered abstraction to efficiently reason about complex tasks and adapt to changing environmental conditions. The top layer represents high-level goals and subgoals, while the bottom layer focuses on low-level action planning. We introduce a probabilistic reasoning mechanism to handle uncertainty and a hierarchical reinforcement learning algorithm to optimize task execution. Experimental results demonstrate that HTD-MA outperforms state-of-the-art multi-agent planning methods in terms of task completion rate, adaptability, and communication efficiency.