Deep neural networks have been shown to be vulnerable to adversarial attacks, which can compromise their performance in critical applications. This paper proposes a novel approach to robustify DNNs against such attacks using Bayesian neural networks (BNNs). We leverage the probabilistic nature of BNNs to model uncertainty and develop a new defense mechanism that adapts to the variability of input data. Our experiments on multiple benchmark datasets demonstrate that the proposed approach significantly improves the robustness of DNNs against various types of adversarial attacks, including white-box and black-box attacks.