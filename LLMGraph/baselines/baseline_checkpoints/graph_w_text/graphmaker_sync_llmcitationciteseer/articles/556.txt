In multi-agent systems, efficient task allocation is crucial for achieving global objectives. This paper presents a decentralized task allocation framework, 'MA-RL', that leverages reinforcement learning to enable agents to adapt to dynamic environments and learn optimal task assignments. We formulate the task allocation problem as a Markov decision process and propose a novel action-critic algorithm that incorporates both local and global reward functions. Experimental results on a simulated robotic swarm demonstrate that MA-RL outperforms traditional auction-based approaches in terms of task completion rate and overall system efficiency.