Voice assistants have become ubiquitous, but their adoption by older adults is hindered by accessibility barriers. This paper presents a multimodal approach to enhance the inclusivity of voice assistants for older adults, incorporating both speech and gesture-based input. We propose a novel framework, 'AccessibleVA', which leverages machine learning and computer vision to recognize and interpret gestures, and integrates them with speech recognition to improve overall system accuracy. Our user study with 30 older adults demonstrates that AccessibleVA significantly improves task completion rates and user satisfaction compared to traditional speech-only interfaces.