In this paper, we propose a decentralized task allocation framework for autonomous agents using multi-agent reinforcement learning. Our approach, called 'AgentTA', enables agents to learn to allocate tasks efficiently in a decentralized manner without requiring a centralized coordinator. We model the task allocation problem as a Markov game and employ a novel variant of the Q-learning algorithm, which incorporates a reward function that encourages cooperation among agents. Experimental results on a simulated logistics scenario demonstrate that AgentTA outperforms traditional centralized task allocation methods in terms of task completion time and resource utilization.