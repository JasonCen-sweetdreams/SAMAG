The proliferation of autonomous vehicles (AVs) on urban roads necessitates efficient coordination mechanisms to optimize traffic flow and safety. This paper proposes a decentralized multi-agent reinforcement learning framework, 'CoAV', which enables AVs to learn cooperative strategies in real-time. We employ a graph neural network to model AV interactions and develop a novel attention-based approach to handle partial observability. Simulation results in a realistic urban setting demonstrate that CoAV reduces congestion by 23% and collision rates by 41% compared to traditional rule-based AV controllers.