In multi-agent systems, task allocation is a crucial problem that requires efficient coordination to achieve optimal performance. This paper proposes a novel approach that leverages reinforcement learning to dynamically allocate tasks to agents in a decentralized manner. We design a hierarchical framework where agents learn to estimate task rewards and costs, and a coordinator agent makes allocation decisions based on these estimates. Experimental results on a simulated logistics scenario demonstrate that our approach outperforms traditional methods in terms of task completion time and agent utilization, and is robust to changes in task arrival rates and agent availability.