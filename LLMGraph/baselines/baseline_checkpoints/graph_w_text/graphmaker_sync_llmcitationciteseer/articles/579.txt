Cooperative multi-agent systems often require efficient task allocation strategies to maximize overall performance. This paper presents a decentralized task allocation framework that leverages multi-armed bandit (MAB) algorithms to adaptively assign tasks to agents. We introduce a novel MAB variant, 'Coop-UCB', which incorporates agent-to-agent communication to share knowledge and reduce exploration-exploitation tradeoffs. Experimental results on a simulated search-and-rescue scenario demonstrate that Coop-UCB achieves significant improvements in task completion rates and overall system efficiency compared to existing decentralized task allocation methods.