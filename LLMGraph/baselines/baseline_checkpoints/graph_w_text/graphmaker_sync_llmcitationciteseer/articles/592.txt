Cooperative object transport tasks, where multiple agents work together to transport large objects, are challenging due to the need for coordination and communication. This paper proposes a decentralized multi-agent reinforcement learning framework, 'CAT', which enables agents to learn cooperative policies without explicit communication. We introduce a novel graph-based representation that captures the agents' spatial relationships and a reward function that promotes cooperation. Experimental results on a simulated object transport domain demonstrate that CAT outperforms state-of-the-art methods in terms of task completion time and success rate.