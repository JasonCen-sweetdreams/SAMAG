This paper presents a novel approach to coordinating autonomous agents for urban traffic management using hierarchical reinforcement learning. We propose a two-level framework, where high-level agents learn to optimize traffic signal control policies, while low-level agents adapt to real-time traffic conditions using deep Q-networks. Our approach leverages graph neural networks to model traffic dynamics and incorporates domain knowledge to improve the coordination of agents. Experimental results on a simulated urban traffic network demonstrate a significant reduction in travel times and increased traffic flow compared to traditional control methods.