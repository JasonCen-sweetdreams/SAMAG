As robots increasingly interact with humans in various settings, understanding human emotions is crucial for effective collaboration. This paper proposes a novel Hierarchical Attention Network (HAN) architecture for emotion recognition in human-robot interaction. Our HAN model utilizes a multi-level attention mechanism to selectively focus on relevant facial features, speech patterns, and context-aware cues. Experimental results on a large-scale emotional intelligence dataset demonstrate that our approach significantly outperforms state-of-the-art methods in recognizing complex emotions, such as empathy and frustration, in real-time human-robot interactions.