Real-time human activity recognition is crucial in various applications, including healthcare, surveillance, and human-computer interaction. This paper presents a novel attention-based neural network architecture, 'ActAttn', which leverages hierarchical attention mechanisms to focus on relevant spatio-temporal features in sensor data. We propose a scalable and interpretable approach to model complex activity patterns, achieving state-of-the-art performance on three benchmark datasets. Our approach is computationally efficient, allowing for real-time processing on edge devices, and provides insights into the decision-making process through attention visualization.