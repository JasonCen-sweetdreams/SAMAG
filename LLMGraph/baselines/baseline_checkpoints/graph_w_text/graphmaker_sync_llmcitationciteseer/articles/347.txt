Deep reinforcement learning (DRL) has achieved remarkable success in complex decision-making tasks, but the lack of interpretability hinders its adoption in high-stakes applications. This paper proposes a novel hierarchical attention network (HAN) architecture that incorporates both spatial and temporal attention mechanisms to provide insights into the decision-making process. We evaluate our approach on a suite of Atari games and demonstrate improved interpretability without compromising performance. Furthermore, we introduce a novel explainability metric, 'attention flow,' which quantifies the contribution of each attention module to the final policy.