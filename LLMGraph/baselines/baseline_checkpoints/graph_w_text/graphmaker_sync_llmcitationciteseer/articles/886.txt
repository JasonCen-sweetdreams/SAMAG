Explainability is crucial in multi-agent reinforcement learning (MARL) systems, where agents interact with each other and their environment. This paper proposes a novel hierarchical attention network (HAN) framework, which enables agents to selectively focus on relevant information when making decisions. Our HAN architecture consists of two levels of attention: an intra-agent attention mechanism that models individual agent behaviors, and an inter-agent attention mechanism that captures complex interactions between agents. We evaluate our approach on a variety of MARL benchmarks, demonstrating improved performance and interpretability compared to state-of-the-art methods.