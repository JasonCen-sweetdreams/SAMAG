This paper presents a novel approach to personalized gesture recognition using hierarchical temporal convolutional networks (HTCNs). Our method leverages the strengths of both convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to model the complex temporal dependencies in gesture data. We propose a hierarchical architecture that captures local and global patterns in gestures, allowing for robust recognition of personalized gestures. Experimental results on the popular Gesture Phase Segmentation dataset demonstrate that our approach outperforms state-of-the-art methods in both accuracy and efficiency.