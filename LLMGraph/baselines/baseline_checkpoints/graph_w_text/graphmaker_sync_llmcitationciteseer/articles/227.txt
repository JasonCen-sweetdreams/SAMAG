As autonomous systems increasingly rely on deep reinforcement learning (DRL) for decision-making, transparency and accountability become crucial. This paper proposes 'TreeX', a novel model-agnostic explainability framework for DRL. TreeX leverages hierarchical feature importance and sparse attention mechanisms to provide interpretable explanations for agent decisions. We evaluate TreeX on a suite of benchmarks, demonstrating improved explainability without compromising policy performance. Furthermore, we provide theoretical guarantees for the fidelity of TreeX explanations, facilitating trustworthiness in high-stakes applications.