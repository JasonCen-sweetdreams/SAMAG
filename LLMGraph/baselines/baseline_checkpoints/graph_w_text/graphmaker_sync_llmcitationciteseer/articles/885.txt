Autonomous vehicles require the ability to perform multiple tasks simultaneously, such as lane following, obstacle avoidance, and speed control. This paper presents a novel multi-task deep reinforcement learning framework, 'MTDRL', which enables a single neural network to learn multiple tasks in a shared environment. We introduce a task-conditioned policy gradient method that adapts to changing task priorities and demonstrate improved performance on a realistic autonomous driving simulator. Experimental results show that MTDRL outperforms single-task and multi-agent baselines in complex urban scenarios.